{"config":{"lang":["es"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>01.-KVM</p> <p>02.-SSH</p> <p>03.-DHCP</p>"},{"location":"01.-KVM/","title":"Index","text":"<p>Las m\u00e1quinas virtuales basadas en el kernel (KVM) son una tecnolog\u00eda de virtualizaci\u00f3n open source integrada a Linux\u00ae. Con ellas, se puede transformar Linux en un hipervisor que permite que una m\u00e1quina host ejecute varios entornos virtuales aislados llamados m\u00e1quinas virtuales (VM) o guests.</p> <p>Las KVM forman parte de Linux. Por eso, si se cuenta con una versi\u00f3n de Linux 2.6.20 o posterior, ya est\u00e1n a nuestra a su disposici\u00f3n. Se anunciaron por primera vez en 2006, y un a\u00f1o despu\u00e9s se incorporaron a la versi\u00f3n principal del kernel de Linux. Dado que forman parte del c\u00f3digo actual de Linux, reciben inmediatamente todas las mejoras, las correcciones y las funciones nuevas de este  sistema, sin requerir ning\u00fan tipo de ingenier\u00eda adicional.</p> <p></p>"},{"location":"01.-KVM/01.-Introducci%C3%B3n/01.-%C2%BFQu%C3%A9%20es%20la%20virtualizaci%C3%B3n%3F/","title":"01.-\u00bfQu\u00e9 es la virtualizaci\u00f3n?","text":"<p>Seg\u00fan la Wikipedia: La virtualizaci\u00f3n utiliza el software para imitar las caracter\u00edsticas del hardware y crear un sistema inform\u00e1tico virtual.</p> <p>Esto nos permite ejecutar m\u00e1s de un sistema virtual, y m\u00faltiples sistemas operativos y aplicaciones, en un solo servidor, aumentando el rendimiento del hardware disponible e incrementando el tiempo de procesamiento de un equipo, ya que habitualmente se desaprovecha gran parte.</p>"},{"location":"01.-KVM/01.-Introducci%C3%B3n/01.-%C2%BFQu%C3%A9%20es%20la%20virtualizaci%C3%B3n%3F/#para-que-se-utiliza-la-virtualizacion","title":"\u00bfPara qu\u00e9 se utiliza la virtualizaci\u00f3n?","text":"<ul> <li>Aislamiento e independencia de servicios y contenidos.</li> <li>Laboratorio de pruebas.</li> <li>Virtualizaci\u00f3n de arquitecturas de las que no se dispone.</li> <li>Creaci\u00f3n de cl\u00faster de m\u00e1quinas y sistemas distribuidos.</li> <li>Herramientas de aprendizajes</li> </ul>"},{"location":"01.-KVM/01.-Introducci%C3%B3n/01.-%C2%BFQu%C3%A9%20es%20la%20virtualizaci%C3%B3n%3F/#ventajas-e-inconvenientes-de-la-virtualizacion","title":"Ventajas e inconvenientes de la virtualizaci\u00f3n","text":"<p>Las principales ventajas que podemos indicar ser\u00edan:</p> <ul> <li>Importante ahorro econ\u00f3mico.</li> <li>Seguridad.</li> <li>Mayor aprovechamiento de recursos.</li> <li>Migraci\u00f3n en vivo. </li> <li>Importante ahorro energ\u00e9tico.</li> </ul> <p>Como desventajas podr\u00edamos se\u00f1alar:</p> <ul> <li>Muchos sistemas dependen de un s\u00f3lo equipo f\u00edsico.</li> <li>Penalizaciones en rendimiento.</li> </ul>"},{"location":"01.-KVM/01.-Introducci%C3%B3n/01.-%C2%BFQu%C3%A9%20es%20la%20virtualizaci%C3%B3n%3F/#conceptos-de-virtualizacion","title":"Conceptos de virtualizaci\u00f3n","text":"<ul> <li>Al sistema operativo que ejecuta el software de virtualizaci\u00f3n se le conoce como anfitri\u00f3n (host). El anfitri\u00f3n controla el hardware real.</li> <li>Al sistema operativo virtualizado se le conoce como invitado o hu\u00e9sped (guest).</li> <li>Al software de virtualizaci\u00f3n se le suele llamar Hipervisor.</li> <li>Desde 2005, Intel y AMD han a\u00f1adido soporte hardware para la virtualizaci\u00f3n: Intel Virtualization Technology (VT) y AMD Virtualization (AMD-V), y permiten a los hipervisores un rendimiento mayor en su labor de virtualizar.</li> </ul>"},{"location":"01.-KVM/01.-Introducci%C3%B3n/02.-Tipos/","title":"02.-Tipos","text":"<p>En el punto anterior aprendimos que un Hipervisor es el software que nos permite realizar la virtualizaci\u00f3n. Seg\u00fan como funcione el Hipervisor podemos clasificar distintas t\u00e9cnicas de virtualizaci\u00f3n:</p>"},{"location":"01.-KVM/01.-Introducci%C3%B3n/02.-Tipos/#emulacion","title":"Emulaci\u00f3n","text":"<p>El hipervisor imita o suplanta v\u00eda software una arquitectura al completo (procesador, memoria, conjunto de instrucciones, comunicaciones...). De esta forma puede hacer creer a los programas y sistemas operativos dise\u00f1ados para una arquitectura concreta que son ejecutados sobre ella. La emulaci\u00f3n suele ofrecer un rendimiento bastante bajo debido a que hay que realizar un proceso completo de traducci\u00f3n. Ejemplo: QEMU, Microsoft Virtual PC, Wine, ...</p> <p></p>"},{"location":"01.-KVM/01.-Introducci%C3%B3n/02.-Tipos/#virtualizacion-completa-o-por-hardware","title":"Virtualizaci\u00f3n completa o por hardware","text":"<p>El hipervisor simula un hardware suficiente para permitir que un sistema operativo no adaptado se ejecute de forma aislada. En este caso podemos hacer una subdivisi\u00f3n seg\u00fan el tipo de hipervisor que estemos utilizando:</p> <ul> <li> <p>Virtualizaci\u00f3n por hardware: En este caso usamos hipervisores de tipo 1, que controlan directamente el hardware f\u00edsico del host ofreci\u00e9ndolo directamente a la m\u00e1quina virtual. Es imprescindible que la CPU del host tenga las extensiones de virtualizaci\u00f3n. Ejemplos: Xen, Kernel-based Virtual Machine (KVM), Microsoft Hyper-V, VMware ESXi,...</p> <p></p> </li> <li> <p>Virtualizaci\u00f3n completa: En este tipo se usan hipervisores de tipo 2. Este software se instala sobre el sistema operativo del host, pero no controla directamente el hardware f\u00edsico. Ofrecen menos rendimiento que la virtualizaci\u00f3n por hardware. Ejemplos: VMware Workstation, Parallels Desktop, VirtualBox, VMware Player, ...</p> <p></p> </li> </ul>"},{"location":"01.-KVM/01.-Introducci%C3%B3n/02.-Tipos/#virtualizacion-parcial-o-paravirtualizacion","title":"Virtualizaci\u00f3n parcial o paravirtualizaci\u00f3n","text":"<p>El hipervisor ofrece un interfaz especial para acceder a los recursos. En ocasiones, es necesario la adaptaci\u00f3n del sistema operativo de la m\u00e1quina virtual. Ofrecen el m\u00e1ximo rendimiento, pero no se pueden usar sistemas operativos sin modificaciones o hardware especifico. Ejemplos: XEN, Microsoft Hyper-V, VMware ESXi, ...</p> <p></p>"},{"location":"01.-KVM/01.-Introducci%C3%B3n/02.-Tipos/#virtualizacion-ligera","title":"Virtualizaci\u00f3n ligera","text":"<p>O tambi\u00e9n llamada virtualizaci\u00f3n a nivel de sistema operativo, o virtualizaci\u00f3n basada en contenedores. Es un m\u00e9todo de virtualizaci\u00f3n en el que, sobre el n\u00facleo del sistema operativo se ejecuta una capa de virtualizaci\u00f3n que permite que existan m\u00faltiples instancias aisladas de espacios de usuario. A cada espacio de usuario aislado lo llamamos contenedor. Por lo tanto, un contenedor es un conjunto de procesos aislados, que se ejecutan en un servidor, y que acceden a un sistema de ficheros propio, tienen una configuraci\u00f3n red propio y accede a los recursos del host (memoria y CPU). Podemos hacer la siguiente clasificaci\u00f3n de contenedores:</p> <ul> <li>Contenedores de Sistemas: El uso que se hace de ellos es muy similar al que hacemos sobre una m\u00e1quina virtual: se accede a ellos (normalmente por ssh), se instalan servicios, se actualizan, ejecutan un conjunto de procesos, ... Ejemplo: LXC(Linux Container).</li> <li>Contenedores de Aplicaci\u00f3n: Se suelen usar para el despliegue de aplicaciones web Ejemplo: Docker, Podman, ...</li> </ul> <p></p>"},{"location":"01.-KVM/01.-Introducci%C3%B3n/03.-qemu-kvm/","title":"03.-qemu-kvm","text":"<p>De acuerdo con la wiki de QEMU, \"QEMU es un emulador gen\u00e9rico y de c\u00f3digo abierto de m\u00e1quinas virtuales.\". Se puede usar como emulador, permitiendo ejecutar sistemas operativos de una determinada arquitectura (por ejemplo ARM) sobre otra arquitectura (por ejemplo amd64). Pero tambi\u00e9n, puede ofrecer una soluci\u00f3n de virtualizaci\u00f3n completa, usando hipervidores como KVM para utilizar las extensiones del procesador para la virtualizaci\u00f3n y ofrecer un rendimiento mayor.</p> <p>KVM, la Maquina virtual basada en el kernel (Kernel-based Virtual Machine), es un hipervisor de tipo 1 integrado al kernel de Linux. Es una soluci\u00f3n de virtualizaci\u00f3n completa para Linux, que contienen las extensiones de virtualizaci\u00f3n Intel VT o AMD-V. Se compone de un m\u00f3dulo del kernel <code>kvm.ko</code>, que provee la infraestructura de virtualizaci\u00f3n base, y un m\u00f3dulo espec\u00edfico para el tipo de procesador, <code>kvm-intel.ko</code> o <code>kvm-amd.ko</code>.</p> <p>Por lo tanto, podemos usar QEMU junto a KVM para permitir la ejecuci\u00f3n de m\u00e1quinas virtuales utilizando im\u00e1genes de disco que contienen sistemas operativos sin modificar. Cada m\u00e1quina virtual tiene su propio hardware virtualizado: una tarjeta de red, discos duros, tarjeta gr\u00e1fica, ...</p>"},{"location":"01.-KVM/01.-Introducci%C3%B3n/03.-qemu-kvm/#dispositivos-paravirtualizados","title":"Dispositivos paravirtualizados","text":"<p>Al crear las m\u00e1quinas virtuales, adem\u00e1s de las caracter\u00edsticas b\u00e1sicas como la cantidad de RAM asignada, el espacio de almacenamiento o la CPU, se deben seleccionar los diferentes dispositivos que van a formar parte de ella: interfaz de red, controladores de disco duro, interfaz gr\u00e1fica, etc. En un sistema de virtualizaci\u00f3n completa como QEMU/KVM todos los dispositivos est\u00e1n inicialmente emulados por software, de manera que la m\u00e1quina virtual interact\u00faa con un dispositivo como si lo hiciera con uno f\u00edsico equivalente. De esta manera podemos encontrar una interfaz de red emulando a la cl\u00e1sica tarjeta de red Realtek 8139 o una interfaz IDE para conectar con un disco duro virtual. Estos dispositivos emulados tienen la ventaja de que pueden utilizar los controladores de dispositivos de sus equivalentes f\u00edsicos, por lo que se suelen utilizar dispositivos emulados muy comunes, que proporcionan compatibilidad con la mayor\u00eda de sistemas operativos y hacen muy sencilla la instalaci\u00f3n de los mismos dentro de una m\u00e1quina virtual. Sin embargo, tienen un inconveniente y es que cuando son dispositivos muy usados, tienen un rendimiento pobre, aumentan el consumo de recursos de la CPU y aumentan la latencia de E/S.</p> <p>El proyecto KVM proporciona una alternativa al uso de dispositivos emulados, que se conocen como dispositivos paravirtualizados y se engloban bajo la denominaci\u00f3n virtIO. El nombre de dispositivos paravirtualizados hace referencia a la t\u00e9cnica que utilizan, m\u00e1s cercana a la paravirtualizaci\u00f3n y que proporciona un rendimiento muy cercano al real, por lo que es muy recomendable utilizar dispositivos virtIO en los dispositivos de E/S que consumen m\u00e1s recursos, por ejemplo, la red y el acceso a discos duros. El \u00fanico inconveniente que tiene utilizar dispositivos virtIO es que son espec\u00edficos para KVM y no todos los sistemas operativos los reconocen por defecto. Evidentemente los sistemas linux s\u00ed reconocen los dispositivos virtIO y en ese caso siempre es recomendable usarlos, pero otros sistemas operativos, como por ejemplo Windows, no incluyen inicialmente soporte virtio, si queremos usarlos en ese caso, ser\u00e1 necesario instalar los controladores de dispositivos durante la instalaci\u00f3n del sistema operativo de la m\u00e1quina virtual.</p>"},{"location":"01.-KVM/01.-Introducci%C3%B3n/03.-qemu-kvm/#libvirt-una-api-de-virtualizacion","title":"libvirt: una API de virtualizaci\u00f3n","text":"<p>Normalmente no trabajamos directamente con las aplicaciones ofrecidas por QEMU/KVM para la gesti\u00f3n de recursos virtualizados. Es m\u00e1s f\u00e1cil usar libvirt, una API intermedia que nos facilita la comunicaci\u00f3n con QEMU/KVM.</p> <p>\u00cdndice</p>"},{"location":"01.-KVM/01.-Introducci%C3%B3n/04.-libvirt/","title":"04.-libvirt","text":"<p>libvirt proporciona una API gen\u00e9rica, un demonio y un conjunto de herramientas de gesti\u00f3n para diferentes sistemas de virtualizaci\u00f3n, en particular los sistemas de virtualizaci\u00f3n nativos de linux: KVM, LXC o Xen. Tambi\u00e9n es posible,  manejar a trav\u00e9s de libvirt otros sistemas de virtualizaci\u00f3n como VMware ESXi o Hyper-V.</p>"},{"location":"01.-KVM/01.-Introducci%C3%B3n/04.-libvirt/#mecanismos-de-conexion","title":"Mecanismos de conexi\u00f3n","text":"<p>libvirt proporciona varios mecanismos para conectarse a un hipervisor Qemu/KVM, tanto de forma local como remota, los que veremos en este curso son:</p>"},{"location":"01.-KVM/01.-Introducci%C3%B3n/04.-libvirt/#acceso-local-con-un-usuario-no-privilegiado","title":"Acceso local con un usuario no privilegiado","text":"<p>Nos conectamos a la URI <code>qemu:///session</code>. Se acceden a las m\u00e1quinas virtuales de ese usuario. En este modo de conexi\u00f3n, el usuario no suele tener permisos para crear conexiones de red, por lo que se limita su uso de la red no privilegiada de qemu (SLIRP) que es \u00fatil para casos simples, pero que tiene bajo rendimiento y es poco configurable. </p>"},{"location":"01.-KVM/01.-Introducci%C3%B3n/04.-libvirt/#acceso-local-privilegiado","title":"Acceso local privilegiado","text":"<p>Nos conectamos a la URI <code>qemu:///system</code>. Se acceden a las m\u00e1quinas virtuales del sistema. Por las limitaciones vistas anteriormente en el acceso local con usuarios no privilegiados, se utiliza la conexi\u00f3n <code>qemu:///system</code>, que es \u00fanica para todo el sistema y que puede utilizar tanto el usuario <code>root</code> como cualquier miembro del grupo <code>libvirt</code>.</p>"},{"location":"01.-KVM/01.-Introducci%C3%B3n/04.-libvirt/#acceso-remoto-privilegiado-por-ssh","title":"Acceso remoto privilegiado por ssh","text":"<p>Nos conectamos a la URI <code>qemu+ssh:///system</code>. En las conexiones citadas anteriormente nos conectamos a un socket linux <code>/var/run/libvirt/libvirt-sock</code>. A este socket tambi\u00e9n nos podemos conectar a trav\u00e9s de un t\u00fanel ssh (qemu+ssh).</p>"},{"location":"01.-KVM/01.-Introducci%C3%B3n/04.-libvirt/#aplicaciones-para-usar-libvirt","title":"Aplicaciones para usar libvirt","text":"<p>libvirt proporciona una API que puede ser utilizada por diferentes aplicaciones (CLI, GUI o web). Podemos destacar algunas que vamos a utilizar en este curso:</p> <ul> <li>virsh: Es el cliente por l\u00ednea de comandos \"oficial\" de libvirt. Ofrece una shell completa para el manejo de la API.</li> <li>virt-manager: Es una aplicaci\u00f3n gr\u00e1fica (GUI) que nos proporciona muchas de las funcionalidades para trabajar con libvirt.</li> <li>virtinst: Paquete que proporciona los comandos <code>virt-clone</code>, <code>virt-install</code> y <code>virt-xml</code> \u00fatiles para crear y copiar m\u00e1quinas virtuales.</li> <li>virt-viewer: Programa que nos permite acceder a a la consola gr\u00e1fica de una m\u00e1quina virtual.</li> <li>gnome-boxes: Aplicaci\u00f3n gr\u00e1fica muy simple, que utilizando el acceso local con usuario no privilegiado, nos permite gestionar, de forma sencilla, m\u00e1quinas virtuales.</li> </ul> <p>Cuando cualquier aplicaci\u00f3n se conecta a libvirt (con cualquiera de los m\u00e9todos que hemos estudiado) el formato de la informaci\u00f3n que se intercambian a trav\u00e9s de la API es XML. Puedes encontrar la definici\u00f3n de este formato en la documentaci\u00f3n oficial: XML Format.</p> <p>\u00cdndice</p>"},{"location":"01.-KVM/01.-Introducci%C3%B3n/05.-LXC/","title":"05.-LXC","text":"<p>LinuX Containers, tambi\u00e9n conocido por el acr\u00f3nimo LXC, es una tecnolog\u00eda de virtualizaci\u00f3n ligera o por contenedores, que es un m\u00e9todo de virtualizaci\u00f3n en el que, sobre el n\u00facleo del sistema operativo se ejecuta una capa de virtualizaci\u00f3n que permite que existan m\u00faltiples instancias aisladas de espacios de usuario, en lugar de solo uno. A estas instancias la llamamos contenedores.</p> <p>Todo esto ha sido posible por el desarrollo de dos componentes del nucleo de Linux:</p> <ul> <li>Los Grupos de Control cgroups, en concreto en Debian 11 se utiliza cgroupsv2: que limita el uso de recursos (l\u00edmite de memoria, cpu, I/O o red) para un proceso y sus hijos.</li> <li>Los Espacios de Nombres namespaces: que proporcionan un punto de vista diferente a un proceso (interfaces de red, procesos, usuarios, etc.).</li> </ul> <p>LXC pertenece a los denominados contenedores de sistemas, su gesti\u00f3n y ciclo de vida es similar al de una m\u00e1quina virtual tradicional. Est\u00e1 mantenido por Canonical y la p\u00e1gina oficial es linuxcontainers.org.</p>"},{"location":"01.-KVM/02.-Instalaci%C3%B3n/01.-Escenario%20de%20instalaci%C3%B3n/","title":"01.-Escenario de instalaci\u00f3n","text":"<p>En un entorno de producci\u00f3n, QEMU/KVM se instalar\u00e1 sobre una m\u00e1quina f\u00edsica con suficientes recursos. Si el sistema operativo tiene entorno gr\u00e1fico, podremos instalar herramientas gr\u00e1ficas, aunque siempre nos podemos conectar remotamente al servidor para gestionar QEMU/KVM.</p> <p>Para ejecutar QEMU/KVM necesitamos que el procesador soporte extensiones de virtualizaci\u00f3n en su juego de instrucciones. Para comprobar si tenemos esta caracter\u00edstica ejecutamos la siguiente instrucci\u00f3n como <code>root</code>:</p> <pre><code>egrep 'svm|vmx' /proc/cpuinfo --color\n</code></pre> <p>El resultado deber\u00eda mostrar varias l\u00edneas con el texto buscado resaltado en color. Si este es el caso entonces nuestro procesador soporta KVM. Los procesadores Intel mostrar\u00e1n el texto vmx resaltado y los procesadores AMD mostrar\u00e1n el texto svm resaltado.</p> <p>NOTA: Es importante comprobar que en la BIOS est\u00e1n activados las instrucciones virtuales VT/x, de lo contrario KVM no funcionar\u00e1.</p>"},{"location":"01.-KVM/02.-Instalaci%C3%B3n/01.-Escenario%20de%20instalaci%C3%B3n/#virtualizacion-anidada","title":"Virtualizaci\u00f3n anidada","text":"<p>Con esta caracter\u00edstica se permite la ejecuci\u00f3n de instrucciones KVM dentro de m\u00e1quinas virtuales KVM, lo cual nos posibilita la ejecuci\u00f3n de m\u00e1quinas virtuales dentro de m\u00e1quinas virtuales. De esta manera,podemos crear un laboratorio de prueba de QEMU/KVM ejecut\u00e1ndolos en una m\u00e1quina virtual.</p>"},{"location":"01.-KVM/02.-Instalaci%C3%B3n/01.-Escenario%20de%20instalaci%C3%B3n/#requerimientos-minimos","title":"Requerimientos m\u00ednimos","text":"<p>Si tenemos un entorno de producci\u00f3n, utilizaremos una m\u00e1quina f\u00edsica para la instalaci\u00f3n de QEMU/KVM. Tambi\u00e9n podr\u00edamos usar una m\u00e1quina virtual (con virtualizaci\u00f3n anidada activa) para tener un laboratorio de pruebas.</p> <p>Dependiendo de la cantidad de memoria RAM, espacio de disco duro y VCPU que tengamos, podremos virtualizar m\u00e1s o menos m\u00e1quinas virtuales:</p> <ul> <li>Por ejemplo, desde el punto de vista de la RAM: si virtualizamos una m\u00e1quina virtual sin entorno gr\u00e1fico podemos asignarle 512Mb, si tiene entorno gr\u00e1fico ya tendr\u00edamos que usar 1 o 2GB, si virtualizamos una m\u00e1quina Windows al menos tendremos que asignar 2Gb de RAM.</li> <li>Desde el punto de vista del almacenamiento: Este factor no es tan importante, pero tenemos que pensar que hay que almacenar las ISO para la instalaci\u00f3n de las m\u00e1quinas y los discos duros de las m\u00e1quinas virtuales. </li> <li> <p>Al crear m\u00e1quinas virtuales o contenedores podremos asignarle cores virtuales de CPU, por lo que aumentar\u00e1 el rendimiento si asignamos a nuestra m\u00e1quina virtual suficientes n\u00facleos de CPU. Por todo lo explicado a continuaci\u00f3n la configuraci\u00f3n recomendada para la m\u00e1quina virtual ser\u00eda:</p> </li> <li> <p>8 Gb de RAM</p> </li> <li>100 Gb de disco duro</li> <li>4 n\u00facleos de CPU</li> </ul>"},{"location":"01.-KVM/02.-Instalaci%C3%B3n/02.-Instalacion/","title":"02.-Instalacion","text":"<p>Para trabajar con el sistema de virtualizaci\u00f3n QEMU/KVM + libvirt en nuestra distribuci\u00f3n Linux Debian/Ubuntu, vamos a instalar los siguientes paquetes:</p> <pre><code>$ apt install qemu-system libvirt-clients libvirt-daemon-system\n</code></pre> <p>libvirt proporciona varios mecanismos para conectarse a un hipervisor qemu-kvm.</p> <p>Podemos obtener las versiones de las aplicaciones que hemos instalado, ejecutando:</p> <pre><code>$ virsh version\nCompilada con biblioteca: libvirt 7.0.0\nUso de biblioteca: libvirt  7.0.0\nUtilizando API: QEMU 7.0.0\nEjecutando hypervisor: QEMU 5.2.0\n</code></pre>"},{"location":"01.-KVM/02.-Instalaci%C3%B3n/02.-Instalacion/#conexion-a-qemukvm","title":"Conexi\u00f3n a QEMU/KVM","text":"<p>Vamos a usar la utilidad <code>virsh</code>, que nos proporciona una shell completa para el manejo de <code>libvirt</code>. Con el comando <code>list</code> mostramos las m\u00e1quinas virtuales que hemos creado.</p> <p>Con un usuario sin privilegios ejecutamos:</p> <pre><code>$ virsh list\n</code></pre> <p>Estar\u00edamos haciendo una conexi\u00f3n local con un usuario no privilegiado (estar\u00edamos conectando con la URI <code>qemu:///session</code> y estar\u00edamos mostrando las m\u00e1quinas virtuales de este usuario.</p> <p>Si por el contrario, como <code>root</code> ejecutamos:</p> <pre><code>root@kvm:~# virsh list\n</code></pre> <p>Estar\u00edamos haciendo una conexi\u00f3n local privilegiada (estar\u00edamos conectando con la URI <code>qemu:///system</code>) y mostrar\u00edamos las m\u00e1quinas virtuales del sistema.</p> <p>Si queremos que un usuario sin privilegios pueda hacer conexiones privilegiadas, el usuario debe pertenecer el grupo <code>libvirt</code>:</p> <pre><code>root@kvm:~# adduser usuario libvirt\n</code></pre> <p>Para que el usuario <code>usuario</code> haga una conexi\u00f3n privilegiada tendr\u00e1 que indicar expl\u00edcitamente la conexi\u00f3n a la URI <code>qemu:///system</code>:</p> <pre><code>usuario@kvm:~$ virsh -c qemu:///system list\n</code></pre> <p>De forma alternativa y seg\u00fan la wiki de Debian, podemos usar la variable de entorno <code>LIBVIRT_DEFAULT_URI</code> con el siguiente comando:</p> <pre><code>export LIBVIRT_DEFAULT_URI='qemu:///system'\n</code></pre>"},{"location":"01.-KVM/02.-Instalaci%C3%B3n/03.-Conexi%C3%B3n%20local%20no%20privilegiada%20a%20libvirt/","title":"03.-Conexi\u00f3n local no privilegiada a libvirt","text":"<p>Como hemos comentado en el punto anterior, un usuario sin privilegio puede crear sus m\u00e1quinas virtuales. Para ello realizar\u00e1 una conexi\u00f3n local a la URI <code>qemu:///session</code>. En este modo de conexi\u00f3n, el usuario no tiene permisos para crear conexiones de red, por lo que se limita su uso de la red no privilegiada de qemu (SLIRP) que es \u00fatil para casos simples, pero que tiene bajo rendimiento y es poco configurable. </p> <p>El usuario podr\u00eda usar cualquier aplicaci\u00f3n que nos permite la creaci\u00f3n de m\u00e1quinas virtuales (<code>virsh</code>, <code>virt-install</code>, <code>virt-manager</code>,...), pero en este apartado vamos a usar Gnome Cajas (Gnome Boxes), que es una aplicaci\u00f3n gr\u00e1fica que nos permite crear m\u00e1quinas virtuales, de forma sencilla, en el espacio de usuario.</p>"},{"location":"01.-KVM/02.-Instalaci%C3%B3n/03.-Conexi%C3%B3n%20local%20no%20privilegiada%20a%20libvirt/#gnome-boxes","title":"Gnome Boxes","text":"<p>Instalamos esta aplicaci\u00f3n:</p> <pre><code># apt install gnome-boxes\n</code></pre> <p>La utilizaci\u00f3n de esta aplicaci\u00f3n es muy sencilla. Podemos descargar distribuciones Linux preconfiguradas o elegir un fichero ISO para realizar la instalaci\u00f3n. Siguiendo la documentaci\u00f3n de la aplicaci\u00f3n, seguimos los siguientes pasos para crear una nueva maquina virtual:</p> <p>Pulsamos el bot\u00f3n \"+\" y elegimos la opci\u00f3n Crea una m\u00e1quina virtual.... A continuaci\u00f3n podemos escoger un sistema predefinido o un fichero ISO para realizar la instalaci\u00f3n. Elegimos un sistema preconfigurado:</p> <p></p> <p>A continuaci\u00f3n buscamos las versiones de Ubuntu:</p> <p></p> <p>Despu\u00e9s de la descarga, configuramos la nueva m\u00e1quina:</p> <p></p> <p>Y al terminar la instalaci\u00f3n  podemos acceder a la m\u00e1quina:</p> <p></p> <p>La m\u00e1quina se conecta a la red de usuario de QEMU (SLIRP) que configura la m\u00e1quina con la direcci\u00f3n IP <code>10.0.2.15</code>, su puerta de enlace, que es el anfitri\u00f3n (la m\u00e1quina f\u00edsica) es la direcci\u00f3n IP <code>10.0.2.2</code> y configura un servidor DNS en la direcci\u00f3n IP <code>10.0.2.3</code>. Esta red permite que la m\u00e1quina tenga acceso a internet, pero no tendr\u00e1 conectividad con el anfitri\u00f3n u otras m\u00e1quinas que creemos.</p> <p></p>"},{"location":"01.-KVM/02.-Instalaci%C3%B3n/03.-Conexi%C3%B3n%20local%20no%20privilegiada%20a%20libvirt/#acceso-a-las-maquinas-desde-la-linea-de-comandos","title":"Acceso a las m\u00e1quinas desde la l\u00ednea de comandos","text":"<p>Para comprobar que la m\u00e1quina virtual que hemos creado est\u00e1 virtualizada con QEMU/KVM + libvirt en el espacio de usuario, podemos ejecutar en el anfitri\u00f3n con el usuario con el que estamos trabajando:</p> <pre><code>usuario@kvm:~$ virsh -c qemu:///session list\n Id   Nombre          Estado\n----------------------------------\n 2    ubuntu20.10-2   ejecutando\n</code></pre> <p>Vemos que la m\u00e1quina est\u00e1 creado en la sesi\u00f3n del usuario <code>usuario</code>. Nota: No es necesario indicar la conexi\u00f3n <code>-c qemu:///session</code>, pero de esa forma se ve m\u00e1s claro que estamos haciendo una conexi\u00f3n local con un usuario sin privilegios.</p> <p>Por \u00faltimo, indicar que la imagen del disco se guarda por defecto en el directorio <code>~/.local/share/gnome-boxes/images</code>:</p> <pre><code>usuario@kvm:~$ ls -l .local/share/gnome-boxes/images\ntotal 196\n-rwxr--r-- 1 usuario usuario 196816 may 15 21:52 ubuntu20.10-2\n</code></pre> <p>\u00cdndice</p>"},{"location":"01.-KVM/02.-Instalaci%C3%B3n/04.-Conexi%C3%B3n%20local%20privilegiada%20a%20libvirt/","title":"04.-Conexi\u00f3n local privilegiada a libvirt","text":"<p>Generalmente vamos a trabajar realizando conexiones locales privilegiadas, por lo tanto si queremos ver todas las m\u00e1quinas creadas en el sistema debemos ejecutar:</p> <pre><code>usuario@kvm:~$ virsh -c qemu:///system list --all\n</code></pre> <ul> <li>Nota 1: La opci\u00f3n <code>--all</code> muestra las m\u00e1quinas que se est\u00e1n ejecutando y las que est\u00e1n paradas.</li> <li>Nota 2: Si nos conectaremos con el usuario <code>root</code> no har\u00eda falta indicar la URI <code>-c qemu:///system</code>.</li> </ul>"},{"location":"01.-KVM/02.-Instalaci%C3%B3n/04.-Conexi%C3%B3n%20local%20privilegiada%20a%20libvirt/#redes-disponibles","title":"Redes disponibles","text":"<p>Cuando instalamos QEMU/KVM + libvirt se crea una red por defecto de tipo NAT, que no est\u00e1 iniciada. Para verla, ejecutamos la siguiente instrucci\u00f3n:</p> <pre><code>usuario@kvm:~$ virsh -c qemu:///system net-list --all\n Nombre    Estado     Inicio autom\u00e1tico   Persistente\n-------------------------------------------------------\n default   inactivo   no                  si\n</code></pre> <ul> <li>Nota: La opci\u00f3n <code>--all</code> muestra las redes activas e inactivas.</li> </ul> <p>Como vemos, el estado es inactivo, para iniciarla, ejecutamos:</p> <pre><code>usuario@kvm:~$ virsh -c qemu:///system net-start default \nLa red default se ha iniciado\n</code></pre> <p>Adem\u00e1s es recomendable activar la propiedad de Incio aut\u00f3matico, para que se inicie de forma autom\u00e1tica despu\u00e9s de reiniciar el host, para ello:</p> <pre><code>usuario@kvm:~$ virsh -c qemu:///system net-autostart default\nLa red default ha sido marcada para iniciarse autom\u00e1ticamente\n</code></pre> <p>Y ejecutando de nuevo <code>virsh -c qemu:///system net-list</code>, aparece la red como activa y Inicio autom\u00e1tico a si.</p> <p>Aunque estudiaremos la redes con profundidad en el m\u00f3dulo correspondiente, podemos se\u00f1alar que las m\u00e1quinas virtuales que se conecten a esta red, tendr\u00e1n las siguientes caracter\u00edsticas:</p> <ul> <li>Tomar\u00e1n una direcci\u00f3n IP de forma din\u00e1mica en el rango <code>192.168.122.2</code> - <code>192.168.122.254</code>. Es decir, existe un servidor DHCP (que se encuentra en el host) asignando de forma din\u00e1mica el direccionamiento.</li> <li>La puerta de enlace ser\u00e1 la direcci\u00f3n IP <code>192.168.122.1</code> que corresponde al host. Est\u00e1 direcci\u00f3n tambi\u00e9n corresponde al servidor DNS que tiene configurado (que tambi\u00e9n se encuentra en el host).</li> <li>La m\u00e1quina virtual estar\u00e1 conectada a un Linux Bridge (switch virtual) llamado <code>virbr0</code> por la que se conectar\u00e1 al host.</li> <li>El host har\u00e1 de router/nat para que la m\u00e1quina tenga conectividad al exterior.</li> </ul> <p>Por defecto, las nuevas m\u00e1quinas que creemos se conectar\u00e1n a esta red.</p>"},{"location":"01.-KVM/02.-Instalaci%C3%B3n/04.-Conexi%C3%B3n%20local%20privilegiada%20a%20libvirt/#almacenamiento-disponible","title":"Almacenamiento disponible","text":"<p>Estudiaremos en profundidad el almacenamiento con el que podemos trabajar en el m\u00f3dulo correspondiente. En este momento, indicar que los ficheros correspondientes a las im\u00e1genes de discos de las nuevas m\u00e1quinas virtuales que creemos se guardar\u00e1n, por defecto, en el directorio <code>/var/lib/libvirt/images</code>.</p> <p>\u00cdndice</p>"},{"location":"01.-KVM/02.-Instalaci%C3%B3n/05.-Conexi%C3%B3n%20remota/","title":"Conexi\u00f3n remota a libvirt","text":"<p>Podemos conectar al hypervirsor libvirt que se est\u00e1 ejecutando en un servidor desde otra m\u00e1quina remota. Es decir, desde una m\u00e1quina cliente podemos usar, por ejmplo, <code>virsh</code> para conectarnos a un hypervisor libvirt remoto. Para ello, la sintaxis es la siguiente:</p> <pre><code>usuario@cliente:~$ virsh -c qemu+ssh://usuario_remoto@ip_servidor_remoto/system comando\n</code></pre> <p>Es decir, se va a producir una conexi\u00f3n ssh entre la m\u00e1quina cliente y el servidor donde se ejecuta libvirt. Por lo tanto hay que configurar las m\u00e1quinas para que el usuario <code>usuario</code> de la m\u00e1quina <code>cliente</code> pueda acceder por SSH al servidor remoto con el usuario <code>usuario_remoto</code>, sin que se se le pida la contrase\u00f1a.</p> <p>Para ello tendremos que copiar la clave p\u00fablica SSH del usuario <code>cliente</code> al fichero <code>~/.ssh/authorized_keys</code> del usuario <code>usuario_remoto</code> en el servidor que queremos acceder.</p> <p>\u00cdndice</p>"},{"location":"01.-KVM/03.-Creaci%C3%B3n%20de%20MV%20desde%20el%20CLI/01.-Creaci%C3%B3n%20de%20MV%20con%20virt-install/","title":"Creaci\u00f3n de m\u00e1quinas virtuales con virt-install","text":"<p>Vamos a crear nuestra primera m\u00e1quina virtual desde la l\u00ednea de comandos con la aplicaci\u00f3n <code>virt-install</code>.</p> <p>Lo primero que tenemos que hacer es instalar el paquete <code>virtinst</code>, que adem\u00e1s de este programa, tiene otras utilidades que iremos usando a los largo del curso.</p> <pre><code>apt install virtinst\n</code></pre> <p>La informaci\u00f3n que tenemos que proporcionar a <code>virt-install</code> para la creaci\u00f3n de la nueva m\u00e1quina virtual ser\u00e1 la siguiente:</p> <ul> <li>El nombre de la m\u00e1quina virtual (par\u00e1metro <code>--name</code>).</li> <li>El tipo de virtualizaci\u00f3n (par\u00e1metro <code>--virt-type</code>). en nuestro caso ser\u00e1 <code>kvm</code>.</li> <li>En nuestro caso vamos a realizar una instalaci\u00f3n desde un fichero ISO, por lo que tendremos que indicar que la nueva m\u00e1quina tendr\u00e1 un CDROM con la ISO que indiquemos (par\u00e1metro <code>--cdrom</code>).</li> <li>La variante del sistema operativo que vamos a utilizar (par\u00e1metro <code>--os-variant</code>). Para obtener la lista de variantes de sistemas operativos, podemos ejecutar <code>osinfo-query os</code> (Instalar el paquete <code>libosinfo-bin</code> si no reconoce el comando). </li> <li>El tama\u00f1o del disco (par\u00e1metro <code>--disk size</code>). Se crear\u00e1 un fichero con la imagen del disco que se guardar\u00e1 en <code>/var/lib/libvirt/images</code>.</li> <li>La cantidad de memoria RAM (par\u00e1metro <code>--memory</code>).</li> <li>La cantidad de vCPU asignadas a la m\u00e1quina (par\u00e1metro <code>--vcpus</code>).</li> </ul> <p>Podemos indicar muchos m\u00e1s par\u00e1metros a la hora de crear la nueva m\u00e1quina. Puedes obtener toda la informaci\u00f3n en la documentaci\u00f3n oficial de la aplicaci\u00f3n. Iremos usando, a lo largo del curso, diferentes par\u00e1metros de esta herramienta.</p>"},{"location":"01.-KVM/03.-Creaci%C3%B3n%20de%20MV%20desde%20el%20CLI/01.-Creaci%C3%B3n%20de%20MV%20con%20virt-install/#creacion-de-nuestra-primera-maquina-virtual","title":"Creaci\u00f3n de nuestra primera m\u00e1quina virtual.","text":"<p>Vamos a crear una m\u00e1quina con las siguientes caracter\u00edsticas: se va a llamar <code>prueba1</code>, se va a usar una ISO de la distribuci\u00f3n GNU/Linux Debian 11, la variante de sistema operativo podemos poner <code>debian10</code>, el tama\u00f1o del disco ser\u00e1 de 10 GB, la memoria RAM ser\u00e1 de 1 GB y le vamos a asignar 1 vCPU. No vamos a indicar la red a la que se conecta ya que, por defecto, se conectar\u00e1 a la red predefinida <code>default</code>.</p> <p>Tenemos que tener en cuenta dos cosas:</p> <ol> <li>La red <code>default</code> debe estar activa: <code>virsh -c qemu:///system net-start default</code>.</li> <li>Hemos bajado una imagen ISO para la instalaci\u00f3n del sistema operativo y la tenemos guardad en el directorio <code>~/iso</code>.</li> </ol> <p>Para crear la nueva m\u00e1quina con esas caracter\u00edsticas, ejecutamos con usuario sin privilegios:</p> <pre><code>virt-install --connect qemu:///system \\\n             --virt-type kvm \\\n             --name prueba1 \\\n             --cdrom ~/iso/debian-11.3.0-amd64-netinst.iso \\\n             --os-variant debian10 \\\n             --disk size=10 \\\n             --memory 1024 \\\n             --vcpus 1\n</code></pre> <p>A continuaci\u00f3n, se iniciar\u00e1 la m\u00e1quina y se abrir\u00e1 una terminal en la aplicaci\u00f3n <code>virt-viewer</code> para que realicemos la instalaci\u00f3n:</p> <p></p> <p>\u00cdndice</p>"},{"location":"01.-KVM/03.-Creaci%C3%B3n%20de%20MV%20desde%20el%20CLI/02.-Caracter%C3%ADsticas%20de%20la%20MV/","title":"Caracter\u00edsticas de las m\u00e1quinas virtuales","text":"<p>Despu\u00e9s de instalar nuestra primera m\u00e1quina, podemos comprobar la lista de m\u00e1quinas ejecutando la siguiente instrucci\u00f3n:</p> <pre><code>virsh -c qemu:///system list\n Id   Nombre    Estado\n----------------------------\n 2    prueba1   ejecutando\n</code></pre> <p>Si queremos acceder a la terminal de una m\u00e1quina podemos usar <code>virt-view</code> de la siguiente forma:</p> <pre><code>virt-viewer -c qemu:///system prueba1\n</code></pre>"},{"location":"01.-KVM/03.-Creaci%C3%B3n%20de%20MV%20desde%20el%20CLI/02.-Caracter%C3%ADsticas%20de%20la%20MV/#red","title":"Red","text":"<p>Como coment\u00e1bamos en el punto anterior, la m\u00e1quina que hemos creado se conecta, por defcto, a la red <code>default</code>. Esta red es de tipo NAT, y comprobamos que la m\u00e1quina ha recibido una IP de forma din\u00e1mica y que su puerta de enlace corresponde a la direcci\u00f3n IP <code>192.168.122.1</code>, que corresponde con el host, el servidor DNS corresponde a la misma IP y comprobamos que tiene resoluci\u00f3n y acceso a internet:</p> <p></p>"},{"location":"01.-KVM/03.-Creaci%C3%B3n%20de%20MV%20desde%20el%20CLI/02.-Caracter%C3%ADsticas%20de%20la%20MV/#recursos-hardware","title":"Recursos hardware","text":"<p>Podemos comprobar que la maq\u00faina tiene un disco de 10 Gb y de memoria RAM 1Gb:</p> <p></p>"},{"location":"01.-KVM/03.-Creaci%C3%B3n%20de%20MV%20desde%20el%20CLI/02.-Caracter%C3%ADsticas%20de%20la%20MV/#almacenamiento","title":"Almacenamiento","text":"<p>Un Pool de almacenamiento es un recurso de almacenamiento. Lo m\u00e1s usual es tener pools de almacenamiento que sean locales, por ejemplo un directorio. En el momento de crear la primera m\u00e1quina se han creado dos pools de almacenamiento de tipo dir y que corresponden a los dos directorios con los que estamos trabajando:</p> <ul> <li><code>default</code>: Es un pool de almacenamiento que corresponde con el directorio <code>/usr/lib/libvirt/images</code> y donde se guardar\u00e1n los ficheros correspondientes a las im\u00e1genes de disco.</li> <li><code>iso</code>: Este pool de almacenamiento se ha creado al indicar en <code>virt-install</code>el directorio donde estaba almacenado el fichero ISO. En este caso es otro pool de almacenamiento de tipo dir, y corresponde al directorio <code>~/ISO</code>.</li> </ul> <p>Podemos ver los pools de almacenamiento, que tenemos creado, ejecutando:</p> <pre><code>virsh -c qemu:///system pool-list \n Nombre    Estado   Inicio autom\u00e1tico\n---------------------------------------\n default   activo   si\n iso       activo   si\n</code></pre> <p>Un volumen es un medio de almacenamiento que podemos crear en un pool de almacenamiento en kvm. Si el pool de almacenamiento es de tipo dir, entonces el volumen ser\u00e1 un fichero de imagen.</p> <p>Veamos el volumen que se ha creado el pool <code>default</code>:</p> <pre><code>virsh -c qemu:///system vol-list default\n Nombre          Ruta\n--------------------------------------------------------\n prueba1.qcow2   /var/lib/libvirt/images/prueba1.qcow2\n</code></pre> <p>Vemos que la imagen del disco de la m\u00e1quina virtual est\u00e1 guardada en un fichero QCOW2. Tambi\u00e9n podemos ver el volumen que est\u00e1 creado en el pool <code>iso</code>:</p> <pre><code>virsh -c qemu:///system vol-list iso\n Nombre                            Ruta\n--------------------------------------------------------------------------------------\n debian-11.3.0-amd64-netinst.iso   /home/usuario/iso/debian-11.3.0-amd64-netinst.iso\n</code></pre> <p>Que corresponde al fichero de la imagen ISO que hemos copiado en el directorio <code>~/ISO</code>.</p> <p>En todos estos conceptos sobre almacenamiento profundizaremos en el m\u00f3dulo correspondiente.</p> <p>\u00cdndice</p>"},{"location":"01.-KVM/03.-Creaci%C3%B3n%20de%20MV%20desde%20el%20CLI/03.-Gesti%C3%B3n%20de%20MV%20con%20virsh/","title":"Gesti\u00f3n de m\u00e1quinas virtuales con virsh","text":"<p>virsh es el cliente por l\u00ednea de comandos \"oficial\" de libvirt. Ofrece una shell completa para el manejo de la API.</p> <p>Cuando obtenga la ayuda de esta herramienta ver\u00e1s que en mucha ocasiones habla de dominio. Un dominio en QEMU/KVM es una m\u00e1quina virtual.</p> <p>Para obtener ayuda sobre todos los comandos que podemos ejecutar:</p> <pre><code>virsh --help\n</code></pre> <p>Si queremos pedir ayuda de un comando en concreto, por ejemplo el comando <code>list</code>, ejecutamos:</p> <pre><code>virsh list --help\n</code></pre> <p>Ya hemos usado el comando <code>list</code> para mostrar las m\u00e1quinas virtuales que tenemos creada:</p> <pre><code>virsh -c qemu:///system list --all\n Id   Nombre    Estado\n----------------------------\n 2    prueba1   ejecutando\n</code></pre> <p>Nota: Podemos referencia una m\u00e1quina virtual por su nombre o por su id.</p>"},{"location":"01.-KVM/03.-Creaci%C3%B3n%20de%20MV%20desde%20el%20CLI/03.-Gesti%C3%B3n%20de%20MV%20con%20virsh/#ciclo-de-vida-de-una-maquina-virtual","title":"Ciclo de vida de una m\u00e1quina virtual","text":"<p>Para apagar de forma adecuada una m\u00e1quina virtual:</p> <pre><code>virsh -c qemu:///system shutdown prueba1\nDomain 'prueba1' is being shutdown\n</code></pre> <p>Para iniciar una m\u00e1quina que est\u00e1 detenida:</p> <pre><code>virsh -c qemu:///system start prueba1\nDomain 'prueba1' started\n</code></pre> <p>Si la propiedad autostart de una maquina est\u00e1 activa, cada vez que se inicie el host, esa m\u00e1quina se encender\u00e1 de forma autom\u00e1tica. Para activarlo:</p> <pre><code>virsh -c qemu:///system autostart prueba1\nDomain 'prueba1' marked as autostarted\n</code></pre> <p>Reiniciamos una m\u00e1quina virtual, ejecutando:</p> <pre><code>virsh -c qemu:///system reboot prueba1\nDomain 'prueba1' is being rebooted\n</code></pre> <p>Podemos forzar el apagado de una m\u00e1quina:</p> <pre><code>virsh -c qemu:///system destroy prueba1\nDomain 'prueba1' destroyed\n</code></pre> <p>Podemos pausar la ejecuci\u00f3n de una m\u00e1quina</p> <pre><code>virsh -c qemu:///system suspend prueba1\nDomain 'prueba1' suspended\n</code></pre> <p>Y continuar la ejecuci\u00f3n:</p> <pre><code>virsh -c qemu:///system resume prueba1\nDomain 'prueba1' resumed\n</code></pre> <p>Por \u00faltimo, para eliminar una m\u00e1quina virtual que est\u00e9 parada (eliminando los vol\u00famenes asociados):</p> <pre><code>virsh -c qemu:///system undefine --remove-all-storage  prueba1\n</code></pre>"},{"location":"01.-KVM/03.-Creaci%C3%B3n%20de%20MV%20desde%20el%20CLI/03.-Gesti%C3%B3n%20de%20MV%20con%20virsh/#obtener-informacion-de-la-maquina-virtual","title":"Obtener informaci\u00f3n de la m\u00e1quina virtual","text":"<p>Todos los comandos de <code>virsh</code> que empiezan por dom nos permiten obtener informaci\u00f3n de la m\u00e1quina. </p> <p>Para obtener informaci\u00f3n de la m\u00e1quina:</p> <pre><code>virsh -c qemu:///system dominfo prueba1 \n</code></pre> <p>Obtener la direcci\u00f3n IP de la interfaz de red:</p> <pre><code>virsh -c qemu:///system domifaddr prueba1\n</code></pre> <p>Obtener los discos que tiene la m\u00e1quina:</p> <pre><code>virsh -c qemu:///system domblklist prueba1\n</code></pre> <p>Puedes buscar informaci\u00f3n de m\u00e1s comandos para obtener distinta informaci\u00f3n de la m\u00e1quina virtual.</p> <p>\u00cdndice</p>"},{"location":"01.-KVM/03.-Creaci%C3%B3n%20de%20MV%20desde%20el%20CLI/04.-Definici%C3%B3n%20XML%20de%20una%20MV/","title":"Definici\u00f3n XML de una m\u00e1quina virtual","text":"<p>Las caracter\u00edsticas, opciones y dispositivos hardware de una m\u00e1quina virtual est\u00e1n estructuradas con el lenguajes de marcas XML. De la misma forma las caracter\u00edsticas de los distintos recursos con los que podemos trabajar (redes, pools de almacenamiento, vol\u00famenes) tambi\u00e9n est\u00e1n definidos con XML.</p>"},{"location":"01.-KVM/03.-Creaci%C3%B3n%20de%20MV%20desde%20el%20CLI/04.-Definici%C3%B3n%20XML%20de%20una%20MV/#esquema-xml-de-una-maquina-virtual","title":"Esquema XML de una m\u00e1quina virtual","text":"<p>Para obtener la definici\u00f3n XML de una m\u00e1quina virtual, ejecutamos la siguiente instrucci\u00f3n:</p> <pre><code>virsh -c qemu:///system  dumpxml prueba1\n</code></pre> <p>Veamos algunos elementos de la definici\u00f3n:</p> <ul> <li>El documento XML empieza con la etiqueta <code>&lt;domain&gt;</code> donde se indica el tipo de virtualizaci\u00f3n utilizada para gestionar la m\u00e1quina y su identificador si la m\u00e1quina est\u00e1 ejecut\u00e1ndose..</li> <li>El nombre de la m\u00e1quina se indica con la etiqueta <code>&lt;name&gt;</code>.</li> <li> <p>La etiqueta <code>&lt;currentMemory&gt;</code> nos indica la memoria asignada actualmente a la m\u00e1quina. Podemos modificar esta memoria asignada sin reiniciar la m\u00e1quina hasta el l\u00edmite indicado por la etiqueta <code>&lt;memory&gt;</code>. Por lo tanto, el valor asignado a <code>&lt;memory&gt;</code> no puede ser menor que el valor asociado a <code>&lt;currentMemory&gt;</code>.</p> <p>En este ejemplo, los dos valores son iguales porque al crear la m\u00e1quina con <code>virt-install</code> usamos el par\u00e1metro <code>--memory</code> y se asigna el valor indicado a los dos par\u00e1metros. M\u00e1s adelante estudiaremos como modificar estos par\u00e1metros.</p> </li> <li> <p>La vCPU asignadas la encontramos definida en la etiqueta <code>&lt;vcpu&gt;</code>.</p> </li> <li>Con la etiqueta <code>&lt;os&gt;</code> tenemos informaci\u00f3n de la arquitectura de la m\u00e1quina virtualizada, adem\u00e1s con las etiquetas <code>&lt;boot&gt;</code> indicamos el orden de arranque entre distintos dispositivos.</li> <li>La informaci\u00f3n de la CPU la encontramos en la etiqueta <code>&lt;cpu&gt;</code>.</li> </ul> <p>Veamos un ejemplo hasta aqu\u00ed:</p> <pre><code>domain type='kvm' id='6'&gt;\n  &lt;name&gt;prueba1&lt;/name&gt;\n  &lt;uuid&gt;a88eebdc-8a00-4b9d-bf48-cbed7bb448d3&lt;/uuid&gt;\n  ...\n  &lt;memory unit='KiB'&gt;1048576&lt;/memory&gt;\n  &lt;currentMemory unit='KiB'&gt;1048576&lt;/currentMemory&gt;\n  &lt;vcpu placement='static'&gt;1&lt;/vcpu&gt;\n  ...\n  &lt;os&gt;\n    &lt;type arch='x86_64' machine='pc-q35-5.2'&gt;hvm&lt;/type&gt;\n    &lt;boot dev='hd'/&gt;\n  &lt;/os&gt;\n  ...\n  &lt;cpu mode='custom' match='exact' check='full'&gt;\n    &lt;model fallback='forbid'&gt;Cooperlake&lt;/model&gt;\n    &lt;vendor&gt;Intel&lt;/vendor&gt;\n    ...\n</code></pre> <p>A continuaci\u00f3n nos encontramos la etiqueta <code>&lt;devices&gt;</code> donde se definen los distintos dispositivos hardware que forman parte de la m\u00e1quina. Veamos algunos ejemplos:</p> <ul> <li>Los discos se definen con la etiqueta <code>&lt;disk&gt;</code>. Encontramos informaci\u00f3n del tipo (en este caso fichero), tipo del fichero (en este caso qcow2), ruta donde se encuentra el fichero,... Es importante se\u00f1alar que, por defecto, se configura el disco con un controlador VirtIO (<code>bus='virtio</code>), es decir, es un dispositivo paravirtualizado que nos ofrece mayor rendimiento. Veamos la definici\u00f3n del disco:</li> </ul> <pre><code>    &lt;disk type='file' device='disk'&gt;\n      &lt;driver name='qemu' type='qcow2'/&gt;\n      &lt;source file='/var/lib/libvirt/images/prueba1.qcow2'/&gt;\n      &lt;target dev='vda' bus='virtio'/&gt;\n      &lt;address type='pci' domain='0x0000' bus='0x04' slot='0x00' function='0x0'/&gt;\n    &lt;/disk&gt;\n</code></pre> <ul> <li>Las interfaces de red se definen con la etiqueta <code>&lt;interface&gt;</code>. Encontramos informaci\u00f3n como la mac, la red a la que est\u00e1 conectada (en este caso la red <code>default</code>),... Tambi\u00e9n observamos que el modelo de la tarjeta es VirtIO (<code>&lt;model type='virtio'/&gt;</code>), de nuevo se configura un dispositivo paravirtualizado de alto rendimiento.</li> </ul> <pre><code>    &lt;interface type='network'&gt;\n      &lt;mac address='52:54:00:8a:50:d1'/&gt;\n      &lt;source network='default'/&gt;\n      &lt;model type='virtio'/&gt;\n      &lt;address type='pci' domain='0x0000' bus='0x01' slot='0x00' function='0x0'/&gt;\n    &lt;/interface&gt;\n</code></pre> <ul> <li>Si nos fijamos en otros dispositivos podremos encontrar la definici\u00f3n del teclado, del rat\u00f3n, el adaptador gr\u00e1fico, controladores PCI, CDROM, ...</li> </ul> <p>Iremos estudiando m\u00e1s elementos de la definici\u00f3n XML de una m\u00e1quina virtual, pero pode\u00eds profundizar en el formato en la documentaci\u00f3n oficial: Domain XML format.</p> <p>\u00cdndice</p>"},{"location":"01.-KVM/03.-Creaci%C3%B3n%20de%20MV%20desde%20el%20CLI/05.-Modificaci%C3%B3n%20de%20una%20MV/","title":"Modificaci\u00f3n de la definici\u00f3n de una m\u00e1quina virtual","text":"<p>Podemos cambiar la configuraci\u00f3n de una m\u00e1quina virtual modificando su definici\u00f3n XML. Podemos cambiar el nombre, la memoria utilizada, la asignaci\u00f3n de CPU, cambiar la configuraci\u00f3n de cualquier dispositivo, eliminar o a\u00f1adir nuevos dispositivos,...</p> <p>Para realizar la modificaci\u00f3n del fichero XML tenemos dos alternativas:</p> <ol> <li>Realizar los cambios directamente en el documento XML utilizando el comando <code>virsh edit</code>.</li> <li>Utilizando comandos espec\u00edficos de <code>virsh</code> que nos ayudan a realizar el cambio de los distintos par\u00e1metros de la configuraci\u00f3n.</li> </ol> <p>Hay cambios que se pueden realizar con la m\u00e1quina funcionando, otros necesitan que la m\u00e1quina est\u00e9 parada y otros necesitan un reinicio de la m\u00e1quina para que se realicen.</p> <p>Veamos algunos ejemplos:</p>"},{"location":"01.-KVM/03.-Creaci%C3%B3n%20de%20MV%20desde%20el%20CLI/05.-Modificaci%C3%B3n%20de%20una%20MV/#modificar-el-nombre-de-una-maquina-virtual","title":"Modificar el nombre de una m\u00e1quina virtual","text":"<p>En este caso la modificaci\u00f3n la vamos a realizar con el comando <code>virsh domrename</code>, que modificar\u00e1 internamente la definici\u00f3n XML:</p> <pre><code>virsh -c qemu:///system domrename prueba2 prueba1\nDomain 'prueba2' XML configuration edited.\n</code></pre> <p>Este cambio requiere que la m\u00e1quina est\u00e9 parada.</p>"},{"location":"01.-KVM/03.-Creaci%C3%B3n%20de%20MV%20desde%20el%20CLI/05.-Modificaci%C3%B3n%20de%20una%20MV/#modificar-la-asignacion-de-vcpu","title":"Modificar la asignaci\u00f3n de vCPU","text":"<p>Suponemos que la m\u00e1quina est\u00e1 parada. Comprobamos el n\u00famero de vCPU asignadas a la m\u00e1quina:</p> <pre><code>virsh -c qemu:///system dominfo prueba1\n...\nCPU(s):         1\n...\n</code></pre> <p>Podemos editar la configuraci\u00f3n XML y cambiar el valor de la etiqueta <code>&lt;vcpu&gt;</code>:</p> <pre><code>virsh -c qemu:///system edit prueba1\n...\n  &lt;vcpu placement='static'&gt;2&lt;/vcpu&gt;\n...\n</code></pre> <p>Y volvemos a comprobar la informaci\u00f3n de la m\u00e1quina:</p> <pre><code>virsh -c qemu:///system dominfo prueba1\n...\nCPU(s):         2\n...\n</code></pre> <p>Tambi\u00e9n podr\u00edamos cambiar la asignaci\u00f3n de vCPU \"en caliente\" con el camando <code>virsh setvcpus</code>, pero no lo vamos a estudiar en este curso. Puedes ver este \u00e1rticulo para m\u00e1s informaci\u00f3n.</p>"},{"location":"01.-KVM/03.-Creaci%C3%B3n%20de%20MV%20desde%20el%20CLI/05.-Modificaci%C3%B3n%20de%20una%20MV/#modificar-la-asignacion-de-memoria-ram","title":"Modificar la asignaci\u00f3n de memoria RAM","text":"<p>Volvemos a suponer que la m\u00e1quina est\u00e1 parada. Podemos editar la configuraci\u00f3n XML y modificar las dos etiquetas relacionadas con la memoria:</p> <ul> <li><code>&lt;memory&gt;</code>: Valor m\u00e1ximo de RAM que podemos asignar a la m\u00e1quina \"en caliente\" (funcionando).</li> <li><code>&lt;currentMemory&gt;</code>: Cantidad de memoria asignada a la m\u00e1quina.</li> </ul> <p>Por ejemplo, dejamos la asignaci\u00f3n de memoria en un 1 Gb, y cambiamos la memoria m\u00e1xima a 3 Gb:</p> <pre><code>virsh -c qemu:///system edit prueba1\n...\n  &lt;memory unit='KiB'&gt;3145728&lt;/memory&gt;\n  &lt;currentMemory unit='KiB'&gt;1048576&lt;/currentMemory&gt;\n...\n</code></pre> <p>Podemos comprobar el cambio:</p> <pre><code>virsh -c qemu:///system dominfo prueba1\n...\nMemoria m\u00e1xima: 3145728 KiB\nMemoria utilizada: 1048576 KiB\n...\n</code></pre> <p>Ahora iniciamos la m\u00e1quina y podemos cambiar \"en caliente\" la memoria de la m\u00e1quina hasta un m\u00e1ximo de 3 Gb, para ello vamos a usar el comando <code>virsh setmem</code>.</p> <pre><code>virsh -c qemu:///system start prueba1\n\nvirsh -c qemu:///system setmem prueba1 2048M\n</code></pre> <p>https://www.unixarena.com/2015/12/linux-kvm-how-to-add-remove-memory-to-guest-on-fly.html/</p>"},{"location":"01.-KVM/04.-Creaci%C3%B3n%20de%20MV%20con%20virt-manager/01.-Primeros%20pasos%20con%20virt-manager/","title":"Primeros pasos con virt-manager","text":"<p>virt-manager es una aplicaci\u00f3n gr\u00e1fica de escritorio para gestionar m\u00e1quinas virtuales a trav\u00e9s de libvirt. Presenta una vista resumida de las m\u00e1quinas virtuales en ejecuci\u00f3n, su rendimiento en vivo y las estad\u00edsticas de utilizaci\u00f3n de recursos. Los usuarios pueden crear nuevas m\u00e1quinas virtuales y configurarlas y gestionar sus dispositivos de hardware. Adem\u00e1s, poseer un cliente VNC / SPICE que permite el acceso de forma sencilla a la consola de la m\u00e1quina.</p>"},{"location":"01.-KVM/04.-Creaci%C3%B3n%20de%20MV%20con%20virt-manager/01.-Primeros%20pasos%20con%20virt-manager/#instalacion-de-virt-manager","title":"Instalaci\u00f3n de virt-manager","text":"<p>En sistemas operativos basados en Debian / Ubuntu, simplemente ejecutamos:</p> <pre><code>apt install virt-manager\n</code></pre>"},{"location":"01.-KVM/04.-Creaci%C3%B3n%20de%20MV%20con%20virt-manager/01.-Primeros%20pasos%20con%20virt-manager/#vista-general-de-virt-manager","title":"Vista general de virt-manager","text":"<p>Pode defecto, podemos ver que virt-manager tiene configurado una conexi\u00f3n local privilegiada que se llama QEMU/KVM. Vemos las m\u00e1quinas virtuales que est\u00e1n creada en esa conexi\u00f3n (en este caso <code>prueba1</code>, que creamos en el m\u00f3dulo anterior).</p> <p>Con la opci\u00f3n Archivo-&gt;Nueva conexi\u00f3n... podemos dar de alta una nueva conexi\u00f3n.</p>"},{"location":"01.-KVM/04.-Creaci%C3%B3n%20de%20MV%20con%20virt-manager/01.-Primeros%20pasos%20con%20virt-manager/#conexion-qemukvm","title":"Conexi\u00f3n QEMU/KVM","text":"<p>Si pulsamos con el bot\u00f3n derecho del rat\u00f3n sobre la conexi\u00f3n QEMU/KVM, adem\u00e1s de distintas opciones, como Nueva, Desconectar,..., encontramos la opci\u00f3n Detalles (esta opci\u00f3n tambi\u00e9n se puede elegir en el men\u00fa Editar -&gt; Detalle de la conexi\u00f3n):</p> <p></p> <p>Al elegir el detalle de la conexi\u00f3n, podemos comprobar que es una conexi\u00f3n local privilegiada. Nos conectamos a la URI <code>qemu:///system</code>. Adem\u00e1s est\u00e1 configurada para que se conecte de forma autom\u00e1tica cada vez que iniciamos la aplicaci\u00f3n:</p> <p></p>"},{"location":"01.-KVM/04.-Creaci%C3%B3n%20de%20MV%20con%20virt-manager/01.-Primeros%20pasos%20con%20virt-manager/#redes-disponibles","title":"Redes disponibles","text":"<p>Tambi\u00e9n podemos gestionar las redes de esta conexi\u00f3n. Podemos ver las redes creadas, crear nuevas redes, eliminarlas, modificarlas, ... Vemos que tenemos creada la red <code>default</code> y ver sus caracter\u00edsticas (tipo NAT, configuraci\u00f3n ofrecida por un servidor  DHCP, Linux Bridge que gestiona,...). Por defecto est\u00e1 inactiva, para activarla, la seleccionamos y pulsamos sobre el bot\u00f3n \u25b6.</p> <p></p>"},{"location":"01.-KVM/04.-Creaci%C3%B3n%20de%20MV%20con%20virt-manager/01.-Primeros%20pasos%20con%20virt-manager/#pools-de-almacenamiento-disponibles","title":"Pools de almacenamiento disponibles","text":"<p>Otro elemento que podemos gestionar son los Pool de almacenamiento que tenemos en la conexi\u00f3n. Recordamos que ten\u00edamos dos creados: el pool <code>default</code>, donde se guardaban las im\u00e1genes de discos, y el pool <code>iso</code>, donde almacenamos los ficheros ISO para las instalaciones de los sistemas operativos. Adem\u00e1s, podemos ver los vol\u00famenes (en este caso, los ficheros) que hay creados en cada pool.</p> <p></p>"},{"location":"01.-KVM/04.-Creaci%C3%B3n%20de%20MV%20con%20virt-manager/01.-Primeros%20pasos%20con%20virt-manager/#conexion-remota-con-virt-manager","title":"Conexi\u00f3n remota con virt-manager","text":"<p>Si quisi\u00e9ramos conectarnos de forma remota a un servidor donde se est\u00e1 ejecutando libvirt, podr\u00edamos crear una nueva conexi\u00f3n: Archivo -&gt; A\u00f1adir conexi\u00f3n..., y crear una conexi\u00f3n y elegir la opci\u00f3n Conectar a anfitri\u00f3n mediante SSH:</p> <p></p>"},{"location":"01.-KVM/04.-Creaci%C3%B3n%20de%20MV%20con%20virt-manager/01.-Primeros%20pasos%20con%20virt-manager/#conclusion","title":"Conclusi\u00f3n","text":"<p><code>virt-manager</code> es otra aplicaci\u00f3n que nos permite hacer conexiones a libvirt, como hacemos con la aplicaci\u00f3n <code>virsh</code> o <code>virt-install</code>. Por lo tanto, los recursos virtualizados que gestionamos con estas aplicaciones cuando nos conectamos a <code>qemu:///system</code> son los mismos. Los cambios que hagamos con una aplicaci\u00f3n se ven reflejados en cualquiera de las otras. <code>virt-manager</code> es m\u00e1s f\u00e1cil de usar, pero nos ofrece menos opciones que la aplicaci\u00f3n <code>virsh</code> o <code>virt-install</code>.</p>"},{"location":"01.-KVM/04.-Creaci%C3%B3n%20de%20MV%20con%20virt-manager/02.-Creaci%C3%B3n%20de%20MV%20linux/","title":"Creaci\u00f3n de m\u00e1quinas virtuales Linux","text":"<p>Vamos a estudiar los pasos fundamentales para la creaci\u00f3n de una m\u00e1quina virtual. en este caso vamos a crear una m\u00e1quina virtual con el sistema operativo GNU/Linux Ubuntu. Observaremos que la informaci\u00f3n que vamos indicando en virt-manager es la misma que utilizamos para la creaci\u00f3n d m\u00e1quinas con la herramienta <code>virt-install</code>.</p> <p>Antes de empezar la creaci\u00f3n de la nueva m\u00e1quina, hemos copiado en el pool de almacenamiento ISO (directorio <code>~/iso</code>) una imagen ISO para la instalaci\u00f3n de Ubuntu:</p> <p></p> <p>Para crear una nueva m\u00e1quina virtual con virt-manager podemos escoger la opci\u00f3n de men\u00fa Archivo -&gt; Nueva m\u00e1quina virtual, o el bot\u00f3n del men\u00fa:</p> <p></p> <p>A continuaci\u00f3n seguimos los pasos del asistente para la creaci\u00f3n de la m\u00e1quina virtual:</p>"},{"location":"01.-KVM/04.-Creaci%C3%B3n%20de%20MV%20con%20virt-manager/02.-Creaci%C3%B3n%20de%20MV%20linux/#elegir-la-fuente-de-instalacion-del-sistema-operativo","title":"Elegir la fuente de instalaci\u00f3n del sistema operativo","text":"<p>Elegimos como fuente de instalaci\u00f3n: instalaci\u00f3n local desde una imagen ISO que se montar\u00e1 en un CDRON. En este apartado tambi\u00e9n podemos escoger la arquitectura de la m\u00e1quina que vamos a utilizar.</p> <p></p>"},{"location":"01.-KVM/04.-Creaci%C3%B3n%20de%20MV%20con%20virt-manager/02.-Creaci%C3%B3n%20de%20MV%20linux/#seleccionar-la-iso-de-instalacion","title":"Seleccionar la ISO de instalaci\u00f3n","text":"<p>Elegimos fichero ISO desde donde vamos a realizar la instalaci\u00f3n. Si no se detecta la variante del sistema operativo, tenemos que a\u00f1adirla manualmente escogiendo la versi\u00f3n m\u00e1s parecida a la que vamos a instalar.</p> <p></p>"},{"location":"01.-KVM/04.-Creaci%C3%B3n%20de%20MV%20con%20virt-manager/02.-Creaci%C3%B3n%20de%20MV%20linux/#configuracion-de-memoria-y-de-vcpu","title":"Configuraci\u00f3n de memoria y de VCPU","text":"<p>A continuaci\u00f3n, asignamos la memoria y el n\u00famero de vCPU a la nueva m\u00e1quina que estamos creando.</p> <p></p>"},{"location":"01.-KVM/04.-Creaci%C3%B3n%20de%20MV%20con%20virt-manager/02.-Creaci%C3%B3n%20de%20MV%20linux/#seleccionar-almacenamiento","title":"Seleccionar almacenamiento","text":"<p>En este paso, habilitamos el almacenamiento para la nueva m\u00e1quina, indicando el tama\u00f1o del disco.</p> <p></p>"},{"location":"01.-KVM/04.-Creaci%C3%B3n%20de%20MV%20con%20virt-manager/02.-Creaci%C3%B3n%20de%20MV%20linux/#resumen-y-seleccion-de-red","title":"Resumen y selecci\u00f3n de red","text":"<p>Por \u00faltimo, aparece un resumen de las caracter\u00edsticas de la m\u00e1quina que vamos a crear. Adem\u00e1s, podemos indicar el nombre y seleccionar la red a la que queremos que se conecte (en nuestro caso, la red de tipo NAT <code>default</code>). Si la red no est\u00e1 activa, nos dar\u00e1 la opci\u00f3n de activarla.</p> <p></p>"},{"location":"01.-KVM/04.-Creaci%C3%B3n%20de%20MV%20con%20virt-manager/02.-Creaci%C3%B3n%20de%20MV%20linux/#comenzamos-la-instalacion","title":"Comenzamos la instalaci\u00f3n","text":"<p>Al pulsar el bot\u00f3n Finalizar, se crea la m\u00e1quina, se inicializa y se abre la consola para que podamos empezar la instalaci\u00f3n.</p> <p></p>"},{"location":"01.-KVM/04.-Creaci%C3%B3n%20de%20MV%20con%20virt-manager/03.-Gesti%C3%B3n%20de%20MV/","title":"Gesti\u00f3n de m\u00e1quinas virtuales","text":"<p>Para elegir las distintas opciones que tenemos para gestionar nuestras m\u00e1quinas, pulsamos sobre el bot\u00f3n derecho en la m\u00e1quina:</p> <p></p> <ul> <li>Ejecutar: Si la m\u00e1quina est\u00e1 parada, la inicia. Tambi\u00e9n podemos usar el bot\u00f3n 1 del men\u00fa.</li> <li>Pausa: Pausa la ejecuci\u00f3n de la m\u00e1quina virtual. Podremos reanudar la ejecuci\u00f3n con la opci\u00f3n Reanudar. Tambi\u00e9n podemos usar el bot\u00f3n 2 del men\u00fa.</li> <li>Apagar: En este men\u00fa tenemos varias opciones (todas estas opciones tambi\u00e9n se pueden elegir en el bot\u00f3n 4 del men\u00fa):<ul> <li>Reiniciar: Reinicia la m\u00e1quina.</li> <li>Apagar: Apaga la m\u00e1quina. Tambi\u00e9n podemos usar el bot\u00f3n 3 del men\u00fa.</li> <li>Forzar Reajuste: Apaga la m\u00e1quina simulando que se pulsa el bot\u00f3n reset.</li> <li>Forzar apagado: Fuerza el apagado de la m\u00e1quina.</li> <li>Guardar: Guarda el estado de la m\u00e1quina en memoria. Para recuperar la m\u00e1quina escogemos la opci\u00f3n Reanudar.</li> </ul> </li> <li>Clonar: Crea una nueva m\u00e1quina a partir de esta.</li> <li>Migrar: Nos permite trasladar la m\u00e1quina a otra m\u00e1quina que este ejecutando QEMU/KVM.</li> <li>Eliminar: Elimina la definici\u00f3n de la m\u00e1quina. Nos da la opci\u00f3n de eliminar el volumen de disco asociado.</li> <li>Abrir: Abre el \"Detalle de la m\u00e1quina\". esta opci\u00f3n tambi\u00e9n se puede escoger desde el bot\u00f3n Abrir, o desde la opci\u00f3n del men\u00fa Editar -&gt; Detalles de la m\u00e1quina virtual. Esta opci\u00f3n la estudiaremos en el siguiente punto.</li> </ul>"},{"location":"01.-KVM/04.-Creaci%C3%B3n%20de%20MV%20con%20virt-manager/04.-Detalles%20de%20las%20MV/","title":"Detalles de las m\u00e1quinas virtuales","text":"<p>Podemos acceder al detalle de una m\u00e1quina virtual de tres formas distintas: haciendo doble click sobre la m\u00e1quina, escogiendo la m\u00e1quina y pulsando el bot\u00f3n Abrir o escogiendo la opci\u00f3n del men\u00fa Editar -&gt; Detalles de la m\u00e1quina virtual.</p> <p>Vamos a abrir una ventana con las siguientes opciones:</p> <p></p> <ul> <li>Archivo: Opciones generales: ver el gestor, cerrar la ventana,...</li> <li>M\u00e1quina Virtual: Opciones para gestionar la m\u00e1quina.</li> <li>Vista: Nos permite ver las distintas vistas, controlar la ventana de la consola (pantalla completa, escalar, ...). Veamos las vistas:<ul> <li>Consola: Accedemos a una consola donde controlamos la m\u00e1quina virtual. Tambi\u00e9n se accede con el bot\u00f3n 1.</li> <li>Detalles: Obtenemos la configuraci\u00f3n de la m\u00e1quina virtual y los dispositivos hardware. Podemos quitar y a\u00f1adir nuevos dispositivos y hacer las modificaciones necesarias.Tambi\u00e9n se accede con el bot\u00f3n 2.</li> <li>Instant\u00e1neas: Ventana para gestionar las instant\u00e1neas de la m\u00e1quina virtual. Estudiaremos m\u00e1s adelante las instant\u00e1neas. Tambi\u00e9n se accede con el bot\u00f3n 3.</li> </ul> </li> <li>Enviar Tecla: Combinaci\u00f3n de teclas que podemos enviar a la m\u00e1quina virtual.</li> </ul>"},{"location":"01.-KVM/04.-Creaci%C3%B3n%20de%20MV%20con%20virt-manager/04.-Detalles%20de%20las%20MV/#vista-consola","title":"Vista Consola","text":"<p>Accedemos a una consola desde donde podemos controlar la m\u00e1quina virtual. Desde el men\u00fa vista podemos configurar el tama\u00f1o de la pantalla (pantalla completa, escalar monitor, ...). Puede ser una buena herramienta para realizar peque\u00f1as modificaciones a la m\u00e1quina, pero es recomendable utilizar distintos protocolos para el acceso y gesti\u00f3n de la m\u00e1quina virtual (SSH, VCN, RDP,...)</p>"},{"location":"01.-KVM/04.-Creaci%C3%B3n%20de%20MV%20con%20virt-manager/04.-Detalles%20de%20las%20MV/#vista-detalles","title":"Vista Detalles","text":"<p>En esta vista se nos muestra la definici\u00f3n XML de la m\u00e1quina virtual de forma gr\u00e1fica. Adem\u00e1s, nos posibilita hacer cambios en la configuraci\u00f3n de la misma. Vemos la configuraci\u00f3n general de la m\u00e1quina y las caracter\u00edsticas de los dispositivos hardware que tiene configurada. Podemos quitas dispositivos y a\u00f1adir otros nuevos.</p> <p>Veamos los elementos fundamentales:</p> <ul> <li>Repaso: Nos da la informaci\u00f3n general de la m\u00e1quina virtual. </li> </ul> <p></p> <p>Adem\u00e1s, en todo momento podemos acceder a la definici\u00f3n XML:</p> <p></p> <ul> <li>CPUs: Configuraci\u00f3n de las vCPU asignadas a la m\u00e1quina. Podemos modificar este valor. Si la m\u00e1quina est\u00e1 ejecut\u00e1ndose la modificaci\u00f3n ser\u00e1 efectiva en el siguiente arranque de la m\u00e1quina.</li> </ul> <p></p> <ul> <li>Memoria: Del mismo modo, vemos la configuraci\u00f3n de asignaci\u00f3n de memoria RAM de la m\u00e1quina. Podemos modificar la memoria actual y la memoria m\u00e1xima. Del mismo modo, necesitamos reiniciar la m\u00e1quina para que tenga efecto el cambio.</li> </ul> <p></p> <ul> <li>Opciones de arranque: Podemos ver y configurar el orden de los dispositivos de arranque.</li> </ul> <p>Imagen de opciones de arranque</p> <p>A continuaci\u00f3n se nos muestra los distintos dispositivos hardware que tiene configurado la m\u00e1quina: unidades de disco, interfaces de red, teclado, rat\u00f3n, adaptador de v\u00eddeo, interfaces, ... Pudiendo hacer tambi\u00e9n, modificaciones en los mismos. Veamos algunos de ellos:</p> <ul> <li>Discos: Nos da informaci\u00f3n del disco que tiene configurada la m\u00e1quina. Es importante, como ya hemos indicado anteriormente, que el el driver sea VirtIO para obtener mayor rendimiento. Vemos que podemos a\u00f1adir a las m\u00e1quinas virtuales tantos discos como sean necesarios.</li> </ul> <p></p> <ul> <li>Interfaces de red: Obtenemos la informaci\u00f3n de las distintas interfaces de red de la m\u00e1quina. en este caso tambi\u00e9n usamos VirtIO como modelo de dispositivo. Vemos a que red est\u00e1 conectada. Si la m\u00e1quina se est\u00e1 ejecutando, podemos ver la direcci\u00f3n IP de la interfaz. Del mismo modo, los cambios ser\u00e1n efectivos tras el reinicio de la m\u00e1quina.</li> </ul> <p></p> <p>Por \u00faltimo, tenemos dos operaciones referente a los dispositivos hardware:</p> <ul> <li>Si seleccionamos uno de ellos, y pulsamos el bot\u00f3n derecho del rat\u00f3n nos da la posibilidad de Eliminar Hardware.</li> <li>Con el bot\u00f3n Agregar Hardware, tenemos la posibilidad de a\u00f1adir nuevos componentes a la configuraci\u00f3n de la m\u00e1quina. Hay que indicar que algunos dispositivos se pueden agregar \"en caliente\", con la m\u00e1quina en estado de ejecuci\u00f3n. En los pr\u00f3ximos apartados del curso usaremos est\u00e1 opci\u00f3n para a\u00f1adir nuevos componentes a nuestras m\u00e1quinas virtuales.</li> </ul> <p></p>"},{"location":"01.-KVM/04.-Creaci%C3%B3n%20de%20MV%20con%20virt-manager/05.-Creaci%C3%B3n%20de%20MV%20Wndows/","title":"Creaci\u00f3n de m\u00e1quinas virtuales Windows","text":"<p>En un apartado anterior hemos visto los pasos fundamentales para la creaci\u00f3n de una m\u00e1quina virtual Linux. Para crear una m\u00e1quina virtual con un sistema operativo tipo Windows se siguen los mismos pasos, pero tenemos que tener en cuenta que Windows no tiene soporte nativo para dispositivos VirtIO. Por lo tanto, a la hora de crear una m\u00e1quina virtual Windows tendremos que a\u00f1adir los controladores de dispositivos (drivers) necesarios para que Windows identifique los dispositivos VirtIO que definamos en la m\u00e1quina virtual.</p> <p>En este caso, el proyecto Fedora proporciona controladores de dispositivos de software libre para VirtIO en Windows.</p>"},{"location":"01.-KVM/04.-Creaci%C3%B3n%20de%20MV%20con%20virt-manager/05.-Creaci%C3%B3n%20de%20MV%20Wndows/#iso-de-los-controladores-de-dispositivo-virtio-para-windows","title":"ISO de los controladores de dispositivo VirtIO para Windows","text":"<p>Podemos bajar la \u00faltima versi\u00f3n de los drivers VirtIO para Windows en el siguiente enlace y copiar la ISO al pool de almacenamiento ISO, es decir, en el directorio <code>~/iso</code>. Tambi\u00e9n hemos copiado a ese directorio una ISO para la instalaci\u00f3n de Windows 10.</p> <p></p> <p>Creamos la nueva m\u00e1quina virtual Windows</p> <p>Teniendo en cuenta los siguiente:</p> <ul> <li>Elegimos una imagen ISO para instalar una versi\u00f3n de Windows y seleccionamos la variante del sistema operativo que estamos instalando.</li> <li>Configuramos la CPU y la RAM para tener recursos suficientes.</li> <li>Como estamos instalando un sistema operativo Windows, virt-manager va a configurar los dispositivos para que sean compatibles con el sistema operativo. En concreto, el driver del disco y de la tarjeta de red no ser\u00e1n VirtIO, con lo que no conseguiremos el rendimiento adecuado. Por lo tanto, antes de realizar la instalaci\u00f3n vamos a cambiar el tipo de driver de estos dispositivos, escogiendo VirtIO para obtener el m\u00e1ximo de rendimiento. </li> </ul> <p>En la pantalla final del asistente de creaci\u00f3n de la m\u00e1quina virtual, escogeremos la opci\u00f3n Personalizar la configuraci\u00f3n antes de instalar:</p> <p></p>"},{"location":"01.-KVM/04.-Creaci%C3%B3n%20de%20MV%20con%20virt-manager/05.-Creaci%C3%B3n%20de%20MV%20Wndows/#elegimos-dispositivos-virtio","title":"Elegimos dispositivos VirtIO","text":"<p>El primer cambio ser\u00e1 elegir el driver VirtIO para el disco. Como observamos se ha configurado con el driver SATA, que ser\u00e1 compatible con Windows, pero al ser un dispositivo emulado, nos dar\u00e1 menos rendimiento. Escogemos la opci\u00f3n VirtIO, y pulsamos en el bot\u00f3n Aplicar:</p> <p></p> <p>A continuaci\u00f3n, cambiamos el driver de la tarjeta de red. Del mismo modo, observamos que ha escogido un modelo e1000e, compatible con Windows, pero del mismo modo nos ofrece menos rendimiento que la opci\u00f3n VirtIO. cuando hagamos el cambio, volvemos a pulsar sobre el bot\u00f3n Aplicar. Nota: Como hemos comentado Windows no es compatible con este modelo de tarjeta de red, por lo que durante la instalaci\u00f3n no tendremos conexi\u00f3n a internet. Si necesitamos tener conexi\u00f3n, podr\u00edamos dejar el modelo escogido por defecto, y posteriormente modificar la configuraci\u00f3n de la tarjeta.</p> <p></p>"},{"location":"01.-KVM/04.-Creaci%C3%B3n%20de%20MV%20con%20virt-manager/05.-Creaci%C3%B3n%20de%20MV%20Wndows/#anadimos-un-cdrom-con-los-drivers-virtio","title":"A\u00f1adimos un CDROM con los drivers VirtIO","text":"<p>Antes de iniciar la m\u00e1quina, le a\u00f1adimos un CD-ROM con la imagen ISO de los drivers VirtIO. Para ello, pulsamos el bot\u00f3n Agregar Hardware, y a\u00f1adimos un nuevo dispositivo de almacenamiento:</p> <p></p> <p>Adem\u00e1s, nos tenemos que asegurar que en el orden de arranque el CDROM donde hemos montado la ISO de Windows est\u00e9 por delante que el CDROM con los drivers VirtIO, y sea la primera opci\u00f3n. Una vez terminado pulsamos el bot\u00f3n Aplicar y el bot\u00f3n Iniciar la instalaci\u00f3n para comenzar la instalaci\u00f3n.</p> <p></p>"},{"location":"01.-KVM/04.-Creaci%C3%B3n%20de%20MV%20con%20virt-manager/05.-Creaci%C3%B3n%20de%20MV%20Wndows/#comenzamos-la-instalacion","title":"Comenzamos la instalaci\u00f3n","text":"<p>Iniciamos la m\u00e1quina, accedemos a la consola y comenzamos la instalaci\u00f3n, hasta que llegamos a la pantalla donde tenemos que escoger el disco duro donde vamos a realizar la instalaci\u00f3n.</p> <p></p> <p>Como vemos no se puede detectar el disco duro, ya que Windows no puede reconocer inicialmente el controlador VirtIO. Vamos a cargar los controladores de dispositivo VirtIO que necesitamos del CDROM que hemos montado:</p> <p>Elegimos la opci\u00f3n Cargar contr., le damos a Examinar y elegimos del CDROM donde tenemos los drivers VirtIO la carpeta de nuestra arquitectura (amd64) y la versi\u00f3n de Windows.</p> <p></p> <p>Y ya podemos continuar con la instalaci\u00f3n de Windows porque ya detecta el disco duro:</p> <p></p>"},{"location":"01.-KVM/04.-Creaci%C3%B3n%20de%20MV%20con%20virt-manager/05.-Creaci%C3%B3n%20de%20MV%20Wndows/#configuracion-de-la-red","title":"Configuraci\u00f3n de la red","text":"<p>Como indic\u00e1bamos anteriormente, tambi\u00e9n hemos escogido el controlador VirtIO para la tarjeta de red. Una vez realizada la configuraci\u00f3n tendremos que instalar los drivers adecuados para que funcione la tarjeta de red. Para ello, actualizamos el controlador del dispositivo Controladora Ethernet en el Administrador de dispositivos:</p> <p></p> <p>Y escogemos la carpeta del CDROM donde hemos montado los drivers VirtIO: <code>NetKVM\\&lt;carpeta con el nombre de tu versi\u00f3n de windows&gt;\\amd64</code>:</p> <p></p>"},{"location":"01.-KVM/04.-Creaci%C3%B3n%20de%20MV%20con%20virt-manager/05.-Creaci%C3%B3n%20de%20MV%20Wndows/#creacion-de-una-maquina-virtual-windos-con-virt-install","title":"Creaci\u00f3n de una m\u00e1quina virtual Windos con virt-install","text":"<p>Si queremos crear con <code>virt-install</code> una m\u00e1quina virtual para la instalaci\u00f3n de Windows con la misma configuraci\u00f3n que hemos visto anteriormente, podemos ejecutar la siguiente instrucci\u00f3n:</p> <pre><code>virt-install --connect qemu:///system \\\n             --virt-type kvm \\\n             --name prueba4 \\\n             --cdrom ~/iso/Win10_21H2_Spanish_x64.iso \\\n             --os-variant win10 \\\n             --disk size=40,bus=virtio \\\n             --disk ~/iso/virtio-win-0.1.217.iso,device=cdrom \\\n             --network=default,model=virtio \\\n             --memory 2048 \\\n             --vcpus 2\n</code></pre> <p>Tenemos que tener en cuanta algunas cosas nuevas que hemos introducido:</p> <ul> <li><code>--disk size=40,bus=virtio</code>: En la declaraci\u00f3n del disco indicamos el controlador VirtIO.</li> <li><code>--disk ~/iso/virtio-win-0.1.217.iso,device=cdrom</code>: El segundo CDROM se indica con el par\u00e1metro <code>disk</code> indicando <code>device=cdrom</code>.</li> <li><code>--network=default,model=virtio</code>: De la misma manera, indicamos el modelo de tarjeta de red como VirtIO.</li> </ul>"},{"location":"01.-KVM/05.-Almacenamiento/01.-Introducci%C3%B3n%20al%20almacenamiento/","title":"01.-Introducci\u00f3n al almacenamiento","text":"<p>El almacenamiento en disco es una parte esencial en los sistemas inform\u00e1ticos, ya que permite guardar de forma persistente grandes cantidades de informaci\u00f3n.</p> <p>Veamos distintas caracter\u00edsticas del almacenamiento en discos:</p>"},{"location":"01.-KVM/05.-Almacenamiento/01.-Introducci%C3%B3n%20al%20almacenamiento/#sistemas-de-ficheros-vs-dispositivos-de-bloques","title":"Sistemas de Ficheros vs. Dispositivos de Bloques","text":"<ul> <li>Dispositivos de Bloques: <ul> <li>Son unidades (f\u00edsicas o l\u00f3gicas) de almacenamiento que gestionan los datos en bloques de tama\u00f1o fijo. </li> <li>Estos dispositivos permiten el acceso directo a cualquier bloque sin necesidad de leer todos los anteriores, lo que facilita la lectura y escritura aleatoria de datos. </li> <li>Estos dispositivos se pueden particionar, formatear, montar,...</li> <li>Ejemplos: Discos, particiones, vol\u00famenes l\u00f3gicos, ficheros llamados im\u00e1genes de discos (osi, img, raw, qcow2,...),...</li> </ul> </li> <li>Sistemas de ficheros:<ul> <li>El formateo de un dispositivo de bloque nos permite estructurarlo de forma l\u00f3gica (ficheros y directorios). Ejemplos: ext4, xfs, ntfs, btrfs, zfs, ...</li> <li>Proporcionan una interfaz que permite a los usuarios y aplicaciones almacenar, organizar y acceder a los archivos y directorios de manera sencilla.</li> </ul> </li> </ul>"},{"location":"01.-KVM/05.-Almacenamiento/01.-Introducci%C3%B3n%20al%20almacenamiento/#fuente-del-almacenamiento","title":"Fuente del almacenamiento","text":"<ul> <li>Si el disco est\u00e1 conectado directamente en el ordenador se denomina DAS (Direct Attached Storage).</li> <li>En otras ocasiones el almacenamiento se encuentra en un servidor y se comparte a un cliente. En este caso se denomina almacenamiento compartido, y tenemos dos alternativas:<ul> <li> <ul> <li>NAS (Network Attached Storage): Se comparte por red el almacenamiento en forma de sistema de ficheros. Ejemplos: nfs, samba, glusterfs,...</li> </ul> </li> <li>SAN (Storage Area Network): En una red de almacenamiento se comparte dispositivos de bloques. Ejemplo: iSCSI, FiberChanel,...</li> </ul> </li> </ul> <p>Dependiendo de la tecnolog\u00eda usada para realizar el almacenamiento compartido tendremos varias caracter\u00edsticas:</p> <ul> <li>NFS es un sistema de almacenamiento compartido de tipo NAS, que permite a varios clientes leer y escribir en los ficheros de un mismo directorio. Se pueden tener problemas  de corrupci\u00f3n de datos si dos clientes tratan al mismo tiempo de cambiar un mismo fichero.</li> <li>iSCSI es un sistema de almacenamiento compartido de tipo SAN, que nos permite compartir un dispositivo de bloque entre varios clientes. Si es uno s\u00f3lo de los clientes el que escribe y los dem\u00e1s leen, no hay ning\u00fan problema. Pero si queremos que todos los clientes tengan la posibilidad de leer y escribir, podemos tener problemas de corrupci\u00f3n. En estos casos es necesario usar sistemas de archivos de cl\u00fasteres que a\u00f1aden mecanismos de bloqueo para que no se pueda cambiar al mismo tiempo un fichero. Por ejemplo: cfs2, ocfs2, glusterFS, Ceph, ...</li> </ul>"},{"location":"01.-KVM/05.-Almacenamiento/01.-Introducci%C3%B3n%20al%20almacenamiento/#snapshots-instantaneas","title":"Snapshots (Instant\u00e1neas)","text":"<p>Los snapshots son una caracter\u00edstica avanzada de los sistemas de almacenamiento que permiten capturar el estado completo de un sistema de ficheros en un momento dado. Los snapshots son muy \u00fatiles para:</p> <ul> <li>Recuperaci\u00f3n ante fallos: Si se produce un fallo en el sistema, se puede restaurar el sistema de ficheros al estado en que se encontraba en el momento en que se tom\u00f3 la instant\u00e1nea.</li> <li>Pruebas y desarrollo: Los snapshots permiten hacer pruebas sin riesgo de da\u00f1ar los datos originales, ya que se puede volver a un estado anterior de forma r\u00e1pida.</li> </ul>"},{"location":"01.-KVM/05.-Almacenamiento/01.-Introducci%C3%B3n%20al%20almacenamiento/#aprovisionamiento-ligero-thin-provisioning","title":"Aprovisionamiento Ligero (Thin Provisioning)","text":"<p>El aprovisionamiento ligero es una t\u00e9cnica utilizada en sistemas de almacenamiento para optimizar la utilizaci\u00f3n del espacio disponible. En lugar de asignar todo el espacio de almacenamiento a una unidad o volumen desde el principio (lo que se conoce como aprovisionamiento grueso o thick provisioning), el aprovisionamiento ligero asigna espacio seg\u00fan sea necesario.</p> <p>Por ejemplo, podemos tener un dispositivo de almacenamiento de 30 GB (virtuales), pero que solo ocupa en disco (almacenamiento real) los datos que va guardando. Ejemplos: Im\u00e1genes de disco qcow2, thin-LVM,...</p>"},{"location":"01.-KVM/05.-Almacenamiento/02.-Introducci%C3%B3n%20al%20almacenamiento%20en%20QEMU%E2%81%84KVM%20%2B%20libvirt/","title":"02.-Introducci\u00f3n al almacenamiento en QEMU\u2044KVM + libvirt","text":"<p>Libvirt proporciona la gesti\u00f3n del almacenamiento a trav\u00e9s de pools de almacenamiento y vol\u00famenes.</p> <ul> <li>Pools de Almacenamiento: Es una fuente de almacenamiento, una cantidad de almacenamiento que el administrador del host ha configurado para su uso por las m\u00e1quinas virtuales.</li> <li>Vol\u00famenes: Los pools de almacenamiento se dividen en vol\u00famenes. Cada uno de estos vol\u00famenes lo utilizaran las m\u00e1quinas virtuales como discos (dispositivos de bloques).</li> </ul>"},{"location":"01.-KVM/05.-Almacenamiento/02.-Introducci%C3%B3n%20al%20almacenamiento%20en%20QEMU%E2%81%84KVM%20%2B%20libvirt/#tipos-de-pools-de-almacenamiento","title":"Tipos de Pools de Almacenamiento","text":"<p>QEMU/KVM + libvirt puede trabajar con distintas fuentes y tecnolog\u00edas de almacenamiento que nos ofrecer\u00e1n distintas caracter\u00edsticas:</p> <ul> <li> <p>dir: Nos ofrece un directorio del host (por lo tanto, nos ofrece un sistema de archivo). Este tipo no nos ofrece la caracter\u00edstica de almacenamiento compartido. Los discos de las m\u00e1quinas virtuales se guardaran en ficheros de imagen de disco. Tenemos distintos formatos de ficheros de im\u00e1genes:</p> <ul> <li>raw: el formato raw es una imagen binaria sencilla de la imagen del disco. Se ocupa todo el espacio que hayamos indicado al crearla. El acceso es m\u00e1s eficiente. No soporta ni snapshots ni aprovisionamiento ligero.</li> <li>qcow2: formato QEMU copy-on-write. Al crearse s\u00f3lo se ocupa el espacio que se est\u00e1 ocupando con los datos (aprovisionamiento ligero), el fichero ir\u00e1 creciendo cuando escribamos en el \u00e9l. Acepta instant\u00e1neas o snapshots. Es menos eficiente en cuanto al acceso.</li> <li>vdi, vmdk,...: formatos de otros sistemas de virtualizaci\u00f3n.</li> </ul> <p>En un Pool de Almacenamiento de tipo dir, los vol\u00famenes son ficheros de im\u00e1genes de disco. Los Pools de Almacenamiento con lo que hemos trabajado hasta ahora (<code>default</code> y <code>iso</code>) son de este tipo.</p> </li> <li> <p>logical: En este caso, utilizamos LVM (Logical Volume Manager). El Pool de Almacenamiento controlar\u00e1 un Grupo de Vol\u00famenes, y los vol\u00famenes (los discos de las m\u00e1quinas virtuales) ser\u00e1n vol\u00famenes l\u00f3gicos que se crear\u00e1n en el grupo de vol\u00famenes. Este tipo de almacenamiento no ofrece almacenamiento compartido.</p> </li> <li>netfs: Este tipo de Pool de Almacenamiento montar\u00e1 un directorio desde un servidor NAS (nfs, glusterfs, cifs,...). Por lo tanto obtendremos la caracter\u00edstica de compartici\u00f3n y de migraci\u00f3n en vivo. Los vol\u00famenes ser\u00e1n ficheros de im\u00e1genes de disco.</li> <li>iSCSI: Este tipo de Pool de Almacenamiento montar\u00e1 un disco desde un servidor SAN de tipo iSCSI. Obtendremos la caracter\u00edstica de almacenamiento compartido a nivel de disco con las consideraciones que vimos en el punto anterior.</li> <li>Muchos m\u00e1s...</li> </ul>"},{"location":"01.-KVM/05.-Almacenamiento/02.-Introducci%C3%B3n%20al%20almacenamiento%20en%20QEMU%E2%81%84KVM%20%2B%20libvirt/#gestion-de-volumenes-de-almacenamiento","title":"Gesti\u00f3n de vol\u00famenes de almacenamiento","text":"<p>Los vol\u00famenes son los medios de medios de almacenamiento que utilizar\u00e1n las m\u00e1quinas virtuales. Un Pool de Almacenamiento estar\u00e1 formado por vol\u00famenes. Dependiendo del tipo del pool, el volumen corresponder\u00e1 a un medio de almacenamiento determinado. Veamos un ejemplo:</p> <ul> <li>Si el tipo del pool es dir, es decir, un directorio del sistema de fichero del host, el volumen corresponde a un fichero (el fichero que contiene la imagen del disco).</li> <li>Si el tipo del pool es logical, es decir, gestiona un grupo de vol\u00famenes LVM, el volumen corresponder\u00e1 a un volumen l\u00f3gico LVM.</li> </ul> <p>Por lo tanto tenemos dos enfoques para crear los vol\u00famenes:</p> <ul> <li>Usar la API de libvirt, es decir, usar herramientas como <code>virsh</code> o <code>virt-manager</code> para gestionar los vol\u00famenes. En este caso, si creamos un volumen en un pool de tipo dir, estar\u00edamos creando un fichero de imagen de disco. Del mismo modo, si lo creamos en un pool de tipo logical estar\u00edamos creando un volumen l\u00f3gico LVM.</li> <li>Utilizar herramientas espec\u00edficas para crear los medios de almacenamiento y posteriormente refrescar el pool para que a\u00f1ada el nuevo volumen. Ejemplo: podemos usar la herramienta <code>qemu-img</code> para la creaci\u00f3n de un fichero de imagen de disco y posteriormente actualizaremos el pool de tipo dir para a\u00f1adir el nuevo volumen que corresponde al fichero que hemos creado. Otro ejemplo: usar la l\u00ednea de comandos de LVM, creando un volumen l\u00f3gico con el comando <code>lvcreate</code> y posteriormente actualizamos el pool de tipo logical para a\u00f1adir el nuevo volumen.</li> </ul> <p>Si estamos trabajando localmente en un servidor donde tenemos QEMU/KVM + libvirt instalado, no hay muchas diferencias de usar una y otra opci\u00f3n. El uso de la API de libvirt puede ser m\u00e1s interesante si estamos conectados a la API de libvirt de forma remota, ya que al gestionar los vol\u00famenes estar\u00edamos gestionando los recursos de almacenamiento (ficheros, vol\u00famenes l\u00f3gicos,...) sin necesidad de acceder al servidor y crearlos con herramientas espec\u00edficas.</p>"},{"location":"01.-KVM/05.-Almacenamiento/02.-Introducci%C3%B3n%20al%20almacenamiento%20en%20QEMU%E2%81%84KVM%20%2B%20libvirt/#conclusiones","title":"Conclusiones","text":"<p>Tenemos la posibilidad de crear distintos tipos de Pools de Almacenamiento, que nos ofrecen distintas caracter\u00edsticas. Podemos ver los distintos tipos al crear un Pool desde <code>virt-manager</code>:</p> <p></p> <p>En este curso vamos a trabajar con los Pool de Almacenamiento de tipo dir. Si quieres profundizar en las caracter\u00edsticas de los distintos tipos de almacenamiento puedes ver la documentaci\u00f3n oficial: Storage Management.</p>"},{"location":"01.-KVM/05.-Almacenamiento/03.-Gesti%C3%B3n%20de%20Pools%20de%20Almacenamiento/","title":"03.-Gesti\u00f3n de Pools de Almacenamiento","text":""},{"location":"01.-KVM/05.-Almacenamiento/03.-Gesti%C3%B3n%20de%20Pools%20de%20Almacenamiento/#gestion-de-pools-de-almacenamiento-con-virsh","title":"Gesti\u00f3n de Pools de Almacenamiento con virsh","text":"<p>Como hemos visto durante este curso tenemos a nuestra disposici\u00f3n dos Pool de Almacenamiento, para ver los pools con la herramienta <code>virsh</code>, ejecutamos la siguiente instrucci\u00f3n:</p> <pre><code>virsh -c qemu:///system pool-list \n Nombre    Estado   Inicio autom\u00e1tico\n---------------------------------------\n default   activo   si\n iso       activo   si\n</code></pre> <p>Recuerda que el pool por defecto donde se guardan las im\u00e1genes de disco, es <code>default</code>. Podemos obtener informaci\u00f3n de ese pool con la instrucci\u00f3n:</p> <pre><code>virsh -c qemu:///system pool-info default \nNombre:         default\nUUID:           0a03e05b-8844-4029-8216-430fc289fe8f\nEstado:         ejecutando\nPersistente:    si\nAutoinicio:     si\nCapacidad:      87,09 GiB\nUbicaci\u00f3n:     36,61 GiB\nDisponible:     50,48 GiB\n</code></pre> <p>Al igual que las m\u00e1quinas virtuales, los Pools de Almacenamiento se definen por un documento XML. Para ver la definici\u00f3n XML del pool <code>default</code> podemos ejecutar <code>virsh -c qemu:///system pool-dumpxml default</code>. A partir de un fichero XML con la definici\u00f3n de un nuevo pool, podr\u00edamos crearlo con el subcomando <code>virsh pool-define</code>. </p> <p>Nota: Para profundizar en el formato XML que define los Pools de Almacenamiento puedes consultar la documentaci\u00f3n oficial: Storage pool and volume XML format.</p> <p>Sin embargo, vamos a usar otro comando que nos permite indicar la informaci\u00f3n del nuevo pool por medio de par\u00e1metros. Vamos a crear un nuevo pool que vamos a llamar <code>mv-images</code>, de tipo dir y cuyo directorio ser\u00e1 <code>/srv/images</code>. Supongamos que hemos a\u00f1adido m\u00e1s almacenamiento al host y que hemos montado el disco en el directorio <code>/srv/images</code> y queremos guardar las im\u00e1genes de disco en esa nueva localizaci\u00f3n. Para crear el nuevo pool, de forma persistente ejecutamos:</p> <pre><code>virsh -c qemu:///system pool-define-as vm-images dir --target /srv/images\nEl grupo vm-images ha sido definido\n</code></pre> <p>Nota: Si utilizamos <code>pool-create</code> o <code>pool-create-as</code>, el pool se crea temporalmente, no ser\u00e1 persistente y despu\u00e9s de un reinicio del host no existir\u00e1.</p> <p>A continuaci\u00f3n creamos el directorio indicado, con la instrucci\u00f3n:</p> <pre><code>virsh -c qemu:///system pool-build vm-images \nEl pool vm-images ha sido compilado\n</code></pre> <p>Ahora debemos iniciar el pool:</p> <pre><code>virsh -c qemu:///system pool-start vm-images \nSe ha iniciado el grupo vm-images\n</code></pre> <p>Y si lo deseamos lo podemos auto iniciar, para que en el reinicio del host vuelva a estar activo:</p> <pre><code>virsh -c qemu:///system pool-autostart vm-images \nSe ha iniciado el grupo vm-images\n</code></pre> <p>Finalmente vemos la lista de pool y pedimos informaci\u00f3n del nuevo pool:</p> <pre><code>virsh -c qemu:///system pool-list\n Nombre      Estado   Inicio autom\u00e1tico\n-----------------------------------------\n default     activo   si\n iso         activo   si\n vm-images   activo   si\n\nvirsh -c qemu:///system pool-info vm-images \nNombre:         vm-images\nUUID:           a9eb290a-9973-47ea-b616-0907a5df8ea2\nEstado:         ejecutando\nPersistente:    si\nAutoinicio:     si\n...\n</code></pre> <p>Ya podemos usar este pool de almacenamiento para guardar ficheros de im\u00e1genes de disco. Si en alg\u00fan momento queremos eliminarlo, es recomendable pararlo:</p> <pre><code>virsh -c qemu:///system pool-destroy vm-images \nEl grupo vm-images ha sido destruid\n</code></pre> <p>A continuaci\u00f3n, opcionalmente, podemos borrar el directorio creado:</p> <pre><code>virsh -c qemu:///system pool-delete vm-images \nEl grupo vm-images ha sido eliminado\n</code></pre> <p>Y por \u00faltimo lo eliminamos:</p> <pre><code>virsh -c qemu:///system pool-undefine vm-images \nSe ha quitado la definici\u00f3n del grupo vm-images\n</code></pre>"},{"location":"01.-KVM/05.-Almacenamiento/03.-Gesti%C3%B3n%20de%20Pools%20de%20Almacenamiento/#gestion-de-pools-de-almacenamiento-con-virt-manager","title":"Gesti\u00f3n de Pools de Almacenamiento con virt-manager","text":"<p>Desde la pesta\u00f1a Almacenamiento de los Detalles de la conexi\u00f3n podemos ver los pools que tenemos creados y podemos gestionarlos:</p> <p></p> <p>Tenemos las siguientes opciones:</p> <ul> <li>Bot\u00f3n 1: A\u00f1adir un nuevo pool.</li> <li>Bot\u00f3n 2: Iniciar el pool seleccionado.</li> <li>Bot\u00f3n 3: Parar el pool seleccionado.</li> <li>Bot\u00f3n 4: Eliminar el pool seleccionado.</li> </ul> <p>Si creamos un nuevo pool, vemos la siguiente pantalla donde indicamos el nombre, el tipo y en el caso del tipo dir, el directorio:</p> <p></p> <p>Una vez creado, observamos que est\u00e1 iniciado y que tiene marcada como activa la propiedad de autoiniciar:</p> <p></p> <p>Por \u00faltimo, recordar que desde <code>virt-manager</code> podemos ver la definici\u00f3n XML de los recursos con los que trabajamos:</p> <p></p>"},{"location":"01.-KVM/05.-Almacenamiento/04.-Gesti%C3%B3n%20de%20vol%C3%BAmenes%20de%20almacenamiento%20con%20libvirt/","title":"04.-Gesti\u00f3n de vol\u00famenes de almacenamiento con libvirt","text":"<p>En este apartado vamos a estudiar la gesti\u00f3n de vol\u00famenes de almacenamiento usando la API de libvirt, por lo tanto, utilizando herramientas como <code>virsh</code> o <code>virt-manager</code>. </p> <p>Vamos a trabajar con los Pool de Almacenamiento que hemos creado que son de tipo dir, por lo tanto los vol\u00famenes corresponden a ficheros de im\u00e1genes de disco. Para estos ejemplos, utilizaremos el formato de imagen qcow2.</p>"},{"location":"01.-KVM/05.-Almacenamiento/04.-Gesti%C3%B3n%20de%20vol%C3%BAmenes%20de%20almacenamiento%20con%20libvirt/#gestion-de-volumenes-de-almacenamiento-con-virsh","title":"Gesti\u00f3n de vol\u00famenes de almacenamiento con virsh","text":"<p>Para obtener los vol\u00famenes de un determinado pool (por ejemplo el pool <code>default</code>), ejecutamos:</p> <pre><code>virsh -c qemu:///system vol-list default\n Nombre            Ruta\n------------------------------------------------------------\n prueba1.qcow2   /var/lib/libvirt/images/prueba1.qcow2\n prueba2.qcow2   /var/lib/libvirt/images/prueba2.qcow2\n win10.qcow2     /var/lib/libvirt/images/win10.qcow2\n</code></pre> <p>Podemos comprobar que los vol\u00famenes listados se corresponden con ficheros que se encuentran en el directorio del pool <code>default</code> (<code>/var/lib/libvirt/images</code>).</p> <p>Al estar utilizando el formato de imagen <code>qcow2</code>, obtenemos la caracter\u00edstica de aprovisionamiento ligero, el fichero tiene un tama\u00f1o virtual (el que hemos indicado en su creaci\u00f3n y el que ver\u00e1 la m\u00e1quina virtual que lo utilice) y el espacio ocupado en el disco del host (que ir\u00e1 creciendo conforme vayamos guardando informaci\u00f3n en la imagen). Podemos ver esta caracter\u00edstica ejecutando la siguiente instrucci\u00f3n:</p> <pre><code>virsh -c qemu:///system vol-list default --details\n Nombre            Ruta                                      Tipo      Capacidad   Alojamiento\n------------------------------------------------------------------------------------------------\n prueba1.qcow2   /var/lib/libvirt/images/prueba1.qcow2   archivo   10,00 GiB   2,06 GiB\n prueba2.qcow2   /var/lib/libvirt/images/prueba2.qcow2   archivo   20,00 GiB   9,99 GiB\n win10.qcow2     /var/lib/libvirt/images/win10.qcow2     archivo   40,00 GiB   10,06 GiB\n\n</code></pre> <p>Podemos obtener la informaci\u00f3n de un determinado volumen de un pool, ejecutando:</p> <pre><code>virsh -c qemu:///system vol-info prueba1.qcow2 default\nNombre:         prueba1.qcow2\nTipo:           archivo\nCapacidad:      10,00 GiB\nUbicaci\u00f3n:     2,06 GiB\n</code></pre> <p>De la misma forma que los pools, los vol\u00famenes est\u00e1n definidos en libvirt con el formato XML. Para ver la definici\u00f3n XML del volumen <code>vol.qcow2</code> del pool <code>default</code>, podemos ejecutar <code>virsh -c qemu:///system vol-dumpxml vol.qcow2 default</code>. A partir de un fichero XML con la definici\u00f3n de un nuevo volumen, podr\u00edamos crearlo con el comando <code>virsh vol-create</code>. Nota: En este caso no existe el comandos <code>virsh vol-define</code>, ya que los vol\u00famenes no se pueden crear temporalmente.</p> <p>Nota: Para profundizar en el formato XML que define los vol\u00famenes puedes consultar la documentaci\u00f3n oficial: Storage pool and volume XML format.</p> <p>Sin embargo, vamos a usar otro comando que nos permite indicar la informaci\u00f3n del nuevo volumen por medio de par\u00e1metros. Vamos a crear un nuevo volumen en el pool <code>default</code>, cuyo nombre ser\u00e1 <code>vol1.qcow2</code>, formato <code>qcow2</code> y tama\u00f1o de 10GB:</p> <pre><code>virsh -c qemu:///system vol-create-as default vol1.qcow2 --format qcow2 10G \nSe ha creado el volumen vol1.qcow2\n</code></pre> <p>Podemos comprobar que se ha creado un nuevo fichero de imagen:</p> <pre><code>sudo ls -l /var/lib/libvirt/images/\n...\n-rw------- 1 root         root              196768 may 26 09:24 vol1.qcow2\n...\n</code></pre> <p>Tambi\u00e9n podemos volver a ejecutar <code>virsh -c qemu:///system vol-list default</code> para comprobar que se ha creado el volumen.</p> <p>Para borrar un volumen, ejecutamos:</p> <pre><code>virsh -c qemu:///system vol-delete vol1.qcow2 default\nSe ha eliminando el volumen vol1.qcow2\n</code></pre> <p>Tenemos a nuestra disposici\u00f3n m\u00e1s operaciones sobre los vol\u00famenes, estudiaremos algunas de ellas en apartados posteriores: <code>vol-clone</code>: para clonar el volumen, <code>vol-resize</code>: para redimensionar, <code>vol-download</code>: para descargar el volumen en un fichero, <code>vol-upload</code>: para cargar informaci\u00f3n a un volumen desde un fichero,...</p> <p>Nota: Hay que recordar que todas estas operaciones se realizan sobre vol\u00famenes, y por tanto el medio de almacenamiento que gestionan depender\u00e1n del tipo del pool con el que estemos trabajando. De esta forma, un <code>vol-create-as</code> en un pool de tipo logical crear\u00eda un volumen l\u00f3gico LVM.</p>"},{"location":"01.-KVM/05.-Almacenamiento/04.-Gesti%C3%B3n%20de%20vol%C3%BAmenes%20de%20almacenamiento%20con%20libvirt/#gestion-de-volumenes-de-almacenamiento-con-virt-manager","title":"Gesti\u00f3n de vol\u00famenes de almacenamiento con virt-manager","text":"<p>Desde la pesta\u00f1a Almacenamiento de los Detalles de la conexi\u00f3n podemos ver los pools y los vol\u00famenes que tenemos creados y podemos gestionarlos:</p> <p></p> <p>Tenemos las siguientes opciones relacionadas con los vol\u00famenes:</p> <ul> <li>Bot\u00f3n 1: A\u00f1adir un nuevo volumen en el pool seleccionado.</li> <li>Bot\u00f3n 2: Refrescar el pool seleccionado. Actualiza el contenido del pool para incluir los vol\u00famenes que se han creado o modificado con herramientas espec\u00edficas.</li> <li>Bot\u00f3n 3: Eliminar el volumen seleccionado.</li> </ul> <p>Si creamos un nuevo volumen, vemos la siguiente pantalla donde indicamos la siguiente informaci\u00f3n (la informaci\u00f3n solicitada depender\u00e1 del tipo de pool con el que estemos trabajando):</p> <ul> <li>El nombre del volumen.</li> <li>El formato: qcow2 o raw.</li> <li>Backing store: Nos proporciona la caracter\u00edstica de crear vol\u00famenes a partir de un volumen base o imagen base. Lo estudiaremos m\u00e1s adelante en el curso.</li> <li>Capacidad: Indicamos el tama\u00f1o del volumen. Por defecto, si usamos el formato qcow2 obtendremos la caracter\u00edstica de aprovisionamiento ligero, el tama\u00f1o indicado ser\u00e1 el que ve la m\u00e1quina virtual, pero no lo que se ocupa realmente en el disco del host. Si elegimos la opci\u00f3n Allocate entire volume now, se perder\u00e1 esa caracter\u00edstica y se ocupara el disco la capacidad total elegida.</li> </ul> <p></p>"},{"location":"01.-KVM/05.-Almacenamiento/05.-Gesti%C3%B3n%20de%20vol%C3%BAmenes%20de%20almacenamiento%20con%20herramientas%20espec%C3%ADficas/","title":"05.-Gesti\u00f3n de vol\u00famenes de almacenamiento con herramientas espec\u00edficas","text":"<p>En este apartado vamos a gestionar los vol\u00famenes con herramienta especificas. Es decir, si estamos trabajando con un pool de tipo dir y con vol\u00famenes que corresponde a ficheros de im\u00e1genes de disco, vamos a trabajar con la herramienta <code>qemu-img</code>. Esta potente herramienta nos permite la gesti\u00f3n completa de los ficheros de im\u00e1genes de disco.</p>"},{"location":"01.-KVM/05.-Almacenamiento/05.-Gesti%C3%B3n%20de%20vol%C3%BAmenes%20de%20almacenamiento%20con%20herramientas%20espec%C3%ADficas/#gestion-de-imagenes-de-disco-con-qemu-img","title":"Gesti\u00f3n de im\u00e1genes de disco con qemu-img","text":"<p>La herramienta <code>qemu-img</code> es una utilidad para gestionar ficheros de imagen de disco. Puedes profundizar en el uso de esta herramienta consultando la documentaci\u00f3n oficial: QEMU disk image utility.</p> <p>Vamos a crear un nuevo fichero de imagen llamado <code>vol2.qcow2</code>, con el formato <code>qcow2</code>, con un tama\u00f1o de 2GB, en el directorio <code>/srv/images</code>, correspondiente al pool <code>vm-images</code>, que creamos en un apartado anterior (si quisi\u00e9ramos trabajar con el pool <code>default</code> trabajar\u00edamos en el directorio <code>/var/lib/libvirt/images</code>).</p> <pre><code>cd /srv/images/\nqemu-img create -f qcow2 vol2.qcow2 2G\nFormatting 'vol2.qcow2', fmt=qcow2 cluster_size=65536 extended_l2=off compression_type=zlib size=2147483648 lazy_refcounts=off refcount_bits=16\n\n</code></pre> <p>Podemos obtener informaci\u00f3n de la imagen que hemos creado, ejecutando en el mismo directorio:</p> <pre><code>qemu-img info vol2.qcow2\nimage: vol2.qcow2\nfile format: qcow2\nvirtual size: 2 GiB (2147483648 bytes)\ndisk size: 196 KiB\ncluster_size: 65536\nFormat specific information:\n    compat: 1.1\n    compression type: zlib\n    lazy refcounts: false\n    refcount bits: 16\n    corrupt: false\n    extended l2: false\n</code></pre> <p>La creaci\u00f3n del fichero de imagen, no conlleva de forma autom\u00e1tica la creaci\u00f3n del volumen en el pool de almacenamiento. Si vemos la lista de vol\u00famenes en el pool <code>vm-images</code> comprobamos que no se ha creado:</p> <pre><code>virsh -c qemu:///system vol-list vm-images\n Nombre            Ruta\n------------------------------------------------------------\n</code></pre> <p>Para que se cree un nuevo volumen a partir del fichero que hemos creado, necesitamos refrescar el pool, para ello:</p> <pre><code>virsh -c qemu:///system pool-refresh vm-images\nEl grupo vm-images ha sido actualizado\n</code></pre> <p>Y comprobamos que ya tenemos el volumen creado ejecutando: <code>virsh -c qemu:///system vol-list vm-images</code>.</p> <p>Para refrescar un pool desde <code>virt-manager</code> usamos el siguiente bot\u00f3n:</p> <p></p> <p>La herramienta <code>qemu-img</code> es muy potente y nos permite realizar muchas operaciones: redimensionar el fichero de imagen, convertir entre formatos de im\u00e1genes, crear im\u00e1genes a a partir de im\u00e1genes base, crear instant\u00e1neas de im\u00e1genes, ... Utilizaremos algunas de estas funciones en apartados posteriores del curso.</p> <p>Nota: Si estuvi\u00e9ramos trabajando con otro tipo de Pool de Almacenamiento, tendr\u00e1imos que usar herramientas especificar para gestionar los medios de almacenamientos adecuados. Por ejemplo, si estuvi\u00e9ramos trabajando con un pool de tipo logical, usar\u00edamos las herramientas de comando de LVM para crear y gestionar los vol\u00famenes l\u00f3gicos que se corresponder\u00edan con los vol\u00famenes de este tipo de pool.</p>"},{"location":"01.-KVM/05.-Almacenamiento/06.-Trabajar%20con%20vol%C3%BAmenes%20en%20las%20m%C3%A1quinas%20virtuales/","title":"06.-Trabajar con vol\u00famenes en las m\u00e1quinas virtuales","text":"<p>En la creaci\u00f3n de las m\u00e1quinas virtuales que estudiamos en el m\u00f3dulo anterior, se creaba el volumen que se asociaba a la m\u00e1quina como disco principal.</p> <p>Sin embargo, en este apartado vamos a aprender algunas cosas nuevas: crear nuevas m\u00e1quinas virtuales pero usando vol\u00famenes que hayamos creado anteriormente, a\u00f1adir nuevos discos a las m\u00e1quinas virtuales y redimensioanrlos para aumentar el espacio de almacenamiento.</p>"},{"location":"01.-KVM/05.-Almacenamiento/06.-Trabajar%20con%20vol%C3%BAmenes%20en%20las%20m%C3%A1quinas%20virtuales/#creacion-de-maquinas-virtuales-usando-volumenes-existentes","title":"Creaci\u00f3n de m\u00e1quinas virtuales usando vol\u00famenes existentes","text":"<p>En apartados anterior creamos un volumen de 10 GB llamado <code>vol1.qcow2</code>. Vamos a crear una nueva m\u00e1quina virtual que tenga como disco duro este volumen.</p>"},{"location":"01.-KVM/05.-Almacenamiento/06.-Trabajar%20con%20vol%C3%BAmenes%20en%20las%20m%C3%A1quinas%20virtuales/#con-virt-install","title":"Con <code>virt-install</code>","text":"<p>Si los hacemos con <code>virt-install</code>:</p> <pre><code>virt-install --connect qemu:///system \\\n             --virt-type kvm \\\n             --name prueba4 \\\n             --cdrom ~/iso/debian-11.3.0-amd64-netinst.iso \\\n             --os-variant debian10 \\\n             --disk vol=default/vol1.qcow2 \\\n             --memory 1024 \\\n             --vcpus 1\n\n</code></pre> <p>Hemos utilizado la opci\u00f3n <code>--disk vol=default/vol1.qcow2</code>, indicando el volumen usando el formato <code>pool/volumen</code>. Otras opciones que podr\u00edamos poner ser\u00edan:</p> <ul> <li><code>--disk path=/var/lib/libvirt/images/vol1.qcow2</code>: Donde indicamos directamente la ruta donde se encuentra el fichero de imagen de disco.</li> <li><code>--pool wm-images,size=10</code>: En este caso no se reutiliza el volumen que tenemos creado, sino que se crear\u00eda un nuevo volumen de 10GB en el pool indicado.</li> </ul>"},{"location":"01.-KVM/05.-Almacenamiento/06.-Trabajar%20con%20vol%C3%BAmenes%20en%20las%20m%C3%A1quinas%20virtuales/#con-virt-manager","title":"Con <code>virt-manager</code>","text":"<p>Si utilizamos <code>virt-manager</code>, para crear la nueva m\u00e1quina, durante el asistente de creaci\u00f3n de la m\u00e1quina, elegimos el volumen que tenemos creado:</p> <p></p>"},{"location":"01.-KVM/05.-Almacenamiento/06.-Trabajar%20con%20vol%C3%BAmenes%20en%20las%20m%C3%A1quinas%20virtuales/#anadir-nuevos-discos-a-maquinas-virtuales","title":"A\u00f1adir nuevos discos a m\u00e1quinas virtuales","text":"<p>Para a\u00f1adir un disco a una m\u00e1quina virtual, vamos a modificar su definici\u00f3n XML. Podr\u00edamos usar <code>virsh edit</code> e incluir la definici\u00f3n XML del nuevo disco. Sin embargo, vamos a usar un comando de <code>virsh</code> que nos facilita la operaci\u00f3n de a\u00f1adir un nuevo disco y por tanto, la modificaci\u00f3n de la definici\u00f3n XML de la m\u00e1quina. Hay que indicar que esta modificaci\u00f3n se puede hacer \"en caliente\", con la m\u00e1quina funcionando.</p> <p>Por lo tanto, vamos a\u00f1adir el volumen <code>vol2.qcow2</code> que creamos en el apartado anterior, a la m\u00e1quina que hemos creado en estado de ejecuci\u00f3n, ejecutamos:</p> <pre><code>virsh -c qemu:///system attach-disk prueba4 /srv/images/vol2.qcow2 vdb --driver=qemu --type disk --subdriver qcow2 --persistent\nEl disco ha sido asociado exitosamente\n</code></pre> <p>Indicamos el nombre de la m\u00e1quina, el path del fichero de imagen, el dispositivo de bloque que se va a crear, indicamos el driver, el tipo que ser\u00e1 un disco, y el formato de la imagen que se va a a\u00f1adir. Por \u00faltimo, con la opci\u00f3n <code>--persistent</code> hacemos el cambio de forma persistente, para que en el pr\u00f3ximo reinicio de la m\u00e1quina se vuelva a a\u00f1adir el disco.</p> <p>Tambi\u00e9n lo podemos hacer desde <code>virt-manager</code>. Si a\u00f1adimos nuevo hardware en la vista detalle de la m\u00e1quina, podemos a\u00f1adir nuevo almacenamiento:</p> <p></p> <p>Como hemos comentado la m\u00e1quina <code>prueba4</code> est\u00e1 en ejecuci\u00f3n y podemos comprobar que se ha a\u00f1adido el disco:</p> <p></p> <p>Y podr\u00edamos formatear, montar y usar el nuevo disco:</p> <p></p> <p>Para desconectar un disco de una m\u00e1quina virtual podemos ejecutar:</p> <pre><code>virsh -c qemu:///system detach-disk prueba4 vdb --persistent\nEl disco ha sido desmontado exitosamente\n</code></pre> <p>Indicando la m\u00e1quina virtual, el dispositivo que se hab\u00eda creado y la opci\u00f3n para que sea un cambio persistente.</p> <p>Desde <code>virt-manager</code> simplemente pulsar\u00edamos con el bot\u00f3n derecho sobre el dispositivo de disco en la vista detalle, y pulsar\u00edamos sobre Eliminar Hardware.</p>"},{"location":"01.-KVM/05.-Almacenamiento/06.-Trabajar%20con%20vol%C3%BAmenes%20en%20las%20m%C3%A1quinas%20virtuales/#redimension-de-discos-en-maquinas-virtuales","title":"Redimensi\u00f3n de discos en m\u00e1quinas virtuales","text":"<p>Antes de desconectar el disco de la m\u00e1quina, vamos a realizar una operaci\u00f3n de redimensi\u00f3n. Vamos a aumentar el tama\u00f1o del volumen, por lo que la m\u00e1quina ver\u00e1 un disco m\u00e1s grande, pero hay que recordar que tambi\u00e9n tendremos que redimensionar el sistemas de ficheros.</p> <p>Para realizar la redimensi\u00f3n tenemos dos alternativas: o usar la API de libvirt usando, por ejemplo <code>virsh</code> o usar herramientas especificas, en este caso <code>qemu-img</code>.</p> <p>Para redimensionar el volumen de una m\u00e1quina que este parada, podemos usar <code>virsh</code>:</p> <pre><code>virsh -c qemu:///system vol-resize vol2.qcow2 3G --pool vm-images\nEl tama\u00f1o de volumen 'vol2.qcow2' se ha cambiado correctamente a 3G\n</code></pre> <p>O podemos usar <code>qemu-img</code>, se ejecuta con un usuario con privilegios o con <code>sudo</code>:</p> <pre><code>sudo qemu-img resize /srv/images/vol2.qcow2 3G\nImage resized.\n</code></pre> <p>Para hacer la redimensi\u00f3n \"en caliente\", con la m\u00e1quina encendida, podemos obtener informaci\u00f3n de los discos conectados a una m\u00e1quina:</p> <pre><code>virsh -c qemu:///system domblklist prueba4 \n Destino   Fuente\n-----------------------------------------------\n vda       /var/lib/libvirt/images/vol1.qcow2\n vdb       /srv/images/vol2.qcow2\n</code></pre> <p>Y continuaci\u00f3n redimensionamos el disco deseado:</p> <pre><code>virsh -c qemu:///system blockresize prueba4 /srv/images/vol2.qcow2 3G\nEl dispositivo de bloque '/srv/images/vol2.qcow2' cambi\u00f3 de tama\u00f1o\n</code></pre> <p>Podemos comprobar que se ha producido la redimensi\u00f3n en el disco de la m\u00e1quina:</p> <p></p> <ol> <li>El disco ahora tiene 3GB.</li> <li>Pero el sistema de archivo sigue teneido 2Gb. </li> <li>Desmontamos el disco, y lo redimensionamos con <code>resize2fs</code>.</li> <li>Volvemos a montarlo y comprobamos que ahora ya tiene los 3Gb.</li> </ol>"},{"location":"01.-KVM/05.-Almacenamiento/06.-Trabajar%20con%20vol%C3%BAmenes%20en%20las%20m%C3%A1quinas%20virtuales/#redimension-del-sistema-de-ficheros-de-una-imagen-de-disco","title":"Redimensi\u00f3n del sistema de ficheros de una imagen de disco","text":"<p>Otra alternativa para redimensionar el sistema de fichero de una imagen es usar la herramienta virt-resize. <code>virt-resize</code> no trabaja sobre im\u00e1genes de discos de m\u00e1quinas que se est\u00e9n ejecutando, adem\u00e1s no puede redimensionar sobre el mismo fichero de la imagen, por lo que vamos a hacer una copia del mismo.</p> <p>Si tenemos un fichero qcow2 que se llama <code>vol1.qcow</code>, podemos redimensionar el disco y su sistema de ficheros con al siguientes instrucciones:</p> <pre><code>qemu-img resize vol1.qcow2 10G\ncp vol1.qcow2 newvol1.qcow2\nvirt-resize --expand /dev/sda1 vol1.qcow2 newvol1.qcow2\nmv newvol1.qcow2 vol1.qcow2\n</code></pre> <p>Resimensionamos el disco, como vimos en el apartado anterior. Como hemos indicado <code>virt-resize</code> no trabaja sobre un fichero qcow2 directamente, es por ello que lo hemos copiado a otro fichero y hemos ejecutado el comando. Finalmente el fichero <code>nwevol1.qcow2</code> tendr\u00e1 un sistema de ficheros de 10Gb, por lo que terminamos copi\u00e1ndolo de nuevo (con el <code>mv</code>) sobre el disco original.</p>"},{"location":"01.-KVM/06.-Clonaci%C3%B3n%20y%20Snapshots/01.-Clonaci%C3%B3n%20de%20m%C3%A1quinas%20virtuales/","title":"01.-Clonaci\u00f3n de m\u00e1quinas virtuales","text":"<p>La clonaci\u00f3n de una m\u00e1quina virtual copia la configuraci\u00f3n XML de la m\u00e1quina de origen y sus im\u00e1genes de disco, y realiza ajustes en las configuraciones para asegurar la unicidad de la nueva m\u00e1quina. Esto incluye cambiar el nombre de la m\u00e1quina y asegurarse de que utiliza los clones de las im\u00e1genes de disco. No obstante, los datos almacenados en los discos virtuales del clon son id\u00e9nticos a los de la m\u00e1quina de origen. </p> <p>La clonaci\u00f3n nos permite crear nuevas m\u00e1quinas de forma muy sencilla, sin necesidad de pasar por el proceso de instalaci\u00f3n desde una imagen ISO.</p> <p>Para realizar la clonaci\u00f3n vamos a partir de una m\u00e1quina virtual que est\u00e9 apagada.</p>"},{"location":"01.-KVM/06.-Clonaci%C3%B3n%20y%20Snapshots/01.-Clonaci%C3%B3n%20de%20m%C3%A1quinas%20virtuales/#uso-virt-clone-para-realizar-la-clonacion","title":"Uso virt-clone para realizar la clonaci\u00f3n","text":"<p>Vamos a usar la aplicaci\u00f3n <code>virt-clone</code> para realizar la clonaci\u00f3n. Puedes profundizar en el uso de esta herramienta consultando la documentaci\u00f3n oficial: virt-clone. Veamos algunos casos de uso:</p> <pre><code>virt-clone --connect=qemu:///system --original prueba4 --auto-clone\nAsignando 'vol1-clone.qcow2'                               |  10 GB  00:15     \n\nEl clon 'prueba4-clone' ha sido creado exitosamente.\n</code></pre> <p>Es la forma m\u00e1s sencilla, se crea una nueva m\u00e1quina. El par\u00e1metro <code>--auto-clone</code> asigna autom\u00e1ticamente:</p> <ul> <li>Un nuevo nombre para la m\u00e1quina virtual clonada si no se especifica uno.</li> <li>Nuevas direcciones MAC para las interfaces de red para evitar conflictos en la red.</li> <li>Una nueva ruta del disco para el almacenamiento del clon, evitando sobrescribir el disco existente.</li> </ul> <p>Si queremos indicar el nombre de la nueva m\u00e1quina: usamos el par\u00e1metro <code>--name</code> y si queremos indicar el nombre del nuevo volumen usamos <code>--file</code>:</p> <pre><code>virt-clone --connect=qemu:///system --original prueba4 --name prueba5 --file /var/lib/libvirt/images/vol_prueba5.qcow2 --auto-clone\n</code></pre>"},{"location":"01.-KVM/06.-Clonaci%C3%B3n%20y%20Snapshots/01.-Clonaci%C3%B3n%20de%20m%C3%A1quinas%20virtuales/#uso-de-virt-manager-para-realizar-la-clonacion","title":"Uso de virt-manager para realizar la clonaci\u00f3n","text":"<p>Si elegimos una m\u00e1quina virtual y pulsamos el bot\u00f3n derecho del rat\u00f3n tenemos a nuestra disposici\u00f3n la opci\u00f3n Clonar:</p> <p></p> <p>Donde podemos indicar el nombre de la nueva m\u00e1quina virtual, y si pulsamos sobre el bot\u00f3n Details... podemos cambiar el nombre del nuevo fichero de imagen donde se realiza la clonaci\u00f3n.</p>"},{"location":"01.-KVM/06.-Clonaci%C3%B3n%20y%20Snapshots/01.-Clonaci%C3%B3n%20de%20m%C3%A1quinas%20virtuales/#las-maquinas-virtuales-clonadas-son-iguales-a-las-originales","title":"Las m\u00e1quinas virtuales clonadas son iguales a las originales","text":"<p>La m\u00e1quina clon que hemos creado es igual a la original. La nueva m\u00e1quina contiene identificadores que deber\u00edan ser \u00fanicos (como el machine ID, direcciones MAC, claves SSH de host, hostname, ...).</p> <p></p> <p>Podemos acceder a la m\u00e1quina y cambiar el fichero <code>/etc/hostname</code> para cambiar el nombre de la m\u00e1quina, pero todav\u00eda tendr\u00edamos mucha informaci\u00f3n repetida entre las dos m\u00e1quinas. </p> <p>Por lo tanto no vamos a realizar la clonaci\u00f3n de esta manera. En el siguiente apartado vamos a aprender a crear plantillas de m\u00e1quinas virtuales que nos permiten realizar la clonaci\u00f3n de forma adecuada.</p>"},{"location":"01.-KVM/06.-Clonaci%C3%B3n%20y%20Snapshots/02.-Plantillas%20de%20MV/","title":"02.-Plantillas de MV","text":"<p>Una plantilla de m\u00e1quina virtual, o simplemente plantilla es una imagen preconfigurada de un sistema operativo que puede utilizarse para desplegar r\u00e1pidamente m\u00e1quinas virtuales. El uso de plantillas permite evitar muchas tareas repetitivas de instalaci\u00f3n y configuraci\u00f3n. El resultado es la creaci\u00f3n de m\u00e1quinas virtuales totalmente instaladas y listas para funcionar en menos tiempo de lo que tardar\u00eda una instalaci\u00f3n manual.</p> <p>Con la herramienta <code>virt-clone</code> hemos creado un clon de una m\u00e1quina virtual, es decir, una copia de una m\u00e1quina. Una plantilla es una copia maestra que podemos utilizar para crear muchos clones.</p> <p>Una vez tengamos una plantilla, tendremos dos manera de crear las nuevas m\u00e1quinas:</p> <ul> <li>Clonaci\u00f3n completa (Full): Creamos una copia completa de la m\u00e1quina virtual que es totalmente independiente de la plantilla. Requiere el mismo espacio en disco que el original.</li> <li>Clonaci\u00f3n enlazada (Linked): Utiliza la imagen de la plantilla como imagen base en modo de s\u00f3lo lectura y vincula una imagen adicional de \"copia en escritura\" para almacenar los nuevos datos generados. Requiere menos espacio en disco, pero no puede ejecutarse sin acceso a la imagen de plantilla base.</li> </ul>"},{"location":"01.-KVM/06.-Clonaci%C3%B3n%20y%20Snapshots/02.-Plantillas%20de%20MV/#creacion-de-plantillas","title":"Creaci\u00f3n de plantillas","text":"<p>Tendr\u00edamos que realizar tres pasos fundamentales:</p> <p>En primer lugar, crear e instalar un nueva m\u00e1quina virtual e instalarle todo el software necesario. A partir de esa m\u00e1quina vamos a crear la plantilla.</p> <p>En segundo lugar, vamos a generalizar la imagen, es decir, vamos a eliminar toda la informaci\u00f3n que deber\u00eda ser \u00fanica en una m\u00e1quina ( contiene identificadores que deber\u00edan ser \u00fanicos (como el machine ID, direcciones MAC, claves SSH de host, hostname, ...). De tal forma, que las m\u00e1quinas clonadas, regenerar\u00e1n esta informaci\u00f3n de for ma \u00fanica al iniciarlas.</p> <p>En m\u00e1quinas Linux vamos a usar la utilidad <code>virt-sysprep</code>, para m\u00e1quinas Windows podemos usar los mecanismos propios de generalizaci\u00f3n que posee: sysprep.</p> <p>Para poder utilizar <code>virt-sysprep</code> tenemos que instalar el siguiente paquete:</p> <pre><code>apt-get install libguestfs-tools\n</code></pre> <p><code>virt-sysprep</code> puede trabajar con un fichero de ima\u01f5en, usando la opci\u00f3n <code>-a</code>, pero en nuestro caso vamos indicarle una m\u00e1quina virtual, usando el par\u00e1metro <code>-d</code>.</p> <p>Vamos a suponer que vamos a convertir en plantilla nuestra m\u00e1quina <code>prueba1</code> que tiene un sistema GNU/Linux Debian 11 instalado. Nuestra m\u00e1quina original tiene que estar parada. Y para generalizarla, ejecutamos como superusuario:</p> <pre><code>sudo virt-sysprep -d prueba1 --hostname plantilla-debian11\n[   0.0] Examining the guest ...\n...\n</code></pre> <p><code>virt-sysprep</code> tienes muchas opciones de configuraci\u00f3n, hemos usado el par\u00e1metro <code>-hostname</code> para cambiar el nombre de la m\u00e1quina de la plantilla.</p> <p>En \u00faltimo lugar, tenemos que evitar ejecutar est\u00e1 m\u00e1quina de nuevo, ya que la generalizaci\u00f3n que hemos hecho se perder\u00eda. Para conseguirlo vamos a configurar la imagen original de solo lectura, de esta manera al intentar ejecutar la plantilla nos dar\u00e1 un error. Para ello como superusuario:</p> <pre><code>/var/lib/libvirt/images# chmod -w prueba1.qcow2 \n</code></pre> <p>Adem\u00e1s, vamos a cambiar el nombre a la m\u00e1quina para recordar que es un plantilla:</p> <pre><code>virsh -c qemu:///system domrename prueba1 plantilla-prueba1\nDomain successfully renamed\n</code></pre> <p>Este cambio tambi\u00e9n se podr\u00eda hacer con <code>virt-manager</code>.</p> <p>Si intentamos ejecutar la plantilla, nos dar\u00e1 un error:</p> <p></p> <p>En cualquier momento podemos cambiar la configuraci\u00f3n de la plantilla. Todas las nuevas m\u00e1quinas clonadas a partir de ella tendr\u00e1n la misma configuraci\u00f3n.</p> <p>Ya tenemos la plantilla lista para ser clonada. Lo veremos en los siguientes apartados.</p>"},{"location":"01.-KVM/06.-Clonaci%C3%B3n%20y%20Snapshots/03.-Clonaci%C3%B3n%20completa%20con%20plantillas/","title":"03.-Clonaci\u00f3n completa con plantillas","text":"<p>La clonaci\u00f3n completa a partir de una plantilla es similar a la clonaci\u00f3n de m\u00e1quinas virtuales que vimos en un punto anterior.</p>"},{"location":"01.-KVM/06.-Clonaci%C3%B3n%20y%20Snapshots/03.-Clonaci%C3%B3n%20completa%20con%20plantillas/#uso-virt-clone-para-realizar-la-clonacion","title":"Uso virt-clone para realizar la clonaci\u00f3n","text":"<p>Podemos usar el siguiente comando para realizar la clonaci\u00f3n:</p> <pre><code>virt-clone --connect=qemu:///system --original plantilla-prueba1 --name clone1 --auto-clone\n</code></pre> <p>Recuerda que puedes usar el par\u00e1metro <code>--file</code> para indicar el nombre de la imagen de la nueva m\u00e1quina que clonamos.</p> <p>El proceso puede ser lento, ya que se hace una copia completa de la imagen original a la de la nueva m\u00e1quina virtual.</p>"},{"location":"01.-KVM/06.-Clonaci%C3%B3n%20y%20Snapshots/03.-Clonaci%C3%B3n%20completa%20con%20plantillas/#uso-de-virt-manager-para-realizar-la-clonacion","title":"Uso de virt-manager para realizar la clonaci\u00f3n","text":"<p>Si elegimos la plantilla y pulsamos el bot\u00f3n derecho del rat\u00f3n tenemos a nuestra disposici\u00f3n la opci\u00f3n Clonar:</p> <p></p> <p>Donde podemos indicar el nombre de la nueva m\u00e1quina virtual, y si pulsamos sobre el bot\u00f3n Details... podemos cambiar el nombre del nuevo fichero de imagen donde se realiza la clonaci\u00f3n.</p>"},{"location":"01.-KVM/06.-Clonaci%C3%B3n%20y%20Snapshots/03.-Clonaci%C3%B3n%20completa%20con%20plantillas/#problemas-de-acceso-por-ssh","title":"Problemas de acceso por SSH","text":"<p>Si intentamos acceder por SSH a la nueva m\u00e1quina vamos a comprobar que no nos lo permite. Para realizar la conexi\u00f3n por SSH vamos a averiguar la IP de la m\u00e1quina, para ello podemos ejecutar:</p> <pre><code>virsh -c qemu:///system domifaddr clone1\n Nombre     direcci\u00f3n MAC       Protocol     Address\n-------------------------------------------------------------------------------\n vnet0      52:54:00:6d:b5:da    ipv4         192.168.122.253/24\n</code></pre> <p>O usando <code>virt-manager</code> vemos el detalle de la interfaz de red:</p> <p></p> <p>Si desde el host intentamos acceder por SSH, obtenemos:</p> <pre><code>ssh usuario@192.168.122.253\nssh: connect to host 192.168.122.253 port 22: Connection refuse\n</code></pre> <p>Esto es debido a que cuando ejecutamos el <code>virt-sysprep</code> uno de los datos que se eliminaron fueron las claves SSH de la m\u00e1quina para que no fueran los mismos que los de la m\u00e1quina original. Por lo tanto tenemos que regenerar estas claves en la nueva m\u00e1quina ejecutando el comando <code>ssh-keygen -A</code>, y de paso le vamos a cambiar el <code>hostname</code>:</p> <p></p> <p>Una reiniciada la m\u00e1quina ya podemos acceder por SSH desde el host:</p> <pre><code>ssh usuario@192.168.122.253\n...\n\nusuario@clone1:~$ \n</code></pre>"},{"location":"01.-KVM/06.-Clonaci%C3%B3n%20y%20Snapshots/04.-Clonaci%C3%B3n%20enlazada%20con%20plantillas/","title":"04.-Clonaci\u00f3n enlazada con plantillas","text":"<p>En este tipo de clonaci\u00f3n la imagen de la m\u00e1quina clonada utiliza la imagen de la plantilla como imagen base (backing store) en modo de s\u00f3lo lectura, en la imagen de la nueva m\u00e1quina s\u00f3lo se guardan los cambios del sistema de archivo. Requiere menos espacio en disco, pero no puede ejecutarse sin acceso a la imagen de plantilla base. </p> <p>El mecanismo es un poco m\u00e1s complejo, tenemos que realziar dos pasos:</p> <ol> <li>Creaci\u00f3n del nuevo volumen a a partir de la imagen base de la plantilla (backing store).</li> <li>Creaci\u00f3n de la nueva m\u00e1quina usando <code>virt-install</code>, <code>virt-manager</code> o <code>virt-clone</code>.</li> </ol>"},{"location":"01.-KVM/06.-Clonaci%C3%B3n%20y%20Snapshots/04.-Clonaci%C3%B3n%20enlazada%20con%20plantillas/#creacion-de-imagenes-de-disco-con-backing-store","title":"Creaci\u00f3n de im\u00e1genes de disco con backing store","text":"<p>Para no complicar la creaci\u00f3n de vol\u00famenes con backing store vamos a indicar el tama\u00f1o del nuevo volumen igual al de la imagen base. Como la imagen base ya tiene guardado un sistema de archivos con un tama\u00f1o determinado, el hecho de que creemos una nueva imagen con m\u00e1s tama\u00f1o no conlleva el redimensionado del sistema de archivo. Este cambio de tama\u00f1o se podr\u00eda realizar, pero con operaciones un poco m\u00e1s complejas.</p> <p>Para asegurarnos de crear un volumen del mismo tama\u00f1o que la imagen base vamos comprobar su tama\u00f1o:</p> <pre><code>virsh -c qemu:///system domblkinfo plantilla-prueba1 vda --human\nCapacidad:      10,000 GiB\n...\n</code></pre> <p>Tambi\u00e9n lo podemos ver con <code>virt-manager</code>:</p> <p></p> <p>Para crear la nueva imagen basada en la imagen base de la plantilla, podemos crear el volumen con <code>virsh</code>:</p> <pre><code>virsh -c qemu:///system vol-create-as default clone2.qcow2 10G --format qcow2 --backing-vol prueba1.qcow2 --backing-vol-format qcow2 \n</code></pre> <p>O podemos usar la aplicaci\u00f3n <code>qemu-img</code> y posterior refrescamos el pool <code>default</code>:</p> <pre><code>cd /var/lib/libvirt/images\nsudo qemu-img create -f qcow2 -b prueba1.qcow2 -F qcow2 clone2.qcow2 10G\nvirsh -c qemu:///system pool-refresh default\n</code></pre> <p>Otra opci\u00f3n es usando <code>virt-manager</code>, creando un nuevo volumen e indicando durante la direcci\u00f3n el volumen base:</p> <p></p>"},{"location":"01.-KVM/06.-Clonaci%C3%B3n%20y%20Snapshots/04.-Clonaci%C3%B3n%20enlazada%20con%20plantillas/#informacion-sobre-imagenes-de-con-disco-con-backing-store","title":"Informaci\u00f3n sobre im\u00e1genes de con disco con backing store","text":"<p>Para comprobar que un volumen est\u00e1 creado con una imagen base podemos usar <code>virsh</code>:</p> <pre><code>virsh -c qemu:///system vol-dumpxml clone2.qcow2 default\n...\n&lt;backingStore&gt;\n    &lt;path&gt;/var/lib/libvirt/images/prueba1.qcow2&lt;/path&gt;\n    &lt;format type='qcow2'/&gt;\n    &lt;permissions&gt;\n    ...\n</code></pre> <p>O usando el comando <code>qemu-img</code>:</p> <pre><code>sudo qemu-img info /var/lib/libvirt/images/clone2.qcow2\n...\nbacking file: prueba1.qcow2\nbacking file format: qcow2\n...\n</code></pre>"},{"location":"01.-KVM/06.-Clonaci%C3%B3n%20y%20Snapshots/04.-Clonaci%C3%B3n%20enlazada%20con%20plantillas/#creacion-de-la-nueva-maquina-a-partir-de-la-imagen-con-backing-store-con-virt-install","title":"Creaci\u00f3n de la nueva m\u00e1quina a partir de la imagen con backing store con virt-install","text":"<p>En este caso podemos usar la herramienta <code>virt-install</code> pero sin indicar el medio de instalaci\u00f3n.</p> <pre><code>virt-install --connect qemu:///system \\\n             --virt-type kvm \\\n             --name nueva_prueba \\\n             --os-variant debian10 \\\n             --disk path=/var/lib/libvirt/images/prueba6.qcow2 \\\n             --memory 1024 \\\n             --vcpus 1 \\\n             --import\n</code></pre> <p>Usamos la opci\u00f3n <code>--import</code> para que no te pida que indique el medio de instalaci\u00f3n, simplemente va a usar el volumen indicado como disco de la m\u00e1quina virtual.</p>"},{"location":"01.-KVM/06.-Clonaci%C3%B3n%20y%20Snapshots/04.-Clonaci%C3%B3n%20enlazada%20con%20plantillas/#creacion-de-la-nueva-maquina-a-partir-de-la-imagen-con-backing-store-con-virt-manager","title":"Creaci\u00f3n de la nueva m\u00e1quina a partir de la imagen con backing store con virt-manager","text":"<p>Si utilizamos <code>virt-manager</code>, para crear la nueva m\u00e1quina, durante el asistente de creaci\u00f3n de la m\u00e1quina, elegimos la opci\u00f3n Manual install, ya que no vamos a usar una imagen ISO:</p> <p></p> <p>Y posteriormente, escogemos el volumen que tenemos creado:</p> <p></p> <p>Otra forma, ser\u00eda escogiendo la opci\u00f3n Importar imagen de disco existente en la creaci\u00f3n de la m\u00e1quina:</p> <p></p> <p>Y eligiendo el volumen en siguiente paso:</p> <p></p>"},{"location":"01.-KVM/06.-Clonaci%C3%B3n%20y%20Snapshots/04.-Clonaci%C3%B3n%20enlazada%20con%20plantillas/#creacion-de-la-nueva-maquina-a-partir-de-la-imagen-con-backing-store-con-virt-clone","title":"Creaci\u00f3n de la nueva m\u00e1quina a partir de la imagen con backing store con virt-clone","text":"<p>Una vez que tenemos creado el volumen basada en el imagen base de la plantilla, podemos crear un nuevo clon con <code>virt-clone</code>, para ello ejecutamos:</p> <pre><code>virt-clone --connect=qemu:///system --original plantilla-prueba1 --name clone2 --file /var/lib/libvirt/images/clone2.qcow2 --preserve-data\n</code></pre> <p>Indicamos como fichero el volumen que hemos creado, pero con la opci\u00f3n <code>--preserve-data</code> no se copia el volumen original al nuevo, simplemente se usa. Se puede comprobar que la clonaci\u00f3n no tarda nada de tiempo, no se est\u00e1 copiando un volumen en otro.</p>"},{"location":"01.-KVM/06.-Clonaci%C3%B3n%20y%20Snapshots/05.-Snapshots%20de%20MV/","title":"05.-Snapshots de MV","text":"<p>Un snapshot (instant\u00e1nea) nos posibilita guardar el estado de una m\u00e1quina virtual en un determinado momento. Se guarda el estado del disco y el estado de la memoria. De esta forma en el futuro puedo volver a un estado anterior de la misma. No todos los formatos y medios de almacenamiento nos posibilitan esta caracter\u00edsticas. Un fichero de imagen de disco con formato <code>qcow2</code> si nos permite la realizaci\u00f3n de instant\u00e1neas.</p>"},{"location":"01.-KVM/06.-Clonaci%C3%B3n%20y%20Snapshots/05.-Snapshots%20de%20MV/#gestion-de-instantaneas-con-virsh","title":"Gesti\u00f3n de instant\u00e1neas con virsh","text":"<p>Vamos a trabajar con la m\u00e1quina <code>prueba2</code> donde tenemos una instalaci\u00f3n de Ubuntu 22.04. </p> <p>Hemos hecho un cambio significativo en nuestra m\u00e1quina (en el ejemplo hemos creado una carpeta). </p> <p></p> <p>Ahora es el momento de crear una instant\u00e1nea, de esta manera podremos volver a este estado en un momento futuro:</p> <pre><code>virsh -c qemu:///system snapshot-create-as prueba2 --name instant\u00e1nea1 --description \"Creada carpeta importante\" --atomic\nHa sido creada la captura instant\u00e1nea instant\u00e1nea1 del dominio\n</code></pre> <p>Se recomienda utilizar la opci\u00f3n <code>--atomic</code> para evitar cualquier corrupci\u00f3n mientras se toma la instant\u00e1nea. Para ver las instant\u00e1neas que tiene creada la m\u00e1quina podemos ejecutar:</p> <pre><code>virsh -c qemu:///system snapshot-list prueba2\n  Nombre         Hora de creaci\u00f3n            Estado\n -----------------------------------------------------\n  instant\u00e1nea1   2022-05-28 18:13:46 +0200   running\n</code></pre> <p>Tambi\u00e9n podemos ver las instant\u00e1neas de un fichero de imagen con la herramienta <code>qemu-img</code> (la m\u00e1quina debe estar parada):</p> <pre><code>sudo qemu-img info /var/lib/libvirt/images/prueba2.qcow2\nimage: /var/lib/libvirt/images/prueba2.qcow2\nfile format: qcow2\nvirtual size: 20 GiB (21474836480 bytes)\ndisk size: 11.9 GiB\ncluster_size: 65536\nSnapshot list:\nID        TAG               VM SIZE                DATE     VM CLOCK     ICOUNT\n1         instant\u00e1nea1     1.79 GiB 2022-05-28 18:13:46 00:16:12.485    \n...\n</code></pre> <p>Los snapshot son otro recurso de libvirt cuya definici\u00f3n se guarda en formato XML. Podr\u00edamos usar el comando <code>snapshot-dumpxml</code> para ver su definici\u00f3n. Tenemos m\u00e1s comandos relacionados con las instant\u00e1neas: para obtener informaci\u00f3n de una instant\u00e1nea usamos <code>snapshot-info</code>, <code>snapshot-delete</code> para borrar una instant\u00e1nea ,... </p> <p>Si hemos tenido un problema en nuestra m\u00e1quina y hemos eliminado nuestra carpeta importante:</p> <p></p> <p>Podemos volver al estado de una determinada instant\u00e1nea ejecutando:</p> <pre><code>virsh -c qemu:///system snapshot-revert prueba2 instant\u00e1nea1\n</code></pre> <p>Y comprobamos que hemos vuelto al estado de la m\u00e1quina donde ten\u00edamos creada la carpeta:</p> <p></p>"},{"location":"01.-KVM/06.-Clonaci%C3%B3n%20y%20Snapshots/05.-Snapshots%20de%20MV/#gestion-de-instantaneas-con-virt-manager","title":"Gesti\u00f3n de instant\u00e1neas con virt-manager","text":"<p>Accediendo a la Vista Instant\u00e1neas obtenemos la ventana para gestionar las instant\u00e1neas:</p> <p></p> <p>Tenemos botones para las opci\u00f3n m\u00e1s comunes:</p> <ul> <li>Bot\u00f3n 1: Crear instant\u00e1nea.</li> <li>Bot\u00f3n 2: Volver al estado de la instant\u00e1nea seleccionada.</li> <li>Bot\u00f3n 3: Refrescar la lista de instant\u00e1neas.</li> <li>Bot\u00f3n 4: Borrar la instant\u00e1nea seleccionada.</li> </ul> <p>Al crear una instant\u00e1nea, podemos indicar el nombre, la descripci\u00f3n y se guarda una captura de pantalla de la m\u00e1quina.</p> <p></p>"},{"location":"01.-KVM/06.-Clonaci%C3%B3n%20y%20Snapshots/05.-Snapshots%20de%20MV/#conclusion","title":"Conclusi\u00f3n","text":"<p>Puede ser muy interesante tomar instant\u00e1neas peri\u00f3dicamente a una m\u00e1quina virtual. Si tenemos cualquier problema con la m\u00e1quina podemos volver a un estado estable anterior. Esta caracter\u00edstica puede ser muy \u00fatil, ya que nos permite experimentar con la m\u00e1quina, y si tenemos alg\u00fan problema, podemos volver al estado original y no tener que eliminar la m\u00e1quina.</p>"},{"location":"01.-KVM/07.-Redes/01.-Introduccion/","title":"01.-Introduccion","text":"<p>libvirt nos proporciona las herramientas necesarias para gestionar las redes virtuales a las que se conectan nuestras m\u00e1quinas virtuales.</p> <p>Tenemos dos grandes grupos de redes que podemos configurar:</p> <ul> <li>Redes Virtuales (Privadas): Son redes privadas que podemos configurar para que tengan distintas caracter\u00edsticas.</li> <li>Redes Puente (P\u00fablicas): Las podemos considerar como redes p\u00fablicas, desde el punto de vista que las m\u00e1quinas virtuales estar\u00e1n conectadas a la misma red a la que est\u00e1 conectada el host.</li> </ul> <p>Recordemos un puente o bridge/switch es un dispositivo de interconexi\u00f3n de redes. La gesti\u00f3n de redes de libvirt se basa en el concepto de switch virtual, para ello utiliza Linux Bridge, que es un software que nos permite crear bridge virtuales con la misma funcionalidad que un bridge f\u00edsico.</p>"},{"location":"01.-KVM/07.-Redes/01.-Introduccion/#tipos-de-redes-virtuales-privadas","title":"Tipos de Redes Virtuales (Privadas)","text":"<p>La clasificaci\u00f3n depender\u00e1 de la configuraci\u00f3n que hagamos a la Red Virtual:</p>"},{"location":"01.-KVM/07.-Redes/01.-Introduccion/#redes-virtuales-de-tipo-nat","title":"Redes Virtuales de tipo NAT","text":"<p>Es un Red Virtual Privada, las m\u00e1quinas virtual tendr\u00e1n un direccionamiento privado y se nos proporciona un mecanismo de router/nat para que tengan conectividad al exterior.</p> <p></p> <p>La red <code>default</code> con la que hemos trabajado es de este tipo. Veamos sus caracter\u00edsticas:</p> <ul> <li>Crea un bridge virtual donde se conectan las m\u00e1quinas virtuales. En el caso de la red <code>default</code> se llama <code>vmbr0</code>. A este bridge tambi\u00e9n est\u00e1 conectado el host.</li> <li>Las m\u00e1quinas virtuales se configuraran de forma din\u00e1mica por medio de un servidor DHCP. En el caso de la red <code>default</code>, el rango de direcciones es <code>192.168.122.2</code> - <code>192.168.122.254</code>. La puerta de enlace de las m\u00e1quinas se configura con la direcci\u00f3n IP <code>192.168.122.1</code> que corresponde al host. El servidor DHCP esta configurado en el host. </li> <li>En el host tambi\u00e9n se configura un servidor DNS que es el que se configura en las m\u00e1quinas virtuales.</li> <li> <p>El host hace la funci\u00f3n de router/nat de tal manera que las m\u00e1quinas virtuales tienen conectividad al exterior, usando la direcci\u00f3n IP de la interfaz de red del host que est\u00e1 conectada al exterior.</p> <p>Existen otros mecanismos para que las m\u00e1quinas virtuales tengan acceso al exterior:</p> <ul> <li>Modo bridge: Donde se usan rutas de encaminamiento en el host. En este modo hay que configurar con rutas est\u00e1ticas los elementos de enrutamiento de la red local para que funcione de manera adecuada.</li> <li>Modo abierto: Similar a la anterior, excepto que no se a\u00f1aden reglas de firewall para asegurar que cualquier tr\u00e1fico pase o no. Se asume que, o bien no son necesarias, o bien se configuran fuera del \u00e1mbito de libvirt.</li> </ul> <p>En este curso vamos a trabajar con Redes Virtuales de tipo NAT.</p> </li> </ul>"},{"location":"01.-KVM/07.-Redes/01.-Introduccion/#redes-virtuales-aisladas-isolated","title":"Redes Virtuales aisladas (Isolated)","text":"<p>Es un Red Virtual Privada, donde las m\u00e1quinas virtuales tomas direccionamiento privado. No tenemos un mecanismo de router/nat, por lo que las m\u00e1quinas virtuales no tienen conectividad con el exterior. </p> <p></p> <p>Por lo tanto tienen las mismas caracter\u00edsticas que una Red Virtual de tipo NAT, pero sin la caracter\u00edstica de router/nat. Se gestiona un bridge virtual donde se conectan las m\u00e1quinas virtuales y el host, seguimos teniendo un servidor DNS y es posible tener un servidor DHCP en el host que asigna din\u00e1micamente un direccionamiento privado a las m\u00e1quinas.</p>"},{"location":"01.-KVM/07.-Redes/01.-Introduccion/#redes-virtuales-muy-aisladas-very-isolated","title":"Redes Virtuales muy aisladas (Very Isolated)","text":"<p>Es un Red Virtual Aislada, en la que el host no est\u00e1 conectado a las m\u00e1quians virtuales. Por lo tanto,no tenemos servidor DNS ni DHCP para ser utilizados por las m\u00e1quinas. Al ser aislada, tampoco tienen salida al exterior.</p> <p></p> <p>En este tipo de red se suele configurar la red de las m\u00e1quinas virtuales de forma est\u00e1tica.</p>"},{"location":"01.-KVM/07.-Redes/01.-Introduccion/#tipos-de-redes-puente-publicas","title":"Tipos de Redes Puente (P\u00fablicas)","text":"<p>La clasificaci\u00f3n depende de la forma utilizada para conectar las m\u00e1quinas virtuales al exterior.</p>"},{"location":"01.-KVM/07.-Redes/01.-Introduccion/#redes-puente-conectadas-a-un-bridge-externo","title":"Redes Puente conectadas a un bridge externo","text":"<p>En este caso necesitamos crear un bridge virtual (normalmente llamado <code>br0</code>) al que conectaremos la m\u00e1quina f\u00edsica y las m\u00e1quinas virtuales. En este caso las m\u00e1quinas virtuales estar\u00e1n en la misma red red que el host y estar\u00e1n conectadas directamente al router de esta red, tomando la configuraci\u00f3n dhcp (si la hubiera) del mismo modo que la toma el host.</p> <p></p>"},{"location":"01.-KVM/07.-Redes/01.-Introduccion/#redes-puente-compartiendo-la-interfaz-fisica-del-host","title":"Redes Puente compartiendo la interfaz f\u00edsica del host","text":"<p>En este caso vamos a usar una conexi\u00f3n macvtap, que nos permite conectarnos a la red f\u00edsica directamente a trav\u00e9s de una interfaz f\u00edsica del host (sin usar un dispositivo bridge). Al igual que con la red anterior, las m\u00e1quinas virtuales estar\u00e1n conectados directamente a la red f\u00edsica, por lo que sus direcciones IP estar\u00e1n todas en la subred de la red f\u00edsica. Existe una una limitaci\u00f3n en la implementaci\u00f3n de macvtap: estas conexiones no permiten la comunicaci\u00f3n directa entre el host y los invitados.</p> <p></p>"},{"location":"01.-KVM/07.-Redes/02.-Definic%C3%B3n%20de%20RV%20%28Privadas%29/","title":"02.-Definic\u00f3n de RV (Privadas)","text":"<p>Las redes que gestiona libvirt se definen con el formato XML. Puedes profundizar en el formato XML con los que se definen las redes consultando el documento Network XML format. </p>"},{"location":"01.-KVM/07.-Redes/02.-Definic%C3%B3n%20de%20RV%20%28Privadas%29/#definicion-de-redes-virtuales-de-tipo-nat","title":"Definici\u00f3n de Redes Virtuales de tipo NAT","text":"<p>La red <code>default</code> con la que hemos trabajado es de este tipo. La configuraci\u00f3n de la red <code>default</code> la podemos encontrar en el fichero <code>/usr/share/libvirt/networks/default.xml</code>:</p> <pre><code>&lt;network&gt;\n  &lt;name&gt;default&lt;/name&gt;\n  &lt;bridge name='virbr0'/&gt;\n  &lt;forward/&gt;\n  &lt;ip address='192.168.122.1' netmask='255.255.255.0'&gt;\n    &lt;dhcp&gt;\n      &lt;range start='192.168.122.2' end='192.168.122.254'/&gt;\n    &lt;/dhcp&gt;\n  &lt;/ip&gt;\n&lt;/network&gt;\n</code></pre> <p>Veamos las etiquetas:</p> <ul> <li><code>&lt;name&gt;</code>: Nombre de la red.</li> <li><code>&lt;bridge&gt;</code>: Indicamos el nombre del bridge virtual que se va a utilizar.</li> <li><code>&lt;forward&gt;</code>: Indica que las m\u00e1quinas virtuales van a tener conectividad con el exterior. Por defecto, si no se indicada nada, el tipo es nat: <code>&lt;forward mode=\"nat\"/&gt;</code>. El modo tambi\u00e9n puede ser:<ul> <li><code>router</code>: Las redes tipo router tambi\u00e9n dan acceso a las m\u00e1quinas virtuales al exterior, pero en ese caso no se utiliza el mecanismo de NAT, sino que se usan rutas de encaminamiento en el host.</li> <li><code>open</code>: Similar a la anterior, excepto que no se a\u00f1aden reglas de firewall para asegurar que cualquier tr\u00e1fico pase o no. </li> </ul> </li> <li><code>&lt;ip&gt;</code>: Donde se indica la direcci\u00f3n IP y la mascara de red de la direcci\u00f3n del host en la red. Es decir, el host est\u00e1 conectado al bridge virtual con esa direcci\u00f3n.<ul> <li><code>&lt;dhcp&gt;</code>: Este elemento es optativo. Si queremos tener un servidor DHCP configurado en el host lo configuramos en esta etiqueta, por ejemplo poniendo el rango en la etiqueta <code>&lt;range&gt;</code>. </li> </ul> </li> </ul>"},{"location":"01.-KVM/07.-Redes/02.-Definic%C3%B3n%20de%20RV%20%28Privadas%29/#definicion-de-redes-virtuales-aisladas","title":"Definici\u00f3n de Redes Virtuales Aisladas","text":"<p>La definici\u00f3n de una Red Virtual Aislada es igual a la de tipo NAT, pero quitando la etiqueta <code>&lt;forward&gt;</code> para deshabilitar la caracter\u00edstica de que el host haga router/nat. La definici\u00f3n podr\u00eda quedar de este modo:</p> <pre><code>&lt;network&gt;\n  &lt;name&gt;red_aislada&lt;/name&gt;\n  &lt;bridge name='virbr1'/&gt;\n  &lt;ip address='192.168.123.1' netmask='255.255.255.0'&gt;\n    &lt;dhcp&gt;\n      &lt;range start='192.168.123.2' end='192.168.123.254'/&gt;\n    &lt;/dhcp&gt;\n  &lt;/ip&gt;\n&lt;/network&gt;\n</code></pre>"},{"location":"01.-KVM/07.-Redes/02.-Definic%C3%B3n%20de%20RV%20%28Privadas%29/#definicion-de-redes-virtuales-muy-aisladas","title":"Definici\u00f3n de Redes Virtuales muy Aisladas","text":"<p>Son similares a la anterior, pero el host no se conecta a la red. Por lo tanto no tenemos ni servidor DNS, ni DHCP. Al crear este tipo de red, simplemente se creara un bridge virtual donde se conectar\u00e1n las m\u00e1quinas virtuales, que se configurar\u00e1n de forma est\u00e1tica su direccionamiento. Por lo tanto la definici\u00f3n ser\u00e1:</p> <pre><code>&lt;network&gt;\n  &lt;name&gt;red_muy_aislada&lt;/name&gt;\n  &lt;bridge name='virbr2'/&gt;\n&lt;/network&gt;\n</code></pre>"},{"location":"01.-KVM/07.-Redes/03.-Gesti%C3%B3n%20de%20RV/","title":"03.-Gesti\u00f3n de RV","text":"<p>En este apartado vamos  a estudiar como trabajar con las redes virtuales con <code>virsh</code> y <code>virt-manager</code>.</p>"},{"location":"01.-KVM/07.-Redes/03.-Gesti%C3%B3n%20de%20RV/#gestion-de-redes-virtuales-con-virsh","title":"Gesti\u00f3n de Redes Virtuales con virsh","text":"<p>Podemos ver las redes que tenemos definidas ejecutando:</p> <pre><code>virsh -c qemu:///system net-list --all\n Nombre    Estado   Inicio autom\u00e1tico   Persistente\n-----------------------------------------------------\n default   activo   si                  si\n</code></pre> <p>Utilizamos la opci\u00f3n <code>--all</code> para listar las redes iniciadas y paradas.</p> <p>Las redes se crean a partir de su definici\u00f3n XML que tenemos guardado en un fichero. En este caso tenemos el fichero <code>red-nat.xml</code>, donde tenemos la definici\u00f3n de una red virtual de tipo NAT, con el siguiente contenido:</p> <pre><code>&lt;network&gt;\n  &lt;name&gt;red_nat&lt;/name&gt;\n  &lt;bridge name='virbr1'/&gt;\n  &lt;forward/&gt;\n  &lt;ip address='192.168.123.1' netmask='255.255.255.0'&gt;\n    &lt;dhcp&gt;\n      &lt;range start='192.168.123.2' end='192.168.123.254'/&gt;\n    &lt;/dhcp&gt;\n  &lt;/ip&gt;\n&lt;/network&gt;\n</code></pre> <p>Para crear la nueva red, ejecutamos:</p> <pre><code>virsh -c qemu:///system net-define red-nat.xml\nLa red red_nat se encuentra definida desde red-nat.xml\n</code></pre> <p>Si utilizamos el comando <code>virsh create</code> estar\u00edamos creando la red de forma temporal, no persistente.</p> <p>La red no se puede utilizar hasta que no se inicie, para ello:</p> <pre><code>virsh -c qemu:///system net-start red_nat\nLa red red_nat se ha iniciado\n</code></pre> <p>Si vamos a usar esta red con mucha frecuencia es recomendable activar la propiedad de autoiniciar para que se inicie de forma autom\u00e1tica al iniciar el host. Para ello:</p> <pre><code>virsh -c qemu:///system net-autostart red_nat\nLa red red_nat ha sido marcada para iniciarse autom\u00e1ticamente\n</code></pre> <p>Podemos obtener informaci\u00f3n de la red ejecutando:</p> <pre><code>virsh -c qemu:///system net-info red_nat\nNombre:         red_nat\nUUID:           af756f61-9ffd-44d0-850f-90a75db773c1\nActivar:        si\nPersistente:    si\nAutoinicio:     si\nPuente:         virbr1\n</code></pre> <p>Al iniciar podemos comprobar que se ha creado el bridge virtual y una nueva interfaz de red en el host.</p> <pre><code>sudo brctl show\nbridge name bridge id       STP enabled interfaces\nvirbr0      8000.525400aea33d   yes     \nvirbr1      8000.5254002daec2   yes \n</code></pre> <p>En el host, el bridge virtual aparece como una interfaz de red:</p> <pre><code>ip a\n...\n4: virbr0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN group default qlen 1000\n    link/ether 52:54:00:ae:a3:3d brd ff:ff:ff:ff:ff:ff\n    inet 192.168.122.1/24 brd 192.168.122.255 scope global virbr0\n       valid_lft forever preferred_lft forever\n5: virbr1: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN group default qlen 1000\n    link/ether 52:54:00:2d:ae:c2 brd ff:ff:ff:ff:ff:ff\n    inet 192.168.123.1/24 brd 192.168.123.255 scope global virbr1\n       valid_lft forever preferred_lft forever\n</code></pre> <p>Podemos considerar que la interfaz de red del bridge virtual corresponde a la conexi\u00f3n del host con el bridge.</p> <p>Para ver la definici\u00f3n XML de la red que hemos creado, ejecutamos:</p> <pre><code>virsh -c qemu:///system net-dumpxml red_nat\n</code></pre> <p>Podemos crear tambi\u00e9n una red muy aislada de la que tenemos guardada la definici\u00f3n XML en el fichero <code>red-muy-aislada.xml</code>, con el contenido:</p> <pre><code>&lt;network&gt;\n  &lt;name&gt;red_muy_aislada&lt;/name&gt;\n  &lt;bridge name='virbr2'/&gt;\n&lt;/network&gt;\n</code></pre> <p>Y si la creamos y la iniciamos:</p> <pre><code>virsh -c qemu:///system net-define red-muy-aislada.xml\nLa red red_muy_aislada se encuentra definida desde red-muy-aislada.xml\n\nvirsh -c qemu:///system net-start red_muy_aislada\nLa red red_muy_aislada se ha iniciado\n</code></pre> <p>Comprobamos que se ha creado el bridge virtual. </p> <pre><code>sudo brctl show\nbridge name bridge id       STP enabled interfaces\nvirbr0      8000.525400aea33d   yes     \nvirbr1      8000.5254002daec2   yes     \nvirbr2      8000.525400d51f31   yes\n</code></pre> <p>Pero al ser una red muy aislada, el host no est\u00e1 conectado al bridge, y por lo tanto no tiene direcci\u00f3n IP asignada:</p> <pre><code>ip a\n...\n6: virbr2: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN group default qlen 1000\n    link/ether 52:54:00:d5:1f:31 brd ff:ff:ff:ff:ff:\n</code></pre> <p>Finalmente indicar que para parar una red utilizamos el comando <code>virsh net-stop</code> y para eliminarla el comando <code>virsh undefined</code>.</p>"},{"location":"01.-KVM/07.-Redes/03.-Gesti%C3%B3n%20de%20RV/#gestion-de-redes-virtuales-con-virt-manager","title":"Gesti\u00f3n de Redes Virtuales con virt-manager","text":"<p>Desde la pesta\u00f1a Redes virtuales de los Detalles de la conexi\u00f3n podemos ver las redes que tenemos creadas y podemos gestionarlas:</p> <p></p> <p>Tenemos las siguientes opciones:</p> <ul> <li>Bot\u00f3n 1: A\u00f1adir una nueva red.</li> <li>Bot\u00f3n 2: Iniciar la red seleccionada.</li> <li>Bot\u00f3n 3: Parar la red seleccionada.</li> <li>Bot\u00f3n 4: Eliminar la red seleccionada.</li> </ul> <p>Si creamos una red, indicamos un nombre, el tipo y la configuraci\u00f3n. Por ejemplo, vamos a crear una red de tipo aislada con servidor DHCP:</p> <p></p> <p>Una vez creado, observamos que est\u00e1 iniciado y que tiene marcada como activa la propiedad de autoiniciar. Adem\u00e1s observamos que el nombre del bridge lo ah asignado de forma autom\u00e1tica:</p> <p></p> <p>Por \u00faltimo, recordar que desde <code>virt-manager</code> podemos ver la definici\u00f3n XML de los recursos con los que trabajamos:</p> <p></p>"},{"location":"01.-KVM/07.-Redes/04.-Creaci%C3%B3n%20de%20un%20Puerte%20Externo%20con%20Linux%20Bridge/","title":"04.-Creaci\u00f3n de un Puerte Externo con Linux Bridge","text":"<p>Un bridge externo es un bridge virtual que estar\u00e1 conectado al router de la red local. El bridge se crear\u00e1 en el servidor donde estamos virtualizando (host). El host estar\u00e1 conectado a este bridge para tener conectividad al exterior. Veamos un esquema:</p> <p></p> <ul> <li>El bridge que vamos a crear lo vamos a llamar <code>br0</code>.</li> <li>En el host aparecer\u00e1 una interfaz de red con el mismo nombre que representa la conexi\u00f3n al bridge. Est\u00e1 interfaz de red se configurar\u00e1 de forma est\u00e1tica o din\u00e1mica (si la red local tiene un servidor DHCP).</li> <li>En el ejemplo vemos que la interfaz f\u00edsica de red es <code>eth0</code> que estar\u00e1 conectada a <code>br0</code> para que el host tenga conectividad al exterior. Esa interfaz de red no tendr\u00e1 asignada direcci\u00f3n IP.</li> <li>Posteriormente veremos como podemos conectar las m\u00e1quinas virtuales a este bridge de tal manera que tomaran direcciones IP en el mismo direccionamiento que el host.</li> </ul> <p>Nota: Si conectamos al bridge una interfaz de tipo wifi podemos tener problemas de conectividad. No todas las tarjetas inal\u00e1mbricas permiten la conexi\u00f3n a puentes virtuales.</p> <p>Nos aseguremos que tenemos instalado el siguiente paquete que nos permite trabajar con Linux Bridge:</p> <pre><code>apt install bridge-utils\n</code></pre>"},{"location":"01.-KVM/07.-Redes/04.-Creaci%C3%B3n%20de%20un%20Puerte%20Externo%20con%20Linux%20Bridge/#creacion-de-un-bridge-externo-con-networkmanager","title":"Creaci\u00f3n de un bridge externo con NetworkManager","text":"<p>NetworkManager es una utilidad de gr\u00e1fica para simplificar el uso de redes en sistemas Linux. Normalmente la tenemos instaladas con sistemas Linux con entornos gr\u00e1ficos como Gnome. Junto a esa utilidad tenemos otra que se puede ejecutar con el comando <code>nm-connection-editor</code>, y que se llama Configuraci\u00f3n avanzada de redes:</p> <p></p> <p>Si lo ejecutamos accedemos a la siguiente pantalla:</p> <p></p> <p>Donde vemos la conexi\u00f3n de red cableada (o de wifi) que tenemos y los bridge virtuales que se han creado cuando hemos estado trabajando con las redes en libvirt. Pulsando el bot\u00f3n +, podemos de alta nueva conexi\u00f3n. A\u00f1adiremos una conexi\u00f3n de tipo Puente:</p> <p></p> <p>Y podemos indicar el nombre de la conexi\u00f3n, el nombre del puente que estamos creando, y a continuaci\u00f3n vamos a a\u00f1adirle una conexi\u00f3n al bridge que ser\u00e1 la interfaz de red f\u00edsica del host que est\u00e1 actualmente conectada al exterior.</p> <p></p> <p>A\u00f1adimos un conexi\u00f3n Cableada que ser\u00e1 la interfaz f\u00edsica del host (en mi caso <code>enp1s0</code>):</p> <p></p> <p></p> <p>Finalmente borramos la conexi\u00f3n cableada que tenemos actualmente:</p> <p></p> <p>Y en unos segundos, se conectar\u00e1 de forma autom\u00e1tica a la conexi\u00f3n Puente Externo:</p> <p> </p> <p>Comprobamos la configuraci\u00f3n de red del host:</p> <pre><code>$ ip a\n2: enp1s0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast master br0 state UP group default qlen 1000\n    link/ether 52:54:00:22:d7:3f brd ff:ff:ff:ff:ff:ff\n...\n7: br0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000\n    link/ether 92:d8:69:79:60:69 brd ff:ff:ff:ff:ff:ff\n    inet 192.168.121.168/24 brd 192.168.121.255 scope global dynamic noprefixroute br0\n       valid_lft 3459sec preferred_lft 3459sec\n...\n</code></pre> <p>Comprobamos que la interfaz f\u00edsica <code>enp1s0</code> no tiene direcci\u00f3n IP, ya que est\u00e1 conectada al bridge. La interfaz de red <code>br0</code> representa la conexi\u00f3n del bridge que ha tomado una ip del servidor DHCP de la red local (esta direcci\u00f3n IP ser\u00e1 diferente a la que ten\u00eda anteriormente la interfaz f\u00edsica).</p> <p>Si tenemos instalado el paquete <code>bridge-utils</code> podremos ver los puentes virtuales y las interfaces que tienen conectadas, ejecutando como superusuario:</p> <pre><code>brctl show\nbridge name bridge id       STP enabled interfaces\nbr0     8000.92d869796069   yes     enp1s0\nvirbr0      8000.525400aea33d   yes     \nvirbr1      8000.5254002daec2   yes     \nvirbr3      8000.52540052838e   yes\n</code></pre>"},{"location":"01.-KVM/07.-Redes/04.-Creaci%C3%B3n%20de%20un%20Puerte%20Externo%20con%20Linux%20Bridge/#creacion-de-un-bridge-externo-en-debian","title":"Creaci\u00f3n de un bridge externo en Debian","text":"<p>Si estamos trabajando en un servidor con Linux Debian instalado y no tenemos instalado NetworkManager, la configuraci\u00f3n se har\u00e1 directamente en el fichero de configuraci\u00f3n de red <code>/etc/network/intefaces</code>:</p> <pre><code>auto lo\niface lo inet loopback\n\nauto enp1s0\niface enp1s0 inet manual\n\nauto br0\niface br0 inet dhcp\n        bridge-ports enp1s0\n</code></pre> <p>Donde vemos como hemos configurado la interfaz f\u00edsica <code>enp1s0</code> de tipo <code>manual</code> para que no tome direccionamiento. Adem\u00e1s hemos declarado nuestro puente <code>br0</code> para que tome direccionamiento de forma din\u00e1mica y hemos indicado que tendr\u00e1 una interfaz conectada (<code>bridge-ports</code>) que ser\u00e1 la f\u00edsica (<code>enp1s0</code>).</p> <p>Finalmente, reiniciamos la red como superusuario:</p> <pre><code>ifdown enp1s0\nsystemctl restart networking.service\n</code></pre> <p>Y comprobamos:</p> <pre><code>ip a\n...\n2: enp1s0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast master br0 state UP group default qlen 1000\n    link/ether 52:54:00:22:d7:3f brd ff:ff:ff:ff:ff:ff\n3: br0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000\n    link/ether 92:d8:69:79:60:69 brd ff:ff:ff:ff:ff:ff\n    inet 192.168.121.169/24 brd 192.168.121.255 scope global dynamic br0\n       valid_lft 3595sec preferred_lft 3595sec\n</code></pre> <p>Podemos comprobar los puentes que tenemos creados y las interfaces que est\u00e1n conectados a \u00e9l, ejecutando la siguiente instrucci\u00f3n:</p> <pre><code>brctl show\nbridge name bridge id       STP enabled interfaces\nbr0     8000.7eb448933f70   no      enp1s0\n</code></pre>"},{"location":"01.-KVM/07.-Redes/04.-Creaci%C3%B3n%20de%20un%20Puerte%20Externo%20con%20Linux%20Bridge/#creacion-de-un-bridge-externo-en-ubuntu","title":"Creaci\u00f3n de un bridge externo en Ubuntu","text":"<p>En Ubuntu vamos a configurar el fichero <code>/etc/netplan/01-network-manager-all.yaml</code> de la siguiente forma:</p> <pre><code># Let NetworkManager manage all devices on this system\nnetwork:\n  version: 2\n  renderer: networkd\n  ethernets:\n    enp1s0:\n      dhcp4: no\n  bridges:\n    br0:\n      dhcp4: yes\n      interfaces:\n             - enp1s0\n</code></pre> <p>Y reiniciamos la red ejecutando:</p> <pre><code>sudo netplan apply\n</code></pre>"},{"location":"01.-KVM/07.-Redes/05.-Gesti%C3%B3n%20de%20Redes%20Puentes%20%28P%C3%BAblicas%29/","title":"05.-Gesti\u00f3n de Redes Puentes (P\u00fablicas)","text":"<p>En este apartado vamos  a estudiar como trabajar con las redes puentes.</p>"},{"location":"01.-KVM/07.-Redes/05.-Gesti%C3%B3n%20de%20Redes%20Puentes%20%28P%C3%BAblicas%29/#gestion-de-redes-puentes-conectadas-a-un-bridge-externo-con-virsh","title":"Gesti\u00f3n de Redes Puentes conectadas a un bridge externo con virsh","text":"<p>Partimos de que en el host tenemos creado un bridge virtual (que se suele llamar <code>br0</code>) al que est\u00e1 conectado el host. Las m\u00e1quinas virtuales se conectar\u00e1n en ese bridge y tomar\u00e1n configuraci\u00f3n de red de la misma red a la que est\u00e1 conectada el host. La definici\u00f3n quedar\u00eda de la siguiente manera.</p> <p>La configuraci\u00f3n la tenemos en el fichero <code>red-bridge.xml</code>, con el contenido:</p> <pre><code>&lt;network&gt;\n  &lt;name&gt;red_bridge&lt;/name&gt;\n  &lt;forward mode=\"bridge\"/&gt;\n  &lt;bridge name=\"br0\"/&gt;\n&lt;/network&gt;\n</code></pre> <ul> <li>El modo de forward se indica como <code>bridge</code>.</li> <li>Y en la etiqueta <code>bridge</code> se pone el nombre del bridge virtual que estamos usando.</li> </ul> <p>Para crear esta nueva red, ejecutamos:</p> <pre><code>virsh -c qemu:///system net-define red-bridge.xml \nLa red red_bridge se encuentra definida desde red-bridge.xml\n</code></pre> <p>La iniciamos:</p> <pre><code>virsh -c qemu:///system net-start red_bridge\nLa red red_bridge se ha iniciado\n</code></pre> <p>Y podemos ver que se ha creado:</p> <pre><code>virsh -c qemu:///system net-list --all\n Nombre            Estado     Inicio autom\u00e1tico   Persistente\n---------------------------------------------------------------\n default           activo     si                  si\n red_aislada       activo     si                  si\n red_bridge        inactivo   no                  si\n red_muy_aislada   inactivo   no                  si\n red_nat           activo     si                  si\n</code></pre> <p>Desde <code>virt-manager</code> no podemos crear una red de este tipo. De todas formas veremos que podemos conectar una m\u00e1quina virtual directamente al bridge <code>br0</code> con lo que ser\u00e1 lo mismo que usar la red.</p>"},{"location":"01.-KVM/07.-Redes/05.-Gesti%C3%B3n%20de%20Redes%20Puentes%20%28P%C3%BAblicas%29/#redes-puente-compartiendo-la-interfaz-fisica-del-host","title":"Redes Puente compartiendo la interfaz f\u00edsica del host","text":"<p>En este caso vamos a usar una conexi\u00f3n macvtap, que nos permite conectarnos a la red f\u00edsica directamente a trav\u00e9s de una interfaz f\u00edsica del host (sin usar un dispositivo bridge). Al igual que con la red anterior, las m\u00e1quinas virtuales estar\u00e1n conectados directamente a la red f\u00edsica, por lo que sus direcciones IP estar\u00e1n todas en la subred de la red f\u00edsica.  La definici\u00f3n de este tipo de red le hemos guardado en el fichero <code>red-interface.xml</code> y ser\u00eda la siguiente:</p> <pre><code>&lt;network&gt;\n  &lt;name&gt;red_interface&lt;/name&gt;\n  &lt;forward mode=\"bridge\"&gt;\n    &lt;interface dev=\"enp1s0\"/&gt;\n  &lt;/forward&gt;\n&lt;/network&gt;\n</code></pre> <p>Es similar a la anterior, pero se utiliza la etiqueta <code>&lt;interface&gt;</code> para indicar el nombre de la interfaz de red f\u00edsica que vamos a utilizar.</p> <p>Para utilizar este tipo de red, la interfaz que utilicemos no puede estar conectado a un puente virtual.</p>"},{"location":"01.-KVM/07.-Redes/06.-Configuraci%C3%B3n%20de%20red%20en%20MV/","title":"06.-Configuraci\u00f3n de red en MV","text":"<p>Todas las m\u00e1quinas que hemos creado durante el curso se han conectado de forma predeterminada a la red <code>default</code>. </p> <p>Sin embargo, en este apartado vamos a aprender algunas cosas nuevas: a crear m\u00e1quinas virtuales conectadas a otras redes definidas por el usuario y a a\u00f1adir interfaces de red a m\u00e1quinas virtuales ya existentes.</p>"},{"location":"01.-KVM/07.-Redes/06.-Configuraci%C3%B3n%20de%20red%20en%20MV/#crear-maquinas-virtuales-conectada-a-una-red-existente","title":"Crear m\u00e1quinas virtuales conectada a una red existente","text":"<p>Para crear una m\u00e1quina virtual conectada, por ejemplo, a la red <code>red_nat</code>, podemos usar <code>virt-install</code>:</p> <pre><code>virt-install --connect qemu:///system \\\n             --virt-type kvm \\\n             --name prueba5 \\\n             --cdrom ~/iso/debian-11.3.0-amd64-netinst.iso \\\n             --os-variant debian10 \\\n             --network network=red_nat \\\n             --disk size=10 \\\n             --memory 1024 \\\n             --vcpus 1\n</code></pre> <ul> <li>Con la opci\u00f3n <code>--network network=red_nat</code> indicamos que la m\u00e1quina tendr\u00e1 una interfaz de red conectada a la red cuyo nombre es <code>red_nat</code>.</li> <li>Para conectar una m\u00e1quina a una red tambi\u00e9n podemos indicar el bridge virtual al que queremos conectarla. en este caso utilizar\u00edamos la opci\u00f3n <code>--network bridge=virbr1</code>. <code>vribr1</code> es el bridge virtual que gestiona la red <code>red_nat</code>.</li> <li>Si indicamos varios par\u00e1metros <code>--network</code>, estar\u00edamos a\u00f1adiendo a la nueva m\u00e1quina varias interfaces de red.</li> </ul> <p>Si utilizamos <code>virt-manager</code>, para crear la nueva m\u00e1quina, durante el asistente de creaci\u00f3n de la m\u00e1quina, el el \u00faltimo paso, podemos escoger la red a la que nos vamos a conectar:</p> <p></p> <p>Tambi\u00e9n podemos escoger el puente virtual al que nos queremos conectar:</p> <p></p>"},{"location":"01.-KVM/07.-Redes/06.-Configuraci%C3%B3n%20de%20red%20en%20MV/#anadir-nuevas-interfaces-de-red-a-maquinas-virtuales","title":"A\u00f1adir nuevas interfaces de red a m\u00e1quinas virtuales","text":"<p>Para a\u00f1adir una nueva interfaz de red a una m\u00e1quina virtual, vamos a modificar su definici\u00f3n XML. Podr\u00edamos usar <code>virsh edit</code> e incluir la definici\u00f3n XML de la nueva interfaz. Sin embargo, vamos a usar un comando de <code>virsh</code> que nos facilita la operaci\u00f3n de a\u00f1adir una nueva interfaz de red y por tanto, la modificaci\u00f3n de la definici\u00f3n XML de la m\u00e1quina. Es recomendable hacer esta operaci\u00f3n con la m\u00e1quina parada.</p> <p>Por lo tanto, vamos a a\u00f1adir a la m\u00e1quina <code>prueba4</code> una interfaz de red conectada a la red <code>red_nat</code>. Para ello, ejecutamos:</p> <pre><code>virsh -c qemu:///system attach-interface prueba4 network red_nat --model virtio --persistent\nLa interfaz ha sido asociada exitosamente\n</code></pre> <p>Si la m\u00e1quina virtual no tiene entorno gr\u00e1fico y por tanto no tiene instalado el programa <code>NetworkManager</code> habr\u00e1 que acceder a ella y configurar la nueva interfaz de red.</p> <p>En nuestro caso es una m\u00e1quina virtual con Debian 11, donde se ha creado un  interfaz con el nombre <code>enp10s0</code>. Para configurarla modificamos el fichero <code>/etc/network/interfaces</code>:</p> <p></p> <p>Levantamos la interfaz y comprobamos que la nueva interfaz de red ha tomado configuraci\u00f3n de red en el direccionamiento que hab\u00edamos configura en la red <code>red_nat</code>:</p> <p></p> <p>Adem\u00e1s, podr\u00edamos ver la configuraci\u00f3n de las interfaces de red con el comando <code>virsh</code>:</p> <pre><code>virsh -c qemu:///system domifaddr prueba4\n Nombre     direcci\u00f3n MAC       Protocol     Address\n-------------------------------------------------------------------------------\n vnet7      52:54:00:d6:0a:19    ipv4         192.168.122.201/24\n vnet8      52:54:00:2a:37:fc    ipv4         192.168.123.225/24\n</code></pre> <p>Podr\u00edamos a\u00f1adir una nueva interfaz de red indicando el puente virtual al que queremos realizar la conexi\u00f3n. En este caso tendr\u00edamos que ejecutar la misma instrucci\u00f3n pero el tipo de la conexi\u00f3n ser\u00e1 <code>bridge</code>:</p> <pre><code>virsh -c qemu:///system attach-interface prueba4 bridge virbr1 --model virtio --persistent\nLa interfaz ha sido asociada exitosamente\n</code></pre> <p>Y comprobamos que tenemos una tercera interfaz:</p> <pre><code>virsh -c qemu:///system domiflist prueba4\n Interfaz   Tipo      Fuente    Modelo   MAC\n------------------------------------------------------------\n -          network   default   virtio   52:54:00:d6:0a:19\n -          network   red_nat   virtio   52:54:00:2a:37:fc\n -          bridge    virbr1    virtio   52:54:00:0c:06:2a\n</code></pre> <p>Por \u00faltimo indicar que si queremos desconectar una interfaz de red tenemos que indicar el tipo (<code>network</code> o <code>bridge</code>) y la direcci\u00f3n MAC:</p> <pre><code>virsh -c qemu:///system detach-interface prueba4 bridge --mac 52:54:00:0c:06:2a --persistent \nLa interfaz ha sido desmontada exitosamente\n</code></pre> <p>Tambi\u00e9n lo podemos hacer desde <code>virt-manager</code>. Si a\u00f1adimos nuevo hardware en la vista detalle de la m\u00e1quina, podemos a\u00f1adir una nueva conexi\u00f3n indicando la red:</p> <p></p> <p>O indicando el puente virtual donde nos vamos a conectar:</p> <p></p> <p>Tambi\u00e9n podemos modificar en cualquier momento a la red o al puente al que estamos conectado, modificando la interfaz de red desde la vista detalles:</p> <p></p> <p>Para eliminar la interfaz de red desde <code>virt-manager</code> simplemente pulsar\u00edamos con el bot\u00f3n derecho sobre el dispositivo de red en la vista detalle, y pulsar\u00edamos sobre Eliminar Hardware.</p>"},{"location":"01.-KVM/07.-Redes/06.-Configuraci%C3%B3n%20de%20red%20en%20MV/#consideraciones-finales","title":"Consideraciones finales","text":"<ul> <li>Si conectamos una m\u00e1quina virtual a una Red de tipo Aislada, tendremos que configurar de forma est\u00e1tica la interfaz y poner el mismo direccionamiento que hemos configurado para el host. Por ejemplo, para la red <code>red_aislada</code> usamos el direccionamiento <code>192.168.123.0/224</code> y la direcci\u00f3n que le asignamos al host fue <code>192.168.123.1</code>. Otras m\u00e1quinas conectadas a esta red tendr\u00e1n que estar configurada con el mismo direccionamiento.</li> <li>Si conectamos una m\u00e1quina virtual a una Red de tipo Muy Aislada, tendremos que configurar de forma est\u00e1tica la interfaz y poner el direccionamiento que nos interese. Normalmente todas las m\u00e1quinas conectada a esta red tendr\u00e1n el mismo direccionamiento para que tengan conectividad entre ellas.</li> <li> <p>Si conectamos a una Red de tipo Bridge conectada a un bridge externo, la m\u00e1quina virtual se configurar\u00e1 con el mismo direccionamiento que el host. En mis caso, trabajo con la red local <code>172.22.0.0/16</code>, si conecto la m\u00e1quina <code>prueba2</code> (tiene instalada un Ubuntu con NetworkManager) al bridge externo <code>br0</code>, tomar\u00e1 la siguiente configuraci\u00f3n:</p> <p><code>virsh -c qemu:///system attach-interface prueba2 bridge br0 --model virtio --persistent La interfaz ha sido asociada exitosamente</code></p> <p>Iniciamos la m\u00e1quina y comprobamos como la interfaz que acabamos de a\u00f1adir se configura con el direccionamiento de la red local. Esta en la misma red que el host:</p> <p></p> </li> <li> <p>Finalmente, si conectamos a una Red de tipo Bridge compartiendo la interfaz f\u00edsica del host tambi\u00e9n se debe configurar en la misma red local del host. Para realizar la conexi\u00f3n podr\u00edamos conectarnos a la red <code>red_interface</code> como hemos anteriormente. Desde <code>virt-manager</code> tambi\u00e9n podemos hacer la conexi\u00f3n indicando el dispositivo f\u00edsico que vamos a usar:</p> <p></p> <p>Iniciamos la m\u00e1quina y comprobamos:</p> <p></p> </li> </ul>"},{"location":"01.-KVM/08.-LXC/01.-Introduccion%20a%20LXC/","title":"01.-Introduccion a LXC","text":"<p>LinuX Containers, tambi\u00e9n conocido por el acr\u00f3nimo LXC, es una tecnolog\u00eda de virtualizaci\u00f3n ligera o por contenedores, que es un m\u00e9todo de virtualizaci\u00f3n en el que, sobre el n\u00facleo del sistema operativo se ejecuta una capa de virtualizaci\u00f3n que permite que existan m\u00faltiples instancias aisladas de espacios de usuario, en lugar de solo uno. A estas instancias la llamamos contenedores.</p> <p>LXC pertenece a los denominados contenedores de sistemas, su gesti\u00f3n y ciclo de vida es similar al de una m\u00e1quina virtual tradicional. Est\u00e1 mantenido por Canonical y la p\u00e1gina oficial es linuxcontainers.org.</p>"},{"location":"01.-KVM/08.-LXC/01.-Introduccion%20a%20LXC/#instalacion-de-lxc","title":"Instalaci\u00f3n de LXC","text":"<p>Vamos a trabajar sobre una distribuci\u00f3n GNU/Linux Debian 11. Para la instalaci\u00f3n de LXC ejecutamos:</p> <pre><code>apt install lxc\n</code></pre> <p>Podemos crear contenedores LXC privilegiados (ejecutados como root) y no privilegiados (ejecutados por un usuario normal). En este curso vamos a trabajar con contenedores privilegiados.</p>"},{"location":"01.-KVM/08.-LXC/02.-Creaci%C3%B3n%20y%20gesti%C3%B3n%20de%20contenedores/","title":"02.-Creaci\u00f3n y gesti\u00f3n de contenedores","text":"<p>Al crear un contenedor se bajar\u00e1 el sistema de archivos que formar\u00e1 parte de \u00e9l. La primera vez que bajamos con <code>debootstrap</code> una versi\u00f3n de un sistema operativo se descargar\u00e1 un sistema de archivo m\u00ednimo del sistema (que llamamos plantilla) que servir\u00e1 para crear todos los contenedores que creemos de la misma versi\u00f3n del sistema.</p> <p>La creaci\u00f3n de un contenedor con la \u00faltima versi\u00f3n de debian, se realiza con la instrucci\u00f3n (ejecutada como <code>root</code>):</p> <pre><code>$ lxc-create -n contenedor1 -t debian -- -r bullseye\n</code></pre> <ul> <li><code>-n</code>: Nombre del contenedor.</li> <li><code>-t</code>: Nombre de la plantilla.</li> <li><code>-r</code>: Es una opci\u00f3n de la plantilla. Es el nombre de la versi\u00f3n del sistema operativo. Para ver m\u00e1s opciones de una plantilla ejecutamos: <code>lxc-create -t debian -h</code>.</li> </ul> <p>Podemos comprobar que se ha creado un contenedor, ejecutando:</p> <pre><code>$ lxc-ls\ncontenedor1 \n</code></pre> <p>La plantilla que hemos descargado se guarda en <code>/var/cache/lxc/debian/rootfs-bullseye-amd64/</code>. Esta copia del sistema de archivo se utilizar\u00e1 cuando creemos otro contenedor con el mismo sistema operativo. El sistema de archivo del <code>contenedor1</code> se guarda en <code>/var/lib/lxc/contenedor1/rootfs/</code>.</p> <p>Ahora podemos iniciar la ejecuci\u00f3n del contenedor, comprobar que est\u00e1 funcionando y acceder a \u00e9l:</p> <pre><code>$ lxc-start contenedor1\n$ lxc-ls -f\nNAME        STATE   AUTOSTART GROUPS IPV4       IPV6 UNPRIVILEGED \ncontenedor1 RUNNING 0         -      10.0.3.180 -    false        \n$ lxc-attach contenedor1\nroot@contenedor1:~# \n</code></pre> <p>Iniciamos el contenedor con <code>lxc-start</code>, comprobamos los contenedores que tenemos creados con <code>lxc-ls</code> con la opci\u00f3n <code>-f</code> nos da m\u00e1s informaci\u00f3n (vemos que est\u00e1 ejecut\u00e1ndose, que no se ejecuta al inicio, que ha tomado una direcci\u00f3n ip y que es privilegiado). Por \u00faltimo nos hemos conectado al contenedor con <code>lxc-attach</code>.</p> <p>Podemos parar el contenedor con <code>lxc-stop</code> y eliminar el contenedor con <code>lxc-destroy</code>.</p> <p>Para visualizar todas las plantillas que podemos descargar, ejecutamos:</p> <pre><code>$ ls /usr/share/lxc/templates/\nlxc-alpine    lxc-archlinux  lxc-centos  lxc-debian    lxc-fedora     lxc-gentoo  lxc-oci       lxc-opensuse  lxc-plamo  lxc-sabayon    lxc-sparclinux  lxc-ubuntu    lxc-voidlinux\nlxc-altlinux  lxc-busybox    lxc-cirros  lxc-download  lxc-fedora-legacy  lxc-local   lxc-openmandriva  lxc-oracle    lxc-pld    lxc-slackware  lxc-sshd    lxc-ubuntu-cloud\n</code></pre> <p>Tambi\u00e9n puedes obtener la lista de plantillas en la p\u00e1gina Image server for LXC and LXD.</p>"},{"location":"01.-KVM/08.-LXC/02.-Creaci%C3%B3n%20y%20gesti%C3%B3n%20de%20contenedores/#ejecucion-de-comandos-en-un-contenedor","title":"Ejecuci\u00f3n de comandos en un contenedor","text":"<p>Podemos ejecutar un comando en un contenedor que se est\u00e9 ejecutando de la siguiente manera:</p> <pre><code>$ lxc-attach contenedor1 -- ls -al\n</code></pre> <p>si el contenedor est\u00e1 apagado, lo har\u00edamos de la siguiente forma:</p> <pre><code>$ lxc-stop contenedor1\n$ lxc-execute contenedor1 -- ls -al\n</code></pre>"},{"location":"01.-KVM/08.-LXC/02.-Creaci%C3%B3n%20y%20gesti%C3%B3n%20de%20contenedores/#eliminar-un-contenedor","title":"Eliminar un contenedor","text":"<p>Para eliminar un contenedor podemos ejecutar la siguiente instrucci\u00f3n con el contenedor parado:</p> <pre><code>$ lxc-destroy contendor1\n</code></pre> <p>Si el contenedor est\u00e1 inicado podemos usar el par\u00e1metro <code>-f</code> de la instracci\u00f3n <code>lxc-destroy</code> para eliminarlo.</p>"},{"location":"01.-KVM/08.-LXC/03.-Configuraci%C3%B3n%20de%20contenedores%20LXC/","title":"03.-Configuraci\u00f3n de contenedores LXC","text":"<p>El fichero <code>/etc/lxc/default.conf</code> contiene la configuraci\u00f3n general que van a tener los contenedores que creemos. Su contenido es el siguiente:</p> <pre><code>lxc.net.0.type = veth\nlxc.net.0.link = lxcbr0\nlxc.net.0.flags = up\n\nlxc.apparmor.profile = generated\nlxc.apparmor.allow_nesting = 1\n</code></pre> <p>Como vemos se indica a qu\u00e9 red se va a conectar (<code>lxc.net.</code>). Una vez creado un contenedor, el contenido de este fichero se copia a su fichero de configuraci\u00f3n (al que se a\u00f1aden otras configuraciones por defecto). Por ejemplo el fichero de configuraci\u00f3n del contenedor <code>contenedor1</code> lo encontramos en el fichero <code>/var/lib/lxc/contenedor1/config</code>. en este caso, su contenido es:</p> <pre><code>lxc.net.0.type = veth\nlxc.net.0.hwaddr = 00:16:3e:cf:8f:c3\nlxc.net.0.link = lxcbr0\nlxc.net.0.flags = up\nlxc.apparmor.profile = generated\nlxc.apparmor.allow_nesting = 1\nlxc.rootfs.path = dir:/var/lib/lxc/contenedor1/rootfs\n\n# Common configuration\nlxc.include = /usr/share/lxc/config/debian.common.conf\n\n# Container specific configuration\nlxc.tty.max = 4\nlxc.uts.name = contenedor1\nlxc.arch = amd64\nlxc.pty.max = 1024\n</code></pre> <p>Vemos que se han copiado los par\u00e1metros de la configuraci\u00f3n general (<code>/etc/lxc/default.conf</code>) y se han a\u00f1adido nuevos par\u00e1metros: n\u00famero m\u00e1ximo de terminales (<code>lxc.tty.max</code>,<code>lxc.pty.max</code>), nombre del contenedor (<code>lxc.uts.name</code>), arquitectura (<code>lxc.arch</code>), ubicaci\u00f3n del sistema de fichero (<code>lxc.rootfs.path</code>), ...</p> <p>Puedes ver los distintos par\u00e1metros que podemos incluir en la documentaci\u00f3n oficial. Por ejemplo si queremos que los contenedores se inicien autom\u00e1ticamente al iniciar el host podr\u00edamos:</p> <pre><code>lxc.start.auto = 1\n</code></pre> <p>Recuerda que tenemos dos opciones:</p> <ol> <li>Si escribimos el par\u00e1metro en la configuraci\u00f3n general, en el fichero <code>/etc/lxc/default.conf</code>, afectar\u00e1 a los contenedores que se creen nuevos.</li> <li>Si queremos modificar la configuraci\u00f3n de un contenedor ya creado, tenemos que incluir el par\u00e1metro en su fichero de configuraci\u00f3n, por ejemplo para el <code>contenedor1</code> en <code>/var/lib/lxc/contenedor1/config</code>.</li> </ol>"},{"location":"01.-KVM/08.-LXC/03.-Configuraci%C3%B3n%20de%20contenedores%20LXC/#obteniendo-informacion-de-un-contenedor","title":"Obteniendo informaci\u00f3n de un contenedor","text":"<p>Para obtener informaci\u00f3n de un contenedor podemos ejecutar:</p> <pre><code>$ lxc-info contenedor1\nName:           contenedor1\nState:          RUNNING\nPID:            12587\nIP:             10.0.3.180\nLink:           vethuLaHzY\n TX bytes:      1.70 KiB\n RX bytes:      3.80 KiB\n Total bytes:   5.50 KiB\n</code></pre> <p>Con la opci\u00f3n <code>-i</code> s\u00f3lo nos da  la direcci\u00f3n ip, con la opci\u00f3n <code>-S</code> nos da la estad\u00edstica de informaci\u00f3n enviada y recibida por la interfaz de red y con la opci\u00f3n <code>-s</code> nos da informaci\u00f3n del estado.</p>"},{"location":"01.-KVM/08.-LXC/03.-Configuraci%C3%B3n%20de%20contenedores%20LXC/#limitando-los-recursos-para-los-contenedores-lxc","title":"Limitando los recursos para los contenedores LXC","text":"<p>Por defectos los contenedores LXC pueden usar todos los recursos de CPU, RAM, disco del host. Podemos limitar estos recursos. El componente del n\u00facleo que posibilita limitar los recursos para cada contenedor son los Grupos de control cgroups, en concreto en Debian 11 y Debian 12 se utiliza cgroupsv2.</p> <p>Lo primero es que tenemos que habilitar la modificaci\u00f3n de la memoria en los Grupos de control (cgroups). Para ello tenemos que a\u00f1adir al fichero <code>/etc/default/grub</code> la siguiente informaci\u00f3n: a\u00f1adimos al par\u00e1metro <code>GRUB_CMDLINE_LINUX_DEFAULT</code> el valor <code>cgroup_enable=memory</code>. Para que tenga este cambio efecto, reiniciamos la m\u00e1quina.</p> <p>Vamos a limitar el uso de memoria RAM (512Mb) y de n\u00famero de procesadores (1 CPU: la CPU 0) (en la m\u00e1quina donde estoy corriendo los contenedores tenemos 2Gb de RAM y 2 CPUs), para ello en el fichero de configuraci\u00f3n del <code>contenedor1</code> indicamos los siguientes par\u00e1metros:</p> <pre><code>lxc.cgroup2.memory.max = 512M\nlxc.cgroup2.cpuset.cpus = 0\n</code></pre> <p>Reiniciamos el contenedor y comprobamos que se ha llevado a efecto el cambio:</p> <pre><code>$ lxc-stop contenedor1\n$ lxc-start contenedor1\n\n$ lxc-attach contenedor1 -- free -h\n               total        used        free      shared  buff/cache   available\nMem:           512Mi       6.0Mi       505Mi       0.0Ki       0.0Ki       505Mi\n\n$ lxc-attach contenedor1 -- cat /proc/cpuinfo \nprocessor   : 0\n...\n</code></pre> <p>Aparece un s\u00f3lo procesador.</p>"},{"location":"01.-KVM/08.-LXC/04.-Redes%20en%20LXC/","title":"04.-Redes en LXC","text":"<p>LXC nos ofrece distintos mecanismos para conectar nuestros contenedores a una red. En este curso nos vamos a centrar en las conexiones de tipo bridge. Tenemos dos posibilidades:</p> <ul> <li>Podemos crear manualmente el bridge o usar libvirt para su creaci\u00f3n (podemos crear distintos tipos de redes con libvirt).</li> <li>Podemos usar <code>lxc-net</code>, servicio ofrecido por LXC, que nos facilita la creaci\u00f3n de un bridge, que por defecto se llama <code>lxcbr0</code>, y que nos ofrece una red de tipo NAT con los servicios de DHCP y DNS.</li> </ul>"},{"location":"01.-KVM/08.-LXC/04.-Redes%20en%20LXC/#redes-con-lxc-net","title":"Redes con lxc-net","text":"<p>Veamos en primer lugar la segunda opci\u00f3n. El servicio <code>lxc-net</code>  crea un bridge llamado <code>lxcbr0</code> que nos ofrece una red de tipo NAT con los servicios DHCP y DNS. Por defecto nos ofrece una red con direccionamiento <code>10.0.3.0/24</code>.</p>"},{"location":"01.-KVM/08.-LXC/04.-Redes%20en%20LXC/#conexion-de-los-contenedores-a-lxcbr0","title":"Conexi\u00f3n de los contenedores a <code>lxcbr0</code>","text":"<p>La configuraci\u00f3n por defecto posibilita que los contenedores que creemos se conecten a esta red. Lo podemos ver en la configuraci\u00f3n general, en el fichero <code>/etc/lxc/default.conf</code>:</p> <pre><code>lxc.net.0.type = veth\nlxc.net.0.link = lxcbr0\nlxc.net.0.flags = up\n...\n</code></pre> <p>Si hemos creado un contenedor llamado <code>contenedor1</code> recibir\u00e1 esta configuraci\u00f3n que podremos encontrar en su fichero de configuraci\u00f3n <code>/var/lib/lxc/contenedor1/config</code>:</p> <pre><code>lxc.net.0.type = veth\nlxc.net.0.hwaddr = 00:16:3e:cf:8f:c3\nlxc.net.0.link = lxcbr0\nlxc.net.0.flags = up\n...\n</code></pre> <p>Por lo tanto podemos comprobar que el <code>contenedor1</code> est\u00e1 conectado a esa red. Por ejemplo, si mostramos los contenedores que hemos creado, vemos que ha recibido una ip en ese rango:</p> <pre><code>$ lxc-ls -f\nNAME        STATE   AUTOSTART GROUPS IPV4       IPV6 UNPRIVILEGED \ncontenedor1 RUNNING 1         -      10.0.3.180 -    false        \n</code></pre> <p>Si accedemos al contenedor podemos hacer varias comprobaciones:</p> <pre><code>$ lxc-attach contenedor1\nroot@contenedor1:~# ip a\n...\n2: eth0@if4: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000\n    inet 10.0.3.180/24 brd 10.0.3.255 scope global dynamic eth0\n...\n\nroot@contenedor1:~# ip r\ndefault via 10.0.3.1 dev eth0 \n10.0.3.0/24 dev eth0 proto kernel scope link src 10.0.3.180 \n\nroot@contenedor1:~# cat /etc/resolv.conf \nnameserver 10.0.3.1\n\nroot@contenedor1:~# apt install iputils-ping\n...\nroot@contenedor1:~# ping www.josedomingo.org\nPING endor.josedomingo.org (37.187.119.60) 56(84) bytes of data.\n64 bytes from ns330309.ip-37-187-119.eu (37.187.119.60): icmp_seq=1 ttl=49 time=28.7 ms\n...\n</code></pre> <ol> <li>Comprobamos que se ha configurado con la ip <code>10.0.3.180</code>.</li> <li>Vemos que la puerta de enlace es la <code>10.0.3.1</code> que corresponde a nuestra m\u00e1quina f\u00edsica.</li> <li>Del mismo modo la m\u00e1quina f\u00edsica es el servidor DNS.</li> <li>Hemos instalado la herramienta <code>ping</code> y comprobamos que tenemos resoluci\u00f3n y acceso al exterior.</li> </ol>"},{"location":"01.-KVM/08.-LXC/04.-Redes%20en%20LXC/#conexion-de-los-contenedores-a-un-bridge-existente","title":"Conexi\u00f3n de los contenedores a un bridge existente","text":"<p>Imaginemos que tenemos en nuestro host instalado libvirt para manejar los recursos de KVM/QEMU y hemos creado una red con <code>virsh</code> de tipo NAT, que ha creado un bridge llamado <code>virbr0</code>, con las siguientes caracter\u00edsticas:</p> <pre><code>$ virsh net-dumpxml default\n&lt;network&gt;\n  &lt;name&gt;default&lt;/name&gt;\n  &lt;uuid&gt;c411a5a1-f998-42a9-bc8a-9a9052fc36f6&lt;/uuid&gt;\n  &lt;forward mode='nat'&gt;\n    &lt;nat&gt;\n      &lt;port start='1024' end='65535'/&gt;\n    &lt;/nat&gt;\n  &lt;/forward&gt;\n  &lt;bridge name='virbr0' stp='on' delay='0'/&gt;\n  &lt;mac address='52:54:00:fc:32:a2'/&gt;\n  &lt;ip address='192.168.122.1' netmask='255.255.255.0'&gt;\n    &lt;dhcp&gt;\n      &lt;range start='192.168.122.2' end='192.168.122.254'/&gt;\n    &lt;/dhcp&gt;\n  &lt;/ip&gt;\n&lt;/network&gt;\n</code></pre> <p>Podemos modificar el fichero de configuraci\u00f3n por defecto <code>/etc/lxc/default.conf</code>, indicando el bridge <code>virbr0</code>:</p> <pre><code>lxc.net.0.type = veth\nlxc.net.0.link = virbr0\nlxc.net.0.flags = up\n...\n</code></pre> <p>Todos los nuevos contenedores que creemos se conectar\u00e1n a la red <code>default</code>:</p> <pre><code>$ lxc-create -n contenedor2 -t debian -- -r bullseye\n$ lxc-start contenedor2\n$ lxc-ls -f\nNAME        STATE   AUTOSTART GROUPS IPV4            IPV6 UNPRIVILEGED \ncontenedor1 RUNNING 1         -      10.0.3.10       -    false        \ncontenedor2 RUNNING 1         -      192.168.122.228 -    false        \n</code></pre> <p>Vemos como el <code>contenedor2</code> ha tomado en una ip de la red <code>default</code>.</p> <p>Si quisi\u00e9ramos cambiar la conexi\u00f3n del un contenedor ya existente deber\u00edamos hacer la modificaci\u00f3n en su fichero de configuraci\u00f3n: <code>/var/lib/lxc/&lt;NOMBRE_CONTENEDOR&gt;/config</code> y reiniciar el contenedor.</p> <p>Tambi\u00e9n podr\u00edamos conectar el <code>contenedor1</code> a la red <code>default</code>, para ello vamos a a\u00f1adir la informaci\u00f3n de la conexi\u00f3n en su fichero de configuraci\u00f3n <code>/var/lib/lxc/contenedor1/config</code>:</p> <pre><code>lxc.net.0.type = veth\nlxc.net.0.hwaddr = 00:16:3e:cf:8f:c3\nlxc.net.0.link = lxcbr0\nlxc.net.0.flags = up\n\nlxc.net.1.type = veth\nlxc.net.1.hwaddr = 00:16:3e:cf:8f:d3\nlxc.net.1.link = virbr0\nlxc.net.1.flags = up\n...\n</code></pre> <p>Indicamos la segunda conexi\u00f3n utilizando el nombre de los par\u00e1metros como <code>lxc.net.1.*</code>. Adem\u00e1s hemos cambiado la mac de la segunda tarjeta de red. Ahora reiniciamos y accedemos al contenedor:</p> <pre><code>$ lxc-stop -r contenedor1\n$ lxc-attach contenedor1\nroot@contenedor1:~# apt install nano\nroot@contenedor1:~# nano /etc/network/interfaces\n</code></pre> <p>Configuramos la segunda interfaz de red:</p> <pre><code>auto lo\niface lo inet loopback\n\nauto eth0\niface eth0 inet dhcp\n\nauto eth1\niface eth1 inet dhcp\n</code></pre> <p>Y obtenemos una nueva direcci\u00f3n ip en la nueva red:</p> <pre><code>root@contenedor1:~# ifup eth1\nroot@contenedor1:~# ip a\n...\n2: eth0@if13: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000\n...\n    inet 10.0.3.10/24 brd 10.0.3.255 scope global dynamic eth0\n...\n3: eth1@if14: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000\n...\n    inet 192.168.122.196/24 brd 192.168.122.255 scope global dynamic eth1\n...\n</code></pre> <p>Si listamos los contenedores que tenemos, podemos ver las dos direcciones ip:</p> <pre><code>$ lxc-ls -f\nNAME        STATE   AUTOSTART GROUPS IPV4                        IPV6 UNPRIVILEGED \ncontenedor1 RUNNING 1         -      10.0.3.10, 192.168.122.196  -    false        \ncontenedor2 RUNNING 1         -      192.168.122.228             -    false    \n</code></pre>"},{"location":"01.-KVM/08.-LXC/05.-Almacenamiento%20en%20LXC/","title":"05.-Almacenamiento en LXC","text":"<p>Veamos c\u00f3mo montar un directorio del host en un contenedor. Imaginemos que tenemos el directorio <code>/opt/contenedor1</code> con un fichero <code>index.html</code> y lo queremos montar en el <code>contenedor1</code> en el directorio <code>/srv/www</code>. Tenemos que tener en cuenta los siguiente:</p> <p>El directorio de montaje debe existir en el contenedor:</p> <pre><code>$ lxc-attach contenedor1\nroot@contenedor1:~# cd /srv\nroot@contenedor1:/srv# mkdir www\n</code></pre> <p>En el fichero de configuraci\u00f3n del contenedor (<code>/var/lib/lxc/contenedor1/config</code>) a\u00f1adimos la siguiente l\u00ednea:</p> <pre><code>lxc.mount.entry=/opt/contenedor1 srv/www none bind 0 0\n</code></pre> <p>Hay que tener en cuenta que al indicar el directorio de montaje hay que usar una ruta relativa (es relativa al directorio donde se encuentra el sistema de fichero del contenedor, en este caso <code>/var/lib/lxc/contenedor1/rootfs/</code>).</p> <p>Reiniciamos el contenedor y comprobamos que se ha montado el directorio de forma correcta:</p> <pre><code>$ lxc-stop contenedor1\n$ lxc-start contenedor1\n$ lxc-attach contenedor1\nroot@contenedor1:~# cd /srv/www\nroot@contenedor1:/srv/www# ls\nindex.html\n</code></pre>"},{"location":"01.-KVM/08.-LXC/06.-Introducci%C3%B3n%20a%20LXD/","title":"06.-Introducci\u00f3n a LXD","text":"<p>LXD, Linux Container Daemon, es una herramienta de gesti\u00f3n de los contenedores y m\u00e1quinas virtuales del sistema operativo Linux, desarrollada por Canonical.</p> <p>Internamente usa LXC para la gesti\u00f3n de contenedores, pero facilita el uso de los contenedores a\u00f1adiendo nuevas funcionalidades.</p> <ul> <li>LXD no trabaja con plantillas, trabaja con im\u00e1genes de sistemas operativos para crear los contenedores. Lista de im\u00e1genes.</li> <li>No ofrece soporte para diferentes backends de almacenamiento y tipos de red. Facilitando la gesti\u00f3n de red y almacenamiento.</li> <li>LXD ofrece una REST API que podemos usar con una simple herramienta de l\u00ednea de comandos o con herramientas de terceros.</li> <li>LXD gestiona instancias, que pueden ser de tipos: contenedores, usando LXC internamente, y m\u00e1quinas virtuales usando QEMU internamente.</li> </ul>"},{"location":"01.-KVM/08.-LXC/06.-Introducci%C3%B3n%20a%20LXD/#instalacion-de-lxd","title":"Instalaci\u00f3n de LXD","text":"<p>Vamos a usar el gestor de paquetes snap (si est\u00e1s trabajando con la distribuci\u00f3n Debian 11 debes instalar el paquete <code>snapd</code>).</p> <pre><code>sudo snap install lxd\n</code></pre> <p>En la versi\u00f3n Debian 12 lo podemos instalar con <code>apt</code>:</p> <pre><code>apt install lxd\n</code></pre> <p>Antes de ejecutar una instancia (contenedor o m\u00e1quina virtual) tenemos que hacer una configuraci\u00f3n inicial de LXD, para ello ejecutamos como root:</p> <pre><code>lxd init\n</code></pre> <p>Interactivamente nos va preguntando distintos par\u00e1metros que nos permitir\u00e1n realizar la configuraci\u00f3n inicial:</p> <pre><code>Would you like to use LXD clustering? (yes/no) [default=no]: \nDo you want to configure a new storage pool? (yes/no) [default=yes]: \nName of the new storage pool [default=default]: \nName of the storage backend to use (cephobject, dir, lvm, btrfs, ceph) [default=btrfs]: dir\nWould you like to connect to a MAAS server? (yes/no) [default=no]: \nWould you like to create a new local network bridge? (yes/no) [default=yes]: \nWhat should the new bridge be called? [default=lxdbr0]: \nWhat IPv4 address should be used? (CIDR subnet notation, \u201cauto\u201d or \u201cnone\u201d) [default=auto]: \nWhat IPv6 address should be used? (CIDR subnet notation, \u201cauto\u201d or \u201cnone\u201d) [default=auto]: \nWould you like the LXD server to be available over the network? (yes/no) [default=no]: \nWould you like stale cached images to be updated automatically? (yes/no) [default=yes]: \nWould you like a YAML \"lxd init\" preseed to be printed? (yes/no) [default=no]: \n</code></pre> <p>Hemos dejado todos los valores por defecto, a excepci\u00f3n del tipo de pool de almacenamiento que he indicado que sea un directorio (dir). Tambi\u00e9n ha creado una red puente para conectar los contenedores.</p>"},{"location":"01.-KVM/08.-LXC/06.-Introducci%C3%B3n%20a%20LXD/#creacion-de-un-contenedor","title":"Creaci\u00f3n de un contenedor","text":"<p>Para crear un contenedor, ejecutamos:</p> <pre><code>lxc launch &lt;image_server&gt;:&lt;image_name&gt; &lt;instance_name&gt;\n</code></pre> <p>Por ejemplo:</p> <pre><code>lxc launch images:ubuntu/20.04 ubuntu-container\n</code></pre>"},{"location":"01.-KVM/08.-LXC/06.-Introducci%C3%B3n%20a%20LXD/#creacion-de-maquinas-virtuales","title":"Creaci\u00f3n de m\u00e1quinas virtuales","text":"<p>Para crear una m\u00e1quina virtual, ejecutamos:</p> <pre><code>lxc launch &lt;image_server&gt;:&lt;image_name&gt; &lt;instance_name&gt; --vm\n</code></pre> <p>Por ejemplo:</p> <pre><code>lxc launch images:ubuntu/20.04 ubuntu-vm --vm\n</code></pre> <p>Y comprobamos que hemos creado un contenedor y una m\u00e1quina virtual:</p> <pre><code>lxc list\n+------------------+---------+-------------------------+-------------------------------------------------+-----------------+-----------+\n|       NAME       |  STATE  |          IPV4           |                      IPV6                       |      TYPE       | SNAPSHOTS |\n+------------------+---------+-------------------------+-------------------------------------------------+-----------------+-----------+\n| ubuntu-container | RUNNING | 10.242.154.69 (eth0)    | fd42:40c4:7788:440e:216:3eff:fe61:66b0 (eth0)   | CONTAINER       | 0         |\n+------------------+---------+-------------------------+-------------------------------------------------+-----------------+-----------+\n| ubuntu-vm        | RUNNING | 10.242.154.119 (enp5s0) | fd42:40c4:7788:440e:216:3eff:fea3:8748 (enp5s0) | VIRTUAL-MACHINE | 0         |\n+------------------+---------+-------------------------+-------------------------------------------------+-----------------+-----------+\n</code></pre>"},{"location":"01.-KVM/08.-LXC/06.-Introducci%C3%B3n%20a%20LXD/#gestion-de-imagenes","title":"Gesti\u00f3n de im\u00e1genes","text":"<p>En la creaci\u00f3n de las dos instancias hemos descargado dos im\u00e1genes que podemos gestionar con el subcomando <code>lxc image</code>, por ejemplo para ver las im\u00e1genes que hemos descargado:</p> <pre><code>lxc image  list\n+-------+--------------+--------+-------------------------------------+--------------+-----------------+----------+------------------------------+\n| ALIAS | FINGERPRINT  | PUBLIC |             DESCRIPTION             | ARCHITECTURE |      TYPE       |   SIZE   |         UPLOAD DATE          |\n+-------+--------------+--------+-------------------------------------+--------------+-----------------+----------+------------------------------+\n|       | 3aa3fa64e5d0 | no     | Ubuntu focal amd64 (20220911_07:42) | x86_64       | VIRTUAL-MACHINE | 230.98MB | Sep 12, 2022 at 7:28am (UTC) |\n+-------+--------------+--------+-------------------------------------+--------------+-----------------+----------+------------------------------+\n|       | 7628425e768e | no     | Ubuntu focal amd64 (20220911_07:42) | x86_64       | CONTAINER       | 110.65MB | Sep 12, 2022 at 7:22am (UTC) |\n+-------+--------------+--------+-------------------------------------+--------------+-----------------+----------+------------------------------+\n</code></pre> <p>Para m\u00e1s informaci\u00f3n ejecuta <code>lxc image --help</code>.</p>"},{"location":"01.-KVM/08.-LXC/06.-Introducci%C3%B3n%20a%20LXD/#gestion-de-instancia","title":"Gesti\u00f3n de instancia","text":"<p>Vamos a usar la utilidad de l\u00ednea de comandos <code>lxc</code>, para ver todas las funcionalidades puedes ejecutar <code>lxc --help</code>. Veamos algunas de ella:</p> <ul> <li><code>lxc list</code>: Listar instancias. Podemos filtrar la lista, por ejemplo <code>lxc list type=container</code> o <code>lxc list ubuntu.*</code>.</li> <li><code>lxc info</code>: Nos da informaci\u00f3n de una instancia. Con la opci\u00f3n <code>--show-log</code> nos muestra los logs de la instancia.</li> <li><code>lxc start</code>: Inicia una instancia.</li> <li><code>lxc stop</code>: Detiene una instancia.</li> <li><code>lxc delete</code>: Borra una instancia.</li> </ul> <p>Si queremos ejecutar un comando en una instancia, ejecutamos:</p> <pre><code>lxc exec &lt;instance_name&gt; -- &lt;command&gt;\n</code></pre> <p>Por ejemplo:</p> <pre><code>lxc exec ubuntu-container -- apt update\n</code></pre> <p>Si queremos acceder a una shell de la instancia:</p> <pre><code>lxc exec ubuntu-container -- /bin/bash\n</code></pre> <p>Si queremos conectarnos a una instancia por una consola, ejecutamos:</p> <pre><code>lxc console &lt;instance_name&gt;\n</code></pre> <p>Nota: Deber\u00edamos configurar una contrase\u00f1a para un usuario anteriormente accediendo al bash de la instancia.</p>"},{"location":"01.-KVM/08.-LXC/06.-Introducci%C3%B3n%20a%20LXD/#configuracion-de-las-instancias","title":"Configuraci\u00f3n de las instancias","text":"<p>Tenemos muchos par\u00e1metros de configuraci\u00f3n de las instancias, que podemos devivir en tres bloques: propiedades de las instancias, openciones de las instancias y dispositivos de las instancias.</p> <p>Al crear una instancia podemos indicar los par\u00e1metros de configuraci\u00f3n deseados, por ejemplo, si queremos limitar el n\u00famero de CPU y la memoria de un contenedor, podemos ejecutar:</p> <pre><code>lxc launch images:ubuntu/20.04 ubuntu-limited -c limits.cpu=1 -c limits.memory=192MiB\n</code></pre> <p>Con el subcomando <code>lxc config</code> podemos gestionar la configuraci\u00f3n de las instancias, por ejemplo para mostrar la configuraci\u00f3n de una instancia, ejecutamos:</p> <pre><code>lxc config show ubuntu-container\n</code></pre> <p>Por ejemplo, para cambiar un par\u00e1metro:</p> <pre><code>lxc config set ubuntu-container limits.memory=128MiB\n</code></pre>"},{"location":"01.-KVM/08.-LXC/06.-Introducci%C3%B3n%20a%20LXD/#para-seguir-profundizando","title":"Para seguir profundizando","text":"<ul> <li>M\u00e1s informaci\u00f3n sobre la configuraci\u00f3n de instancias.</li> <li>M\u00e1s informaci\u00f3n sobre la gesti\u00f3n de im\u00e1genes.</li> <li>Con el subcomando <code>lxc network</code> gestionamos las redes. M\u00e1s informaci\u00f3n.</li> <li>Con el subcomando <code>lxc storage</code> gestionamos los pools de almacenamiento. M\u00e1s informaci\u00f3n.</li> </ul>"},{"location":"01.-KVM/09.-Anexos/01.-Uso%20de%20los%20puertos%20USB%20en%20KVM/","title":"01.-Uso de los puertos USB en KVM","text":""},{"location":"01.-KVM/09.-Anexos/01.-Uso%20de%20los%20puertos%20USB%20en%20KVM/#tutorial-uso-de-un-puerto-usb-en-una-maquina-virtual-kvmqemu","title":"Tutorial: Uso de un puerto USB en una m\u00e1quina virtual KVM/QEMU","text":""},{"location":"01.-KVM/09.-Anexos/01.-Uso%20de%20los%20puertos%20USB%20en%20KVM/#requisitos-previos","title":"Requisitos previos","text":"<ul> <li>Tienes instalado y configurado KVM y QEMU en tu m\u00e1quina host.</li> <li>Tienes una m\u00e1quina virtual (MV) ya creada y en funcionamiento en tu sistema de virtualizaci\u00f3n KVM/QEMU.</li> <li>El puerto USB y los dispositivos que quieres conectar deben estar f\u00edsicamente accesibles en tu host.</li> </ul>"},{"location":"01.-KVM/09.-Anexos/01.-Uso%20de%20los%20puertos%20USB%20en%20KVM/#pasos-para-usar-un-puerto-usb-en-una-mv-kvmqemu","title":"Pasos para usar un puerto USB en una MV KVM/QEMU","text":""},{"location":"01.-KVM/09.-Anexos/01.-Uso%20de%20los%20puertos%20USB%20en%20KVM/#1-verificar-dispositivos-usb-en-el-host","title":"1. Verificar dispositivos USB en el host","text":"<p>Primero, debemos identificar los dispositivos USB conectados en el host que queremos pasar a la m\u00e1quina virtual.</p> <ol> <li>Abre una terminal en el host.</li> <li>Ejecuta el comando:    <code>bash    lsusb</code>    Esto listar\u00e1 todos los dispositivos USB conectados. El formato de salida se ver\u00e1 algo como esto:    <code>Bus 001 Device 003: ID 0951:16a4 Kingston Technology    Bus 001 Device 002: ID 8087:0024 Intel Corp. Integrated Rate Matching Hub</code></li> </ol> <p>Toma nota del Bus y Device ID del dispositivo USB que deseas conectar a tu m\u00e1quina virtual (en este caso, <code>Bus 001 Device 003</code>).</p>"},{"location":"01.-KVM/09.-Anexos/01.-Uso%20de%20los%20puertos%20USB%20en%20KVM/#2-anadir-el-dispositivo-usb-a-la-mv-con-virt-manager","title":"2. A\u00f1adir el dispositivo USB a la MV con virt-manager","text":"<p>Si prefieres una interfaz gr\u00e1fica, puedes usar virt-manager para a\u00f1adir el dispositivo USB a tu MV.</p> <ol> <li>Abre virt-manager:    <code>bash    virt-manager</code></li> <li>Selecciona la m\u00e1quina virtual a la que deseas conectar el USB.</li> <li>Haz clic en el bot\u00f3n de Detalles de la MV (icono de herramientas).</li> <li>Navega a la pesta\u00f1a Add Hardware (Agregar Hardware).</li> <li>Selecciona USB Host Device en la lista y elige el dispositivo USB que aparece en la lista (ej. \"Kingston Technology\").</li> <li>Haz clic en Finish o Apply para a\u00f1adir el dispositivo USB a la m\u00e1quina virtual.</li> </ol>"},{"location":"01.-KVM/09.-Anexos/01.-Uso%20de%20los%20puertos%20USB%20en%20KVM/#3-anadir-el-dispositivo-usb-a-la-mv-desde-la-linea-de-comandos-virsh","title":"3. A\u00f1adir el dispositivo USB a la MV desde la l\u00ednea de comandos (virsh)","text":"<p>Si prefieres trabajar con la terminal, puedes a\u00f1adir el dispositivo USB usando el comando <code>virsh</code>.</p> <ol> <li> <p>Aseg\u00farate de que tu MV est\u00e9 detenida antes de agregar el dispositivo USB:    <code>bash    virsh shutdown &lt;nombreMV&gt;</code></p> </li> <li> <p>Agrega el dispositivo USB usando el comando <code>virsh attach-device</code>:    <code>bash    virsh attach-device &lt;nombreMV&gt; --file &lt;path_al_xml_del_dispositivo&gt;</code></p> </li> </ol> <p>El archivo XML debe tener la siguiente estructura:    <code>xml    &lt;hostdev mode='subsystem' type='usb'&gt;      &lt;source&gt;        &lt;vendor id='0x0951'/&gt;        &lt;product id='0x16a4'/&gt;      &lt;/source&gt;    &lt;/hostdev&gt;</code></p> <p>Donde <code>vendor id</code> y <code>product id</code> son los valores que obtuviste con <code>lsusb</code>. En este caso, <code>0951</code> es el vendor id de Kingston, y <code>16a4</code> es el product id.</p> <ol> <li>Inicia la m\u00e1quina virtual de nuevo:    <code>bash    virsh start &lt;nombreMV&gt;</code></li> </ol>"},{"location":"01.-KVM/09.-Anexos/01.-Uso%20de%20los%20puertos%20USB%20en%20KVM/#4-verificar-el-dispositivo-usb-en-la-mv","title":"4. Verificar el dispositivo USB en la MV","text":"<p>Una vez que hayas agregado el dispositivo USB, inicia sesi\u00f3n en tu m\u00e1quina virtual (por ejemplo, mediante <code>virt-manager</code> o SSH). Luego:</p> <ol> <li>Abre una terminal en la MV.</li> <li>Ejecuta el comando:    <code>bash    lsusb</code>    El dispositivo USB deber\u00eda aparecer en la lista dentro de la MV.</li> </ol>"},{"location":"01.-KVM/09.-Anexos/01.-Uso%20de%20los%20puertos%20USB%20en%20KVM/#notas-adicionales","title":"Notas adicionales:","text":"<ul> <li> <p>Desconectar el dispositivo USB: Para desconectar el dispositivo USB de la MV mientras est\u00e1 en funcionamiento, puedes usar el siguiente comando:   <code>bash   virsh detach-device &lt;nombreMV&gt; &lt;path_al_xml_del_dispositivo&gt;</code></p> </li> <li> <p>Acceso exclusivo: Cuando conectas un dispositivo USB a una MV, este dispositivo ya no estar\u00e1 accesible desde el host hasta que se desasocie de la MV.</p> </li> <li> <p>Compatibilidad: Aseg\u00farate de que los drivers necesarios para el dispositivo USB est\u00e1n instalados tanto en el host como en la m\u00e1quina virtual para evitar problemas de compatibilidad.</p> </li> </ul>"},{"location":"01.-KVM/09.-Anexos/02.-Copiar%20y%20Pegar/","title":"02.-Copiar y Pegar","text":""},{"location":"01.-KVM/09.-Anexos/02.-Copiar%20y%20Pegar/#tutorial-configurar-kvm-para-permitir-copiar-y-pegar-entre-maquinas-virtuales","title":"Tutorial: Configurar KVM para permitir copiar y pegar entre m\u00e1quinas virtuales","text":""},{"location":"01.-KVM/09.-Anexos/02.-Copiar%20y%20Pegar/#requisitos-previos","title":"Requisitos previos","text":"<ul> <li>Tienes KVM y QEMU instalados y funcionando correctamente en tu m\u00e1quina host.</li> <li>Tienes una m\u00e1quina virtual (MV) creada y en funcionamiento.</li> </ul>"},{"location":"01.-KVM/09.-Anexos/02.-Copiar%20y%20Pegar/#pasos-para-habilitar-la-funcionalidad-de-copiar-y-pegar-portapapeles-compartido","title":"Pasos para habilitar la funcionalidad de copiar y pegar (Portapapeles compartido)","text":"<p>Para poder copiar y pegar texto entre el host y las m\u00e1quinas virtuales, debes instalar y configurar un conjunto de herramientas llamado Spice. Spice es un protocolo que, entre otras cosas, permite habilitar la compartici\u00f3n del portapapeles.</p>"},{"location":"01.-KVM/09.-Anexos/02.-Copiar%20y%20Pegar/#paso-1-instalar-spice-en-el-host","title":"Paso 1: Instalar Spice en el host","text":"<ol> <li>Abre una terminal en tu host.</li> <li>Aseg\u00farate de que tienes instalado el paquete <code>spice-vdagent</code> en el host. Ejecuta:    <code>bash    sudo apt update    sudo apt install spice-vdagent</code></li> </ol> <p>En otras distribuciones, puedes utilizar el gestor de paquetes de tu sistema (por ejemplo, <code>dnf</code> en Fedora).</p>"},{"location":"01.-KVM/09.-Anexos/02.-Copiar%20y%20Pegar/#paso-2-configurar-la-maquina-virtual-en-virt-manager","title":"Paso 2: Configurar la m\u00e1quina virtual en <code>virt-manager</code>","text":"<ol> <li>Abre virt-manager en tu host:    <code>bash    virt-manager</code></li> <li>Selecciona la m\u00e1quina virtual a la que deseas agregar la funcionalidad de copiar y pegar.</li> <li>Haz clic en el bot\u00f3n de Detalles de la MV (icono de herramientas).</li> <li>En el men\u00fa de la izquierda, selecciona la opci\u00f3n Display Spice (o Display en algunas versiones).</li> <li>Aseg\u00farate de que el servidor de Spice est\u00e9 seleccionado para la visualizaci\u00f3n y no VNC.</li> <li>Navega a la pesta\u00f1a de Video dentro de la configuraci\u00f3n de la m\u00e1quina virtual y selecciona el controlador QXL como el dispositivo de video.</li> <li>Guarda los cambios y arranca la m\u00e1quina virtual.</li> </ol>"},{"location":"01.-KVM/09.-Anexos/02.-Copiar%20y%20Pegar/#paso-3-instalar-spice-y-spice-vdagent-en-la-maquina-virtual","title":"Paso 3: Instalar Spice y <code>spice-vdagent</code> en la m\u00e1quina virtual","text":"<p>Dependiendo del sistema operativo que est\u00e9s utilizando en la m\u00e1quina virtual, necesitar\u00e1s instalar el spice-vdagent para habilitar la funcionalidad de portapapeles compartido.</p>"},{"location":"01.-KVM/09.-Anexos/02.-Copiar%20y%20Pegar/#en-linux-debianubuntu","title":"En Linux (Debian/Ubuntu)","text":"<ol> <li>Abre una terminal dentro de la m\u00e1quina virtual.</li> <li>Instala el paquete <code>spice-vdagent</code> ejecutando:    <code>bash    sudo apt update    sudo apt install spice-vdagent</code></li> <li>Reinicia la m\u00e1quina virtual para que los cambios surtan efecto.</li> </ol>"},{"location":"01.-KVM/09.-Anexos/02.-Copiar%20y%20Pegar/#en-windows","title":"En Windows","text":"<ol> <li>Descarga e instala los Spice Guest Tools desde este enlace.</li> <li>Sigue el asistente de instalaci\u00f3n para agregar los controladores de Spice a tu sistema Windows.</li> <li>Reinicia la m\u00e1quina virtual.</li> </ol>"},{"location":"01.-KVM/09.-Anexos/02.-Copiar%20y%20Pegar/#paso-4-probar-copiar-y-pegar","title":"Paso 4: Probar copiar y pegar","text":"<ol> <li>Una vez reiniciada la m\u00e1quina virtual, intenta copiar texto desde el host (por ejemplo, selecciona texto y presiona <code>Ctrl+C</code>).</li> <li>Luego, ve a la m\u00e1quina virtual, selecciona un \u00e1rea de texto y presiona <code>Ctrl+V</code> para pegar.</li> <li>Verifica que el texto copiado se haya transferido correctamente.</li> </ol>"},{"location":"01.-KVM/09.-Anexos/02.-Copiar%20y%20Pegar/#notas-adicionales","title":"Notas adicionales:","text":"<ul> <li>Spice-vdagent es el agente responsable de la compartici\u00f3n del portapapeles, entre otras funciones (como la redirecci\u00f3n de dispositivos USB).</li> <li>Adem\u00e1s de copiar y pegar texto, tambi\u00e9n puedes redimensionar autom\u00e1ticamente la ventana de la m\u00e1quina virtual si usas el controlador de video QXL.</li> <li>En virt-manager, aseg\u00farate siempre de que est\u00e1s utilizando Spice en lugar de VNC para habilitar estas funciones avanzadas.</li> </ul>"},{"location":"01.-KVM/10.-Ejercicios/","title":"Ejercicios KVM","text":""},{"location":"01.-KVM/10.-Ejercicios/#ejercicio-1-verificacion-del-soporte-de-virtualizacion-en-el-host","title":"Ejercicio 1: Verificaci\u00f3n del Soporte de Virtualizaci\u00f3n en el Host","text":"<p>Tarea: Ejecuta el comando egrep -c '(vmx|svm)' /proc/cpuinfo en tu m\u00e1quina host para verificar si el procesador soporta virtualizaci\u00f3n por hardware (Intel VT o AMD-V).</p> <p>Instrucciones:</p> <ul> <li>Abre una terminal en tu sistema Linux.</li> <li>Ejecuta el comando indicado.</li> <li>Si el resultado es mayor que 0, la virtualizaci\u00f3n est\u00e1 habilitada.  Objetivo: Verificar que el hardware soporta la creaci\u00f3n de m\u00e1quinas virtuales con KVM.</li> </ul>"},{"location":"01.-KVM/10.-Ejercicios/#ejercicio-2-instalacion-de-kvm-y-herramientas-de-virtualizacion","title":"Ejercicio 2: Instalaci\u00f3n de KVM y Herramientas de Virtualizaci\u00f3n","text":"<p>Tarea: Instala el paquete qemu-kvm, libvirt-bin, y virt-manager en una distribuci\u00f3n Linux (por ejemplo, Ubuntu) y habilita el servicio de libvirtd.</p> <p>Instrucciones:</p> <ul> <li> <p>Ejecuta <code>apt install qemu-system libvirt-clients libvirt-daemon-system</code>.</p> </li> <li> <p>Habilita el servicio con <code>sudo systemctl enable libvirtd</code> y luego in\u00edcialo con sudo <code>systemctl start libvirtd</code>.</p> </li> <li> <p>Verifica la correcta instalaci\u00f3n ejecutando <code>virsh list --all</code>.</p> </li> </ul> <p>Objetivo: Preparar el sistema para crear y administrar m\u00e1quinas virtuales.</p>"},{"location":"01.-KVM/10.-Ejercicios/#ejercicio-3-creacion-de-una-maquina-virtual-desde-la-cli","title":"Ejercicio 3: Creaci\u00f3n de una M\u00e1quina Virtual desde la CLI","text":"<p>Tarea: Utiliza el comando <code>virt-install</code> para crear una m\u00e1quina virtual Ubuntu desde la l\u00ednea de comandos con un disco de 10GB y 2GB de RAM.</p> <p>Instrucciones:</p> <ul> <li>Descarga una imagen de Ubuntu Server (ISO).</li> <li>Ejecuta el siguiente comando:</li> </ul> <pre><code>sudo virt-install --name UbuntuVM \\\n  --ram 2048 \\\n  --vcpus 2 \\\n  --disk path=/var/lib/libvirt/images/ubuntu.qcow2,size=10 \\\n  --location ./Desktop/ubuntu-24.04.1-live-server-amd64.iso,kernel=casper/vmlinuz,initrd=casper/initrd \\\n  --os-variant ubuntu24.04 \\\n  --network bridge=virbr0 \\\n  --graphics none \\\n  --console pty,target_type=serial \\\n  --extra-args 'console=ttyS0,115200n8 serial'\n</code></pre> <p>Sigue el proceso de instalaci\u00f3n a trav\u00e9s de la consola.</p> <p>Objetivo: Crear y administrar una m\u00e1quina virtual usando solo la CLI.</p>"},{"location":"01.-KVM/10.-Ejercicios/#ejercicio-4-creacion-de-un-disco-virtual-adicional-para-una-mv-existente","title":"Ejercicio 4: Creaci\u00f3n de un Disco Virtual Adicional para una MV Existente","text":"<p>Tarea: A\u00f1adir un segundo disco virtual de 5GB a una m\u00e1quina virtual existente. Instrucciones: - Det\u00e9n la m\u00e1quina virtual con virsh shutdown . - Usa el comando virsh edit  para editar la configuraci\u00f3n XML de la m\u00e1quina. - A\u00f1ade la siguiente secci\u00f3n en el archivo XML: <pre><code>&lt;disk type='file' device='disk'&gt;\n   &lt;driver name='qemu' type='qcow2'/&gt;\n   &lt;source file='/var/lib/libvirt/images/disk2.qcow2'/&gt;\n   &lt;target dev='vdb' bus='virtio'/&gt;\n&lt;/disk&gt;\n</code></pre> <ul> <li>Guarda el archivo y arranca la MV de nuevo.</li> </ul> <p>Objetivo: Familiarizarse con la administraci\u00f3n de almacenamiento adicional en una MV.</p>"},{"location":"01.-KVM/10.-Ejercicios/#ejercicio-5-migracion-en-vivo-de-una-mv-a-otro-host","title":"Ejercicio 5: Migraci\u00f3n en Vivo de una MV a Otro Host","text":"<p>Tarea: Realizar una migraci\u00f3n en vivo de una m\u00e1quina virtual desde un host KVM a otro sin detenerla. Instrucciones: - Aseg\u00farate de que ambos hosts est\u00e1n configurados correctamente para permitir la migraci\u00f3n. - Ejecuta el siguiente comando desde el host origen:</p> <pre><code>$ virsh migrate --live &lt;nombreMV&gt; qemu+ssh://user@destination/system\n</code></pre> <ul> <li>Verifica que la MV sigue ejecut\u00e1ndose en el host destino con virsh list.</li> </ul> <p>Objetivo: Ejecutar una migraci\u00f3n en vivo para mejorar la disponibilidad y el mantenimiento de sistemas.</p>"},{"location":"01.-KVM/10.-Ejercicios/#ejercicio-6-uso-de-snapshots-en-mvs","title":"Ejercicio 6: Uso de Snapshots en MVs","text":"<p>Tarea: Crear un snapshot de una m\u00e1quina virtual en funcionamiento y restaurarla a ese punto despu\u00e9s de realizar cambios en el sistema operativo. Instrucciones:</p> <ul> <li>Para crear un snapshot:</li> </ul> <pre><code>$virsh snapshot-create-as --domain &lt;nombreMV&gt; --name \"snapshot1\" --description \"Estado limpio antes de actualizaciones\"\n</code></pre> <p>Realiza algunos cambios en la MV, como instalar software o modificar configuraciones. Restaura el estado anterior usando:</p> <pre><code>virsh snapshot-revert &lt;nombreMV&gt; snapshot1\n</code></pre> <p>Objetivo: Aprender a utilizar snapshots para la recuperaci\u00f3n r\u00e1pida de MVs.</p>"},{"location":"01.-KVM/10.-Ejercicios/#ejercicio-7-configuracion-de-nat-en-la-red-virtual","title":"Ejercicio 7: Configuraci\u00f3n de NAT en la Red Virtual","text":"<p>Tarea: Configurar NAT para las m\u00e1quinas virtuales, permitiendo que accedan a Internet a trav\u00e9s del host.</p> <p>Instrucciones:</p> <ul> <li>Edita el archivo de red default con el siguiente comando:</li> </ul> <pre><code>virsh net-edit default\n</code></pre> <ul> <li>Configura el modo de red en NAT, verificando la conectividad de la MV hacia el exterior.</li> </ul> <p>Usa <code>ping</code> desde la MV para verificar que puede acceder a Internet.</p> <p>Objetivo: Configurar redes virtuales para conectar MVs con redes externas.</p>"},{"location":"01.-KVM/10.-Ejercicios/#ejercicio-8-creacion-de-una-maquina-virtual-con-virt-manager","title":"Ejercicio 8: Creaci\u00f3n de una M\u00e1quina Virtual con Virt-Manager","text":"<p>Tarea: Utiliza la interfaz gr\u00e1fica virt-manager para crear una m\u00e1quina virtual Windows 10 con 4GB de RAM y un disco de 20GB. Instrucciones:</p> <ul> <li>Abre virt-manager y selecciona la opci\u00f3n para crear una nueva m\u00e1quina.</li> <li>Sigue las instrucciones para elegir la imagen de instalaci\u00f3n y configurar los recursos de la m\u00e1quina.</li> <li>Inicia la instalaci\u00f3n de Windows desde la interfaz gr\u00e1fica.</li> </ul> <p>Objetivo: Familiarizarse con la administraci\u00f3n de MVs desde la interfaz gr\u00e1fica.</p>"},{"location":"01.-KVM/10.-Ejercicios/#ejercicio-9-clonacion-de-una-maquina-virtual","title":"Ejercicio 9: Clonaci\u00f3n de una M\u00e1quina Virtual","text":"<p>Tarea: Clona una m\u00e1quina virtual existente y c\u00e1mbiale el nombre y la direcci\u00f3n MAC de la interfaz de red. Instrucciones:</p> <ul> <li>Ejecuta el comando:</li> </ul> <pre><code>$ virt-clone --original &lt;nombreMV&gt; --name &lt;nombreClon&gt; --file /var/lib/libvirt/images/&lt;nombreClon&gt;.qcow2\n</code></pre> <p>Edita la direcci\u00f3n MAC para evitar conflictos de red:</p> <pre><code>$ virsh edit &lt;nombreClon&gt;\n</code></pre> <ul> <li>Busca la secci\u00f3n de la interfaz de red y cambia el valor de la direcci\u00f3n MAC.</li> </ul> <p>Objetivo: Dominar la clonaci\u00f3n y personalizaci\u00f3n de m\u00e1quinas virtuales.</p>"},{"location":"01.-KVM/10.-Ejercicios/#ejercicio-10-implementacion-de-contenedores-lxc","title":"Ejercicio 10: Implementaci\u00f3n de Contenedores LXC","text":"<p>Tarea: Crear un contenedor LXC en el entorno KVM, configurando las capacidades de red compartida con el host. Instrucciones: - Instala LXC con sudo apt install lxc. - Crea un contenedor b\u00e1sico:</p> <pre><code>lxc-create -n mycontainer -t ubuntu\n</code></pre> <ul> <li>Configura el acceso a la red compartida entre el contenedor y el host.</li> <li>Inicia el contenedor con lxc-start.</li> </ul> <p>Objetivo: Integrar la tecnolog\u00eda de contenedores dentro del entorno de virtualizaci\u00f3n KVM.</p>"},{"location":"01.-KVM/10.-Ejercicios/01.-Instrucciones%20para%20la%20captura/","title":"01.-Instrucciones para la captura","text":""},{"location":"01.-KVM/10.-Ejercicios/01.-Instrucciones%20para%20la%20captura/#ejercicio-1-verificacion-del-soporte-de-virtualizacion-en-el-host","title":"Ejercicio 1: Verificaci\u00f3n del soporte de virtualizaci\u00f3n en el host","text":"<p>Instrucciones para la captura:</p> <ol> <li> <p>Abre una terminal en tu sistema Linux.</p> </li> <li> <p>Ejecuta el comando: <code>bash    egrep -c '(vmx|svm)' /proc/cpuinfo</code></p> </li> <li> <p>Aseg\u00farate de que el resultado del comando sea visible en la terminal.</p> </li> <li> <p>Haz una captura de pantalla mostrando claramente la terminal con el comando ejecutado y el resultado visible.</p> </li> </ol>"},{"location":"01.-KVM/10.-Ejercicios/01.-Instrucciones%20para%20la%20captura/#ejercicio-2-instalacion-de-kvm-y-herramientas-de-virtualizacion","title":"Ejercicio 2: Instalaci\u00f3n de KVM y herramientas de virtualizaci\u00f3n","text":"<p>Instrucciones para la captura:</p> <ol> <li> <p>Abre una terminal.</p> </li> <li> <p>Ejecuta el siguiente comando para mostrar que los paquetes necesarios est\u00e1n instalados:     <code>bash    dpkg -l | grep -E 'qemu-kvm|libvirt-bin|virt-manager'</code></p> </li> <li> <p>Aseg\u00farate de que la salida de los paquetes instalados se vea completa en la terminal.</p> </li> <li> <p>Haz una captura de pantalla mostrando el resultado en la terminal con el comando ejecutado.</p> </li> </ol>"},{"location":"01.-KVM/10.-Ejercicios/01.-Instrucciones%20para%20la%20captura/#ejercicio-3-creacion-de-una-maquina-virtual-desde-la-cli","title":"Ejercicio 3: Creaci\u00f3n de una m\u00e1quina virtual desde la CLI","text":"<p>Instrucciones para la captura:</p> <ol> <li> <p>Tras haber creado la m\u00e1quina virtual usando el comando <code>virt-install</code>, abre una terminal.</p> </li> <li> <p>Ejecuta el comando para listar las m\u00e1quinas virtuales:    <code>bash    virsh list --all</code></p> </li> <li> <p>Aseg\u00farate de que el nombre de la MV que has creado est\u00e9 en la lista.</p> </li> <li> <p>Haz una captura de pantalla de la terminal mostrando el comando y la salida con la MV visible.</p> </li> </ol>"},{"location":"01.-KVM/10.-Ejercicios/01.-Instrucciones%20para%20la%20captura/#ejercicio-4-creacion-de-un-disco-virtual-adicional-para-una-mv-existente","title":"Ejercicio 4: Creaci\u00f3n de un disco virtual adicional para una MV existente","text":"<p>Instrucciones para la captura:</p> <ol> <li> <p>Abre una terminal y ejecuta el siguiente comando para verificar que el segundo disco ha sido a\u00f1adido correctamente:    <code>bash    virsh domblklist &lt;nombreMV&gt;</code></p> </li> <li> <p>Aseg\u00farate de que la salida muestre tanto el disco principal como el disco adicional (<code>vdb</code>).</p> </li> <li> <p>Haz una captura de pantalla de la terminal con el comando ejecutado y los discos listados.</p> </li> </ol>"},{"location":"01.-KVM/10.-Ejercicios/01.-Instrucciones%20para%20la%20captura/#ejercicio-5-migracion-en-vivo-de-una-mv-a-otro-host","title":"Ejercicio 5: Migraci\u00f3n en vivo de una MV a otro host","text":"<p>Instrucciones para la captura:</p> <ol> <li> <p>Realiza la migraci\u00f3n en vivo de la MV a otro host.</p> </li> <li> <p>En el host de origen, ejecuta el comando:    <code>bash    virsh list --all</code></p> </li> <li> <p>Aseg\u00farate de que la MV ya no est\u00e9 en la lista del host de origen.</p> </li> <li> <p>En el host de destino, ejecuta el mismo comando <code>virsh list --all</code> y aseg\u00farate de que la MV aparece en la lista.</p> </li> <li> <p>Haz una captura de pantalla de ambas terminales (host origen y host destino) mostrando la migraci\u00f3n completada.</p> </li> </ol>"},{"location":"01.-KVM/10.-Ejercicios/01.-Instrucciones%20para%20la%20captura/#ejercicio-6-uso-de-snapshots-en-mvs","title":"Ejercicio 6: Uso de Snapshots en MVs","text":"<p>Instrucciones para la captura:</p> <ol> <li> <p>Tras crear el snapshot, ejecuta el siguiente comando para listar los snapshots de la m\u00e1quina virtual:    <code>bash    virsh snapshot-list &lt;nombreMV&gt;</code></p> </li> <li> <p>Aseg\u00farate de que el snapshot creado est\u00e9 en la lista.</p> </li> <li> <p>Haz una captura de pantalla de la terminal con el comando ejecutado y el snapshot visible.</p> </li> </ol>"},{"location":"01.-KVM/10.-Ejercicios/01.-Instrucciones%20para%20la%20captura/#ejercicio-7-configuracion-de-nat-en-la-red-virtual","title":"Ejercicio 7: Configuraci\u00f3n de NAT en la Red Virtual","text":"<p>Instrucciones para la captura:</p> <ol> <li> <p>Abre una terminal y edita la red predeterminada con el comando:    <code>bash    virsh net-edit default</code></p> </li> <li> <p>Captura la ventana mostrando la configuraci\u00f3n de la red en modo de edici\u00f3n.</p> </li> <li> <p>Luego, ejecuta el comando:    <code>bash    virsh net-list</code></p> </li> <li> <p>Aseg\u00farate de que la red NAT est\u00e9 activa.</p> </li> <li> <p>Haz una captura de pantalla mostrando la configuraci\u00f3n y el estado de la red.</p> </li> </ol>"},{"location":"01.-KVM/10.-Ejercicios/01.-Instrucciones%20para%20la%20captura/#ejercicio-8-creacion-de-una-mv-con-virt-manager","title":"Ejercicio 8: Creaci\u00f3n de una MV con Virt-Manager","text":"<p>Instrucciones para la captura:</p> <ol> <li> <p>Abre <code>virt-manager</code> y navega hasta la m\u00e1quina virtual que creaste con esta herramienta.</p> </li> <li> <p>Muestra la ventana de la MV donde se vea su nombre, los recursos asignados (RAM, disco, etc.), y que est\u00e1 en ejecuci\u00f3n.</p> </li> <li> <p>Haz una captura de pantalla de la interfaz de <code>virt-manager</code> con estos detalles visibles.</p> </li> </ol>"},{"location":"01.-KVM/10.-Ejercicios/01.-Instrucciones%20para%20la%20captura/#ejercicio-9-clonacion-de-una-maquina-virtual","title":"Ejercicio 9: Clonaci\u00f3n de una M\u00e1quina Virtual","text":"<p>Instrucciones para la captura:</p> <ol> <li> <p>Despu\u00e9s de haber clonado la MV, ejecuta en una terminal:    <code>bash    virsh list --all</code></p> </li> <li> <p>Aseg\u00farate de que tanto la m\u00e1quina original como el clon est\u00e1n en la lista, mostrando claramente los dos nombres.</p> </li> <li> <p>Haz una captura de pantalla de la terminal con ambos nombres de m\u00e1quinas visibles.</p> </li> </ol>"},{"location":"01.-KVM/10.-Ejercicios/01.-Instrucciones%20para%20la%20captura/#ejercicio-10-implementacion-de-contenedores-lxc","title":"Ejercicio 10: Implementaci\u00f3n de Contenedores LXC","text":"<p>Instrucciones para la captura:</p> <ol> <li> <p>Despu\u00e9s de crear el contenedor LXC, ejecuta el siguiente comando para verificar que el contenedor est\u00e1 en funcionamiento:    <code>bash    lxc-ls --fancy</code></p> </li> <li> <p>Aseg\u00farate de que el contenedor que has creado est\u00e9 listado con su nombre y estado.</p> </li> <li> <p>Haz una captura de pantalla mostrando el comando y la lista de contenedores.</p> </li> </ol>"},{"location":"01.-KVM/10.-Ejercicios/02.-Solucionario/","title":"02.-Solucionario","text":""},{"location":"01.-KVM/10.-Ejercicios/02.-Solucionario/#ejercicio-1-verificacion-del-soporte-de-virtualizacion-en-el-host","title":"Ejercicio 1: Verificaci\u00f3n del soporte de virtualizaci\u00f3n en el host","text":"<ul> <li> <p>Abro una terminal en el host.</p> </li> <li> <p>Ejecuto el comando:</p> </li> </ul> <pre><code>egrep -c '(vmx|svm)' /proc/cpuinfo\n</code></pre> <p>Resultado:  </p> <pre><code>2\n</code></pre> <p>Esto indica que la CPU del host soporta virtualizaci\u00f3n por hardware.</p>"},{"location":"01.-KVM/10.-Ejercicios/02.-Solucionario/#ejercicio-2-instalacion-de-kvm-y-herramientas-de-virtualizacion","title":"Ejercicio 2: Instalaci\u00f3n de KVM y herramientas de virtualizaci\u00f3n","text":"<ul> <li>Abro una terminal en el host.</li> <li>Ejecuto los siguientes comandos para instalar KVM y las herramientas necesarias:</li> </ul> <pre><code>sudo apt update\nsudo apt upgrade\nsudo apt install qemu-system libvirt-clients libvirt-daemon-system\n\n</code></pre> <p>Resultado:  </p> <p>KVM y <code>virt-manager</code> est\u00e1n instalados exitosamente.</p> <ul> <li>Verifico que el servicio de <code>libvirtd</code> est\u00e1 activo:</li> </ul> <pre><code>sudo systemctl status libvirtd\n</code></pre> <p>Resultado: El servicio de <code>libvirtd</code> est\u00e1 corriendo y habilitado.</p>"},{"location":"01.-KVM/10.-Ejercicios/02.-Solucionario/#ejercicio-3-creacion-de-una-maquina-virtual-desde-la-cli","title":"Ejercicio 3: Creaci\u00f3n de una m\u00e1quina virtual desde la CLI","text":"<ul> <li>Descargo una imagen ISO de Ubuntu Server.</li> <li>Creo una m\u00e1quina virtual desde la CLI usando el siguiente comando:</li> </ul> <pre><code>sudo virt-install \\\n  --name UbuntuVM \\\n  --ram 2048 \\\n  --vcpus 2 \\\n  --disk path=/var/lib/libvirt/images/ubuntu.qcow2,size=10 \\\n  --cdrom /home/tu_usuario/Descargas/ubuntu-20.04.iso \\\n  --os-variant ubuntu20.04 \\\n  --network bridge=virbr0 \\\n  --graphics none \\\n  --console pty,target_type=serial \\\n  --extra-args 'console=ttyS0,115200n8 serial'\n</code></pre> <ul> <li>Verifico que la MV est\u00e1 creada:</li> </ul> <pre><code>$ virsh list --all\n</code></pre> <p>Resultado: La m\u00e1quina virtual <code>UbuntuVM</code> aparece en la lista con el estado apagada o running si se ha iniciado correctamente.</p>"},{"location":"01.-KVM/10.-Ejercicios/02.-Solucionario/#ejercicio-4-creacion-de-un-disco-virtual-adicional-para-una-mv-existente","title":"Ejercicio 4: Creaci\u00f3n de un disco virtual adicional para una MV existente","text":"<ul> <li>Detengo la m\u00e1quina virtual:</li> </ul> <pre><code>virsh shutdown UbuntuVM\n</code></pre> <ul> <li>Edici\u00f3n del archivo XML de la MV para agregar un segundo disco:</li> </ul> <pre><code>virsh edit UbuntuVM\n</code></pre> <ul> <li>Agrego el siguiente bloque XML para el disco adicional:</li> </ul> <pre><code>&lt;disk type='file' device='disk'&gt;\n  &lt;driver name='qemu' type='qcow2'/&gt;\n  &lt;source file='/var/lib/libvirt/images/disk2.qcow2'/&gt;\n  &lt;target dev='vdb' bus='virtio'/&gt;\n&lt;/disk&gt;\n</code></pre> <ul> <li>Inicio la MV de nuevo:</li> </ul> <pre><code>virsh start UbuntuVM\n</code></pre> <ul> <li>Verifico los discos conectados:</li> </ul> <pre><code>virsh domblklist UbuntuVM\n</code></pre> <p>Resultado: La MV muestra los discos conectados, incluyendo <code>vda</code> (disco original) y <code>vdb</code> (nuevo disco).</p>"},{"location":"01.-KVM/10.-Ejercicios/02.-Solucionario/#nota-aclaratoria","title":"Nota Aclaratoria:","text":"<ul> <li>\u00bfPor qu\u00e9 <code>virsh edit</code> abre un archivo ubicado en el directorio <code>/tmp</code>?</li> </ul> <p>Cuando ejecutas el comando:</p> <pre><code>virsh edit ubuntu_server\n</code></pre> <p>virsh realiza lo siguiente:</p> <ul> <li>Generaci\u00f3n del Archivo Temporal: Crea una copia de la configuraci\u00f3n XML actual de la m\u00e1quina virtual ubuntu_server en un archivo temporal dentro de /tmp. Esto permite que realices modificaciones sin afectar directamente el archivo de configuraci\u00f3n original.</li> <li>Edici\u00f3n de la Configuraci\u00f3n: Abre el archivo temporal en tu editor de texto predeterminado (como vi, nano, etc.). Aqu\u00ed puedes realizar los cambios que consideres necesarios.</li> <li>Validaci\u00f3n y Aplicaci\u00f3n de Cambios: Al guardar y cerrar el editor, virsh valida la sintaxis del XML modificado. Si la validaci\u00f3n es exitosa, libvirt aplica los cambios a la configuraci\u00f3n persistente de la m\u00e1quina virtual. El archivo temporal en /tmp se descarta autom\u00e1ticamente.</li> </ul>"},{"location":"01.-KVM/10.-Ejercicios/02.-Solucionario/#ejercicio-5-migracion-en-vivo-de-una-mv-a-otro-host","title":"Ejercicio 5: Migraci\u00f3n en vivo de una MV a otro host","text":"<ul> <li>En el host de origen, ejecuto:</li> </ul> <pre><code>virsh migrate --live UbuntuVM qemu+ssh://user@destination/system\n</code></pre> <ul> <li>Verifico que la MV ha sido migrada correctamente:</li> <li>En el host de origen:   <code>bash   virsh list --all</code> Resultado:   La MV no aparece en el host de origen.</li> <li>En el host de destino:   <code>bash   virsh list --all</code> Resultado:   La MV <code>UbuntuVM</code> aparece en el host de destino y est\u00e1 corriendo.</li> </ul>"},{"location":"01.-KVM/10.-Ejercicios/02.-Solucionario/#ejercicio-6-uso-de-snapshots-en-mvs","title":"Ejercicio 6: Uso de Snapshots en MVs","text":"<ul> <li>Creo un snapshot de la m\u00e1quina virtual:</li> </ul> <pre><code>virsh snapshot-create-as --domain UbuntuVM --name \"snapshot1\" --description \"Estado limpio antes de actualizaciones\"\n</code></pre> <ul> <li>Listo los snapshots creados:</li> </ul> <pre><code>virsh snapshot-list UbuntuVM\n</code></pre> <p>Resultado: El snapshot <code>snapshot1</code> aparece en la lista. - Realizo algunos cambios en el sistema. - Restaura el snapshot:</p> <pre><code>virsh snapshot-revert UbuntuVM snapshot1\n</code></pre> <p>Resultado: La MV se ha revertido al estado del snapshot.</p>"},{"location":"01.-KVM/10.-Ejercicios/02.-Solucionario/#ejercicio-7-configuracion-de-nat-en-la-red-virtual","title":"Ejercicio 7: Configuraci\u00f3n de NAT en la Red Virtual","text":"<ul> <li>Edito la configuraci\u00f3n de la red predeterminada:</li> </ul> <pre><code>virsh net-edit default\n</code></pre> <ul> <li>Verifico que la red est\u00e1 configurada en modo NAT.</li> <li>Verifico que la red est\u00e1 activa:</li> </ul> <pre><code>virsh net-list\n</code></pre> <p>Resultado: La red <code>default</code> est\u00e1 activa y las m\u00e1quinas virtuales pueden acceder a Internet a trav\u00e9s de NAT.</p>"},{"location":"01.-KVM/10.-Ejercicios/02.-Solucionario/#ejercicio-8-creacion-de-una-mv-con-virt-manager","title":"Ejercicio 8: Creaci\u00f3n de una MV con Virt-Manager","text":"<ul> <li>Abro <code>virt-manager</code>.</li> <li>Creo una nueva m\u00e1quina virtual seleccionando la imagen ISO de Windows 10, asignando 4GB de RAM y un disco de 20GB.</li> <li>Inicio la instalaci\u00f3n y sigo las instrucciones.</li> <li>Verifico que la MV est\u00e1 creada y en ejecuci\u00f3n en <code>virt-manager</code>.</li> </ul>"},{"location":"01.-KVM/10.-Ejercicios/02.-Solucionario/#ejercicio-9-clonacion-de-una-maquina-virtual","title":"Ejercicio 9: Clonaci\u00f3n de una M\u00e1quina Virtual","text":"<ul> <li>Clono la MV <code>UbuntuVM</code>:</li> </ul> <pre><code>virt-clone --original UbuntuVM --name UbuntuClone --file /var/lib/libvirt/images/UbuntuClone.qcow2\n</code></pre> <ul> <li>Verifico que tanto la m\u00e1quina original como el clon est\u00e1n presentes:</li> </ul> <pre><code>virsh list --all\n</code></pre> <p>Resultado: Ambas m\u00e1quinas (<code>UbuntuVM</code> y <code>UbuntuClone</code>) aparecen en la lista.</p>"},{"location":"01.-KVM/10.-Ejercicios/02.-Solucionario/#ejercicio-10-implementacion-de-contenedores-lxc","title":"Ejercicio 10: Implementaci\u00f3n de Contenedores LXC","text":"<ul> <li>Creo un contenedor LXC en el entorno KVM:</li> </ul> <pre><code>lxc-create -n mycontainer -t ubuntu\n</code></pre> <ul> <li>Inicio el contenedor:</li> </ul> <pre><code>lxc-start -n mycontainer\n</code></pre> <ul> <li>Verifico que el contenedor est\u00e1 en ejecuci\u00f3n:</li> </ul> <pre><code>lxc-ls --fancy\n</code></pre> <p>Resultado: El contenedor <code>mycontainer</code> aparece en la lista y est\u00e1 corriendo.</p>"},{"location":"02.-SSH/","title":"Index","text":"<p>SSH es esencial para la administraci\u00f3n de sistemas y DevOps, clave para el control remoto de servidores y la gesti\u00f3n segura de la infraestructura. Proporciona un acceso seguro y cifrado, fundamental para proteger datos sensibles y garantizar la seguridad de la comunicaci\u00f3n entre cliente y servidor. Adem\u00e1s, SSH permite realizar tareas administrativas desde cualquier lugar, lo cual es imprescindible para equipos de TI que gestionan infraestructuras en la nube o sistemas distribuidos.</p> <p>Con la configuraci\u00f3n adecuada, puedes mejorar la productividad y simplificar muchas tareas y, todo ello, en un entorno m\u00e1s seguro.</p> <p>Arqu\u00edmedes habr\u00eda dicho: \"Dame acceso por SSH y controlar\u00e9 el mundo.\"</p>"},{"location":"02.-SSH/02.-Instalaci%C3%B3n%20del%20entorno%20de%20pruebas/","title":"02.-Instalaci\u00f3n del entorno de pruebas","text":"<p>Habitualmente los equipos con alguna variedad de GNU/Linux traen un servidor <code>ssh</code> instalado, en el caso de los sistemas Debian y derivados el paquete que proporciona el servidor <code>ssh</code> se llama <code>openssh-server</code>.</p> <p>Podemos comprobar si ya est\u00e1 instalado mediante la instrucci\u00f3n:</p> <pre><code>dpkg -l | grep openssh-server\n</code></pre> <p>o si est\u00e1 en marcha con</p> <pre><code>systemctl status sshd\n</code></pre> <p>o con <code>ps</code></p> <pre><code>ps aux | grep sshd\n</code></pre> <p>o bien comprobando la escucha sobre el puerto 22 con</p> <pre><code>ss -lntp\n</code></pre> <p>En caso de no estarlo, podemos instalarlo con:</p> <pre><code>sudo apt-get install openssh-server\n</code></pre> <p>\u00f3 en Arch con </p> <pre><code>pacman -S openssh\n</code></pre> <p>El fichero de configuraci\u00f3n de este servicio se encuentra habitualmente en <code>/etc/ssh/sshd_config</code> y contiene las opciones de configuraci\u00f3n.</p> <p>Las opciones aplicadas las obtendr\u00edamos mediante:</p> <pre><code>grep -v '^$\\|^#' /etc/ssh/sshd_config\n\nChallengeResponseAuthentication no\nUsePAM yes\nX11Forwarding yes\nPrintMotd no\nAcceptEnv LANG LC_*\nSubsystem    sftp    /usr/lib/openssh/sftp-server\n</code></pre> <p>Sin embargo, en el caso de <code>ssh</code> hay muchas opciones que no vienen definidas y que se asume un valor por defecto, lo que puede resultar confuso. Sin embargo podemos utilizar la opci\u00f3n <code>-T: extended test mode</code> que comprueba la validez del fichero de configuraci\u00f3n y muestra las opciones efectivas que se aplican (las que est\u00e1n habilitadas de forma expl\u00edcita y las que tienen valores por defecto (en sistemas GNU/linux <code>sshd</code> s\u00f3lo puede ejecutarlo un usuario privilegiado):</p> <pre><code>sshd -T\n...\nport 22\naddressfamily any\nlistenaddress [::]:22\nlistenaddress 0.0.0.0:22\nusepam yes\nlogingracetime 120\nx11displayoffset 10\nmaxauthtries 6\nmaxsessions 10\nclientaliveinterval 120\nclientalivecountmax 3\nstreamlocalbindmask 0177\npermitrootlogin without-password\nignorerhosts yes\nignoreuserknownhosts no\nhostbasedauthentication no\nhostbasedusesnamefrompacketonly no\npubkeyauthentication yes\nkerberosauthentication no\nkerberosorlocalpasswd yes\nkerberosticketcleanup yes\ngssapiauthentication no\ngssapikeyexchange no\ngssapicleanupcredentials yes\ngssapistrictacceptorcheck yes\ngssapistorecredentialsonrekey no\npasswordauthentication yes\nkbdinteractiveauthentication no\nchallengeresponseauthentication no\nprintmotd no\nprintlastlog yes\nx11forwarding yes\nx11uselocalhost yes\npermittty yes\npermituserrc yes\nstrictmodes yes\ntcpkeepalive yes\npermitemptypasswords no\npermituserenvironment no\ncompression yes\ngatewayports no\nusedns no\nallowtcpforwarding yes\nallowagentforwarding yes\ndisableforwarding no\nallowstreamlocalforwarding yes\nstreamlocalbindunlink no\nuseprivilegeseparation sandbox\nfingerprinthash SHA256\npidfile /run/sshd.pid\nxauthlocation /usr/bin/xauth\nciphers chacha20-poly1305@openssh.com,aes128-ctr, ...\nmacs umac-64-etm@openssh.com,umac-128-etm@openssh.com, ...\nversionaddendum none\nkexalgorithms curve25519-sha256,curve25519-sha256@libssh.org, ...\nhostbasedacceptedkeytypes ecdsa-sha2-nistp256-cert-v01@openssh.com, ...\nhostkeyalgorithms ecdsa-sha2-nistp256-cert-v01@openssh.com, ...\npubkeyacceptedkeytypes ecdsa-sha2-nistp256-cert-v01@openssh.com, ...\nloglevel INFO\nsyslogfacility AUTH\nauthorizedkeysfile .ssh/authorized_keys .ssh/authorized_keys2\nhostkey /etc/ssh/ssh_host_rsa_key\nhostkey /etc/ssh/ssh_host_ecdsa_key\nhostkey /etc/ssh/ssh_host_ed25519_key\nacceptenv LANG\nacceptenv LC_*\nauthenticationmethods any\nsubsystem sftp /usr/lib/openssh/sftp-server\nmaxstartups 10:30:100\npermittunnel no\nipqos lowdelay throughput\nrekeylimit 0 0\npermitopen any\n</code></pre> <p>Muchas m\u00e1quinas vienen con un servidor <code>ssh</code> que s\u00f3lo permite acceder con clave p\u00fablica, por lo que no funciona inicialmente si nos intentamos conectar con usuario/contrase\u00f1a. Para poder hacerlo se debe descomentar el siguiente par\u00e1metro del fichero de configuraci\u00f3n <code>/etc/ssh/sshd_config</code>:</p> <pre><code>PasswordAuthentication yes\n</code></pre> <p>Y reiniciar el servidor <code>ssh</code> con:</p> <pre><code>systemctl restart ssh\n</code></pre>"},{"location":"02.-SSH/01.-Introducci%C3%B3n/01.-Caracter%C3%ADsticas%20Principales/01.-Precedentes.%20%60telnet%60%2C%20%60rlogin%60%20y%20%60rsh%60/","title":"01.-Precedentes. `telnet`, `rlogin` y `rsh`","text":"<ul> <li> <p>Shell remota</p> <ul> <li> <p>Remote login: <code>rlogin</code></p> </li> <li> <p>Remote shell: <code>rsh</code></p> </li> </ul> </li> <li> <p>Ejecuci\u00f3n remota de instrucciones</p> </li> <li> <p>Muy utilizado desde los a\u00f1os 70</p> </li> <li> <p>Autenticaci\u00f3n no cifrada</p> <ul> <li>La seguridad no era una preocupaci\u00f3n</li> </ul> </li> </ul>"},{"location":"02.-SSH/01.-Introducci%C3%B3n/01.-Caracter%C3%ADsticas%20Principales/02.-Cifrado%20Completo/","title":"02.-Cifrado Completo","text":"<ul> <li>Se cifra todo el proceso, tanto la autenticaci\u00f3n como toda la comunicaci\u00f3n</li> </ul>"},{"location":"02.-SSH/01.-Introducci%C3%B3n/01.-Caracter%C3%ADsticas%20Principales/03.-Historia%20de%20%60ssh%60/","title":"03.-Historia de `ssh`","text":"<ul> <li> <p>En 1995, Tatu Yl\u00f6nen crea <code>ssh</code></p> </li> <li> <p>Posteriormente funda SSH Communications Security (ssh.com)</p> </li> <li> <p>En 1999 se desarrolla OpenSSH</p> </li> </ul>"},{"location":"02.-SSH/01.-Introducci%C3%B3n/01.-Caracter%C3%ADsticas%20Principales/04.-OpenSSH/","title":"04.-OpenSSH","text":"<ul> <li> <p>Desarrollado en OpenBSD</p> </li> <li> <p>Escrito en C</p> </li> <li> <p>Licencia BSD simple, dominio p\u00fablico</p> </li> <li> <p>Ampliamente extendida</p> </li> <li> <p>Utilizada en BSD, GNU/Linux y UNIX</p> </li> <li> <p>Se apoya en el proyecto LibreSSL (Fork de OpenSSL tras heartbleed)</p> <ul> <li>OpenSSL es la biblioteca de seguridad en comunicaciones que utilizaba <code>openssh</code></li> </ul> </li> <li> <p>Programas</p> <ul> <li><code>ssh</code>, <code>scp</code>, <code>sftp</code>, <code>ssh-keygen</code>, <code>ssh-agent</code>, <code>sshd</code>, <code>ssh-keyscan</code></li> </ul> </li> <li> <p>Versiones</p> <ul> <li> <p>SSH-1</p> </li> <li> <p>SSH-2 incompatible con SSH-1. Incluye importantes mejoras:</p> <ul> <li> <p>D-H para intercambiar claves</p> </li> <li> <p>Verificaci\u00f3n de integridad mediante Message authentication code (MAC)</p> </li> <li> <p>M\u00faltiples sesiones en una conexi\u00f3n</p> </li> <li> <p>Actualmente s\u00f3lo se usa SSH-2</p> </li> </ul> </li> </ul> </li> </ul>"},{"location":"02.-SSH/01.-Introducci%C3%B3n/02.-Criptograf%C3%ADa/","title":"Index","text":"<p>Arte y t\u00e9cnica de escribir con procedimientos o claves secretas o de un modo enigm\u00e1tico, de tal forma que lo escrito solamente sea inteligible para quien sepa descifrarlo.</p> <p>En castellano son sin\u00f3nimos cifrar y encriptar, as\u00ed como las acciones inversas descifrar y desencriptar.</p>"},{"location":"02.-SSH/01.-Introducci%C3%B3n/02.-Criptograf%C3%ADa/01.-Criptograf%C3%ADa%20de%20clave%20sim%C3%A9trica/","title":"01.-Criptograf\u00eda de clave sim\u00e9trica","text":"<p>Se utiliza la misma clave para cifrar y descifrar</p> <ul> <li> <p>Algoritmos:</p> <ul> <li> <p>DES</p> </li> <li> <p>3DES</p> </li> <li> <p>IDEA</p> </li> <li> <p>Blowfish</p> </li> <li> <p>CAST5</p> </li> <li> <p>AES (Rijndael)</p> </li> </ul> </li> <li> <p>Mecanismo \u00e1mpliamente utilizado</p> </li> <li> <p>Principal limitaci\u00f3n:</p> <ul> <li>Comunicaci\u00f3n de la clave</li> </ul> </li> </ul>"},{"location":"02.-SSH/01.-Introducci%C3%B3n/02.-Criptograf%C3%ADa/02.-Clave%20asim%C3%A9trica%20o%20de%20clave%20p%C3%BAblica/","title":"02.-Clave asim\u00e9trica o de clave p\u00fablica","text":"<ul> <li> <p>Se crean dos claves relacionadas</p> <ul> <li> <p>clave privada</p> </li> <li> <p>clave p\u00fablica</p> </li> </ul> </li> <li> <p>La privada descifra lo cifrado por la p\u00fablica y al contrario</p> </li> <li> <p>Evita el problema del cifrado sim\u00e9trico</p> </li> <li> <p>Limitaciones</p> <ul> <li> <p>M\u00e1s complejo</p> </li> <li> <p>Menos algoritmos disponibles</p> </li> </ul> </li> <li> <p>Funcionamiento:</p> <ul> <li> <p>idea (International Data Encryption Algorithm)</p> </li> <li> <p>Algoritmos</p> <ul> <li> <p>Factorizaci\u00f3n de n\u00fameros primos (antiguos)</p> <ul> <li> <p>RSA (Antes protegido por patente ahora caducada)</p> </li> <li> <p>DSA</p> </li> <li> <p>Curvas el\u00edpticas (modernos: m\u00e1s r\u00e1pidos) ECDSA Ed25519</p> </li> </ul> </li> </ul> </li> </ul> </li> </ul>"},{"location":"02.-SSH/01.-Introducci%C3%B3n/02.-Criptograf%C3%ADa/03.-Funciones%20Hash/","title":"03.-Funciones Hash","text":"<p>Operaciones matem\u00e1ticas con las siguientes propiedades:</p> <ul> <li> <p>Mismo tama\u00f1o de resultado</p> </li> <li> <p>Unidireccionales</p> </li> <li> <p>No muestran informaci\u00f3n del origen</p> </li> <li> <p>Difieren con cualquier modificaci\u00f3n del origen</p> </li> </ul> <p>Funciones hash habituales</p> <ul> <li>CRC, MD5, Whirpool, Tiger, SHA-1, SHA-256, SHA-512, SHA-3</li> </ul>"},{"location":"02.-SSH/01.-Introducci%C3%B3n/03.-M%C3%A9todos%20de%20autenticaci%C3%B3n/","title":"Index","text":"<p>La autenticaci\u00f3n en el entorno de conexiones SSH (Secure Shell) es un proceso cr\u00edtico para asegurar el acceso remoto a servidores y dispositivos, utilizando m\u00e9todos robustos que garantizan la confidencialidad e integridad de la comunicaci\u00f3n. Existen varios tipos de autenticaci\u00f3n en conexiones SSH, cada uno con sus caracter\u00edsticas y niveles de seguridad.</p>"},{"location":"02.-SSH/01.-Introducci%C3%B3n/03.-M%C3%A9todos%20de%20autenticaci%C3%B3n/01.-Contrase%C3%B1a/","title":"01.-Contrase\u00f1a","text":"<ul> <li> <p>M\u00e9todo b\u00e1sico</p> </li> <li> <p>Usamos la contrase\u00f1a del usuario en el sistema remoto</p> </li> </ul>"},{"location":"02.-SSH/01.-Introducci%C3%B3n/03.-M%C3%A9todos%20de%20autenticaci%C3%B3n/02.-Clave%20P%C3%BAblica/","title":"02.-Clave P\u00fablica","text":"<ul> <li> <p>El usuario genera un par de claves p\u00fablica/privada</p> </li> <li> <p>Ubica la clave p\u00fablica en el equipo remoto</p> </li> <li> <p>Accede a su sesi\u00f3n sin contrase\u00f1a</p> </li> </ul>"},{"location":"02.-SSH/01.-Introducci%C3%B3n/03.-M%C3%A9todos%20de%20autenticaci%C3%B3n/03.-Kerberos/","title":"03.-Kerberos","text":"<ul> <li> <p>Principalmente en entornos corporativos</p> </li> <li> <p>Se solicita un ticket al servidor kerberos</p> </li> <li> <p>Kerberos proporciona SSO (Single Sign-On sesi\u00f3n de inicio \u00fanica)</p> </li> <li> <p>Permite comunicarse con cualquier servidor <code>ssh</code> kerberizado</p> </li> </ul>"},{"location":"02.-SSH/01.-Introducci%C3%B3n/03.-M%C3%A9todos%20de%20autenticaci%C3%B3n/04.-GSSAPI/","title":"04.-GSSAPI","text":"<ul> <li> <p>GSSAPI (Generic Security Services Application Program Interface) es una API est\u00e1ndar que proporciona servicios de autenticaci\u00f3n y seguridad a aplicaciones distribuidas. GSSAPI permite a las aplicaciones autenticarse entre s\u00ed utilizando mecanismos de seguridad sin tener que preocuparse por los detalles espec\u00edficos de cada uno de ellos. </p> </li> <li> <p>GSSAPI abstrae estos mecanismos para ofrecer una forma consistente de autenticaci\u00f3n y establecer una conexi\u00f3n segura. Es com\u00fanmente usado en combinaci\u00f3n con Kerberos, que es el mecanismo m\u00e1s utilizado para autenticaci\u00f3n en entornos empresariales.</p> </li> <li> <p>En el contexto de SSH, GSSAPI permite autenticarse en servidores sin necesidad de introducir manualmente credenciales, ya que puede utilizar los tickets de autenticaci\u00f3n de Kerberos que ya est\u00e9n disponibles en el sistema. Esto facilita la autenticaci\u00f3n \u00fanica (Single Sign-On) en entornos de red corporativos, mejorando la experiencia del usuario y la seguridad.</p> </li> <li> <p>Por ejemplo, si tienes configurado Kerberos en tu organizaci\u00f3n y habilitado GSSAPI para SSH, podr\u00edas acceder a servidores sin necesidad de escribir una contrase\u00f1a cada vez, porque el ticket de Kerberos ya proporciona las credenciales necesarias.</p> </li> </ul>"},{"location":"02.-SSH/01.-Introducci%C3%B3n/04.-Funcionamiento/","title":"Index","text":"<p>A continuaci\u00f3n se describen las principales fases del protocolo SSH, que permiten establecer una conexi\u00f3n segura y autenticada entre el cliente y el servidor, garantizando la confidencialidad e integridad de los datos intercambiados.</p>"},{"location":"02.-SSH/01.-Introducci%C3%B3n/04.-Funcionamiento/01.-Fase%201%20%28Negociaci%C3%B3n%29/","title":"01.-Fase 1 (Negociaci\u00f3n)","text":"<ul> <li> <p>El cliente se conecta al servidor</p> </li> <li> <p>El servidor muestra su versi\u00f3n de <code>ssh</code></p> </li> <li> <p>El cliente muestra su versi\u00f3n de <code>ssh</code></p> </li> <li> <p>El servidor env\u00eda su clave p\u00fablica</p> </li> <li> <p>El cliente verifica la huella de la clave p\u00fablica entre las que tiene guardadas</p> </li> <li> <p>Negocian qu\u00e9 algoritmo y semilla utilizar</p> </li> <li> <p>Ambos generan las claves de la sesi\u00f3n e intercambian la p\u00fablica para verificar que la otra parte lo ha hecho igual</p> </li> </ul>"},{"location":"02.-SSH/01.-Introducci%C3%B3n/04.-Funcionamiento/02.-Fase%202%20%28Autenticaci%C3%B3n%29/","title":"02.-Fase 2 (Autenticaci\u00f3n)","text":"<ul> <li> <p>Una vez establecida la clave de sesi\u00f3n se utiliza para cifrar toda la comunicaci\u00f3n</p> </li> <li> <p>El servidor ofrece en orden los m\u00e9todos de autenticaci\u00f3n disponibles</p> </li> <li> <p>El cliente los rechaza hasta que encuentra uno a utilizar</p> </li> <li> <p>Cuando el usuario se ha autenticado satisfactoriamente se abre una sesi\u00f3n en el equipo remoto</p> </li> </ul>"},{"location":"02.-SSH/03.-Uso%20de%20ssh/01.-Autenticaci%C3%B3n%20con%20usuario%20y%20contrase%C3%B1a/","title":"01.-Autenticaci\u00f3n con usuario y contrase\u00f1a","text":"<p>El m\u00e9todo inicial de autenticaci\u00f3n se basa en utilizar los usuarios del sistema y sus contrase\u00f1as que est\u00e1n almacenadas en \u00e9l. A SSH no le afecta la forma en la que el sistema las almacena (fichero, LDAP, etc.).</p> <p>Las opciones de configuraci\u00f3n que afectan en este caso son las siguientes:</p> <pre><code>passwordauthentication yes|no\nchallengeresponseauthentication yes|no\npermitemptypasswords yes|no\n</code></pre> <p>Te\u00f3ricamente <code>challengeresponseauthentication</code> es un mecanismo m\u00e1s complejo que permite preguntar al usuario otras cuestiones, no s\u00f3lo la contrase\u00f1a, pero en la pr\u00e1ctica se suele preguntar la contrase\u00f1a.</p> <p>En sistemas GNU/Linux se a\u00f1ade la opci\u00f3n</p> <pre><code>usepam yes\n</code></pre> <p>Que permite utilizar el subsistema PAM como mecanismo de autenticaci\u00f3n.</p>"},{"location":"02.-SSH/03.-Uso%20de%20ssh/01.-Autenticaci%C3%B3n%20con%20usuario%20y%20contrase%C3%B1a/#311-ejercicio-simple-de-acceso-con-usuariocontrasena","title":"3.1.1 Ejercicio simple de acceso con usuario/contrase\u00f1a","text":"<p>Accedemos a un servidor remoto con:</p> <pre><code>ssh usuario@172.22.200.175\nThe authenticity of host '172.22.200.175 (172.22.200.175)' can't be established.\nECDSA key fingerprint is SHA256:Bsv9OS7Qf94ANguOiDLNPHn7J+XlwisWZydmfqa4QMo.\nAre you sure you want to continue connecting (yes/no)?\n</code></pre> <p>Para verificar el servidor, en lugar de mostrarnos la clave p\u00fablica completa, nos muestra la huella (fingerprint) de la clave p\u00fablica del servidor, que no es m\u00e1s que un hash de la clave p\u00fablica, en este caso utlizando SHA256. Podemos comprobar la correspondencia entre la clave p\u00fablica y la huella mediante la instrucci\u00f3n:</p> <pre><code>ssh-keygen -l -E sha256 -f fichero_con_clave_publica\n</code></pre> <p>Se podr\u00eda hablar con detalle de la forma efectiva de verificar las claves p\u00fablicas, pero en este momento se aceptar\u00e1 la clave que se ofrece y por tanto se teclear\u00e1 \u201cyes\u201d y a continuaci\u00f3n se pide la contrase\u00f1a de acceso, se introduce y se accede a una shell en el equipo remoto:</p> <pre><code>Warning: Permanently added '172.22.200.175' (ECDSA) to the list of known hosts.\nusuario@172.22.200.175's password: **********\nLast login: Fri Feb 16 17:34:41 2018 from 172.23.0.22\nusuario@host:~$\n</code></pre>"},{"location":"02.-SSH/03.-Uso%20de%20ssh/01.-Autenticaci%C3%B3n%20con%20usuario%20y%20contrase%C3%B1a/#312-ejecucion-remota","title":"3.1.2 Ejecuci\u00f3n remota","text":"<p>SSH permite ejecutar una orden remotamente de forma no interactiva, lo que resulta muy c\u00f3modo cuando hay que realizar tareas muy espec\u00edficas en un equipo remoto. Por ejemplo:</p> <pre><code>ssh usuario@172.22.200.175 sudo apt update\n</code></pre> <p>Tambi\u00e9n se pueden encadenar varias \u00f3rdenes o ejecutar un script:</p> <pre><code>ssh usuario@172.22.200.175 'sudo apt update &amp;&amp; sudo apt upgrade'\n</code></pre>"},{"location":"02.-SSH/03.-Uso%20de%20ssh/01.-Autenticaci%C3%B3n%20con%20usuario%20y%20contrase%C3%B1a/#313-consideraciones-acerca-de-root","title":"3.1.3 Consideraciones acerca de root","text":"<p>Se puede restringir el acceso con el usuario root utilizando contrase\u00f1a, aspecto importante desde el punto de vista de seguridad, por lo que hoy en d\u00eda habitualmente se utiliza la opcion:</p> <pre><code>PermitRootLogin without-password\n</code></pre> <p>En caso de que quisi\u00e9ramos permitir acceder con el usuario root y contrase\u00f1a, deber\u00edamos poner esta opci\u00f3n a yes.</p>"},{"location":"02.-SSH/03.-Uso%20de%20ssh/01.-Autenticaci%C3%B3n%20con%20usuario%20y%20contrase%C3%B1a/#314-otras-opciones","title":"3.1.4 Otras opciones","text":"<p>No espec\u00edficas del acceso con usuario y contrase\u00f1a, pero adecuadas para empezar:</p> <pre><code>PrintLastLog yes|no\nPrintMotd yes|no\nBanner Ruta_a_fichero\n</code></pre>"},{"location":"02.-SSH/03.-Uso%20de%20ssh/02.-Autenticaci%C3%B3n%20con%20claves%20p%C3%BAblica-privada/","title":"02.-Autenticaci\u00f3n con claves p\u00fablica-privada","text":"<p>Aunque el mecanismo m\u00e1s f\u00e1cil de entender al utilizar <code>ssh</code> es la autenticaci\u00f3n del usuario mediante la contrase\u00f1a en el equipo remoto, el mecanismo m\u00e1s \u201cnatural\u201d y probablemente m\u00e1s habitual es la autenticaci\u00f3n mediante un par de claves p\u00fablica/privada.</p>"},{"location":"02.-SSH/03.-Uso%20de%20ssh/02.-Autenticaci%C3%B3n%20con%20claves%20p%C3%BAblica-privada/#321-creacion-de-la-clave-privada","title":"3.2.1 Creaci\u00f3n de la clave privada","text":"<p>Para crear la clave privada utilizaremos la herramienta <code>ssh-keygen</code>, especificando el algoritmo que deseamos utilizar mediante el par\u00e1metro -t (dsa | ecdsa | ed25519 | rsa | rsa1), por ejemplo:</p> <pre><code>ssh-keygen -t ecdsa\n</code></pre> <p>Se crear\u00e1 un di\u00e1logo mediante el cual nos pedir\u00e1 una frase de paso para proteger la clave privada, paso que se ignorar\u00e1 de momento y se explicar\u00e1 con detalle en la siguiente secci\u00f3n:</p> <pre><code>Generating public/private ecdsa key pair.\nEnter file in which to save the key (/home/alberto/.ssh/id_ecdsa): [ENTER]\nEnter passphrase (empty for no passphrase): [ENTER]\nEnter same passphrase again: [ENTER]\nYour identification has been saved in /home/alberto/.ssh/id_ecdsa.\nYour public key has been saved in /home/alberto/.ssh/id_ecdsa.pub.\nThe key fingerprint is:\nSHA256:QQ0bm3FBXKhLyWUfa7teeHgufwLPdK8nIu0UlMCJ6/M alberto@mut\nThe key's randomart image is:\n+---[ECDSA 256]---+\n|        =B==.    |\n|       ..BO...   |\n|       .=* .oo   |\n|        *. .+    |\n|       oS. ...   |\n|        +   o+. .|\n|         o .+*+..|\n|          E.=== +|\n|           +o++* |\n+----[SHA256]-----+\n</code></pre> <p>En este caso hemos optado por dejar el nombre de la clave por defecto (~/.ssh/idecdsa). Si vamos al directorio ~/.ssh veremos que existen dos nuevos ficheros, que se corresponden con la clave p\u00fablica y la privada:</p> <pre><code>-rw------- 1 alberto alberto   227 feb 18 09:16 id_ecdsa\n-rw-r--r-- 1 alberto alberto   173 feb 18 09:16 id_ecdsa.pub\n</code></pre> <p>L\u00f3gicamente la clave privada se ha protegido en el sistema de forma que s\u00f3lo el propietario puede leerla o modificarla, mientras que la p\u00fablica puede leerla cualquier usuario y en general podr\u00e1 estar accesible en cualquier sitio sin restricciones, ya que no es posible obtener la clave privada a partir de ella.</p> <p>Vemos el contenido de estas claves (obviamente se muestran aqu\u00ed a modo de ejemplo y se trata de claves que no se van a utilizar nunca en un entorno real):</p> <pre><code>~/.ssh/id_ecdsa\n-----BEGIN EC PRIVATE KEY-----\nMHcCAQEEIN53r8/ghcQ94wjNPtvz0VvSFsuU7ePsPkriWPhpC137oAoGCCqGSM49\nAwEHoUQDQgAEXJKU4yRlIdnKGG8qQA2PXpfCPVz9xpbB3TXOh9ymC9XtjgP3ZCwU\ntdNnLTQNJm8PO4MHtFZBTxeFE39lD7WVYQ==\n-----END EC PRIVATE KEY-----\n\n~/.ssh/id_ecdsa.pub \necdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAy\\\nNTYAAABBBFySlOMkZSHZyhhvKkANj16Xwj1c/caWwd01zofcpgvV7Y4D92QsFLXT\\\nZy00DSZvDzuDB7RWQU8XhRN/ZQ+1lWE= alberto@mut\n</code></pre>"},{"location":"02.-SSH/03.-Uso%20de%20ssh/02.-Autenticaci%C3%B3n%20con%20claves%20p%C3%BAblica-privada/#322-copia-de-la-clave-publica-en-el-equipo-remoto","title":"3.2.2 Copia de la clave p\u00fablica en el equipo remoto","text":"<p>Para que se pueda utilizar este mecanismo de autenticaci\u00f3n es preciso que la clave p\u00fablica del usuario se encuentre en la cuenta que \u00e9ste posee en el equipo remoto, de forma m\u00e1s concreta, dentro del fichero <code>~/.ssh/authorized_keys</code>, por lo que debemos utilizar alg\u00fan m\u00e9todo para ubicarla all\u00ed:</p> <ul> <li>Accedemos con contrase\u00f1a y copiamos y pegamos la clave p\u00fablica</li> <li>Accedemos con otra clave p\u00fablica que hubi\u00e9semos copiado previamente y pegamos la nueva clave p\u00fablica</li> <li>Utilizamos cualquier sistema en el arranque de la m\u00e1quina que obtenga la clave p\u00fablica y la ubique en su sitio (muy habitual en cloud computing)</li> <li>Utilizamos la herramienta <code>ssh-copy-id</code></li> </ul> <p>Vamos a ver el \u00faltimo m\u00e9todo:</p> <pre><code>ssh-copy-id -i ~/.ssh/id_ecdsa debian@172.22.200.175\n\n/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: \"/home/alberto/.ssh/id_ecdsa.pub\"\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\ndebian@172.22.200.175's password: \n\nNumber of key(s) added: 1\n\nNow try logging into the machine, with:   \"ssh 'debian@172.22.200.175'\"\nand check to make sure that only the key(s) you wanted were added.\n</code></pre> <p>Si accedemos al equipo remoto, podremos comprobar que la clave p\u00fablica que hemos exportado se encuentra en el fichero<code>~/.ssh/authorized_keys</code>.</p>"},{"location":"02.-SSH/03.-Uso%20de%20ssh/02.-Autenticaci%C3%B3n%20con%20claves%20p%C3%BAblica-privada/#323-clave-privada-con-nombre-no-estandar","title":"3.2.3 Clave privada con nombre no est\u00e1ndar","text":"<p>En el caso anterior hemos creado un par de claves con nombre est\u00e1ndar (<code>idecdsa</code> e <code>idecdsa.pub</code>), pero es posible definir cualquier nombre a la hora de crear el par de claves, por ejemplo:</p> <pre><code>ssh-keygen -t ed25519\nGenerating public/private ed25519 key pair.\nEnter file in which to save the key (/home/debian/.ssh/id_ed25519): openwebinars\nEnter passphrase (empty for no passphrase): \nEnter same passphrase again: \nYour identification has been saved in openwebinars.\nYour public key has been saved in openwebinars.pub.\nThe key fingerprint is:\nSHA256:HzEVg7wVelxLpuHrv+BUG8QG4bI0AsED7PnUvzFdlCI debian@asd\nThe key's randomart image is:\n+--[ED25519 256]--+\n|   ..oo. . .O++. |\n|    . o.  E*oXo. |\n|   . . o. B+*o=  |\n|    o . .o.B +.  |\n|     o  S.o...o  |\n|      .  .+o.. o |\n|          .++ .  |\n|          .o o   |\n|            . o. |\n+----[SHA256]-----+\n</code></pre> <p>Proceder\u00edamos de igual forma que en el caso anterior, aunque ahora para utilizar la clave en cualquier sesi\u00f3n <code>ssh</code>, deber\u00edamos indicarlo de forma expl\u00edcita:</p> <pre><code>ssh -i ~/.ssh/openwebinars debian@172.22.200.175\n</code></pre>"},{"location":"02.-SSH/03.-Uso%20de%20ssh/02.-Autenticaci%C3%B3n%20con%20claves%20p%C3%BAblica-privada/#324-utilizacion-en-cloud-computing","title":"3.2.4 Utilizaci\u00f3n en cloud computing","text":"<p>Hoy en d\u00eda es cada vez m\u00e1s habitual la utilizaci\u00f3n de m\u00e1quinas virtuales en alg\u00fan proveedor de nube de infraestructura p\u00fablica o privada (AWS, Azure, OpenStack, etc.), en estos casos es imprescindible utilizar este mecanismo de clave p\u00fablica/privada para acceder a estas m\u00e1quinas virtuales.</p>"},{"location":"02.-SSH/03.-Uso%20de%20ssh/02.-Autenticaci%C3%B3n%20con%20claves%20p%C3%BAblica-privada/#325-generacion-de-una-clave-publica-a-partir-de-la-privada","title":"3.2.5 Generaci\u00f3n de una clave p\u00fablica a partir de la privada","text":"<p>Aunque habitualmente se generan ambas claves, en diferentes circunstancias puede ocurrir que tengamos la clave privada, pero no la correspondiente clave p\u00fablica, en ese caso podemos utilizar <code>ssh-keygen</code> para obtenerla:</p> <pre><code>ssh-keygen -y -f clave &gt;&gt; clave.pub\n</code></pre> <p>Evidentemente si tenemos la clave p\u00fablica y no la privada, no podemos hacer el proceso inverso.</p>"},{"location":"02.-SSH/03.-Uso%20de%20ssh/02.-Autenticaci%C3%B3n%20con%20claves%20p%C3%BAblica-privada/#326-utilizacion-en-procesos-no-interactivos","title":"3.2.6 Utilizaci\u00f3n en procesos no interactivos","text":"<p>Puesto que teniendo acceso a la clave privada el acceso se puede realizar al equipo remoto sin ninguna intervenci\u00f3n, este mecanismo es ideal para su utilizaci\u00f3n en procesos que no requieran intervenci\u00f3n humana, como muchas conexiones que pueden realizarse entre diferentes equipos. La conexi\u00f3n es segura y autenticada, aunque es muy importante custodiar adecuadamente las claves privadas.</p>"},{"location":"02.-SSH/03.-Uso%20de%20ssh/03.-Autenticaci%C3%B3n%20con%20claves%20p%C3%BAblica-privada%20y%20frase%20de%20paso/","title":"03.-Autenticaci\u00f3n con claves p\u00fablica-privada y frase de paso","text":"<p>La autenticaci\u00f3n con clave privada tiene importantes ventajas respecto al acceso con contrase\u00f1a, pero tiene el inconveniente de la custodia de la clave privada. Cualquier usuario que obtuviese nuestra clave privada podr\u00eda entrar en nuestra cuenta de cualquier equipo en el que tuvi\u00e9semos exportada la correspondiente clave p\u00fablica. Para aumentar la seguridad en esta situaci\u00f3n se utiliza una frase de paso para proteger la clave privada, frase que se introduce al crear la clave privada o que puede modificarse a posteriori. Vamos a crear una nueva clave, pero en este caso protegida con frase de paso:</p> <pre><code>ssh-keygen -t ecdsa\nGenerating public/private ecdsa key pair.\nEnter file in which to save the key (/home/alberto/.ssh/id_ecdsa): \nEnter passphrase (empty for no passphrase): &lt;- Teclear frase de paso -&gt;\nEnter same passphrase again: &lt;- Teclear frase de paso de nuevo -&gt;\nYour identification has been saved in /home/alberto/.ssh/id_ecdsa.\nYour public key has been saved in /home/alberto/.ssh/id_ecdsa.pub.\nThe key fingerprint is:\nSHA256:mvCLrZMvdUDOorOkvd/1iosAZmhGS2fWPQmjAVMjjtk alberto@mut\nThe key's randomart image is:\n+---[ECDSA 256]---+\n| +o+ o           |\n|ooo = = .        |\n|o+E= = +         |\n|+ = . + .        |\n|o* ... .S        |\n|=.+  o.o.        |\n| +.o o+..        |\n|. o.+= + .       |\n|  .o==B....      |\n+----[SHA256]-----+\n</code></pre> <p>De esta forma la clave privada no es \u00fatil a menos que se conozca la frase de paso.</p> <p>Procedemos de igual forma que en el caso anterior, exportando la clave p\u00fablica, aunque ahora cada vez que accedamos nos solicitar\u00e1 la frase de paso de la clave privada:</p> <pre><code>ssh -i ~/.ssh/id_ecdsa debian@172.22.200.175\nEnter passphrase for key '/home/alberto/.ssh/id_ecdsa':\n</code></pre> <p>Hemos ganado en seguridad, pero hemos perdido en usabilidad, porque ahora tenemos que escribir la frase de paso cada vez que accedamos al equipo remoto y adem\u00e1s no es v\u00e1lido para procesos no interactivos. Para solucionar este inconveniente usaremos <code>ssh-agent</code> en una secci\u00f3n posterior.</p>"},{"location":"02.-SSH/03.-Uso%20de%20ssh/04.-%60ssh-agent%60/","title":"04.-`ssh-agent`","text":"<p><code>ssh-agent</code> es un programa que permite almacenar las claves privadas de una sesi\u00f3n y es muy \u00fatil cuando usamos claves con frase de paso, ya que podemos a\u00f1adir la clave privada al agente ssh y s\u00f3lo tendremos que poner la frase de paso una vez, permitiendo utilizar <code>ssh</code> de forma transparente sin volver a introducir la frase de paso todo el tiempo que dure la sesi\u00f3n del usuario (realmente se puede limitar a una cantidad de tiempo menor si se desea).</p> <p><code>ssh-agent</code> se suele ejecutar autom\u00e1ticamente en las sesiones gr\u00e1ficas de los sistemas, como podemos verificar mediante:</p> <pre><code>env |grep SSH\n...\nSSH_AUTH_SOCK=/run/user/1001/keyring/ssh\nSSH_AGENT_PID=2743\n</code></pre> <p>O a trav\u00e9s de ps:</p> <pre><code>ps aux |grep ssh-agent\nalberto   2743  .... ..... 0:00 /usr/bin/ssh-agent x-session-manager\n</code></pre> <p>De hecho, si tuvi\u00e9ramos alguna clave privada sin frase de paso se habr\u00eda cargado autom\u00e1ticamente en el agente ssh y podr\u00edamos utilizarla de forma totalmente transparente.</p>"},{"location":"02.-SSH/03.-Uso%20de%20ssh/04.-%60ssh-agent%60/#341-anadir-una-clave-privada-a-ssh-agent","title":"3.4.1 A\u00f1adir una clave privada a <code>ssh-agent</code>","text":"<p>Mediante la herramienta <code>ssh-add</code> podemos a\u00f1adir una clave al agente ssh, por ejemplo:</p> <pre><code>ssh-add ~/.ssh/openwebinars\n</code></pre> <p>Si la clave est\u00e1 protegida por una frase de paso, se nos pedir\u00e1 en ese momento, o se utilizar\u00e1 la aplicaci\u00f3n ssh-askpass si se tratase de una aplicaci\u00f3n gr\u00e1fica u otra que no tuviese asociada una terminal.</p> <p>Podemos ver las claves cargadas mediante:</p> <pre><code>ssh-add -L\n</code></pre> <p>Y sus huellas con:</p> <pre><code>ssh-add -l\n</code></pre> <p><code>ssh-agent</code> permite que cualquier otra aplicaci\u00f3n de la misma sesi\u00f3n utilice las claves privadas que almacena sin tener que volver a autenticarse, por lo que es importante controlar el uso de la sesi\u00f3n, bloque\u00e1ndola cuando no se est\u00e9 usando.</p> <p>Se pueden eliminar claves ssh del agente mediante:</p> <pre><code>ssh-add -d openwebinars\n</code></pre> <p>O incluso eliminar todas las claves con:</p> <pre><code>ssh-add -D\n</code></pre>"},{"location":"02.-SSH/03.-Uso%20de%20ssh/04.-%60ssh-agent%60/#342-ejecucion-de-ssh-agent","title":"3.4.2 Ejecuci\u00f3n de <code>ssh-agent</code>","text":"<p>En el caso de que utilicemos un sistema que no haya cargado autom\u00e1ticamente un agente ssh, podemos ejecutarlo directamente, habitualmente se har\u00eda abriendo una nueva shell:</p> <pre><code>ssh-agent /bin/bash\n</code></pre>"},{"location":"02.-SSH/03.-Uso%20de%20ssh/05.-Gesti%C3%B3n%20de%20ficheros.%20%60authorized_keys%60%20y%20%60known_hosts%60/","title":"05.-Gesti\u00f3n de ficheros. `authorized_keys` y `known_hosts`","text":""},{"location":"02.-SSH/03.-Uso%20de%20ssh/05.-Gesti%C3%B3n%20de%20ficheros.%20%60authorized_keys%60%20y%20%60known_hosts%60/#351-fichero-sshauthorized_keys","title":"3.5.1 Fichero ~/.ssh/authorized_keys","text":"<p>Se almacenan las claves p\u00fablicas de los usuarios que pueden acceder a esta cuenta mediante clave p\u00fablica/clave privada, el formato es:</p> <pre><code>&lt;algoritmo&gt; &lt;clavepublica&gt; &lt;comentario&gt;\n</code></pre> <p>Por ejemplo:</p> <pre><code>ssh-rsa AAAAB3NzaC1yc2EAA\u2026dPh alberto@mut\n</code></pre> <p>Si queremos que utilizar un par de claves para acceder a un equipo, debemos asegurarnos de que exista la clave p\u00fablica en este fichero y cuando ya dejemos de utilizarla debemos borrar la l\u00ednea correspondiente. Fichero ~/.ssh/knownhosts</p> <p>Se almacenan las claves p\u00fablicas de todos los equipos remotos a los que nos hemos conectado y que hemos aceptado, el formato es:</p> <pre><code>&lt;nombre o IP equipo&gt; &lt;algoritmo&gt; &lt;clavep\u00fablica&gt;\n</code></pre> <p>Actualmente es m\u00e1s habitual que no se guarde el nombre o direcci\u00f3n IP del equipo en claro, sino que se almacene el hash. Para encontrar un determinado equipo por nombre o direcci\u00f3n IP podemos utilizar la instrucci\u00f3n:</p> <pre><code>ssh-keygen -F 172.22.200.175\n1   lbA\u2026.9Lo= ecdsa-sha2-nistp256 AAAA\u2026..ynTO90=\n</code></pre> <p>Cambio de clave p\u00fablica del servidor</p> <p>Habitualmente se almacenan las claves p\u00fablicas de los servidores a los que nos hemos conectado previamente en el fichero ~/.ssh/knownhosts, por lo que se verifica cada vez que se conecta que el servidor ofrece la misma clave p\u00fablica. En caso de que no coincida veremos el siguiente mensaje:</p> <pre><code>ssh debian@172.22.200.175 @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ @ WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED! @ @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ IT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY! Someone could be eavesdropping on you right now (man-in-the-middle attack)! It is also possible that a host key has just been changed. The fingerprint for the ECDSA key sent by the remote host is SHA256:J9CMWSbavkqECRI1KWhy8s/D7UVJWDiysAocAbo1F6k. Please contact your system administrator. Add correct host key in home/alberto.ssh/knownhosts to get rid of this message. Offending ECDSA key in home/alberto.ssh/knownhosts:88 remove with: ssh-keygen -f \"home/alberto.ssh/knownhosts\" -R 172.22.200.175 ECDSA host key for 172.22.200.175 has changed and you have requested strict checking. Host key verification failed.\n</code></pre> <p>Es posible que se trate de una suplantaci\u00f3n y por tanto un problema de seguridad, pero tambi\u00e9n es posible que se haya realizado un cambio en el servidor que haya implicado un cambio en las claves del servicio ssh o una situaci\u00f3n muy habitual hoy en d\u00eda: estamos reutilizando la misma IP para un nuevo servidor.</p> <p>En caso de que estemos seguros de que no hay ning\u00fan problema de seguridad al acceder a ese equipo remoto, debemos eliminar la antigua clave asociada a la direcci\u00f3n IP (o al nombre), mediante la instrucci\u00f3n:</p> <pre><code>ssh-keygen -R 172.22.200.175\n\nhome/alberto.ssh/knownhosts updated. Original contents retained as home/alberto.ssh/knownhosts.old\n</code></pre>"},{"location":"02.-SSH/03.-Uso%20de%20ssh/05.-Gesti%C3%B3n%20de%20ficheros.%20%60authorized_keys%60%20y%20%60known_hosts%60/#352-fichero-sshauthorized_keys","title":"3.5.2 Fichero ~/.ssh/authorized_keys","text":"<p>Almacena las claves p\u00fablicas de los usuarios que pueden acceder a esta cuenta mediante clave p\u00fablica/clave privada, el formato es:</p> <pre><code>&lt;algoritmo&gt; &lt;clave_publica&gt; &lt;comentario&gt;\n</code></pre> <p>Por ejemplo:</p> <pre><code>ssh-rsa AAAAB3NzaC1yc2EAA...dPh alberto@mut\n</code></pre> <p>Si queremos utilizar un par de claves para acceder a un equipo, debemos asegurarnos de que exista la clave p\u00fablica en este fichero y cuando ya dejemos de utilizarla debemos borrar la l\u00ednea correspondiente.</p>"},{"location":"02.-SSH/03.-Uso%20de%20ssh/05.-Gesti%C3%B3n%20de%20ficheros.%20%60authorized_keys%60%20y%20%60known_hosts%60/#353-fichero-sshknownhosts","title":"3.5.3 Fichero ~/.ssh/knownhosts","text":"<p>Almacena las claves p\u00fablicas de todos los equipos remotos a los que nos hemos conectado y que hemos aceptado, el formato es:</p> <pre><code>nombre_o_IP_equipo algoritmo clave_p\u00fablica\n</code></pre> <p>Actualmente es m\u00e1s habitual que no se guarde el nombre o direcci\u00f3n IP del equipo en claro, sino que se almacene el hash. Para encontrar un determinado equipo por nombre o direcci\u00f3n IP podemos utilizar la instrucci\u00f3n:</p> <pre><code>ssh-keygen -F 172.22.200.175\n#Host 172.22.200.175 found: line 88 \n|1|lbA....9Lo= ecdsa-sha2-nistp256 AAAA.....ynTO90=\n</code></pre>"},{"location":"02.-SSH/03.-Uso%20de%20ssh/05.-Gesti%C3%B3n%20de%20ficheros.%20%60authorized_keys%60%20y%20%60known_hosts%60/#354-cambio-de-clave-publica-del-servidor","title":"3.5.4 Cambio de clave p\u00fablica del servidor","text":"<p>Habitualmente se almacenan las claves p\u00fablicas de los servidores a los que nos hemos conectado previamente en el fichero ~/.ssh/known_hosts, por lo que se verifica, cada vez que se conecta, que el servidor ofrece la misma clave p\u00fablica. En caso de que no coincida veremos el siguiente mensaje:</p> <pre><code>ssh debian@172.22.200.175\n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n@    WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!     @\n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\nIT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY!\nSomeone could be eavesdropping on you right now (man-in-the-middle attack)!\nIt is also possible that a host key has just been changed.\nThe fingerprint for the ECDSA key sent by the remote host is\nSHA256:J9CMWSbavkqECRI1KWhy8s/D7UVJWDiysAocAbo1F6k.\nPlease contact your system administrator.\nAdd correct host key in /home/alberto/.ssh/known_hosts to get rid of this message.\nOffending ECDSA key in /home/alberto/.ssh/known_hosts:88\n  remove with:\n  ssh-keygen -f \"/home/alberto/.ssh/known_hosts\" -R 172.22.200.175\nECDSA host key for 172.22.200.175 has changed and you have requested strict checking.\nHost key verification failed.\n</code></pre> <p>Es posible que se trate de una suplantaci\u00f3n y por tanto un problema de seguridad, pero tambi\u00e9n es posible que se haya realizado un cambio en el servidor que haya implicado un cambio en las claves del servicio ssh o una situaci\u00f3n muy habitual hoy en d\u00eda: estamos reutilizando la misma IP para un nuevo servidor.</p> <p>En caso de que estemos seguros de que no hay ning\u00fan problema de seguridad al acceder a ese equipo remoto, debemos eliminar la antigua clave asociada a la direcci\u00f3n IP (o al nombre), mediante la instrucci\u00f3n:</p> <pre><code>ssh-keygen -R 172.22.200.175\n#Host 172.22.200.175 found: line 88\n/home/alberto/.ssh/known_hosts updated.\nOriginal contents retained as /home/alberto/.ssh/known_hosts.old\n</code></pre>"},{"location":"02.-SSH/03.-Uso%20de%20ssh/06.-Forwarding/","title":"06.-Forwarding","text":""},{"location":"02.-SSH/03.-Uso%20de%20ssh/06.-Forwarding/#361-agent-forwarding","title":"3.6.1 Agent forwarding","text":"<p>Mediante esta t\u00e9cnica, es posible que el cliente ssh se comunique con un agente ssh que corre un una m\u00e1quina remota y sin necesidad de poner las claves privadas en \u00e9l, poder saltar a otro equipo remoto no accesible directamente. Es una t\u00e9cnica muy \u00fatil que permite no exponer directamente los servidores a los que realmente queremos acceder mediante ssh, sino que accedemos a ellos de forma transparente usando un equipo a modo de basti\u00f3n.</p> <p>Esta posibilidad debe estar habilitada en el servidor intermedio mediante la directiva:</p> <pre><code>allowagentforwarding yes\n</code></pre> <p>Que est\u00e1 habilitada por defecto.</p> <p>En el cliente es necesario habilitar el par\u00e1metro:</p> <pre><code>ForwardAgent yes\n</code></pre>"},{"location":"02.-SSH/03.-Uso%20de%20ssh/06.-Forwarding/#362-x11-forwarding","title":"3.6.2 X11 forwarding","text":"<p>A trav\u00e9s de la t\u00e9cnica de X11 forwarding podemos ver en nuestra pantalla aplicaciones gr\u00e1ficas que se ejecutan a trav\u00e9s de ssh en un equipo remoto (y viceversa).</p> <p>Aunque en primer lugar tiene que estar permitido en el servidor a trav\u00e9s de las directivas:</p> <pre><code>X11Forwarding yes\nX11DisplayOffset 10\n</code></pre> <p>El cliente para conectarse y utilizar esta funcionalidad, deber\u00e1 configurar adicionalmente la opci\u00f3n:</p> <pre><code>ForwardX11 yes\n</code></pre> <p>Al conectarnos por ssh podremos comprobar que est\u00e1 definida la variable DISPLAY con un valor definido a trav\u00e9s de la variable X11DisplayOffset, por ejemplo:</p> <pre><code>env |grep DISPLAY\nDISPLAY=localhost:10\n</code></pre> <p>Al ejecutar una aplicaci\u00f3n en el equipo remoto sobre la conexi\u00f3n ssh nos aparecer\u00e1 en nuestra pantalla.</p>"},{"location":"02.-SSH/04.-Configuraci%C3%B3n%20de%20ssh/01.-Configuraci%C3%B3n%20del%20cliente%20ssh/","title":"01.-Configuraci\u00f3n del cliente ssh","text":"<p>Existe el fichero <code>/etc/ssh/ssh_config</code> en el que se especifican los par\u00e1metros de configuraci\u00f3n generales que van a utilizar por defecto todos los clientes ssh que se ejecuten en esa m\u00e1quina.</p> <p>Los posibles par\u00e1metros que podemos definir en ese fichero se detallan en la p\u00e1gina 5 del manual de <code>ssh_config</code>. Algunos par\u00e1metros significativos</p>"},{"location":"02.-SSH/04.-Configuraci%C3%B3n%20de%20ssh/01.-Configuraci%C3%B3n%20del%20cliente%20ssh/#411-sendenv-lang-lc_","title":"4.1.1 SendEnv LANG LC_*","text":"<p>Mediante este par\u00e1metro se define en el equipo remoto los par\u00e1metros de localizaci\u00f3n del cliente, siempre que estos est\u00e9n definidos all\u00ed. Por ejemplo, supongamos que la variable local sea <code>LANG=es.ES.UTF-8</code>, seguir\u00e1 siendo en el equipo remoto siempre que exista, en caso contrario se pondr\u00e1 la localizaci\u00f3n por defecto del sistema:</p> <pre><code>usuario@cliente:~$ echo $LANG\nes_ES.UTF-8\nusuario@cliente:~$ ssh root@servidor1\n\nThe programs included with the Debian GNU/Linux system are free software;\nthe exact distribution terms for each program are described in the\nindividual files in /usr/share/doc/*/copyright.\n\nDebian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent\npermitted by applicable law.\nNo mail.\nLast login: Thu Feb 22 10:06:47 2018 from ...\nroot@servidor1:~# echo $LANG\nen_US.UTF-8\n</code></pre>"},{"location":"02.-SSH/04.-Configuraci%C3%B3n%20de%20ssh/01.-Configuraci%C3%B3n%20del%20cliente%20ssh/#412-hashknownhosts-yesno","title":"4.1.2 <code>HashKnownHosts yes|no</code>","text":"<p>Para ofuscar mediante un hash la IP o el nombre de los servidores de los que almacenamos las claves p\u00fablicas en el fichero ~/.ssh/known_hosts</p>"},{"location":"02.-SSH/04.-Configuraci%C3%B3n%20de%20ssh/01.-Configuraci%C3%B3n%20del%20cliente%20ssh/#413-gssapiauthentication-yesno","title":"4.1.3 <code>GSSAPIAuthentication yes|no</code>","text":"<p>Para habilitar este m\u00e9todo de autenticaci\u00f3n, en sistemas Debian viene habilitado, aunque s\u00f3lo es necesario en los casos en los que se vaya a usar este m\u00e9todo de autenticaci\u00f3n.</p>"},{"location":"02.-SSH/04.-Configuraci%C3%B3n%20de%20ssh/01.-Configuraci%C3%B3n%20del%20cliente%20ssh/#414-caracter-de-escape","title":"4.1.4 Car\u00e1cter de escape","text":"<p>En algunas ocasiones podemos tener problemas con nuestra conexi\u00f3n ssh y que la shell remota no responda a las instrucciones que mandamos, en esos casos siempre se podr\u00e1 cerrar la conexi\u00f3n mediante el car\u00e1cter de escape que hayamos definido en nuestro cliente ssh, este caracter por defecto es \u201c~\u201d:</p> <pre><code>EscapeChar ~\n</code></pre> <p>Para ejecutarlo escribir\u00edamos la secuencia \u201c~\u201d.</p>"},{"location":"02.-SSH/04.-Configuraci%C3%B3n%20de%20ssh/01.-Configuraci%C3%B3n%20del%20cliente%20ssh/#415forwardagent-forwardx11","title":"4.1.5<code>ForwardAgent</code>, <code>ForwardX11</code>","text":"<p>Explicados en la secci\u00f3n espec\u00edfica de forwarding</p>"},{"location":"02.-SSH/04.-Configuraci%C3%B3n%20de%20ssh/01.-Configuraci%C3%B3n%20del%20cliente%20ssh/#416-globalknownhostsfile-fichero","title":"4.1.6 <code>GlobalKnownHostsFile &lt;fichero&gt;</code>","text":"<p>Permite la utilizaci\u00f3n de un fichero knownhosts para todos los usuarios de un equipo.</p>"},{"location":"02.-SSH/04.-Configuraci%C3%B3n%20de%20ssh/01.-Configuraci%C3%B3n%20del%20cliente%20ssh/#417-numberofpasswordprompts","title":"4.1.7 <code>NumberOfPasswordPrompts</code>","text":"<p>N\u00famero de intentos de acceso con contrase\u00f1a. Por defecto es 3</p>"},{"location":"02.-SSH/04.-Configuraci%C3%B3n%20de%20ssh/01.-Configuraci%C3%B3n%20del%20cliente%20ssh/#418-stricthostkeychecking-yesaskno","title":"4.1.8 <code>StrictHostKeyChecking yes|ask|no</code>","text":"<p>Par\u00e1metro muy importante, utiliza para la gesti\u00f3n de las claves p\u00fablicas de los equipos remotos. La opci\u00f3n por defecto es \u201cask\u201d, de manera que si no se ha almacenado previamente la clave p\u00fablica se pregunta qu\u00e9 hacer. En el caso de ponerla en \u201cyes\u201d, se rechazar\u00e1 una conexi\u00f3n si no existe previamente la clave p\u00fablica y en caso de optar por la opci\u00f3n \u201cno\u201d, no se har\u00e1 ninguna verificaci\u00f3n.</p>"},{"location":"02.-SSH/04.-Configuraci%C3%B3n%20de%20ssh/01.-Configuraci%C3%B3n%20del%20cliente%20ssh/#419-userknownhostsfile-fichero","title":"4.1.9 <code>UserKnownHostsFile fichero</code>","text":"<p>Fichero knownhosts de usuario, por defecto ~/.ssh/knownhosts</p>"},{"location":"02.-SSH/04.-Configuraci%C3%B3n%20de%20ssh/01.-Configuraci%C3%B3n%20del%20cliente%20ssh/#4110-configuracion-por-usuario","title":"4.1.10 Configuraci\u00f3n por usuario","text":"<p>Salvo algunos par\u00e1metros generales, es poco probable que la mayor\u00eda de los par\u00e1metros que se pueden definir para el cliente ssh sean \u00fatiles para todos los usuarios de un equipo, es mucho m\u00e1s habitual que un usuario defina un fichero de configuraci\u00f3n con sus propios par\u00e1metros. Este fichero es <code>~/.ssh/config</code> y los par\u00e1metros aqu\u00ed definidos prevalecen sobre los generales.</p> <p>Se pueden definir par\u00e1metros para todos los equipos remotos, pero es tambi\u00e9n muy \u00fatil agruparlos con el par\u00e1metro Host como en el siguiente ejemplo:</p> <pre><code>GSSAPIAuthentication no\n\nHost 192.168.1.1\n     User root\n     Port 2022\n     ForwardAgent yes\n     Identityfile ~/.ssh/id_ecdsa\n     StrictHostKeyChecking yes\n\nHost *.example.com\n     StrictHostKeyChecking no\n     UserKnownHostsFile=/dev/null\n     LogLevel QUIET\n</code></pre>"},{"location":"02.-SSH/04.-Configuraci%C3%B3n%20de%20ssh/01.-Configuraci%C3%B3n%20del%20cliente%20ssh/#4111-utilizar-parametros-directamente","title":"4.1.11 Utilizar par\u00e1metros directamente","text":"<p>Independientemente de los par\u00e1metros que est\u00e9n definidos en cualquiera de las opciones anteriores, tambi\u00e9n es posible utilizar par\u00e1metros de forma expl\u00edcita en la propia l\u00ednea de comandos, pas\u00e1ndolos mediante el modificador \u201c-o\u201d, por ejemplo:</p> <pre><code>ssh -o \"ForwardAgent yes\" usuario@172.22.200.175\n</code></pre>"},{"location":"02.-SSH/04.-Configuraci%C3%B3n%20de%20ssh/02.-Configuraci%C3%B3n%20del%20servidor%20ssh/","title":"02.-Configuraci\u00f3n del servidor ssh","text":"<p>Tal como vimos en la instalaci\u00f3n y configuraci\u00f3n elemental del servidor ssh, podemos ver las opciones de configuraci\u00f3n que se aplican a nuestro servidor mediante:</p> <pre><code>sshd -T |less\n</code></pre> <p>Vamos a comentar algunas que pueden ser interesantes porque se modifican con cierta frecuencia.</p>"},{"location":"02.-SSH/04.-Configuraci%C3%B3n%20de%20ssh/02.-Configuraci%C3%B3n%20del%20servidor%20ssh/#421-port-22","title":"4.2.1 <code>Port 22</code>","text":"<p>Puerto tcp en el que va a escuchar peticiones el servidor ssh, por defecto es el 22/tcp, pero puede cambiarse sin problema.</p>"},{"location":"02.-SSH/04.-Configuraci%C3%B3n%20de%20ssh/02.-Configuraci%C3%B3n%20del%20servidor%20ssh/#422-addressfamily-anyinetinet6","title":"4.2.2 <code>AddressFamily any|inet|inet6</code>","text":"<p>El protocolo o protocolos de red a utilizar, puede ser inet(IPv4), inet6 (IPv6) o any(ambos) que es la opci\u00f3n por defecto.</p>"},{"location":"02.-SSH/04.-Configuraci%C3%B3n%20de%20ssh/02.-Configuraci%C3%B3n%20del%20servidor%20ssh/#423-listenaddress","title":"4.2.3 <code>ListenAddress</code>","text":"<p>Si queremos especificar que se permitan conexiones s\u00f3lo a trav\u00e9s de una direcci\u00f3n IP concreta (IPv4/IPv6).</p>"},{"location":"02.-SSH/04.-Configuraci%C3%B3n%20de%20ssh/02.-Configuraci%C3%B3n%20del%20servidor%20ssh/#424-logingracetime-maxauthtries-y-maxsessions","title":"4.2.4 <code>logingracetime</code>, <code>maxauthtries</code> y <code>maxsessions</code>","text":"<p>Para especificar el tiempo que se espera para que el usuario se acceda con \u00e9xito al sistema, el n\u00famero m\u00e1ximo de veces que puede introducir la contrase\u00f1a y el n\u00famero m\u00e1ximo de sesiones en la misma conexi\u00f3n.</p>"},{"location":"02.-SSH/04.-Configuraci%C3%B3n%20de%20ssh/02.-Configuraci%C3%B3n%20del%20servidor%20ssh/#425-loglevel-y-syslogfacility","title":"4.2.5 <code>loglevel</code> y <code>syslogfacility</code>","text":"<p>Para controlar el nivel de detalle que mostrar en los logs del sistema, as\u00ed como la \u201cfacility\u201d a utilizar.</p>"},{"location":"02.-SSH/04.-Configuraci%C3%B3n%20de%20ssh/02.-Configuraci%C3%B3n%20del%20servidor%20ssh/#426-hostkey","title":"4.2.6 <code>hostkey</code>","text":"<p>Fichero o ficheros que especifican la clave o claves privadas a utilizar por el servidor.</p>"},{"location":"02.-SSH/05.-Transferencia%20de%20ficheros%20a%20trav%C3%A9s%20de%20ssh/01.-Uso%20de%20%60scp%60/","title":"01.-Uso de `scp`","text":"<p>El cliente ssh incluye tambi\u00e9n el comando <code>scp</code> que permite copiar ficheros entre entre equipos mediante ssh y hacerlo de forma equivalente a la utilizaci\u00f3n local del cl\u00e1sico comando <code>cp</code>.</p> <p>No es necesario que el equipo origen o destino sea el equipo desde el que se ejecuta <code>scp</code>, tanto origen como destino pueden ser equipos a los que pueda acceder el usuario utilizando ssh.</p> <p>La sintaxis general de <code>scp</code> es:</p> <pre><code>scp [[user@]host1:]file1 [[user@]host2:]file2\n</code></pre>"},{"location":"02.-SSH/05.-Transferencia%20de%20ficheros%20a%20trav%C3%A9s%20de%20ssh/01.-Uso%20de%20%60scp%60/#511-transferir-un-fichero-local-a-un-equipo-remoto","title":"5.1.1 Transferir un fichero local a un equipo remoto","text":"<pre><code>scp  /etc/resolv.conf usuario@172.22.200.175:resolv.conf.local\n</code></pre> <p>El fichero remoto quedar\u00e1 como /home/usuario/resolv.conf.local ya que : indica el punto de acceso al equipo (/home/usuario/ en este caso) Transferir un fichero desde un equipo remoto a mi equipo local</p> <pre><code>scp root@172.22.200.175:/etc/shadow .\n</code></pre> <p>Que guardar\u00eda el fichero /etc/shadow del equipo remoto con el nombre shadow en el directorio en el que nos encontramos</p>"},{"location":"02.-SSH/05.-Transferencia%20de%20ficheros%20a%20trav%C3%A9s%20de%20ssh/01.-Uso%20de%20%60scp%60/#512-transferir-un-fichero-entre-dos-equipos-remotos","title":"5.1.2 Transferir un fichero entre dos equipos remotos","text":"<pre><code>scp root@172.22.200.175:/etc/hosts root@172.22.200.176:/etc/hosts\n</code></pre> <p>Esta opci\u00f3n es muy potente y permite crear sencillos scripts para unificar configuraciones, por ejemplo imaginemos que queremos tener la misma configuraci\u00f3n DNS en un conjunto de servidores, podr\u00edamos hacerlo de forma sencilla y potente con ssh mediante el siguiente script:</p> <pre><code>#!/bin/bash\n\nfor i in `seq 1 100`; do\n  scp root@servidor1:/etc/resolv.conf 192.168.1.$i:/etc/resolv.conf\ndone\n</code></pre>"},{"location":"02.-SSH/05.-Transferencia%20de%20ficheros%20a%20trav%C3%A9s%20de%20ssh/01.-Uso%20de%20%60scp%60/#513-bonus-track","title":"5.1.3 Bonus track","text":"<p>Si utilizamos pares de claves en las conexiones, <code>scp</code> autocompleta el fichero origen o destino utilizando el doble tabulador.</p>"},{"location":"02.-SSH/05.-Transferencia%20de%20ficheros%20a%20trav%C3%A9s%20de%20ssh/02.-Uso%20de%20%60sftp%60/","title":"02.-Uso de `sftp`","text":"<p>Al igual que <code>scp</code>, <code>sftp</code> permite transferir ficheros entre equipos remotos a trav\u00e9s de SSH, aunque su principal diferencia es que <code>sftp</code> permite utilizarlo de una forma interactiva, al igual que el tradicional ftp, incluyendo los mismos comandos que \u00e9ste. <code>scp</code> es mucho m\u00e1s habitual utilizarlo desde l\u00ednea de comandos, mientras que <code>sftp</code> se puede utilizar bien desde la l\u00ednea de comandos o a trav\u00e9s de uno de los m\u00faltiples clientes ftp que lo soportan.</p> <p>Es importante no confundir <code>sftp</code> (ssh ftp) con ftps que es una extensi\u00f3n del protocolo ftp a\u00f1adiendo ssl para el cifrado de la conexi\u00f3n.</p>"},{"location":"02.-SSH/06.-T%C3%BAneles%20SSH/","title":"Index","text":"<p>Esta t\u00e9cnica, tambi\u00e9n conocida como TCP forwarding o port forwarding, permite utilizar cualquier aplicaci\u00f3n de forma segura a trav\u00e9s de una conexi\u00f3n ssh (de ah\u00ed la utilizaci\u00f3n del t\u00e9rmino t\u00fanel).</p>"},{"location":"02.-SSH/06.-T%C3%BAneles%20SSH/01.-Local%20forwarding/","title":"01.-Local forwarding","text":"<p>Desde nuestra m\u00e1quina queremos acceder a un servicio, pero este servicio o bien no es accesible (por ejemplo por un cortafuegos que lo impide), o no es seguro hacerlo desde nuestra m\u00e1quina, pero tenemos acceso a otro equipo a trav\u00e9s de ssh y desde ese equipo s\u00ed podemos acceder al servicio que queremos o es seguro hacerlo.</p> <p>Vamos a verlo con un ejemplo: Queremos enviar un correo desde nuestro servidor de la empresa (puerto 25/tcp), pero estamos fuera y no queremos conectarnos de forma insegura, por lo que establecemos un t\u00fanel ssh de la siguiente forma:</p> <pre><code>ssh -f -L 1025:smtp.example.com:25 remoto.example.com -N\n</code></pre> <p>Esto abrir\u00e1 el puerto 1025/tcp en nuestra m\u00e1quina que podremos utilizar de forma segura para enviar correo, ya que se pasar\u00e1 a trav\u00e9s de ssh al equipo remoto.example.com y de ah\u00ed al servidor smtp.example.com.</p>"},{"location":"02.-SSH/06.-T%C3%BAneles%20SSH/02.-Remote%20forwarding/","title":"02.-Remote forwarding","text":"<p>Supongamos el caso contrario, en el que queremos que una m\u00e1quina remota utilice un servicio de nuestra m\u00e1quina, pero o bien no es accesible de forma directa o bien no es seguro hacerlo, por lo que podr\u00edamos definir una conexi\u00f3n ssh para realizarlo como la siguiente:</p> <pre><code>ssh -f -L 8080:localhost:80 remoto.example.com -N\n</code></pre> <p>De esa manera desde el equipo remoto, quien acceda al puerto 8080/tcp estar\u00e1 accediendo al puerto 80/tcp de nuestra m\u00e1quina a trav\u00e9s de un t\u00fanel ssh.</p> <p>La directiva <code>GatewayPorts yes|no</code> limita el puerto 8080 del caso anterior a que se pueda acceder s\u00f3lo desde el propio equipo remoto, o bien desde cualquier equipo.</p>"},{"location":"02.-SSH/06.-T%C3%BAneles%20SSH/03.-Forwarding%20din%C3%A1mico/","title":"03.-Forwarding din\u00e1mico","text":"<p>Mediante este mecanismo, lo que hacemos es crear un servidor SOCKS en nuestro equipo, que permite utilizar desde nuestra m\u00e1quina cualquier cliente que soporte este mecanismo, en particular un navegador web. Definir\u00edamos un servidor socks local que sale a trav\u00e9s de un t\u00fanel ssh con un equipo remoto de la siguiente forma:</p> <pre><code>ssh -D 8080 -f -C -q -N remote.example.com\n</code></pre>"},{"location":"03.-DHCP/","title":"Index","text":"<p>El protocolo de configuraci\u00f3n din\u00e1mica de host DHCP (Dynamic Host Configuration Protocol) es un est\u00e1ndar TCP/IP que simplifica la administraci\u00f3n de la configuraci\u00f3n IP haci\u00e9ndola autom\u00e1tica. Un servidor gestiona la concesi\u00f3n de direcciones IP de un determinado segmento de red y mantiene una lista actualizada de la correspondencia entre estas direcciones IP y las direcciones MAC de los equipos que las han solicitado. En el protocolo DHCP, el servidor utiliza el puerto 67/udp y el cliente el 68/udp.</p>"},{"location":"03.-DHCP/01.-Introducci%C3%B3n%20a%20DHCP/","title":"01.-Introducci\u00f3n a DHCP","text":"<ul> <li>Definici\u00f3n: DHCP (Dynamic Host Configuration Protocol) es un protocolo de red que permite la asignaci\u00f3n autom\u00e1tica de direcciones IP y otros par\u00e1metros de configuraci\u00f3n a los dispositivos que se conectan a una red. Este protocolo es esencial para facilitar la administraci\u00f3n de direcciones IP, ya que los dispositivos conectados a una red necesitan una direcci\u00f3n IP para comunicarse adecuadamente. DHCP garantiza que cada dispositivo obtenga una IP sin intervenci\u00f3n manual, lo cual reduce significativamente el esfuerzo administrativo.</li> <li>Prop\u00f3sito: El objetivo principal de DHCP es reducir la carga administrativa de asignar manualmente direcciones IP, especialmente en redes grandes o din\u00e1micas. En una red extensa, la asignaci\u00f3n manual de direcciones IP puede ser un proceso engorroso y propenso a errores. DHCP automatiza esta tarea, asegurando que los dispositivos se configuren correctamente, lo cual es especialmente importante en redes con dispositivos que se conectan y desconectan frecuentemente.</li> </ul>"},{"location":"03.-DHCP/02.-Funcionamiento%20del%20Protocolo%20DHCP/","title":"02.-Funcionamiento del Protocolo DHCP","text":"<ul> <li> <p>Proceso: DHCP opera mediante un mecanismo en el que el servidor DHCP asigna direcciones IP a los dispositivos (clientes) que lo solicitan. Este proceso es completamente automatizado y permite que cada dispositivo reciba una direcci\u00f3n IP v\u00e1lida junto con otros par\u00e1metros necesarios para la comunicaci\u00f3n en la red. El ciclo de trabajo est\u00e1ndar de DHCP se describe mediante las fases DORA, que garantizan una asignaci\u00f3n efectiva y sin conflictos de las direcciones IP disponibles.</p> </li> <li> <p>DORA: Estas cuatro fases describen c\u00f3mo se establece la conexi\u00f3n entre el cliente y el servidor DHCP:</p> <ol> <li> <p>Discover: El cliente busca un servidor DHCP enviando un mensaje de difusi\u00f3n para solicitar una IP. Este mensaje se env\u00eda a toda la red y espera una respuesta de cualquier servidor DHCP disponible.</p> </li> <li> <p>Offer: El servidor DHCP responde ofreciendo una direcci\u00f3n IP disponible. La oferta tambi\u00e9n puede incluir otros par\u00e1metros de red, como la m\u00e1scara de subred y la puerta de enlace predeterminada, que son necesarios para que el dispositivo funcione correctamente en la red.</p> </li> <li> <p>Request: El cliente acepta la IP ofrecida y solicita asignarla. Este mensaje tambi\u00e9n se env\u00eda como una difusi\u00f3n para informar a otros servidores DHCP que el cliente ha seleccionado una oferta espec\u00edfica.</p> </li> <li> <p>Acknowledge: El servidor confirma la asignaci\u00f3n y el cliente puede usar la direcci\u00f3n IP. Esta fase finaliza el proceso y permite al dispositivo comenzar a comunicarse dentro de la red con los par\u00e1metros asignados.</p> </li> </ol> </li> </ul>"},{"location":"03.-DHCP/04.-Componentes%20del%20Servidor%20DHCP/","title":"04.-Componentes del Servidor DHCP","text":"<p>Un servidor DHCP no solo asigna direcciones IP, sino que tambi\u00e9n proporciona otros par\u00e1metros necesarios para la correcta configuraci\u00f3n del dispositivo en la red:</p> <ul> <li> <p>*Direcci\u00f3n IP*: Asigna IPs din\u00e1micas dentro de un rango definido. Estas direcciones son temporales y se asignan a los dispositivos por un periodo determinado, lo cual permite una mejor gesti\u00f3n del espacio de direcciones.</p> </li> <li> <p>*M\u00e1scara de Subred*: Define qu\u00e9 porci\u00f3n de la direcci\u00f3n IP corresponde a la red y cu\u00e1l a los dispositivos. Esto es fundamental para que los dispositivos sepan c\u00f3mo comunicarse dentro de la misma red y cu\u00e1ndo necesitan enviar tr\u00e1fico a trav\u00e9s de un enrutador.</p> </li> <li> <p>*Puerta de Enlace Predeterminada (Gateway)*: Direcci\u00f3n del router a trav\u00e9s del cual los dispositivos pueden acceder a otras redes. Sin esta informaci\u00f3n, los dispositivos solo podr\u00edan comunicarse dentro de la red local, limitando su funcionalidad.</p> </li> <li> <p>*Servidores DNS*: Permiten que los dispositivos resuelvan nombres de dominio en direcciones IP. Esto es crucial para la navegaci\u00f3n por Internet, ya que permite que los usuarios accedan a sitios web mediante nombres en lugar de recordar direcciones IP.</p> </li> <li> <p>*Lease Time*: Tiempo durante el cual se asigna una direcci\u00f3n IP al dispositivo antes de que deba renovarse. Una vez expirado, el dispositivo debe solicitar una nueva IP o renovar la existente, lo cual permite al servidor recuperar IPs que ya no est\u00e1n en uso y reasignarlas a otros dispositivos.</p> </li> </ul>"},{"location":"03.-DHCP/05.-Configuraci%C3%B3n%20de%20un%20Servidor%20DHCP/","title":"05.-Configuraci\u00f3n de un Servidor DHCP","text":"<ul> <li> <p>*Instalaci\u00f3n*: Se requiere un servidor que soporte DHCP, que puede ser un servidor f\u00edsico, virtual o un dispositivo de red como un router. Esta flexibilidad permite que tanto redes peque\u00f1as como grandes puedan implementar DHCP de acuerdo a sus necesidades.</p> </li> <li> <p>*Rangos de Direcciones IP*: El administrador define un rango de direcciones que pueden ser asignadas din\u00e1micamente a los dispositivos. Este rango debe ser planificado cuidadosamente para evitar conflictos y garantizar que haya suficientes direcciones para todos los dispositivos conectados.</p> </li> <li> <p>*Par\u00e1metros Adicionales*: M\u00e1scara de subred, puerta de enlace, DNS, y otros par\u00e1metros de configuraci\u00f3n que se distribuyen a los clientes. Estos par\u00e1metros garantizan que los dispositivos puedan comunicarse de manera efectiva tanto dentro de la red como hacia el exterior.</p> </li> <li> <p>*Tiempo de Concesi\u00f3n (Lease Time)*: Define el tiempo durante el cual una IP est\u00e1 asignada a un cliente. Una vez expirado, la IP puede reasignarse. Este par\u00e1metro es importante para optimizar el uso del espacio de direcciones IP, especialmente en redes con dispositivos que se conectan y desconectan frecuentemente.</p> </li> </ul>"},{"location":"03.-DHCP/06.-Ventajas%20de%20DHCP/","title":"06.-Ventajas de DHCP","text":"<p>Automatizaci\u00f3n: Elimina la necesidad de asignar manualmente direcciones IP a cada dispositivo, lo que es especialmente \u00fatil en redes grandes o redes con dispositivos m\u00f3viles. La automatizaci\u00f3n de la asignaci\u00f3n de direcciones IP reduce significativamente la carga de trabajo del administrador de red y previene errores humanos comunes.</p> <p>Reducci\u00f3n de Errores: Minimiza errores humanos como la asignaci\u00f3n de IPs duplicadas, lo que puede causar conflictos en la red. Los conflictos de direcciones IP pueden hacer que los dispositivos sean incapaces de comunicarse, lo cual se evita mediante la gesti\u00f3n automatizada de DHCP.</p> <p>Escalabilidad: Facilita la expansi\u00f3n de redes al permitir una gesti\u00f3n centralizada de la asignaci\u00f3n de IPs y configuraci\u00f3n de red. Esto es particularmente importante en redes empresariales que crecen r\u00e1pidamente y necesitan una soluci\u00f3n de administraci\u00f3n flexible y eficiente.</p>"},{"location":"03.-DHCP/07.-Escenarios%20de%20uso/","title":"07.-Escenarios de uso","text":"<p>Redes Empresariales: En empresas con cientos o miles de dispositivos conectados a la red, DHCP permite una gesti\u00f3n centralizada y eficiente. Esta capacidad de gesti\u00f3n centralizada reduce la complejidad de mantener la red operativa y disminuye los costos de administraci\u00f3n.</p> <p>Proveedores de Servicios de Internet (ISP): Asignan din\u00e1micamente direcciones IP p\u00fablicas a sus clientes. Esto asegura que los recursos de IP se utilicen eficientemente, ya que las IP se asignan solo cuando los clientes se conectan.</p> <p>Redes Dom\u00e9sticas: Los routers caseros suelen actuar como servidores DHCP para gestionar los dispositivos de la red local. Esto simplifica la configuraci\u00f3n de la red para los usuarios finales, ya que no necesitan conocimientos t\u00e9cnicos para conectar dispositivos a la red.</p> <p>Dispositivos M\u00f3viles: Conexiones din\u00e1micas en redes Wi-Fi, donde los dispositivos se conectan y desconectan frecuentemente. DHCP permite que los dispositivos m\u00f3viles se conecten r\u00e1pidamente y sin intervenci\u00f3n del usuario, lo cual es esencial para la movilidad y flexibilidad de las redes modernas.</p>"},{"location":"03.-DHCP/08.-Conclusi%C3%B3n/","title":"08.-Conclusi\u00f3n","text":"<p>DHCP es un protocolo fundamental en la gesti\u00f3n eficiente de redes modernas. Su capacidad para asignar autom\u00e1ticamente direcciones IP y otros par\u00e1metros de red lo convierte en una herramienta crucial para reducir la complejidad de la administraci\u00f3n de redes, evitar errores y mejorar la escalabilidad. Gracias a DHCP, los administradores de red pueden gestionar eficientemente una gran cantidad de dispositivos sin preocuparse por la asignaci\u00f3n manual de direcciones IP, lo cual permite un mejor uso de los recursos de red y garantiza la conectividad de los dispositivos en todo momento. Esto es especialmente valioso en entornos con alta rotaci\u00f3n de dispositivos, como oficinas, universidades y redes p\u00fablicas, donde la simplicidad y eficiencia en la configuraci\u00f3n son esenciales para mantener una red estable y operativa.</p>"},{"location":"03.-DHCP/03.Fases%20del%20Proceso%20DHCP/01.-Discover%20%28Descubrimiento%29/","title":"01.-Discover (Descubrimiento)","text":"<p>El cliente env\u00eda una solicitud para encontrar un servidor DHCP en la red. Este paso es esencial para identificar qu\u00e9 servidores DHCP est\u00e1n disponibles y pueden proporcionar una direcci\u00f3n IP al cliente. El mensaje de descubrimiento se env\u00eda a trav\u00e9s de un broadcast, ya que el cliente a\u00fan no tiene una direcci\u00f3n IP.</p>"},{"location":"03.-DHCP/03.Fases%20del%20Proceso%20DHCP/02.-Offer%20%28Oferta%29/","title":"02.-Offer (Oferta)","text":"<p>El servidor DHCP ofrece una direcci\u00f3n IP y par\u00e1metros de configuraci\u00f3n de red como la m\u00e1scara de subred, la puerta de enlace predeterminada, etc. Este mensaje contiene toda la informaci\u00f3n que el cliente necesita para integrarse a la red.</p>"},{"location":"03.-DHCP/03.Fases%20del%20Proceso%20DHCP/03.-Request%20%28Solicitud%29/","title":"03.-Request (Solicitud)","text":"<p>El cliente responde al servidor solicitando la direcci\u00f3n IP que se le ha ofrecido. Este mensaje tambi\u00e9n notifica a otros servidores que ya no es necesario ofrecer una direcci\u00f3n, ya que el cliente ha elegido una oferta espec\u00edfica.</p>"},{"location":"03.-DHCP/03.Fases%20del%20Proceso%20DHCP/04.-Acknowledge%20%28Confirmaci%C3%B3n%29/","title":"04.-Acknowledge (Confirmaci\u00f3n)","text":"<p>El servidor DHCP confirma la asignaci\u00f3n de la IP, y el cliente la acepta. Este mensaje asegura que el cliente puede comenzar a usar la direcci\u00f3n IP, y la asignaci\u00f3n queda registrada en el servidor para evitar conflictos futuros.</p>"}]}