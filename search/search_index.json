{"config":{"lang":["es"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>01.-KVM</p> <p>02.-SSH</p> <p>03.-DHCP</p> <p>04.-DNS</p> <p>05.-Docker</p>"},{"location":"01.-KVM/","title":"Index","text":"<p>Las m\u00e1quinas virtuales basadas en el kernel (KVM) son una tecnolog\u00eda de virtualizaci\u00f3n open source integrada a Linux\u00ae. Con ellas, se puede transformar Linux en un hipervisor que permite que una m\u00e1quina host ejecute varios entornos virtuales aislados llamados m\u00e1quinas virtuales (VM) o guests.</p> <p>Las KVM forman parte de Linux. Por eso, si se cuenta con una versi\u00f3n de Linux 2.6.20 o posterior, ya est\u00e1n a nuestra a su disposici\u00f3n. Se anunciaron por primera vez en 2006, y un a\u00f1o despu\u00e9s se incorporaron a la versi\u00f3n principal del kernel de Linux. Dado que forman parte del c\u00f3digo actual de Linux, reciben inmediatamente todas las mejoras, las correcciones y las funciones nuevas de este  sistema, sin requerir ning\u00fan tipo de ingenier\u00eda adicional.</p> <p></p>"},{"location":"01.-KVM/01.-Introducci%C3%B3n/01.-Qu%C3%A9%20es%20la%20virtualizaci%C3%B3n/","title":"01.-Qu\u00e9 es la virtualizaci\u00f3n","text":"<p>Seg\u00fan la Wikipedia: La virtualizaci\u00f3n utiliza el software para imitar las caracter\u00edsticas del hardware y crear un sistema inform\u00e1tico virtual.</p> <p>Esto nos permite ejecutar m\u00e1s de un sistema virtual, y m\u00faltiples sistemas operativos y aplicaciones, en un solo servidor, aumentando el rendimiento del hardware disponible e incrementando el tiempo de procesamiento de un equipo, ya que habitualmente se desaprovecha gran parte.</p>"},{"location":"01.-KVM/01.-Introducci%C3%B3n/01.-Qu%C3%A9%20es%20la%20virtualizaci%C3%B3n/#para-que-se-utiliza-la-virtualizacion","title":"Para qu\u00e9 se utiliza la virtualizaci\u00f3n","text":"<ul> <li>Aislamiento e independencia de servicios y contenidos.</li> <li>Laboratorio de pruebas.</li> <li>Virtualizaci\u00f3n de arquitecturas de las que no se dispone.</li> <li>Creaci\u00f3n de cl\u00faster de m\u00e1quinas y sistemas distribuidos.</li> <li>Herramientas de aprendizajes</li> </ul>"},{"location":"01.-KVM/01.-Introducci%C3%B3n/01.-Qu%C3%A9%20es%20la%20virtualizaci%C3%B3n/#ventajas-e-inconvenientes-de-la-virtualizacion","title":"Ventajas e inconvenientes de la virtualizaci\u00f3n","text":"<p>Las principales ventajas que podemos indicar ser\u00edan:</p> <ul> <li>Importante ahorro econ\u00f3mico.</li> <li>Seguridad.</li> <li>Mayor aprovechamiento de recursos.</li> <li>Migraci\u00f3n en vivo. </li> <li>Importante ahorro energ\u00e9tico.</li> </ul> <p>Como desventajas podr\u00edamos se\u00f1alar:</p> <ul> <li>Muchos sistemas dependen de un s\u00f3lo equipo f\u00edsico.</li> <li>Penalizaciones en rendimiento.</li> </ul>"},{"location":"01.-KVM/01.-Introducci%C3%B3n/01.-Qu%C3%A9%20es%20la%20virtualizaci%C3%B3n/#conceptos-de-virtualizacion","title":"Conceptos de virtualizaci\u00f3n","text":"<ul> <li>Al sistema operativo que ejecuta el software de virtualizaci\u00f3n se le conoce como anfitri\u00f3n (host). El anfitri\u00f3n controla el hardware real.</li> <li>Al sistema operativo virtualizado se le conoce como invitado o hu\u00e9sped (guest).</li> <li>Al software de virtualizaci\u00f3n se le suele llamar Hipervisor.</li> <li>Desde 2005, Intel y AMD han a\u00f1adido soporte hardware para la virtualizaci\u00f3n: Intel Virtualization Technology (VT) y AMD Virtualization (AMD-V), y permiten a los hipervisores un rendimiento mayor en su labor de virtualizar.</li> </ul>"},{"location":"01.-KVM/01.-Introducci%C3%B3n/02.-Tipos/","title":"02.-Tipos","text":"<p>En el punto anterior aprendimos que un Hipervisor es el software que nos permite realizar la virtualizaci\u00f3n. Seg\u00fan como funcione el Hipervisor podemos clasificar distintas t\u00e9cnicas de virtualizaci\u00f3n:</p>"},{"location":"01.-KVM/01.-Introducci%C3%B3n/02.-Tipos/#emulacion","title":"Emulaci\u00f3n","text":"<p>El hipervisor imita o suplanta v\u00eda software una arquitectura al completo (procesador, memoria, conjunto de instrucciones, comunicaciones...). De esta forma puede hacer creer a los programas y sistemas operativos dise\u00f1ados para una arquitectura concreta que son ejecutados sobre ella. La emulaci\u00f3n suele ofrecer un rendimiento bastante bajo debido a que hay que realizar un proceso completo de traducci\u00f3n. Ejemplo: QEMU, Microsoft Virtual PC, Wine, ...</p> <p></p>"},{"location":"01.-KVM/01.-Introducci%C3%B3n/02.-Tipos/#virtualizacion-completa-o-por-hardware","title":"Virtualizaci\u00f3n completa o por hardware","text":"<p>El hipervisor simula un hardware suficiente para permitir que un sistema operativo no adaptado se ejecute de forma aislada. En este caso podemos hacer una subdivisi\u00f3n seg\u00fan el tipo de hipervisor que estemos utilizando:</p> <ul> <li> <p>Virtualizaci\u00f3n por hardware: En este caso usamos hipervisores de tipo 1, que controlan directamente el hardware f\u00edsico del host ofreci\u00e9ndolo directamente a la m\u00e1quina virtual. Es imprescindible que la CPU del host tenga las extensiones de virtualizaci\u00f3n. Ejemplos: Xen, Kernel-based Virtual Machine (KVM), Microsoft Hyper-V, VMware ESXi,...</p> <p></p> </li> <li> <p>Virtualizaci\u00f3n completa: En este tipo se usan hipervisores de tipo 2. Este software se instala sobre el sistema operativo del host, pero no controla directamente el hardware f\u00edsico. Ofrecen menos rendimiento que la virtualizaci\u00f3n por hardware. Ejemplos: VMware Workstation, Parallels Desktop, VirtualBox, VMware Player, ...</p> <p></p> </li> </ul>"},{"location":"01.-KVM/01.-Introducci%C3%B3n/02.-Tipos/#virtualizacion-parcial-o-paravirtualizacion","title":"Virtualizaci\u00f3n parcial o paravirtualizaci\u00f3n","text":"<p>El hipervisor ofrece un interfaz especial para acceder a los recursos. En ocasiones, es necesario la adaptaci\u00f3n del sistema operativo de la m\u00e1quina virtual. Ofrecen el m\u00e1ximo rendimiento, pero no se pueden usar sistemas operativos sin modificaciones o hardware especifico. Ejemplos: XEN, Microsoft Hyper-V, VMware ESXi, ...</p> <p></p>"},{"location":"01.-KVM/01.-Introducci%C3%B3n/02.-Tipos/#virtualizacion-ligera","title":"Virtualizaci\u00f3n ligera","text":"<p>O tambi\u00e9n llamada virtualizaci\u00f3n a nivel de sistema operativo, o virtualizaci\u00f3n basada en contenedores. Es un m\u00e9todo de virtualizaci\u00f3n en el que, sobre el n\u00facleo del sistema operativo se ejecuta una capa de virtualizaci\u00f3n que permite que existan m\u00faltiples instancias aisladas de espacios de usuario. A cada espacio de usuario aislado lo llamamos contenedor. Por lo tanto, un contenedor es un conjunto de procesos aislados, que se ejecutan en un servidor, y que acceden a un sistema de ficheros propio, tienen una configuraci\u00f3n red propio y accede a los recursos del host (memoria y CPU). Podemos hacer la siguiente clasificaci\u00f3n de contenedores:</p> <ul> <li>Contenedores de Sistemas: El uso que se hace de ellos es muy similar al que hacemos sobre una m\u00e1quina virtual: se accede a ellos (normalmente por ssh), se instalan servicios, se actualizan, ejecutan un conjunto de procesos, ... Ejemplo: LXC(Linux Container).</li> <li>Contenedores de Aplicaci\u00f3n: Se suelen usar para el despliegue de aplicaciones web Ejemplo: Docker, Podman, ...</li> </ul> <p></p>"},{"location":"01.-KVM/01.-Introducci%C3%B3n/03.-qemu-kvm/","title":"03.-qemu-kvm","text":"<p>De acuerdo con la wiki de QEMU, \"QEMU es un emulador gen\u00e9rico y de c\u00f3digo abierto de m\u00e1quinas virtuales.\". Se puede usar como emulador, permitiendo ejecutar sistemas operativos de una determinada arquitectura (por ejemplo ARM) sobre otra arquitectura (por ejemplo amd64). Pero tambi\u00e9n, puede ofrecer una soluci\u00f3n de virtualizaci\u00f3n completa, usando hipervidores como KVM para utilizar las extensiones del procesador para la virtualizaci\u00f3n y ofrecer un rendimiento mayor.</p> <p>KVM, la Maquina virtual basada en el kernel (Kernel-based Virtual Machine), es un hipervisor de tipo 1 integrado al kernel de Linux. Es una soluci\u00f3n de virtualizaci\u00f3n completa para Linux, que contienen las extensiones de virtualizaci\u00f3n Intel VT o AMD-V. Se compone de un m\u00f3dulo del kernel <code>kvm.ko</code>, que provee la infraestructura de virtualizaci\u00f3n base, y un m\u00f3dulo espec\u00edfico para el tipo de procesador, <code>kvm-intel.ko</code> o <code>kvm-amd.ko</code>.</p> <p>Por lo tanto, podemos usar QEMU junto a KVM para permitir la ejecuci\u00f3n de m\u00e1quinas virtuales utilizando im\u00e1genes de disco que contienen sistemas operativos sin modificar. Cada m\u00e1quina virtual tiene su propio hardware virtualizado: una tarjeta de red, discos duros, tarjeta gr\u00e1fica, ...</p>"},{"location":"01.-KVM/01.-Introducci%C3%B3n/03.-qemu-kvm/#dispositivos-paravirtualizados","title":"Dispositivos paravirtualizados","text":"<p>Al crear las m\u00e1quinas virtuales, adem\u00e1s de las caracter\u00edsticas b\u00e1sicas como la cantidad de RAM asignada, el espacio de almacenamiento o la CPU, se deben seleccionar los diferentes dispositivos que van a formar parte de ella: interfaz de red, controladores de disco duro, interfaz gr\u00e1fica, etc. En un sistema de virtualizaci\u00f3n completa como QEMU/KVM todos los dispositivos est\u00e1n inicialmente emulados por software, de manera que la m\u00e1quina virtual interact\u00faa con un dispositivo como si lo hiciera con uno f\u00edsico equivalente. De esta manera podemos encontrar una interfaz de red emulando a la cl\u00e1sica tarjeta de red Realtek 8139 o una interfaz IDE para conectar con un disco duro virtual. Estos dispositivos emulados tienen la ventaja de que pueden utilizar los controladores de dispositivos de sus equivalentes f\u00edsicos, por lo que se suelen utilizar dispositivos emulados muy comunes, que proporcionan compatibilidad con la mayor\u00eda de sistemas operativos y hacen muy sencilla la instalaci\u00f3n de los mismos dentro de una m\u00e1quina virtual. Sin embargo, tienen un inconveniente y es que cuando son dispositivos muy usados, tienen un rendimiento pobre, aumentan el consumo de recursos de la CPU y aumentan la latencia de E/S.</p> <p>El proyecto KVM proporciona una alternativa al uso de dispositivos emulados, que se conocen como dispositivos paravirtualizados y se engloban bajo la denominaci\u00f3n virtIO. El nombre de dispositivos paravirtualizados hace referencia a la t\u00e9cnica que utilizan, m\u00e1s cercana a la paravirtualizaci\u00f3n y que proporciona un rendimiento muy cercano al real, por lo que es muy recomendable utilizar dispositivos virtIO en los dispositivos de E/S que consumen m\u00e1s recursos, por ejemplo, la red y el acceso a discos duros. El \u00fanico inconveniente que tiene utilizar dispositivos virtIO es que son espec\u00edficos para KVM y no todos los sistemas operativos los reconocen por defecto. Evidentemente los sistemas linux s\u00ed reconocen los dispositivos virtIO y en ese caso siempre es recomendable usarlos, pero otros sistemas operativos, como por ejemplo Windows, no incluyen inicialmente soporte virtio, si queremos usarlos en ese caso, ser\u00e1 necesario instalar los controladores de dispositivos durante la instalaci\u00f3n del sistema operativo de la m\u00e1quina virtual.</p>"},{"location":"01.-KVM/01.-Introducci%C3%B3n/03.-qemu-kvm/#libvirt-una-api-de-virtualizacion","title":"libvirt: una API de virtualizaci\u00f3n","text":"<p>Normalmente no trabajamos directamente con las aplicaciones ofrecidas por QEMU/KVM para la gesti\u00f3n de recursos virtualizados. Es m\u00e1s f\u00e1cil usar libvirt, una API intermedia que nos facilita la comunicaci\u00f3n con QEMU/KVM.</p> <p>\u00cdndice</p>"},{"location":"01.-KVM/01.-Introducci%C3%B3n/04.-libvirt/","title":"04.-libvirt","text":"<p>libvirt proporciona una API gen\u00e9rica, un demonio y un conjunto de herramientas de gesti\u00f3n para diferentes sistemas de virtualizaci\u00f3n, en particular los sistemas de virtualizaci\u00f3n nativos de linux: KVM, LXC o Xen. Tambi\u00e9n es posible,  manejar a trav\u00e9s de libvirt otros sistemas de virtualizaci\u00f3n como VMware ESXi o Hyper-V.</p>"},{"location":"01.-KVM/01.-Introducci%C3%B3n/04.-libvirt/#mecanismos-de-conexion","title":"Mecanismos de conexi\u00f3n","text":"<p>libvirt proporciona varios mecanismos para conectarse a un hipervisor Qemu/KVM, tanto de forma local como remota, los que veremos en este curso son:</p>"},{"location":"01.-KVM/01.-Introducci%C3%B3n/04.-libvirt/#acceso-local-con-un-usuario-no-privilegiado","title":"Acceso local con un usuario no privilegiado","text":"<p>Nos conectamos a la URI <code>qemu:///session</code>. Se acceden a las m\u00e1quinas virtuales de ese usuario. En este modo de conexi\u00f3n, el usuario no suele tener permisos para crear conexiones de red, por lo que se limita su uso de la red no privilegiada de qemu (SLIRP) que es \u00fatil para casos simples, pero que tiene bajo rendimiento y es poco configurable. </p>"},{"location":"01.-KVM/01.-Introducci%C3%B3n/04.-libvirt/#acceso-local-privilegiado","title":"Acceso local privilegiado","text":"<p>Nos conectamos a la URI <code>qemu:///system</code>. Se acceden a las m\u00e1quinas virtuales del sistema. Por las limitaciones vistas anteriormente en el acceso local con usuarios no privilegiados, se utiliza la conexi\u00f3n <code>qemu:///system</code>, que es \u00fanica para todo el sistema y que puede utilizar tanto el usuario <code>root</code> como cualquier miembro del grupo <code>libvirt</code>.</p>"},{"location":"01.-KVM/01.-Introducci%C3%B3n/04.-libvirt/#acceso-remoto-privilegiado-por-ssh","title":"Acceso remoto privilegiado por ssh","text":"<p>Nos conectamos a la URI <code>qemu+ssh:///system</code>. En las conexiones citadas anteriormente nos conectamos a un socket linux <code>/var/run/libvirt/libvirt-sock</code>. A este socket tambi\u00e9n nos podemos conectar a trav\u00e9s de un t\u00fanel ssh (qemu+ssh).</p>"},{"location":"01.-KVM/01.-Introducci%C3%B3n/04.-libvirt/#aplicaciones-para-usar-libvirt","title":"Aplicaciones para usar libvirt","text":"<p>libvirt proporciona una API que puede ser utilizada por diferentes aplicaciones (CLI, GUI o web). Podemos destacar algunas que vamos a utilizar en este curso:</p> <ul> <li>virsh: Es el cliente por l\u00ednea de comandos \"oficial\" de libvirt. Ofrece una shell completa para el manejo de la API.</li> <li>virt-manager: Es una aplicaci\u00f3n gr\u00e1fica (GUI) que nos proporciona muchas de las funcionalidades para trabajar con libvirt.</li> <li>virtinst: Paquete que proporciona los comandos <code>virt-clone</code>, <code>virt-install</code> y <code>virt-xml</code> \u00fatiles para crear y copiar m\u00e1quinas virtuales.</li> <li>virt-viewer: Programa que nos permite acceder a a la consola gr\u00e1fica de una m\u00e1quina virtual.</li> <li>gnome-boxes: Aplicaci\u00f3n gr\u00e1fica muy simple, que utilizando el acceso local con usuario no privilegiado, nos permite gestionar, de forma sencilla, m\u00e1quinas virtuales.</li> </ul> <p>Cuando cualquier aplicaci\u00f3n se conecta a libvirt (con cualquiera de los m\u00e9todos que hemos estudiado) el formato de la informaci\u00f3n que se intercambian a trav\u00e9s de la API es XML. Puedes encontrar la definici\u00f3n de este formato en la documentaci\u00f3n oficial: XML Format.</p> <p>\u00cdndice</p>"},{"location":"01.-KVM/01.-Introducci%C3%B3n/05.-LXC/","title":"05.-LXC","text":"<p>LinuX Containers, tambi\u00e9n conocido por el acr\u00f3nimo LXC, es una tecnolog\u00eda de virtualizaci\u00f3n ligera o por contenedores, que es un m\u00e9todo de virtualizaci\u00f3n en el que, sobre el n\u00facleo del sistema operativo se ejecuta una capa de virtualizaci\u00f3n que permite que existan m\u00faltiples instancias aisladas de espacios de usuario, en lugar de solo uno. A estas instancias la llamamos contenedores.</p> <p>Todo esto ha sido posible por el desarrollo de dos componentes del nucleo de Linux:</p> <ul> <li>Los Grupos de Control cgroups, en concreto en Debian 11 se utiliza cgroupsv2: que limita el uso de recursos (l\u00edmite de memoria, cpu, I/O o red) para un proceso y sus hijos.</li> <li>Los Espacios de Nombres namespaces: que proporcionan un punto de vista diferente a un proceso (interfaces de red, procesos, usuarios, etc.).</li> </ul> <p>LXC pertenece a los denominados contenedores de sistemas, su gesti\u00f3n y ciclo de vida es similar al de una m\u00e1quina virtual tradicional. Est\u00e1 mantenido por Canonical y la p\u00e1gina oficial es linuxcontainers.org.</p>"},{"location":"01.-KVM/02.-Instalaci%C3%B3n/01.-Escenario%20de%20instalaci%C3%B3n/","title":"01.-Escenario de instalaci\u00f3n","text":"<p>En un entorno de producci\u00f3n, QEMU/KVM se instalar\u00e1 sobre una m\u00e1quina f\u00edsica con suficientes recursos. Si el sistema operativo tiene entorno gr\u00e1fico, podremos instalar herramientas gr\u00e1ficas, aunque siempre nos podemos conectar remotamente al servidor para gestionar QEMU/KVM.</p> <p>Para ejecutar QEMU/KVM necesitamos que el procesador soporte extensiones de virtualizaci\u00f3n en su juego de instrucciones. Para comprobar si tenemos esta caracter\u00edstica ejecutamos la siguiente instrucci\u00f3n como <code>root</code>:</p> <pre><code>egrep 'svm|vmx' /proc/cpuinfo --color\n</code></pre> <p>El resultado deber\u00eda mostrar varias l\u00edneas con el texto buscado resaltado en color. Si este es el caso entonces nuestro procesador soporta KVM. Los procesadores Intel mostrar\u00e1n el texto vmx resaltado y los procesadores AMD mostrar\u00e1n el texto svm resaltado.</p> <p>NOTA: Es importante comprobar que en la BIOS est\u00e1n activados las instrucciones virtuales VT/x, de lo contrario KVM no funcionar\u00e1.</p>"},{"location":"01.-KVM/02.-Instalaci%C3%B3n/01.-Escenario%20de%20instalaci%C3%B3n/#virtualizacion-anidada","title":"Virtualizaci\u00f3n anidada","text":"<p>Con esta caracter\u00edstica se permite la ejecuci\u00f3n de instrucciones KVM dentro de m\u00e1quinas virtuales KVM, lo cual nos posibilita la ejecuci\u00f3n de m\u00e1quinas virtuales dentro de m\u00e1quinas virtuales. De esta manera,podemos crear un laboratorio de prueba de QEMU/KVM ejecut\u00e1ndolos en una m\u00e1quina virtual.</p>"},{"location":"01.-KVM/02.-Instalaci%C3%B3n/01.-Escenario%20de%20instalaci%C3%B3n/#requerimientos-minimos","title":"Requerimientos m\u00ednimos","text":"<p>Si tenemos un entorno de producci\u00f3n, utilizaremos una m\u00e1quina f\u00edsica para la instalaci\u00f3n de QEMU/KVM. Tambi\u00e9n podr\u00edamos usar una m\u00e1quina virtual (con virtualizaci\u00f3n anidada activa) para tener un laboratorio de pruebas.</p> <p>Dependiendo de la cantidad de memoria RAM, espacio de disco duro y VCPU que tengamos, podremos virtualizar m\u00e1s o menos m\u00e1quinas virtuales:</p> <ul> <li>Por ejemplo, desde el punto de vista de la RAM: si virtualizamos una m\u00e1quina virtual sin entorno gr\u00e1fico podemos asignarle 512Mb, si tiene entorno gr\u00e1fico ya tendr\u00edamos que usar 1 o 2GB, si virtualizamos una m\u00e1quina Windows al menos tendremos que asignar 2Gb de RAM.</li> <li>Desde el punto de vista del almacenamiento: Este factor no es tan importante, pero tenemos que pensar que hay que almacenar las ISO para la instalaci\u00f3n de las m\u00e1quinas y los discos duros de las m\u00e1quinas virtuales. </li> <li> <p>Al crear m\u00e1quinas virtuales o contenedores podremos asignarle cores virtuales de CPU, por lo que aumentar\u00e1 el rendimiento si asignamos a nuestra m\u00e1quina virtual suficientes n\u00facleos de CPU. Por todo lo explicado a continuaci\u00f3n la configuraci\u00f3n recomendada para la m\u00e1quina virtual ser\u00eda:</p> </li> <li> <p>8 Gb de RAM</p> </li> <li>100 Gb de disco duro</li> <li>4 n\u00facleos de CPU</li> </ul>"},{"location":"01.-KVM/02.-Instalaci%C3%B3n/02.-Instalacion/","title":"02.-Instalacion","text":"<p>Para trabajar con el sistema de virtualizaci\u00f3n QEMU/KVM + libvirt en nuestra distribuci\u00f3n Linux Debian/Ubuntu, vamos a instalar los siguientes paquetes:</p> <pre><code>$ sudo apt install qemu-system libvirt-clients libvirt-daemon-system\n</code></pre> <p>libvirt proporciona varios mecanismos para conectarse a un hipervisor qemu-kvm.</p> <p>Podemos obtener las versiones de las aplicaciones que hemos instalado, ejecutando:</p> <pre><code>$ virsh version\nCompiled against library: libvirt 10.8.0\nUsing library: libvirt 10.8.0\nUsing API: QEMU 10.8.0\nRunning hypervisor: QEMU 9.1.0\n</code></pre>"},{"location":"01.-KVM/02.-Instalaci%C3%B3n/02.-Instalacion/#conexion-a-qemukvm","title":"Conexi\u00f3n a QEMU/KVM","text":"<p>Vamos a usar la utilidad <code>virsh</code>, que nos proporciona una shell completa para el manejo de <code>libvirt</code>. Con el comando <code>list</code> mostramos las m\u00e1quinas virtuales que hemos creado.</p> <p>Con un usuario sin privilegios ejecutamos:</p> <pre><code>$ virsh list\n</code></pre> <p>Estar\u00edamos haciendo una conexi\u00f3n local con un usuario no privilegiado (estar\u00edamos conectando con la URI <code>qemu:///session</code> y estar\u00edamos mostrando las m\u00e1quinas virtuales de este usuario.</p> <p>Si por el contrario, como <code>root</code> ejecutamos:</p> <pre><code>root@kvm:~# virsh list\n</code></pre> <p>Estar\u00edamos haciendo una conexi\u00f3n local privilegiada (estar\u00edamos conectando con la URI <code>qemu:///system</code>) y mostrar\u00edamos las m\u00e1quinas virtuales del sistema.</p> <p>Si queremos que un usuario sin privilegios pueda hacer conexiones privilegiadas, el usuario debe pertenecer el grupo <code>libvirt</code>:</p> <pre><code>root@kvm:~# adduser usuario libvirt\n</code></pre> <p>Para que el usuario <code>usuario</code> haga una conexi\u00f3n privilegiada tendr\u00e1 que indicar expl\u00edcitamente la conexi\u00f3n a la URI <code>qemu:///system</code>:</p> <pre><code>usuario@kvm:~$ virsh -c qemu:///system list\n</code></pre> <p>De forma alternativa y seg\u00fan la wiki de Debian, podemos usar la variable de entorno <code>LIBVIRT_DEFAULT_URI</code> con el siguiente comando:</p> <pre><code>export LIBVIRT_DEFAULT_URI='qemu:///system'\n</code></pre>"},{"location":"01.-KVM/02.-Instalaci%C3%B3n/03.-Conexi%C3%B3n%20local%20no%20privilegiada%20a%20libvirt/","title":"03.-Conexi\u00f3n local no privilegiada a libvirt","text":"<p>Como hemos comentado en el punto anterior, un usuario sin privilegio puede crear sus m\u00e1quinas virtuales. Para ello realizar\u00e1 una conexi\u00f3n local a la URI <code>qemu:///session</code>. En este modo de conexi\u00f3n, el usuario no tiene permisos para crear conexiones de red, por lo que se limita su uso de la red no privilegiada de qemu (SLIRP) que es \u00fatil para casos simples, pero que tiene bajo rendimiento y es poco configurable. </p> <p>El usuario podr\u00eda usar cualquier aplicaci\u00f3n que nos permite la creaci\u00f3n de m\u00e1quinas virtuales (<code>virsh</code>, <code>virt-install</code>, <code>virt-manager</code>,...), pero en este apartado vamos a usar Gnome Boxes, que es una aplicaci\u00f3n gr\u00e1fica que nos permite crear m\u00e1quinas virtuales, de forma sencilla, en el espacio de usuario.</p>"},{"location":"01.-KVM/02.-Instalaci%C3%B3n/03.-Conexi%C3%B3n%20local%20no%20privilegiada%20a%20libvirt/#gnome-boxes","title":"Gnome Boxes","text":"<p>Instalamos esta aplicaci\u00f3n:</p> <pre><code># apt install gnome-boxes\n</code></pre> <p>o en Arch:</p> <pre><code># pacman -S gnome-boxes\n</code></pre> <p>La utilizaci\u00f3n de esta aplicaci\u00f3n es muy sencilla. Podemos descargar distribuciones Linux preconfiguradas o elegir un fichero ISO para realizar la instalaci\u00f3n. Siguiendo la documentaci\u00f3n de la aplicaci\u00f3n, seguimos los siguientes pasos para crear una nueva maquina virtual:</p> <p>Pulsamos el bot\u00f3n \"+\" y elegimos la opci\u00f3n Crea una m\u00e1quina virtual.... A continuaci\u00f3n podemos escoger un sistema predefinido o un fichero ISO para realizar la instalaci\u00f3n. Elegimos un sistema preconfigurado:</p> <p></p> <p>A continuaci\u00f3n buscamos las versiones de Ubuntu:</p> <p></p> <p>Despu\u00e9s de la descarga, configuramos la nueva m\u00e1quina:</p> <p></p> <p>Y al terminar la instalaci\u00f3n  podemos acceder a la m\u00e1quina:</p> <p></p> <p>La m\u00e1quina se conecta a la red de usuario de QEMU (SLIRP) que configura la m\u00e1quina con la direcci\u00f3n IP <code>10.0.2.15</code>, su puerta de enlace, que es el anfitri\u00f3n (la m\u00e1quina f\u00edsica) es la direcci\u00f3n IP <code>10.0.2.2</code> y configura un servidor DNS en la direcci\u00f3n IP <code>10.0.2.3</code>. Esta red permite que la m\u00e1quina tenga acceso a internet, pero no tendr\u00e1 conectividad con el anfitri\u00f3n u otras m\u00e1quinas que creemos.</p> <p></p>"},{"location":"01.-KVM/02.-Instalaci%C3%B3n/03.-Conexi%C3%B3n%20local%20no%20privilegiada%20a%20libvirt/#acceso-a-las-maquinas-desde-la-linea-de-comandos","title":"Acceso a las m\u00e1quinas desde la l\u00ednea de comandos","text":"<p>Para comprobar que la m\u00e1quina virtual que hemos creado est\u00e1 virtualizada con QEMU/KVM + libvirt en el espacio de usuario, podemos ejecutar en el anfitri\u00f3n con el usuario con el que estamos trabajando:</p> <pre><code>usuario@kvm:~$ virsh -c qemu:///session list\n Id   Nombre          Estado\n----------------------------------\n 2    ubuntu20.10-2   ejecutando\n</code></pre> <p>o si queremos ver todas las m\u00e1quinas, tanto las que est\u00e1n en ejecuci\u00f3n como las que est\u00e1n apagadas:</p> <pre><code>usuario@kvm:~$ sudo virsh list --all\n</code></pre> <p>Vemos que la m\u00e1quina est\u00e1 creado en la sesi\u00f3n del usuario <code>usuario</code>. Nota: No es necesario indicar la conexi\u00f3n <code>-c qemu:///session</code>, pero de esa forma se ve m\u00e1s claro que estamos haciendo una conexi\u00f3n local con un usuario sin privilegios.</p> <p>Por \u00faltimo, indicar que la imagen del disco se guarda por defecto en el directorio <code>~/.local/share/gnome-boxes/images</code>:</p> <pre><code>usuario@kvm:~$ ls -l .local/share/gnome-boxes/images\ntotal 196\n-rwxr--r-- 1 usuario usuario 196816 may 15 21:52 ubuntu20.10-2\n</code></pre>"},{"location":"01.-KVM/02.-Instalaci%C3%B3n/04.-Conexi%C3%B3n%20local%20privilegiada%20a%20libvirt/","title":"04.-Conexi\u00f3n local privilegiada a libvirt","text":"<p>Generalmente vamos a trabajar realizando conexiones locales privilegiadas, por lo tanto si queremos ver todas las m\u00e1quinas creadas en el sistema debemos ejecutar:</p> <pre><code>usuario@kvm:~$ virsh -c qemu:///system list --all\n</code></pre> <ul> <li>Nota 1: La opci\u00f3n <code>--all</code> muestra las m\u00e1quinas que se est\u00e1n ejecutando y las que est\u00e1n paradas.</li> <li>Nota 2: Si nos conectaremos con el usuario <code>root</code> no har\u00eda falta indicar la URI <code>-c qemu:///system</code>.</li> </ul>"},{"location":"01.-KVM/02.-Instalaci%C3%B3n/04.-Conexi%C3%B3n%20local%20privilegiada%20a%20libvirt/#redes-disponibles","title":"Redes disponibles","text":"<p>Cuando instalamos QEMU/KVM + libvirt se crea una red por defecto de tipo NAT, que no est\u00e1 iniciada. Para verla, ejecutamos la siguiente instrucci\u00f3n:</p> <pre><code>usuario@kvm:~$ virsh -c qemu:///system net-list --all\n Nombre    Estado     Inicio autom\u00e1tico   Persistente\n-------------------------------------------------------\n default   inactivo   no                  si\n</code></pre> <ul> <li>Nota: La opci\u00f3n <code>--all</code> muestra las redes activas e inactivas.</li> </ul> <p>Como vemos, el estado es inactivo, para iniciarla, ejecutamos:</p> <pre><code>usuario@kvm:~$ virsh -c qemu:///system net-start default \nLa red default se ha iniciado\n</code></pre> <p>Adem\u00e1s es recomendable activar la propiedad de Incio aut\u00f3matico, para que se inicie de forma autom\u00e1tica despu\u00e9s de reiniciar el host, para ello:</p> <pre><code>usuario@kvm:~$ virsh -c qemu:///system net-autostart default\nLa red default ha sido marcada para iniciarse autom\u00e1ticamente\n</code></pre> <p>Y ejecutando de nuevo <code>virsh -c qemu:///system net-list</code>, aparece la red como activa y Inicio autom\u00e1tico a si.</p> <p>Aunque estudiaremos la redes con profundidad en el m\u00f3dulo correspondiente, podemos se\u00f1alar que las m\u00e1quinas virtuales que se conecten a esta red, tendr\u00e1n las siguientes caracter\u00edsticas:</p> <ul> <li>Tomar\u00e1n una direcci\u00f3n IP de forma din\u00e1mica en el rango <code>192.168.122.2</code> - <code>192.168.122.254</code>. Es decir, existe un servidor DHCP (que se encuentra en el host) asignando de forma din\u00e1mica el direccionamiento.</li> <li>La puerta de enlace ser\u00e1 la direcci\u00f3n IP <code>192.168.122.1</code> que corresponde al host. Est\u00e1 direcci\u00f3n tambi\u00e9n corresponde al servidor DNS que tiene configurado (que tambi\u00e9n se encuentra en el host).</li> <li>La m\u00e1quina virtual estar\u00e1 conectada a un Linux Bridge (switch virtual) llamado <code>virbr0</code> por la que se conectar\u00e1 al host.</li> <li>El host har\u00e1 de router/nat para que la m\u00e1quina tenga conectividad al exterior.</li> </ul> <p>Por defecto, las nuevas m\u00e1quinas que creemos se conectar\u00e1n a esta red.</p>"},{"location":"01.-KVM/02.-Instalaci%C3%B3n/04.-Conexi%C3%B3n%20local%20privilegiada%20a%20libvirt/#almacenamiento-disponible","title":"Almacenamiento disponible","text":"<p>Estudiaremos en profundidad el almacenamiento con el que podemos trabajar en el m\u00f3dulo correspondiente. En este momento, indicar que los ficheros correspondientes a las im\u00e1genes de discos de las nuevas m\u00e1quinas virtuales que creemos se guardar\u00e1n, por defecto, en el directorio <code>/var/lib/libvirt/images</code>.</p>"},{"location":"01.-KVM/02.-Instalaci%C3%B3n/05.-Conexi%C3%B3n%20remota%20a%20libvirt/","title":"05.-Conexi\u00f3n remota a libvirt","text":"<p>Podemos conectar al hypervisor libvirt que se est\u00e1 ejecutando en un servidor desde otra m\u00e1quina remota. Es decir, desde una m\u00e1quina cliente podemos usar, por ejemplo, <code>virsh</code> para conectarnos a un hypervisor libvirt remoto. Para ello, la sintaxis es la siguiente:</p> <pre><code>usuario@cliente:~$ virsh -c qemu+ssh://usuario_remoto@ip_servidor_remoto/system comando\n</code></pre> <p>Es decir, se va a producir una conexi\u00f3n ssh entre la m\u00e1quina cliente y el servidor donde se ejecuta libvirt. Por lo tanto hay que configurar las m\u00e1quinas para que el usuario <code>usuario</code> de la m\u00e1quina <code>cliente</code> pueda acceder por SSH al servidor remoto con el usuario <code>usuario_remoto</code>, sin que se se le pida la contrase\u00f1a.</p> <p>Para ello tendremos que copiar la clave p\u00fablica SSH del usuario <code>cliente</code> al fichero <code>~/.ssh/authorized_keys</code> del usuario <code>usuario_remoto</code> en el servidor que queremos acceder.</p>"},{"location":"01.-KVM/03.-Creaci%C3%B3n%20de%20MV%20desde%20el%20CLI/01.-Creaci%C3%B3n%20de%20MV%20con%20virt-install/","title":"Creaci\u00f3n de m\u00e1quinas virtuales con virt-install","text":"<p>Vamos a crear nuestra primera m\u00e1quina virtual desde la l\u00ednea de comandos con la aplicaci\u00f3n <code>virt-install</code>.</p> <p>Lo primero que tenemos que hacer es instalar el paquete <code>virtinst</code>, que adem\u00e1s de este programa, tiene otras utilidades que iremos usando a los largo del curso.</p> <pre><code>apt install virtinst\n</code></pre> <p>La informaci\u00f3n que tenemos que proporcionar a <code>virt-install</code> para la creaci\u00f3n de la nueva m\u00e1quina virtual ser\u00e1 la siguiente:</p> <ul> <li>El nombre de la m\u00e1quina virtual (par\u00e1metro <code>--name</code>).</li> <li>El tipo de virtualizaci\u00f3n (par\u00e1metro <code>--virt-type</code>). en nuestro caso ser\u00e1 <code>kvm</code>.</li> <li>En nuestro caso vamos a realizar una instalaci\u00f3n desde un fichero ISO, por lo que tendremos que indicar que la nueva m\u00e1quina tendr\u00e1 un CDROM con la ISO que indiquemos (par\u00e1metro <code>--cdrom</code>).</li> <li>La variante del sistema operativo que vamos a utilizar (par\u00e1metro <code>--os-variant</code>). Para obtener la lista de variantes de sistemas operativos, podemos ejecutar <code>osinfo-query os</code> (Instalar el paquete <code>libosinfo-bin</code> si no reconoce el comando). </li> <li>El tama\u00f1o del disco (par\u00e1metro <code>--disk size</code>). Se crear\u00e1 un fichero con la imagen del disco que se guardar\u00e1 en <code>/var/lib/libvirt/images</code>.</li> <li>La cantidad de memoria RAM (par\u00e1metro <code>--memory</code>).</li> <li>La cantidad de vCPU asignadas a la m\u00e1quina (par\u00e1metro <code>--vcpus</code>).</li> </ul> <p>Podemos indicar muchos m\u00e1s par\u00e1metros a la hora de crear la nueva m\u00e1quina. Puedes obtener toda la informaci\u00f3n en la documentaci\u00f3n oficial de la aplicaci\u00f3n. Iremos usando, a lo largo del curso, diferentes par\u00e1metros de esta herramienta.</p>"},{"location":"01.-KVM/03.-Creaci%C3%B3n%20de%20MV%20desde%20el%20CLI/01.-Creaci%C3%B3n%20de%20MV%20con%20virt-install/#creacion-de-nuestra-primera-maquina-virtual","title":"Creaci\u00f3n de nuestra primera m\u00e1quina virtual.","text":"<p>Vamos a crear una m\u00e1quina con las siguientes caracter\u00edsticas: se va a llamar <code>prueba1</code>, se va a usar una ISO de la distribuci\u00f3n GNU/Linux Debian 11, la variante de sistema operativo podemos poner <code>debian10</code>, el tama\u00f1o del disco ser\u00e1 de 10 GB, la memoria RAM ser\u00e1 de 1 GB y le vamos a asignar 1 vCPU. No vamos a indicar la red a la que se conecta ya que, por defecto, se conectar\u00e1 a la red predefinida <code>default</code>.</p> <p>Tenemos que tener en cuenta dos cosas:</p> <ol> <li>La red <code>default</code> debe estar activa: <code>virsh -c qemu:///system net-start default</code>.</li> <li>Hemos bajado una imagen ISO para la instalaci\u00f3n del sistema operativo y la tenemos guardad en el directorio <code>~/iso</code>.</li> </ol> <p>Para crear la nueva m\u00e1quina con esas caracter\u00edsticas, ejecutamos con usuario sin privilegios:</p> <pre><code>virt-install --connect qemu:///system \\\n             --virt-type kvm \\\n             --name prueba1 \\\n             --cdrom ~/iso/debian-11.3.0-amd64-netinst.iso \\\n             --os-variant debian10 \\\n             --disk size=10 \\\n             --memory 1024 \\\n             --vcpus 1\n</code></pre> <p>A continuaci\u00f3n, se iniciar\u00e1 la m\u00e1quina y se abrir\u00e1 una terminal en la aplicaci\u00f3n <code>virt-viewer</code> para que realicemos la instalaci\u00f3n:</p> <p></p> <p>\u00cdndice</p>"},{"location":"01.-KVM/03.-Creaci%C3%B3n%20de%20MV%20desde%20el%20CLI/02.-Caracter%C3%ADsticas%20de%20la%20MV/","title":"Caracter\u00edsticas de las m\u00e1quinas virtuales","text":"<p>Despu\u00e9s de instalar nuestra primera m\u00e1quina, podemos comprobar la lista de m\u00e1quinas ejecutando la siguiente instrucci\u00f3n:</p> <pre><code>virsh -c qemu:///system list\n Id   Nombre    Estado\n----------------------------\n 2    prueba1   ejecutando\n</code></pre> <p>Si queremos acceder a la terminal de una m\u00e1quina podemos usar <code>virt-view</code> de la siguiente forma:</p> <pre><code>virt-viewer -c qemu:///system prueba1\n</code></pre>"},{"location":"01.-KVM/03.-Creaci%C3%B3n%20de%20MV%20desde%20el%20CLI/02.-Caracter%C3%ADsticas%20de%20la%20MV/#red","title":"Red","text":"<p>Como coment\u00e1bamos en el punto anterior, la m\u00e1quina que hemos creado se conecta, por defcto, a la red <code>default</code>. Esta red es de tipo NAT, y comprobamos que la m\u00e1quina ha recibido una IP de forma din\u00e1mica y que su puerta de enlace corresponde a la direcci\u00f3n IP <code>192.168.122.1</code>, que corresponde con el host, el servidor DNS corresponde a la misma IP y comprobamos que tiene resoluci\u00f3n y acceso a internet:</p> <p></p>"},{"location":"01.-KVM/03.-Creaci%C3%B3n%20de%20MV%20desde%20el%20CLI/02.-Caracter%C3%ADsticas%20de%20la%20MV/#recursos-hardware","title":"Recursos hardware","text":"<p>Podemos comprobar que la maq\u00faina tiene un disco de 10 Gb y de memoria RAM 1Gb:</p> <p></p>"},{"location":"01.-KVM/03.-Creaci%C3%B3n%20de%20MV%20desde%20el%20CLI/02.-Caracter%C3%ADsticas%20de%20la%20MV/#almacenamiento","title":"Almacenamiento","text":"<p>Un Pool de almacenamiento es un recurso de almacenamiento. Lo m\u00e1s usual es tener pools de almacenamiento que sean locales, por ejemplo un directorio. En el momento de crear la primera m\u00e1quina se han creado dos pools de almacenamiento de tipo dir y que corresponden a los dos directorios con los que estamos trabajando:</p> <ul> <li><code>default</code>: Es un pool de almacenamiento que corresponde con el directorio <code>/usr/lib/libvirt/images</code> y donde se guardar\u00e1n los ficheros correspondientes a las im\u00e1genes de disco.</li> <li><code>iso</code>: Este pool de almacenamiento se ha creado al indicar en <code>virt-install</code>el directorio donde estaba almacenado el fichero ISO. En este caso es otro pool de almacenamiento de tipo dir, y corresponde al directorio <code>~/ISO</code>.</li> </ul> <p>Podemos ver los pools de almacenamiento, que tenemos creado, ejecutando:</p> <pre><code>virsh -c qemu:///system pool-list \n Nombre    Estado   Inicio autom\u00e1tico\n---------------------------------------\n default   activo   si\n iso       activo   si\n</code></pre> <p>Un volumen es un medio de almacenamiento que podemos crear en un pool de almacenamiento en kvm. Si el pool de almacenamiento es de tipo dir, entonces el volumen ser\u00e1 un fichero de imagen.</p> <p>Veamos el volumen que se ha creado el pool <code>default</code>:</p> <pre><code>virsh -c qemu:///system vol-list default\n Nombre          Ruta\n--------------------------------------------------------\n prueba1.qcow2   /var/lib/libvirt/images/prueba1.qcow2\n</code></pre> <p>Vemos que la imagen del disco de la m\u00e1quina virtual est\u00e1 guardada en un fichero QCOW2. Tambi\u00e9n podemos ver el volumen que est\u00e1 creado en el pool <code>iso</code>:</p> <pre><code>virsh -c qemu:///system vol-list iso\n Nombre                            Ruta\n--------------------------------------------------------------------------------------\n debian-11.3.0-amd64-netinst.iso   /home/usuario/iso/debian-11.3.0-amd64-netinst.iso\n</code></pre> <p>Que corresponde al fichero de la imagen ISO que hemos copiado en el directorio <code>~/ISO</code>.</p> <p>En todos estos conceptos sobre almacenamiento profundizaremos en el m\u00f3dulo correspondiente.</p> <p>\u00cdndice</p>"},{"location":"01.-KVM/03.-Creaci%C3%B3n%20de%20MV%20desde%20el%20CLI/03.-Gesti%C3%B3n%20de%20MV%20con%20virsh/","title":"Gesti\u00f3n de m\u00e1quinas virtuales con virsh","text":"<p>virsh es el cliente por l\u00ednea de comandos \"oficial\" de libvirt. Ofrece una shell completa para el manejo de la API.</p> <p>Cuando obtenga la ayuda de esta herramienta ver\u00e1s que en mucha ocasiones habla de dominio. Un dominio en QEMU/KVM es una m\u00e1quina virtual.</p> <p>Para obtener ayuda sobre todos los comandos que podemos ejecutar:</p> <pre><code>virsh --help\n</code></pre> <p>Si queremos pedir ayuda de un comando en concreto, por ejemplo el comando <code>list</code>, ejecutamos:</p> <pre><code>virsh list --help\n</code></pre> <p>Ya hemos usado el comando <code>list</code> para mostrar las m\u00e1quinas virtuales que tenemos creada:</p> <pre><code>virsh -c qemu:///system list --all\n Id   Nombre    Estado\n----------------------------\n 2    prueba1   ejecutando\n</code></pre> <p>Nota: Podemos referencia una m\u00e1quina virtual por su nombre o por su id.</p>"},{"location":"01.-KVM/03.-Creaci%C3%B3n%20de%20MV%20desde%20el%20CLI/03.-Gesti%C3%B3n%20de%20MV%20con%20virsh/#ciclo-de-vida-de-una-maquina-virtual","title":"Ciclo de vida de una m\u00e1quina virtual","text":"<p>Para apagar de forma adecuada una m\u00e1quina virtual:</p> <pre><code>virsh -c qemu:///system shutdown prueba1\nDomain 'prueba1' is being shutdown\n</code></pre> <p>Para iniciar una m\u00e1quina que est\u00e1 detenida:</p> <pre><code>virsh -c qemu:///system start prueba1\nDomain 'prueba1' started\n</code></pre> <p>Si la propiedad autostart de una maquina est\u00e1 activa, cada vez que se inicie el host, esa m\u00e1quina se encender\u00e1 de forma autom\u00e1tica. Para activarlo:</p> <pre><code>virsh -c qemu:///system autostart prueba1\nDomain 'prueba1' marked as autostarted\n</code></pre> <p>Reiniciamos una m\u00e1quina virtual, ejecutando:</p> <pre><code>virsh -c qemu:///system reboot prueba1\nDomain 'prueba1' is being rebooted\n</code></pre> <p>Podemos forzar el apagado de una m\u00e1quina:</p> <pre><code>virsh -c qemu:///system destroy prueba1\nDomain 'prueba1' destroyed\n</code></pre> <p>Podemos pausar la ejecuci\u00f3n de una m\u00e1quina</p> <pre><code>virsh -c qemu:///system suspend prueba1\nDomain 'prueba1' suspended\n</code></pre> <p>Y continuar la ejecuci\u00f3n:</p> <pre><code>virsh -c qemu:///system resume prueba1\nDomain 'prueba1' resumed\n</code></pre> <p>Por \u00faltimo, para eliminar una m\u00e1quina virtual que est\u00e9 parada (eliminando los vol\u00famenes asociados):</p> <pre><code>virsh -c qemu:///system undefine --remove-all-storage  prueba1\n</code></pre>"},{"location":"01.-KVM/03.-Creaci%C3%B3n%20de%20MV%20desde%20el%20CLI/03.-Gesti%C3%B3n%20de%20MV%20con%20virsh/#obtener-informacion-de-la-maquina-virtual","title":"Obtener informaci\u00f3n de la m\u00e1quina virtual","text":"<p>Todos los comandos de <code>virsh</code> que empiezan por dom nos permiten obtener informaci\u00f3n de la m\u00e1quina. </p> <p>Para obtener informaci\u00f3n de la m\u00e1quina:</p> <pre><code>virsh -c qemu:///system dominfo prueba1 \n</code></pre> <p>Obtener la direcci\u00f3n IP de la interfaz de red:</p> <pre><code>virsh -c qemu:///system domifaddr prueba1\n</code></pre> <p>Obtener los discos que tiene la m\u00e1quina:</p> <pre><code>virsh -c qemu:///system domblklist prueba1\n</code></pre> <p>Puedes buscar informaci\u00f3n de m\u00e1s comandos para obtener distinta informaci\u00f3n de la m\u00e1quina virtual.</p> <p>\u00cdndice</p>"},{"location":"01.-KVM/03.-Creaci%C3%B3n%20de%20MV%20desde%20el%20CLI/04.-Definici%C3%B3n%20XML%20de%20una%20MV/","title":"Definici\u00f3n XML de una m\u00e1quina virtual","text":"<p>Las caracter\u00edsticas, opciones y dispositivos hardware de una m\u00e1quina virtual est\u00e1n estructuradas con el lenguajes de marcas XML. De la misma forma las caracter\u00edsticas de los distintos recursos con los que podemos trabajar (redes, pools de almacenamiento, vol\u00famenes) tambi\u00e9n est\u00e1n definidos con XML.</p>"},{"location":"01.-KVM/03.-Creaci%C3%B3n%20de%20MV%20desde%20el%20CLI/04.-Definici%C3%B3n%20XML%20de%20una%20MV/#esquema-xml-de-una-maquina-virtual","title":"Esquema XML de una m\u00e1quina virtual","text":"<p>Para obtener la definici\u00f3n XML de una m\u00e1quina virtual, ejecutamos la siguiente instrucci\u00f3n:</p> <pre><code>virsh -c qemu:///system  dumpxml prueba1\n</code></pre> <p>Veamos algunos elementos de la definici\u00f3n:</p> <ul> <li>El documento XML empieza con la etiqueta <code>&lt;domain&gt;</code> donde se indica el tipo de virtualizaci\u00f3n utilizada para gestionar la m\u00e1quina y su identificador si la m\u00e1quina est\u00e1 ejecut\u00e1ndose..</li> <li>El nombre de la m\u00e1quina se indica con la etiqueta <code>&lt;name&gt;</code>.</li> <li> <p>La etiqueta <code>&lt;currentMemory&gt;</code> nos indica la memoria asignada actualmente a la m\u00e1quina. Podemos modificar esta memoria asignada sin reiniciar la m\u00e1quina hasta el l\u00edmite indicado por la etiqueta <code>&lt;memory&gt;</code>. Por lo tanto, el valor asignado a <code>&lt;memory&gt;</code> no puede ser menor que el valor asociado a <code>&lt;currentMemory&gt;</code>.</p> <p>En este ejemplo, los dos valores son iguales porque al crear la m\u00e1quina con <code>virt-install</code> usamos el par\u00e1metro <code>--memory</code> y se asigna el valor indicado a los dos par\u00e1metros. M\u00e1s adelante estudiaremos como modificar estos par\u00e1metros.</p> </li> <li> <p>La vCPU asignadas la encontramos definida en la etiqueta <code>&lt;vcpu&gt;</code>.</p> </li> <li>Con la etiqueta <code>&lt;os&gt;</code> tenemos informaci\u00f3n de la arquitectura de la m\u00e1quina virtualizada, adem\u00e1s con las etiquetas <code>&lt;boot&gt;</code> indicamos el orden de arranque entre distintos dispositivos.</li> <li>La informaci\u00f3n de la CPU la encontramos en la etiqueta <code>&lt;cpu&gt;</code>.</li> </ul> <p>Veamos un ejemplo hasta aqu\u00ed:</p> <pre><code>domain type='kvm' id='6'&gt;\n  &lt;name&gt;prueba1&lt;/name&gt;\n  &lt;uuid&gt;a88eebdc-8a00-4b9d-bf48-cbed7bb448d3&lt;/uuid&gt;\n  ...\n  &lt;memory unit='KiB'&gt;1048576&lt;/memory&gt;\n  &lt;currentMemory unit='KiB'&gt;1048576&lt;/currentMemory&gt;\n  &lt;vcpu placement='static'&gt;1&lt;/vcpu&gt;\n  ...\n  &lt;os&gt;\n    &lt;type arch='x86_64' machine='pc-q35-5.2'&gt;hvm&lt;/type&gt;\n    &lt;boot dev='hd'/&gt;\n  &lt;/os&gt;\n  ...\n  &lt;cpu mode='custom' match='exact' check='full'&gt;\n    &lt;model fallback='forbid'&gt;Cooperlake&lt;/model&gt;\n    &lt;vendor&gt;Intel&lt;/vendor&gt;\n    ...\n</code></pre> <p>A continuaci\u00f3n nos encontramos la etiqueta <code>&lt;devices&gt;</code> donde se definen los distintos dispositivos hardware que forman parte de la m\u00e1quina. Veamos algunos ejemplos:</p> <ul> <li>Los discos se definen con la etiqueta <code>&lt;disk&gt;</code>. Encontramos informaci\u00f3n del tipo (en este caso fichero), tipo del fichero (en este caso qcow2), ruta donde se encuentra el fichero,... Es importante se\u00f1alar que, por defecto, se configura el disco con un controlador VirtIO (<code>bus='virtio</code>), es decir, es un dispositivo paravirtualizado que nos ofrece mayor rendimiento. Veamos la definici\u00f3n del disco:</li> </ul> <pre><code>    &lt;disk type='file' device='disk'&gt;\n      &lt;driver name='qemu' type='qcow2'/&gt;\n      &lt;source file='/var/lib/libvirt/images/prueba1.qcow2'/&gt;\n      &lt;target dev='vda' bus='virtio'/&gt;\n      &lt;address type='pci' domain='0x0000' bus='0x04' slot='0x00' function='0x0'/&gt;\n    &lt;/disk&gt;\n</code></pre> <ul> <li>Las interfaces de red se definen con la etiqueta <code>&lt;interface&gt;</code>. Encontramos informaci\u00f3n como la mac, la red a la que est\u00e1 conectada (en este caso la red <code>default</code>),... Tambi\u00e9n observamos que el modelo de la tarjeta es VirtIO (<code>&lt;model type='virtio'/&gt;</code>), de nuevo se configura un dispositivo paravirtualizado de alto rendimiento.</li> </ul> <pre><code>    &lt;interface type='network'&gt;\n      &lt;mac address='52:54:00:8a:50:d1'/&gt;\n      &lt;source network='default'/&gt;\n      &lt;model type='virtio'/&gt;\n      &lt;address type='pci' domain='0x0000' bus='0x01' slot='0x00' function='0x0'/&gt;\n    &lt;/interface&gt;\n</code></pre> <ul> <li>Si nos fijamos en otros dispositivos podremos encontrar la definici\u00f3n del teclado, del rat\u00f3n, el adaptador gr\u00e1fico, controladores PCI, CDROM, ...</li> </ul> <p>Iremos estudiando m\u00e1s elementos de la definici\u00f3n XML de una m\u00e1quina virtual, pero pode\u00eds profundizar en el formato en la documentaci\u00f3n oficial: Domain XML format.</p> <p>\u00cdndice</p>"},{"location":"01.-KVM/03.-Creaci%C3%B3n%20de%20MV%20desde%20el%20CLI/05.-Modificaci%C3%B3n%20de%20una%20MV/","title":"Modificaci\u00f3n de la definici\u00f3n de una m\u00e1quina virtual","text":"<p>Podemos cambiar la configuraci\u00f3n de una m\u00e1quina virtual modificando su definici\u00f3n XML. Podemos cambiar el nombre, la memoria utilizada, la asignaci\u00f3n de CPU, cambiar la configuraci\u00f3n de cualquier dispositivo, eliminar o a\u00f1adir nuevos dispositivos,...</p> <p>Para realizar la modificaci\u00f3n del fichero XML tenemos dos alternativas:</p> <ol> <li>Realizar los cambios directamente en el documento XML utilizando el comando <code>virsh edit</code>.</li> <li>Utilizando comandos espec\u00edficos de <code>virsh</code> que nos ayudan a realizar el cambio de los distintos par\u00e1metros de la configuraci\u00f3n.</li> </ol> <p>Hay cambios que se pueden realizar con la m\u00e1quina funcionando, otros necesitan que la m\u00e1quina est\u00e9 parada y otros necesitan un reinicio de la m\u00e1quina para que se realicen.</p> <p>Veamos algunos ejemplos:</p>"},{"location":"01.-KVM/03.-Creaci%C3%B3n%20de%20MV%20desde%20el%20CLI/05.-Modificaci%C3%B3n%20de%20una%20MV/#modificar-el-nombre-de-una-maquina-virtual","title":"Modificar el nombre de una m\u00e1quina virtual","text":"<p>En este caso la modificaci\u00f3n la vamos a realizar con el comando <code>virsh domrename</code>, que modificar\u00e1 internamente la definici\u00f3n XML:</p> <pre><code>virsh -c qemu:///system domrename prueba2 prueba1\nDomain 'prueba2' XML configuration edited.\n</code></pre> <p>Este cambio requiere que la m\u00e1quina est\u00e9 parada.</p>"},{"location":"01.-KVM/03.-Creaci%C3%B3n%20de%20MV%20desde%20el%20CLI/05.-Modificaci%C3%B3n%20de%20una%20MV/#modificar-la-asignacion-de-vcpu","title":"Modificar la asignaci\u00f3n de vCPU","text":"<p>Suponemos que la m\u00e1quina est\u00e1 parada. Comprobamos el n\u00famero de vCPU asignadas a la m\u00e1quina:</p> <pre><code>virsh -c qemu:///system dominfo prueba1\n...\nCPU(s):         1\n...\n</code></pre> <p>Podemos editar la configuraci\u00f3n XML y cambiar el valor de la etiqueta <code>&lt;vcpu&gt;</code>:</p> <pre><code>virsh -c qemu:///system edit prueba1\n...\n  &lt;vcpu placement='static'&gt;2&lt;/vcpu&gt;\n...\n</code></pre> <p>Y volvemos a comprobar la informaci\u00f3n de la m\u00e1quina:</p> <pre><code>virsh -c qemu:///system dominfo prueba1\n...\nCPU(s):         2\n...\n</code></pre> <p>Tambi\u00e9n podr\u00edamos cambiar la asignaci\u00f3n de vCPU \"en caliente\" con el camando <code>virsh setvcpus</code>, pero no lo vamos a estudiar en este curso. Puedes ver este \u00e1rticulo para m\u00e1s informaci\u00f3n.</p>"},{"location":"01.-KVM/03.-Creaci%C3%B3n%20de%20MV%20desde%20el%20CLI/05.-Modificaci%C3%B3n%20de%20una%20MV/#modificar-la-asignacion-de-memoria-ram","title":"Modificar la asignaci\u00f3n de memoria RAM","text":"<p>Volvemos a suponer que la m\u00e1quina est\u00e1 parada. Podemos editar la configuraci\u00f3n XML y modificar las dos etiquetas relacionadas con la memoria:</p> <ul> <li><code>&lt;memory&gt;</code>: Valor m\u00e1ximo de RAM que podemos asignar a la m\u00e1quina \"en caliente\" (funcionando).</li> <li><code>&lt;currentMemory&gt;</code>: Cantidad de memoria asignada a la m\u00e1quina.</li> </ul> <p>Por ejemplo, dejamos la asignaci\u00f3n de memoria en un 1 Gb, y cambiamos la memoria m\u00e1xima a 3 Gb:</p> <pre><code>virsh -c qemu:///system edit prueba1\n...\n  &lt;memory unit='KiB'&gt;3145728&lt;/memory&gt;\n  &lt;currentMemory unit='KiB'&gt;1048576&lt;/currentMemory&gt;\n...\n</code></pre> <p>Podemos comprobar el cambio:</p> <pre><code>virsh -c qemu:///system dominfo prueba1\n...\nMemoria m\u00e1xima: 3145728 KiB\nMemoria utilizada: 1048576 KiB\n...\n</code></pre> <p>Ahora iniciamos la m\u00e1quina y podemos cambiar \"en caliente\" la memoria de la m\u00e1quina hasta un m\u00e1ximo de 3 Gb, para ello vamos a usar el comando <code>virsh setmem</code>.</p> <pre><code>virsh -c qemu:///system start prueba1\n\nvirsh -c qemu:///system setmem prueba1 2048M\n</code></pre> <p>https://www.unixarena.com/2015/12/linux-kvm-how-to-add-remove-memory-to-guest-on-fly.html/</p>"},{"location":"01.-KVM/04.-Creaci%C3%B3n%20de%20MV%20con%20virt-manager/01.-Primeros%20pasos%20con%20virt-manager/","title":"Primeros pasos con virt-manager","text":"<p>virt-manager es una aplicaci\u00f3n gr\u00e1fica de escritorio para gestionar m\u00e1quinas virtuales a trav\u00e9s de libvirt. Presenta una vista resumida de las m\u00e1quinas virtuales en ejecuci\u00f3n, su rendimiento en vivo y las estad\u00edsticas de utilizaci\u00f3n de recursos. Los usuarios pueden crear nuevas m\u00e1quinas virtuales y configurarlas y gestionar sus dispositivos de hardware. Adem\u00e1s, poseer un cliente VNC / SPICE que permite el acceso de forma sencilla a la consola de la m\u00e1quina.</p>"},{"location":"01.-KVM/04.-Creaci%C3%B3n%20de%20MV%20con%20virt-manager/01.-Primeros%20pasos%20con%20virt-manager/#instalacion-de-virt-manager","title":"Instalaci\u00f3n de virt-manager","text":"<p>En sistemas operativos basados en Debian / Ubuntu, simplemente ejecutamos:</p> <pre><code>apt install virt-manager\n</code></pre>"},{"location":"01.-KVM/04.-Creaci%C3%B3n%20de%20MV%20con%20virt-manager/01.-Primeros%20pasos%20con%20virt-manager/#vista-general-de-virt-manager","title":"Vista general de virt-manager","text":"<p>Pode defecto, podemos ver que virt-manager tiene configurado una conexi\u00f3n local privilegiada que se llama QEMU/KVM. Vemos las m\u00e1quinas virtuales que est\u00e1n creada en esa conexi\u00f3n (en este caso <code>prueba1</code>, que creamos en el m\u00f3dulo anterior).</p> <p>Con la opci\u00f3n Archivo-&gt;Nueva conexi\u00f3n... podemos dar de alta una nueva conexi\u00f3n.</p>"},{"location":"01.-KVM/04.-Creaci%C3%B3n%20de%20MV%20con%20virt-manager/01.-Primeros%20pasos%20con%20virt-manager/#conexion-qemukvm","title":"Conexi\u00f3n QEMU/KVM","text":"<p>Si pulsamos con el bot\u00f3n derecho del rat\u00f3n sobre la conexi\u00f3n QEMU/KVM, adem\u00e1s de distintas opciones, como Nueva, Desconectar,..., encontramos la opci\u00f3n Detalles (esta opci\u00f3n tambi\u00e9n se puede elegir en el men\u00fa Editar -&gt; Detalle de la conexi\u00f3n):</p> <p></p> <p>Al elegir el detalle de la conexi\u00f3n, podemos comprobar que es una conexi\u00f3n local privilegiada. Nos conectamos a la URI <code>qemu:///system</code>. Adem\u00e1s est\u00e1 configurada para que se conecte de forma autom\u00e1tica cada vez que iniciamos la aplicaci\u00f3n:</p> <p></p>"},{"location":"01.-KVM/04.-Creaci%C3%B3n%20de%20MV%20con%20virt-manager/01.-Primeros%20pasos%20con%20virt-manager/#redes-disponibles","title":"Redes disponibles","text":"<p>Tambi\u00e9n podemos gestionar las redes de esta conexi\u00f3n. Podemos ver las redes creadas, crear nuevas redes, eliminarlas, modificarlas, ... Vemos que tenemos creada la red <code>default</code> y ver sus caracter\u00edsticas (tipo NAT, configuraci\u00f3n ofrecida por un servidor  DHCP, Linux Bridge que gestiona,...). Por defecto est\u00e1 inactiva, para activarla, la seleccionamos y pulsamos sobre el bot\u00f3n \u25b6.</p> <p></p>"},{"location":"01.-KVM/04.-Creaci%C3%B3n%20de%20MV%20con%20virt-manager/01.-Primeros%20pasos%20con%20virt-manager/#pools-de-almacenamiento-disponibles","title":"Pools de almacenamiento disponibles","text":"<p>Otro elemento que podemos gestionar son los Pool de almacenamiento que tenemos en la conexi\u00f3n. Recordamos que ten\u00edamos dos creados: el pool <code>default</code>, donde se guardaban las im\u00e1genes de discos, y el pool <code>iso</code>, donde almacenamos los ficheros ISO para las instalaciones de los sistemas operativos. Adem\u00e1s, podemos ver los vol\u00famenes (en este caso, los ficheros) que hay creados en cada pool.</p> <p></p>"},{"location":"01.-KVM/04.-Creaci%C3%B3n%20de%20MV%20con%20virt-manager/01.-Primeros%20pasos%20con%20virt-manager/#conexion-remota-con-virt-manager","title":"Conexi\u00f3n remota con virt-manager","text":"<p>Si quisi\u00e9ramos conectarnos de forma remota a un servidor donde se est\u00e1 ejecutando libvirt, podr\u00edamos crear una nueva conexi\u00f3n: Archivo -&gt; A\u00f1adir conexi\u00f3n..., y crear una conexi\u00f3n y elegir la opci\u00f3n Conectar a anfitri\u00f3n mediante SSH:</p> <p></p>"},{"location":"01.-KVM/04.-Creaci%C3%B3n%20de%20MV%20con%20virt-manager/01.-Primeros%20pasos%20con%20virt-manager/#conclusion","title":"Conclusi\u00f3n","text":"<p><code>virt-manager</code> es otra aplicaci\u00f3n que nos permite hacer conexiones a libvirt, como hacemos con la aplicaci\u00f3n <code>virsh</code> o <code>virt-install</code>. Por lo tanto, los recursos virtualizados que gestionamos con estas aplicaciones cuando nos conectamos a <code>qemu:///system</code> son los mismos. Los cambios que hagamos con una aplicaci\u00f3n se ven reflejados en cualquiera de las otras. <code>virt-manager</code> es m\u00e1s f\u00e1cil de usar, pero nos ofrece menos opciones que la aplicaci\u00f3n <code>virsh</code> o <code>virt-install</code>.</p>"},{"location":"01.-KVM/04.-Creaci%C3%B3n%20de%20MV%20con%20virt-manager/02.-Creaci%C3%B3n%20de%20MV%20linux/","title":"Creaci\u00f3n de m\u00e1quinas virtuales Linux","text":"<p>Vamos a estudiar los pasos fundamentales para la creaci\u00f3n de una m\u00e1quina virtual. en este caso vamos a crear una m\u00e1quina virtual con el sistema operativo GNU/Linux Ubuntu. Observaremos que la informaci\u00f3n que vamos indicando en virt-manager es la misma que utilizamos para la creaci\u00f3n d m\u00e1quinas con la herramienta <code>virt-install</code>.</p> <p>Antes de empezar la creaci\u00f3n de la nueva m\u00e1quina, hemos copiado en el pool de almacenamiento ISO (directorio <code>~/iso</code>) una imagen ISO para la instalaci\u00f3n de Ubuntu:</p> <p></p> <p>Para crear una nueva m\u00e1quina virtual con virt-manager podemos escoger la opci\u00f3n de men\u00fa Archivo -&gt; Nueva m\u00e1quina virtual, o el bot\u00f3n del men\u00fa:</p> <p></p> <p>A continuaci\u00f3n seguimos los pasos del asistente para la creaci\u00f3n de la m\u00e1quina virtual:</p>"},{"location":"01.-KVM/04.-Creaci%C3%B3n%20de%20MV%20con%20virt-manager/02.-Creaci%C3%B3n%20de%20MV%20linux/#elegir-la-fuente-de-instalacion-del-sistema-operativo","title":"Elegir la fuente de instalaci\u00f3n del sistema operativo","text":"<p>Elegimos como fuente de instalaci\u00f3n: instalaci\u00f3n local desde una imagen ISO que se montar\u00e1 en un CDRON. En este apartado tambi\u00e9n podemos escoger la arquitectura de la m\u00e1quina que vamos a utilizar.</p> <p></p>"},{"location":"01.-KVM/04.-Creaci%C3%B3n%20de%20MV%20con%20virt-manager/02.-Creaci%C3%B3n%20de%20MV%20linux/#seleccionar-la-iso-de-instalacion","title":"Seleccionar la ISO de instalaci\u00f3n","text":"<p>Elegimos fichero ISO desde donde vamos a realizar la instalaci\u00f3n. Si no se detecta la variante del sistema operativo, tenemos que a\u00f1adirla manualmente escogiendo la versi\u00f3n m\u00e1s parecida a la que vamos a instalar.</p> <p></p>"},{"location":"01.-KVM/04.-Creaci%C3%B3n%20de%20MV%20con%20virt-manager/02.-Creaci%C3%B3n%20de%20MV%20linux/#configuracion-de-memoria-y-de-vcpu","title":"Configuraci\u00f3n de memoria y de VCPU","text":"<p>A continuaci\u00f3n, asignamos la memoria y el n\u00famero de vCPU a la nueva m\u00e1quina que estamos creando.</p> <p></p>"},{"location":"01.-KVM/04.-Creaci%C3%B3n%20de%20MV%20con%20virt-manager/02.-Creaci%C3%B3n%20de%20MV%20linux/#seleccionar-almacenamiento","title":"Seleccionar almacenamiento","text":"<p>En este paso, habilitamos el almacenamiento para la nueva m\u00e1quina, indicando el tama\u00f1o del disco.</p> <p></p>"},{"location":"01.-KVM/04.-Creaci%C3%B3n%20de%20MV%20con%20virt-manager/02.-Creaci%C3%B3n%20de%20MV%20linux/#resumen-y-seleccion-de-red","title":"Resumen y selecci\u00f3n de red","text":"<p>Por \u00faltimo, aparece un resumen de las caracter\u00edsticas de la m\u00e1quina que vamos a crear. Adem\u00e1s, podemos indicar el nombre y seleccionar la red a la que queremos que se conecte (en nuestro caso, la red de tipo NAT <code>default</code>). Si la red no est\u00e1 activa, nos dar\u00e1 la opci\u00f3n de activarla.</p> <p></p>"},{"location":"01.-KVM/04.-Creaci%C3%B3n%20de%20MV%20con%20virt-manager/02.-Creaci%C3%B3n%20de%20MV%20linux/#comenzamos-la-instalacion","title":"Comenzamos la instalaci\u00f3n","text":"<p>Al pulsar el bot\u00f3n Finalizar, se crea la m\u00e1quina, se inicializa y se abre la consola para que podamos empezar la instalaci\u00f3n.</p> <p></p>"},{"location":"01.-KVM/04.-Creaci%C3%B3n%20de%20MV%20con%20virt-manager/03.-Gesti%C3%B3n%20de%20MV/","title":"Gesti\u00f3n de m\u00e1quinas virtuales","text":"<p>Para elegir las distintas opciones que tenemos para gestionar nuestras m\u00e1quinas, pulsamos sobre el bot\u00f3n derecho en la m\u00e1quina:</p> <p></p> <ul> <li>Ejecutar: Si la m\u00e1quina est\u00e1 parada, la inicia. Tambi\u00e9n podemos usar el bot\u00f3n 1 del men\u00fa.</li> <li>Pausa: Pausa la ejecuci\u00f3n de la m\u00e1quina virtual. Podremos reanudar la ejecuci\u00f3n con la opci\u00f3n Reanudar. Tambi\u00e9n podemos usar el bot\u00f3n 2 del men\u00fa.</li> <li>Apagar: En este men\u00fa tenemos varias opciones (todas estas opciones tambi\u00e9n se pueden elegir en el bot\u00f3n 4 del men\u00fa):<ul> <li>Reiniciar: Reinicia la m\u00e1quina.</li> <li>Apagar: Apaga la m\u00e1quina. Tambi\u00e9n podemos usar el bot\u00f3n 3 del men\u00fa.</li> <li>Forzar Reajuste: Apaga la m\u00e1quina simulando que se pulsa el bot\u00f3n reset.</li> <li>Forzar apagado: Fuerza el apagado de la m\u00e1quina.</li> <li>Guardar: Guarda el estado de la m\u00e1quina en memoria. Para recuperar la m\u00e1quina escogemos la opci\u00f3n Reanudar.</li> </ul> </li> <li>Clonar: Crea una nueva m\u00e1quina a partir de esta.</li> <li>Migrar: Nos permite trasladar la m\u00e1quina a otra m\u00e1quina que este ejecutando QEMU/KVM.</li> <li>Eliminar: Elimina la definici\u00f3n de la m\u00e1quina. Nos da la opci\u00f3n de eliminar el volumen de disco asociado.</li> <li>Abrir: Abre el \"Detalle de la m\u00e1quina\". esta opci\u00f3n tambi\u00e9n se puede escoger desde el bot\u00f3n Abrir, o desde la opci\u00f3n del men\u00fa Editar -&gt; Detalles de la m\u00e1quina virtual. Esta opci\u00f3n la estudiaremos en el siguiente punto.</li> </ul>"},{"location":"01.-KVM/04.-Creaci%C3%B3n%20de%20MV%20con%20virt-manager/04.-Detalles%20de%20las%20MV/","title":"Detalles de las m\u00e1quinas virtuales","text":"<p>Podemos acceder al detalle de una m\u00e1quina virtual de tres formas distintas: haciendo doble click sobre la m\u00e1quina, escogiendo la m\u00e1quina y pulsando el bot\u00f3n Abrir o escogiendo la opci\u00f3n del men\u00fa Editar -&gt; Detalles de la m\u00e1quina virtual.</p> <p>Vamos a abrir una ventana con las siguientes opciones:</p> <p></p> <ul> <li>Archivo: Opciones generales: ver el gestor, cerrar la ventana,...</li> <li>M\u00e1quina Virtual: Opciones para gestionar la m\u00e1quina.</li> <li>Vista: Nos permite ver las distintas vistas, controlar la ventana de la consola (pantalla completa, escalar, ...). Veamos las vistas:<ul> <li>Consola: Accedemos a una consola donde controlamos la m\u00e1quina virtual. Tambi\u00e9n se accede con el bot\u00f3n 1.</li> <li>Detalles: Obtenemos la configuraci\u00f3n de la m\u00e1quina virtual y los dispositivos hardware. Podemos quitar y a\u00f1adir nuevos dispositivos y hacer las modificaciones necesarias.Tambi\u00e9n se accede con el bot\u00f3n 2.</li> <li>Instant\u00e1neas: Ventana para gestionar las instant\u00e1neas de la m\u00e1quina virtual. Estudiaremos m\u00e1s adelante las instant\u00e1neas. Tambi\u00e9n se accede con el bot\u00f3n 3.</li> </ul> </li> <li>Enviar Tecla: Combinaci\u00f3n de teclas que podemos enviar a la m\u00e1quina virtual.</li> </ul>"},{"location":"01.-KVM/04.-Creaci%C3%B3n%20de%20MV%20con%20virt-manager/04.-Detalles%20de%20las%20MV/#vista-consola","title":"Vista Consola","text":"<p>Accedemos a una consola desde donde podemos controlar la m\u00e1quina virtual. Desde el men\u00fa vista podemos configurar el tama\u00f1o de la pantalla (pantalla completa, escalar monitor, ...). Puede ser una buena herramienta para realizar peque\u00f1as modificaciones a la m\u00e1quina, pero es recomendable utilizar distintos protocolos para el acceso y gesti\u00f3n de la m\u00e1quina virtual (SSH, VCN, RDP,...)</p>"},{"location":"01.-KVM/04.-Creaci%C3%B3n%20de%20MV%20con%20virt-manager/04.-Detalles%20de%20las%20MV/#vista-detalles","title":"Vista Detalles","text":"<p>En esta vista se nos muestra la definici\u00f3n XML de la m\u00e1quina virtual de forma gr\u00e1fica. Adem\u00e1s, nos posibilita hacer cambios en la configuraci\u00f3n de la misma. Vemos la configuraci\u00f3n general de la m\u00e1quina y las caracter\u00edsticas de los dispositivos hardware que tiene configurada. Podemos quitas dispositivos y a\u00f1adir otros nuevos.</p> <p>Veamos los elementos fundamentales:</p> <ul> <li>Repaso: Nos da la informaci\u00f3n general de la m\u00e1quina virtual. </li> </ul> <p></p> <p>Adem\u00e1s, en todo momento podemos acceder a la definici\u00f3n XML:</p> <p></p> <ul> <li>CPUs: Configuraci\u00f3n de las vCPU asignadas a la m\u00e1quina. Podemos modificar este valor. Si la m\u00e1quina est\u00e1 ejecut\u00e1ndose la modificaci\u00f3n ser\u00e1 efectiva en el siguiente arranque de la m\u00e1quina.</li> </ul> <p></p> <ul> <li>Memoria: Del mismo modo, vemos la configuraci\u00f3n de asignaci\u00f3n de memoria RAM de la m\u00e1quina. Podemos modificar la memoria actual y la memoria m\u00e1xima. Del mismo modo, necesitamos reiniciar la m\u00e1quina para que tenga efecto el cambio.</li> </ul> <p></p> <ul> <li>Opciones de arranque: Podemos ver y configurar el orden de los dispositivos de arranque.</li> </ul> <p>Imagen de opciones de arranque</p> <p>A continuaci\u00f3n se nos muestra los distintos dispositivos hardware que tiene configurado la m\u00e1quina: unidades de disco, interfaces de red, teclado, rat\u00f3n, adaptador de v\u00eddeo, interfaces, ... Pudiendo hacer tambi\u00e9n, modificaciones en los mismos. Veamos algunos de ellos:</p> <ul> <li>Discos: Nos da informaci\u00f3n del disco que tiene configurada la m\u00e1quina. Es importante, como ya hemos indicado anteriormente, que el el driver sea VirtIO para obtener mayor rendimiento. Vemos que podemos a\u00f1adir a las m\u00e1quinas virtuales tantos discos como sean necesarios.</li> </ul> <p></p> <ul> <li>Interfaces de red: Obtenemos la informaci\u00f3n de las distintas interfaces de red de la m\u00e1quina. en este caso tambi\u00e9n usamos VirtIO como modelo de dispositivo. Vemos a que red est\u00e1 conectada. Si la m\u00e1quina se est\u00e1 ejecutando, podemos ver la direcci\u00f3n IP de la interfaz. Del mismo modo, los cambios ser\u00e1n efectivos tras el reinicio de la m\u00e1quina.</li> </ul> <p></p> <p>Por \u00faltimo, tenemos dos operaciones referente a los dispositivos hardware:</p> <ul> <li>Si seleccionamos uno de ellos, y pulsamos el bot\u00f3n derecho del rat\u00f3n nos da la posibilidad de Eliminar Hardware.</li> <li>Con el bot\u00f3n Agregar Hardware, tenemos la posibilidad de a\u00f1adir nuevos componentes a la configuraci\u00f3n de la m\u00e1quina. Hay que indicar que algunos dispositivos se pueden agregar \"en caliente\", con la m\u00e1quina en estado de ejecuci\u00f3n. En los pr\u00f3ximos apartados del curso usaremos est\u00e1 opci\u00f3n para a\u00f1adir nuevos componentes a nuestras m\u00e1quinas virtuales.</li> </ul> <p></p>"},{"location":"01.-KVM/04.-Creaci%C3%B3n%20de%20MV%20con%20virt-manager/05.-Creaci%C3%B3n%20de%20MV%20Wndows/","title":"Creaci\u00f3n de m\u00e1quinas virtuales Windows","text":"<p>En un apartado anterior hemos visto los pasos fundamentales para la creaci\u00f3n de una m\u00e1quina virtual Linux. Para crear una m\u00e1quina virtual con un sistema operativo tipo Windows se siguen los mismos pasos, pero tenemos que tener en cuenta que Windows no tiene soporte nativo para dispositivos VirtIO. Por lo tanto, a la hora de crear una m\u00e1quina virtual Windows tendremos que a\u00f1adir los controladores de dispositivos (drivers) necesarios para que Windows identifique los dispositivos VirtIO que definamos en la m\u00e1quina virtual.</p> <p>En este caso, el proyecto Fedora proporciona controladores de dispositivos de software libre para VirtIO en Windows.</p>"},{"location":"01.-KVM/04.-Creaci%C3%B3n%20de%20MV%20con%20virt-manager/05.-Creaci%C3%B3n%20de%20MV%20Wndows/#iso-de-los-controladores-de-dispositivo-virtio-para-windows","title":"ISO de los controladores de dispositivo VirtIO para Windows","text":"<p>Podemos bajar la \u00faltima versi\u00f3n de los drivers VirtIO para Windows en el siguiente enlace y copiar la ISO al pool de almacenamiento ISO, es decir, en el directorio <code>~/iso</code>. Tambi\u00e9n hemos copiado a ese directorio una ISO para la instalaci\u00f3n de Windows 10.</p> <p></p> <p>Creamos la nueva m\u00e1quina virtual Windows</p> <p>Teniendo en cuenta los siguiente:</p> <ul> <li>Elegimos una imagen ISO para instalar una versi\u00f3n de Windows y seleccionamos la variante del sistema operativo que estamos instalando.</li> <li>Configuramos la CPU y la RAM para tener recursos suficientes.</li> <li>Como estamos instalando un sistema operativo Windows, virt-manager va a configurar los dispositivos para que sean compatibles con el sistema operativo. En concreto, el driver del disco y de la tarjeta de red no ser\u00e1n VirtIO, con lo que no conseguiremos el rendimiento adecuado. Por lo tanto, antes de realizar la instalaci\u00f3n vamos a cambiar el tipo de driver de estos dispositivos, escogiendo VirtIO para obtener el m\u00e1ximo de rendimiento. </li> </ul> <p>En la pantalla final del asistente de creaci\u00f3n de la m\u00e1quina virtual, escogeremos la opci\u00f3n Personalizar la configuraci\u00f3n antes de instalar:</p> <p></p>"},{"location":"01.-KVM/04.-Creaci%C3%B3n%20de%20MV%20con%20virt-manager/05.-Creaci%C3%B3n%20de%20MV%20Wndows/#elegimos-dispositivos-virtio","title":"Elegimos dispositivos VirtIO","text":"<p>El primer cambio ser\u00e1 elegir el driver VirtIO para el disco. Como observamos se ha configurado con el driver SATA, que ser\u00e1 compatible con Windows, pero al ser un dispositivo emulado, nos dar\u00e1 menos rendimiento. Escogemos la opci\u00f3n VirtIO, y pulsamos en el bot\u00f3n Aplicar:</p> <p></p> <p>A continuaci\u00f3n, cambiamos el driver de la tarjeta de red. Del mismo modo, observamos que ha escogido un modelo e1000e, compatible con Windows, pero del mismo modo nos ofrece menos rendimiento que la opci\u00f3n VirtIO. cuando hagamos el cambio, volvemos a pulsar sobre el bot\u00f3n Aplicar. Nota: Como hemos comentado Windows no es compatible con este modelo de tarjeta de red, por lo que durante la instalaci\u00f3n no tendremos conexi\u00f3n a internet. Si necesitamos tener conexi\u00f3n, podr\u00edamos dejar el modelo escogido por defecto, y posteriormente modificar la configuraci\u00f3n de la tarjeta.</p> <p></p>"},{"location":"01.-KVM/04.-Creaci%C3%B3n%20de%20MV%20con%20virt-manager/05.-Creaci%C3%B3n%20de%20MV%20Wndows/#anadimos-un-cdrom-con-los-drivers-virtio","title":"A\u00f1adimos un CDROM con los drivers VirtIO","text":"<p>Antes de iniciar la m\u00e1quina, le a\u00f1adimos un CD-ROM con la imagen ISO de los drivers VirtIO. Para ello, pulsamos el bot\u00f3n Agregar Hardware, y a\u00f1adimos un nuevo dispositivo de almacenamiento:</p> <p></p> <p>Adem\u00e1s, nos tenemos que asegurar que en el orden de arranque el CDROM donde hemos montado la ISO de Windows est\u00e9 por delante que el CDROM con los drivers VirtIO, y sea la primera opci\u00f3n. Una vez terminado pulsamos el bot\u00f3n Aplicar y el bot\u00f3n Iniciar la instalaci\u00f3n para comenzar la instalaci\u00f3n.</p> <p></p>"},{"location":"01.-KVM/04.-Creaci%C3%B3n%20de%20MV%20con%20virt-manager/05.-Creaci%C3%B3n%20de%20MV%20Wndows/#comenzamos-la-instalacion","title":"Comenzamos la instalaci\u00f3n","text":"<p>Iniciamos la m\u00e1quina, accedemos a la consola y comenzamos la instalaci\u00f3n, hasta que llegamos a la pantalla donde tenemos que escoger el disco duro donde vamos a realizar la instalaci\u00f3n.</p> <p></p> <p>Como vemos no se puede detectar el disco duro, ya que Windows no puede reconocer inicialmente el controlador VirtIO. Vamos a cargar los controladores de dispositivo VirtIO que necesitamos del CDROM que hemos montado:</p> <p>Elegimos la opci\u00f3n Cargar contr., le damos a Examinar y elegimos del CDROM donde tenemos los drivers VirtIO la carpeta de nuestra arquitectura (amd64) y la versi\u00f3n de Windows.</p> <p></p> <p>Y ya podemos continuar con la instalaci\u00f3n de Windows porque ya detecta el disco duro:</p> <p></p>"},{"location":"01.-KVM/04.-Creaci%C3%B3n%20de%20MV%20con%20virt-manager/05.-Creaci%C3%B3n%20de%20MV%20Wndows/#configuracion-de-la-red","title":"Configuraci\u00f3n de la red","text":"<p>Como indic\u00e1bamos anteriormente, tambi\u00e9n hemos escogido el controlador VirtIO para la tarjeta de red. Una vez realizada la configuraci\u00f3n tendremos que instalar los drivers adecuados para que funcione la tarjeta de red. Para ello, actualizamos el controlador del dispositivo Controladora Ethernet en el Administrador de dispositivos:</p> <p></p> <p>Y escogemos la carpeta del CDROM donde hemos montado los drivers VirtIO: <code>NetKVM\\&lt;carpeta con el nombre de tu versi\u00f3n de windows&gt;\\amd64</code>:</p> <p></p>"},{"location":"01.-KVM/04.-Creaci%C3%B3n%20de%20MV%20con%20virt-manager/05.-Creaci%C3%B3n%20de%20MV%20Wndows/#creacion-de-una-maquina-virtual-windos-con-virt-install","title":"Creaci\u00f3n de una m\u00e1quina virtual Windos con virt-install","text":"<p>Si queremos crear con <code>virt-install</code> una m\u00e1quina virtual para la instalaci\u00f3n de Windows con la misma configuraci\u00f3n que hemos visto anteriormente, podemos ejecutar la siguiente instrucci\u00f3n:</p> <pre><code>virt-install --connect qemu:///system \\\n             --virt-type kvm \\\n             --name prueba4 \\\n             --cdrom ~/iso/Win10_21H2_Spanish_x64.iso \\\n             --os-variant win10 \\\n             --disk size=40,bus=virtio \\\n             --disk ~/iso/virtio-win-0.1.217.iso,device=cdrom \\\n             --network=default,model=virtio \\\n             --memory 2048 \\\n             --vcpus 2\n</code></pre> <p>Tenemos que tener en cuanta algunas cosas nuevas que hemos introducido:</p> <ul> <li><code>--disk size=40,bus=virtio</code>: En la declaraci\u00f3n del disco indicamos el controlador VirtIO.</li> <li><code>--disk ~/iso/virtio-win-0.1.217.iso,device=cdrom</code>: El segundo CDROM se indica con el par\u00e1metro <code>disk</code> indicando <code>device=cdrom</code>.</li> <li><code>--network=default,model=virtio</code>: De la misma manera, indicamos el modelo de tarjeta de red como VirtIO.</li> </ul>"},{"location":"01.-KVM/05.-Almacenamiento/01.-Introducci%C3%B3n%20al%20almacenamiento/","title":"01.-Introducci\u00f3n al almacenamiento","text":"<p>El almacenamiento en disco es una parte esencial en los sistemas inform\u00e1ticos, ya que permite guardar de forma persistente grandes cantidades de informaci\u00f3n.</p> <p>Veamos distintas caracter\u00edsticas del almacenamiento en discos:</p>"},{"location":"01.-KVM/05.-Almacenamiento/01.-Introducci%C3%B3n%20al%20almacenamiento/#sistemas-de-ficheros-vs-dispositivos-de-bloques","title":"Sistemas de Ficheros vs. Dispositivos de Bloques","text":"<ul> <li>Dispositivos de Bloques: <ul> <li>Son unidades (f\u00edsicas o l\u00f3gicas) de almacenamiento que gestionan los datos en bloques de tama\u00f1o fijo. </li> <li>Estos dispositivos permiten el acceso directo a cualquier bloque sin necesidad de leer todos los anteriores, lo que facilita la lectura y escritura aleatoria de datos. </li> <li>Estos dispositivos se pueden particionar, formatear, montar,...</li> <li>Ejemplos: Discos, particiones, vol\u00famenes l\u00f3gicos, ficheros llamados im\u00e1genes de discos (osi, img, raw, qcow2,...),...</li> </ul> </li> <li>Sistemas de ficheros:<ul> <li>El formateo de un dispositivo de bloque nos permite estructurarlo de forma l\u00f3gica (ficheros y directorios). Ejemplos: ext4, xfs, ntfs, btrfs, zfs, ...</li> <li>Proporcionan una interfaz que permite a los usuarios y aplicaciones almacenar, organizar y acceder a los archivos y directorios de manera sencilla.</li> </ul> </li> </ul>"},{"location":"01.-KVM/05.-Almacenamiento/01.-Introducci%C3%B3n%20al%20almacenamiento/#fuente-del-almacenamiento","title":"Fuente del almacenamiento","text":"<ul> <li>Si el disco est\u00e1 conectado directamente en el ordenador se denomina DAS (Direct Attached Storage).</li> <li>En otras ocasiones el almacenamiento se encuentra en un servidor y se comparte a un cliente. En este caso se denomina almacenamiento compartido, y tenemos dos alternativas:<ul> <li> <ul> <li>NAS (Network Attached Storage): Se comparte por red el almacenamiento en forma de sistema de ficheros. Ejemplos: nfs, samba, glusterfs,...</li> </ul> </li> <li>SAN (Storage Area Network): En una red de almacenamiento se comparte dispositivos de bloques. Ejemplo: iSCSI, FiberChanel,...</li> </ul> </li> </ul> <p>Dependiendo de la tecnolog\u00eda usada para realizar el almacenamiento compartido tendremos varias caracter\u00edsticas:</p> <ul> <li>NFS es un sistema de almacenamiento compartido de tipo NAS, que permite a varios clientes leer y escribir en los ficheros de un mismo directorio. Se pueden tener problemas  de corrupci\u00f3n de datos si dos clientes tratan al mismo tiempo de cambiar un mismo fichero.</li> <li>iSCSI es un sistema de almacenamiento compartido de tipo SAN, que nos permite compartir un dispositivo de bloque entre varios clientes. Si es uno s\u00f3lo de los clientes el que escribe y los dem\u00e1s leen, no hay ning\u00fan problema. Pero si queremos que todos los clientes tengan la posibilidad de leer y escribir, podemos tener problemas de corrupci\u00f3n. En estos casos es necesario usar sistemas de archivos de cl\u00fasteres que a\u00f1aden mecanismos de bloqueo para que no se pueda cambiar al mismo tiempo un fichero. Por ejemplo: cfs2, ocfs2, glusterFS, Ceph, ...</li> </ul>"},{"location":"01.-KVM/05.-Almacenamiento/01.-Introducci%C3%B3n%20al%20almacenamiento/#snapshots-instantaneas","title":"Snapshots (Instant\u00e1neas)","text":"<p>Los snapshots son una caracter\u00edstica avanzada de los sistemas de almacenamiento que permiten capturar el estado completo de un sistema de ficheros en un momento dado. Los snapshots son muy \u00fatiles para:</p> <ul> <li>Recuperaci\u00f3n ante fallos: Si se produce un fallo en el sistema, se puede restaurar el sistema de ficheros al estado en que se encontraba en el momento en que se tom\u00f3 la instant\u00e1nea.</li> <li>Pruebas y desarrollo: Los snapshots permiten hacer pruebas sin riesgo de da\u00f1ar los datos originales, ya que se puede volver a un estado anterior de forma r\u00e1pida.</li> </ul>"},{"location":"01.-KVM/05.-Almacenamiento/01.-Introducci%C3%B3n%20al%20almacenamiento/#aprovisionamiento-ligero-thin-provisioning","title":"Aprovisionamiento Ligero (Thin Provisioning)","text":"<p>El aprovisionamiento ligero es una t\u00e9cnica utilizada en sistemas de almacenamiento para optimizar la utilizaci\u00f3n del espacio disponible. En lugar de asignar todo el espacio de almacenamiento a una unidad o volumen desde el principio (lo que se conoce como aprovisionamiento grueso o thick provisioning), el aprovisionamiento ligero asigna espacio seg\u00fan sea necesario.</p> <p>Por ejemplo, podemos tener un dispositivo de almacenamiento de 30 GB (virtuales), pero que solo ocupa en disco (almacenamiento real) los datos que va guardando. Ejemplos: Im\u00e1genes de disco qcow2, thin-LVM,...</p>"},{"location":"01.-KVM/05.-Almacenamiento/02.-Introducci%C3%B3n%20al%20almacenamiento%20en%20QEMU%E2%81%84KVM%20%2B%20libvirt/","title":"02.-Introducci\u00f3n al almacenamiento en QEMU\u2044KVM + libvirt","text":"<p>Libvirt proporciona la gesti\u00f3n del almacenamiento a trav\u00e9s de pools de almacenamiento y vol\u00famenes.</p> <ul> <li>Pools de Almacenamiento: Es una fuente de almacenamiento, una cantidad de almacenamiento que el administrador del host ha configurado para su uso por las m\u00e1quinas virtuales.</li> <li>Vol\u00famenes: Los pools de almacenamiento se dividen en vol\u00famenes. Cada uno de estos vol\u00famenes lo utilizaran las m\u00e1quinas virtuales como discos (dispositivos de bloques).</li> </ul>"},{"location":"01.-KVM/05.-Almacenamiento/02.-Introducci%C3%B3n%20al%20almacenamiento%20en%20QEMU%E2%81%84KVM%20%2B%20libvirt/#tipos-de-pools-de-almacenamiento","title":"Tipos de Pools de Almacenamiento","text":"<p>QEMU/KVM + libvirt puede trabajar con distintas fuentes y tecnolog\u00edas de almacenamiento que nos ofrecer\u00e1n distintas caracter\u00edsticas:</p> <ul> <li> <p>dir: Nos ofrece un directorio del host (por lo tanto, nos ofrece un sistema de archivo). Este tipo no nos ofrece la caracter\u00edstica de almacenamiento compartido. Los discos de las m\u00e1quinas virtuales se guardaran en ficheros de imagen de disco. Tenemos distintos formatos de ficheros de im\u00e1genes:</p> <ul> <li>raw: el formato raw es una imagen binaria sencilla de la imagen del disco. Se ocupa todo el espacio que hayamos indicado al crearla. El acceso es m\u00e1s eficiente. No soporta ni snapshots ni aprovisionamiento ligero.</li> <li>qcow2: formato QEMU copy-on-write. Al crearse s\u00f3lo se ocupa el espacio que se est\u00e1 ocupando con los datos (aprovisionamiento ligero), el fichero ir\u00e1 creciendo cuando escribamos en el \u00e9l. Acepta instant\u00e1neas o snapshots. Es menos eficiente en cuanto al acceso.</li> <li>vdi, vmdk,...: formatos de otros sistemas de virtualizaci\u00f3n.</li> </ul> <p>En un Pool de Almacenamiento de tipo dir, los vol\u00famenes son ficheros de im\u00e1genes de disco. Los Pools de Almacenamiento con lo que hemos trabajado hasta ahora (<code>default</code> y <code>iso</code>) son de este tipo.</p> </li> <li> <p>logical: En este caso, utilizamos LVM (Logical Volume Manager). El Pool de Almacenamiento controlar\u00e1 un Grupo de Vol\u00famenes, y los vol\u00famenes (los discos de las m\u00e1quinas virtuales) ser\u00e1n vol\u00famenes l\u00f3gicos que se crear\u00e1n en el grupo de vol\u00famenes. Este tipo de almacenamiento no ofrece almacenamiento compartido.</p> </li> <li>netfs: Este tipo de Pool de Almacenamiento montar\u00e1 un directorio desde un servidor NAS (nfs, glusterfs, cifs,...). Por lo tanto obtendremos la caracter\u00edstica de compartici\u00f3n y de migraci\u00f3n en vivo. Los vol\u00famenes ser\u00e1n ficheros de im\u00e1genes de disco.</li> <li>iSCSI: Este tipo de Pool de Almacenamiento montar\u00e1 un disco desde un servidor SAN de tipo iSCSI. Obtendremos la caracter\u00edstica de almacenamiento compartido a nivel de disco con las consideraciones que vimos en el punto anterior.</li> <li>Muchos m\u00e1s...</li> </ul>"},{"location":"01.-KVM/05.-Almacenamiento/02.-Introducci%C3%B3n%20al%20almacenamiento%20en%20QEMU%E2%81%84KVM%20%2B%20libvirt/#gestion-de-volumenes-de-almacenamiento","title":"Gesti\u00f3n de vol\u00famenes de almacenamiento","text":"<p>Los vol\u00famenes son los medios de medios de almacenamiento que utilizar\u00e1n las m\u00e1quinas virtuales. Un Pool de Almacenamiento estar\u00e1 formado por vol\u00famenes. Dependiendo del tipo del pool, el volumen corresponder\u00e1 a un medio de almacenamiento determinado. Veamos un ejemplo:</p> <ul> <li>Si el tipo del pool es dir, es decir, un directorio del sistema de fichero del host, el volumen corresponde a un fichero (el fichero que contiene la imagen del disco).</li> <li>Si el tipo del pool es logical, es decir, gestiona un grupo de vol\u00famenes LVM, el volumen corresponder\u00e1 a un volumen l\u00f3gico LVM.</li> </ul> <p>Por lo tanto tenemos dos enfoques para crear los vol\u00famenes:</p> <ul> <li>Usar la API de libvirt, es decir, usar herramientas como <code>virsh</code> o <code>virt-manager</code> para gestionar los vol\u00famenes. En este caso, si creamos un volumen en un pool de tipo dir, estar\u00edamos creando un fichero de imagen de disco. Del mismo modo, si lo creamos en un pool de tipo logical estar\u00edamos creando un volumen l\u00f3gico LVM.</li> <li>Utilizar herramientas espec\u00edficas para crear los medios de almacenamiento y posteriormente refrescar el pool para que a\u00f1ada el nuevo volumen. Ejemplo: podemos usar la herramienta <code>qemu-img</code> para la creaci\u00f3n de un fichero de imagen de disco y posteriormente actualizaremos el pool de tipo dir para a\u00f1adir el nuevo volumen que corresponde al fichero que hemos creado. Otro ejemplo: usar la l\u00ednea de comandos de LVM, creando un volumen l\u00f3gico con el comando <code>lvcreate</code> y posteriormente actualizamos el pool de tipo logical para a\u00f1adir el nuevo volumen.</li> </ul> <p>Si estamos trabajando localmente en un servidor donde tenemos QEMU/KVM + libvirt instalado, no hay muchas diferencias de usar una y otra opci\u00f3n. El uso de la API de libvirt puede ser m\u00e1s interesante si estamos conectados a la API de libvirt de forma remota, ya que al gestionar los vol\u00famenes estar\u00edamos gestionando los recursos de almacenamiento (ficheros, vol\u00famenes l\u00f3gicos,...) sin necesidad de acceder al servidor y crearlos con herramientas espec\u00edficas.</p>"},{"location":"01.-KVM/05.-Almacenamiento/02.-Introducci%C3%B3n%20al%20almacenamiento%20en%20QEMU%E2%81%84KVM%20%2B%20libvirt/#conclusiones","title":"Conclusiones","text":"<p>Tenemos la posibilidad de crear distintos tipos de Pools de Almacenamiento, que nos ofrecen distintas caracter\u00edsticas. Podemos ver los distintos tipos al crear un Pool desde <code>virt-manager</code>:</p> <p></p> <p>En este curso vamos a trabajar con los Pool de Almacenamiento de tipo dir. Si quieres profundizar en las caracter\u00edsticas de los distintos tipos de almacenamiento puedes ver la documentaci\u00f3n oficial: Storage Management.</p>"},{"location":"01.-KVM/05.-Almacenamiento/03.-Gesti%C3%B3n%20de%20Pools%20de%20Almacenamiento/","title":"03.-Gesti\u00f3n de Pools de Almacenamiento","text":""},{"location":"01.-KVM/05.-Almacenamiento/03.-Gesti%C3%B3n%20de%20Pools%20de%20Almacenamiento/#gestion-de-pools-de-almacenamiento-con-virsh","title":"Gesti\u00f3n de Pools de Almacenamiento con virsh","text":"<p>Como hemos visto durante este curso tenemos a nuestra disposici\u00f3n dos Pool de Almacenamiento, para ver los pools con la herramienta <code>virsh</code>, ejecutamos la siguiente instrucci\u00f3n:</p> <pre><code>virsh -c qemu:///system pool-list \n Nombre    Estado   Inicio autom\u00e1tico\n---------------------------------------\n default   activo   si\n iso       activo   si\n</code></pre> <p>Recuerda que el pool por defecto donde se guardan las im\u00e1genes de disco, es <code>default</code>. Podemos obtener informaci\u00f3n de ese pool con la instrucci\u00f3n:</p> <pre><code>virsh -c qemu:///system pool-info default \nNombre:         default\nUUID:           0a03e05b-8844-4029-8216-430fc289fe8f\nEstado:         ejecutando\nPersistente:    si\nAutoinicio:     si\nCapacidad:      87,09 GiB\nUbicaci\u00f3n:     36,61 GiB\nDisponible:     50,48 GiB\n</code></pre> <p>Al igual que las m\u00e1quinas virtuales, los Pools de Almacenamiento se definen por un documento XML. Para ver la definici\u00f3n XML del pool <code>default</code> podemos ejecutar <code>virsh -c qemu:///system pool-dumpxml default</code>. A partir de un fichero XML con la definici\u00f3n de un nuevo pool, podr\u00edamos crearlo con el subcomando <code>virsh pool-define</code>. </p> <p>Nota: Para profundizar en el formato XML que define los Pools de Almacenamiento puedes consultar la documentaci\u00f3n oficial: Storage pool and volume XML format.</p> <p>Sin embargo, vamos a usar otro comando que nos permite indicar la informaci\u00f3n del nuevo pool por medio de par\u00e1metros. Vamos a crear un nuevo pool que vamos a llamar <code>mv-images</code>, de tipo dir y cuyo directorio ser\u00e1 <code>/srv/images</code>. Supongamos que hemos a\u00f1adido m\u00e1s almacenamiento al host y que hemos montado el disco en el directorio <code>/srv/images</code> y queremos guardar las im\u00e1genes de disco en esa nueva localizaci\u00f3n. Para crear el nuevo pool, de forma persistente ejecutamos:</p> <pre><code>virsh -c qemu:///system pool-define-as vm-images dir --target /srv/images\nEl grupo vm-images ha sido definido\n</code></pre> <p>Nota: Si utilizamos <code>pool-create</code> o <code>pool-create-as</code>, el pool se crea temporalmente, no ser\u00e1 persistente y despu\u00e9s de un reinicio del host no existir\u00e1.</p> <p>A continuaci\u00f3n creamos el directorio indicado, con la instrucci\u00f3n:</p> <pre><code>virsh -c qemu:///system pool-build vm-images \nEl pool vm-images ha sido compilado\n</code></pre> <p>Ahora debemos iniciar el pool:</p> <pre><code>virsh -c qemu:///system pool-start vm-images \nSe ha iniciado el grupo vm-images\n</code></pre> <p>Y si lo deseamos lo podemos auto iniciar, para que en el reinicio del host vuelva a estar activo:</p> <pre><code>virsh -c qemu:///system pool-autostart vm-images \nSe ha iniciado el grupo vm-images\n</code></pre> <p>Finalmente vemos la lista de pool y pedimos informaci\u00f3n del nuevo pool:</p> <pre><code>virsh -c qemu:///system pool-list\n Nombre      Estado   Inicio autom\u00e1tico\n-----------------------------------------\n default     activo   si\n iso         activo   si\n vm-images   activo   si\n\nvirsh -c qemu:///system pool-info vm-images \nNombre:         vm-images\nUUID:           a9eb290a-9973-47ea-b616-0907a5df8ea2\nEstado:         ejecutando\nPersistente:    si\nAutoinicio:     si\n...\n</code></pre> <p>Ya podemos usar este pool de almacenamiento para guardar ficheros de im\u00e1genes de disco. Si en alg\u00fan momento queremos eliminarlo, es recomendable pararlo:</p> <pre><code>virsh -c qemu:///system pool-destroy vm-images \nEl grupo vm-images ha sido destruid\n</code></pre> <p>A continuaci\u00f3n, opcionalmente, podemos borrar el directorio creado:</p> <pre><code>virsh -c qemu:///system pool-delete vm-images \nEl grupo vm-images ha sido eliminado\n</code></pre> <p>Y por \u00faltimo lo eliminamos:</p> <pre><code>virsh -c qemu:///system pool-undefine vm-images \nSe ha quitado la definici\u00f3n del grupo vm-images\n</code></pre>"},{"location":"01.-KVM/05.-Almacenamiento/03.-Gesti%C3%B3n%20de%20Pools%20de%20Almacenamiento/#gestion-de-pools-de-almacenamiento-con-virt-manager","title":"Gesti\u00f3n de Pools de Almacenamiento con virt-manager","text":"<p>Desde la pesta\u00f1a Almacenamiento de los Detalles de la conexi\u00f3n podemos ver los pools que tenemos creados y podemos gestionarlos:</p> <p></p> <p>Tenemos las siguientes opciones:</p> <ul> <li>Bot\u00f3n 1: A\u00f1adir un nuevo pool.</li> <li>Bot\u00f3n 2: Iniciar el pool seleccionado.</li> <li>Bot\u00f3n 3: Parar el pool seleccionado.</li> <li>Bot\u00f3n 4: Eliminar el pool seleccionado.</li> </ul> <p>Si creamos un nuevo pool, vemos la siguiente pantalla donde indicamos el nombre, el tipo y en el caso del tipo dir, el directorio:</p> <p></p> <p>Una vez creado, observamos que est\u00e1 iniciado y que tiene marcada como activa la propiedad de autoiniciar:</p> <p></p> <p>Por \u00faltimo, recordar que desde <code>virt-manager</code> podemos ver la definici\u00f3n XML de los recursos con los que trabajamos:</p> <p></p>"},{"location":"01.-KVM/05.-Almacenamiento/04.-Gesti%C3%B3n%20de%20vol%C3%BAmenes%20de%20almacenamiento%20con%20libvirt/","title":"04.-Gesti\u00f3n de vol\u00famenes de almacenamiento con libvirt","text":"<p>En este apartado vamos a estudiar la gesti\u00f3n de vol\u00famenes de almacenamiento usando la API de libvirt, por lo tanto, utilizando herramientas como <code>virsh</code> o <code>virt-manager</code>. </p> <p>Vamos a trabajar con los Pool de Almacenamiento que hemos creado que son de tipo dir, por lo tanto los vol\u00famenes corresponden a ficheros de im\u00e1genes de disco. Para estos ejemplos, utilizaremos el formato de imagen qcow2.</p>"},{"location":"01.-KVM/05.-Almacenamiento/04.-Gesti%C3%B3n%20de%20vol%C3%BAmenes%20de%20almacenamiento%20con%20libvirt/#gestion-de-volumenes-de-almacenamiento-con-virsh","title":"Gesti\u00f3n de vol\u00famenes de almacenamiento con virsh","text":"<p>Para obtener los vol\u00famenes de un determinado pool (por ejemplo el pool <code>default</code>), ejecutamos:</p> <pre><code>virsh -c qemu:///system vol-list default\n Nombre            Ruta\n------------------------------------------------------------\n prueba1.qcow2   /var/lib/libvirt/images/prueba1.qcow2\n prueba2.qcow2   /var/lib/libvirt/images/prueba2.qcow2\n win10.qcow2     /var/lib/libvirt/images/win10.qcow2\n</code></pre> <p>Podemos comprobar que los vol\u00famenes listados se corresponden con ficheros que se encuentran en el directorio del pool <code>default</code> (<code>/var/lib/libvirt/images</code>).</p> <p>Al estar utilizando el formato de imagen <code>qcow2</code>, obtenemos la caracter\u00edstica de aprovisionamiento ligero, el fichero tiene un tama\u00f1o virtual (el que hemos indicado en su creaci\u00f3n y el que ver\u00e1 la m\u00e1quina virtual que lo utilice) y el espacio ocupado en el disco del host (que ir\u00e1 creciendo conforme vayamos guardando informaci\u00f3n en la imagen). Podemos ver esta caracter\u00edstica ejecutando la siguiente instrucci\u00f3n:</p> <pre><code>virsh -c qemu:///system vol-list default --details\n Nombre            Ruta                                      Tipo      Capacidad   Alojamiento\n------------------------------------------------------------------------------------------------\n prueba1.qcow2   /var/lib/libvirt/images/prueba1.qcow2   archivo   10,00 GiB   2,06 GiB\n prueba2.qcow2   /var/lib/libvirt/images/prueba2.qcow2   archivo   20,00 GiB   9,99 GiB\n win10.qcow2     /var/lib/libvirt/images/win10.qcow2     archivo   40,00 GiB   10,06 GiB\n\n</code></pre> <p>Podemos obtener la informaci\u00f3n de un determinado volumen de un pool, ejecutando:</p> <pre><code>virsh -c qemu:///system vol-info prueba1.qcow2 default\nNombre:         prueba1.qcow2\nTipo:           archivo\nCapacidad:      10,00 GiB\nUbicaci\u00f3n:     2,06 GiB\n</code></pre> <p>De la misma forma que los pools, los vol\u00famenes est\u00e1n definidos en libvirt con el formato XML. Para ver la definici\u00f3n XML del volumen <code>vol.qcow2</code> del pool <code>default</code>, podemos ejecutar <code>virsh -c qemu:///system vol-dumpxml vol.qcow2 default</code>. A partir de un fichero XML con la definici\u00f3n de un nuevo volumen, podr\u00edamos crearlo con el comando <code>virsh vol-create</code>. Nota: En este caso no existe el comandos <code>virsh vol-define</code>, ya que los vol\u00famenes no se pueden crear temporalmente.</p> <p>Nota: Para profundizar en el formato XML que define los vol\u00famenes puedes consultar la documentaci\u00f3n oficial: Storage pool and volume XML format.</p> <p>Sin embargo, vamos a usar otro comando que nos permite indicar la informaci\u00f3n del nuevo volumen por medio de par\u00e1metros. Vamos a crear un nuevo volumen en el pool <code>default</code>, cuyo nombre ser\u00e1 <code>vol1.qcow2</code>, formato <code>qcow2</code> y tama\u00f1o de 10GB:</p> <pre><code>virsh -c qemu:///system vol-create-as default vol1.qcow2 --format qcow2 10G \nSe ha creado el volumen vol1.qcow2\n</code></pre> <p>Podemos comprobar que se ha creado un nuevo fichero de imagen:</p> <pre><code>sudo ls -l /var/lib/libvirt/images/\n...\n-rw------- 1 root         root              196768 may 26 09:24 vol1.qcow2\n...\n</code></pre> <p>Tambi\u00e9n podemos volver a ejecutar <code>virsh -c qemu:///system vol-list default</code> para comprobar que se ha creado el volumen.</p> <p>Para borrar un volumen, ejecutamos:</p> <pre><code>virsh -c qemu:///system vol-delete vol1.qcow2 default\nSe ha eliminando el volumen vol1.qcow2\n</code></pre> <p>Tenemos a nuestra disposici\u00f3n m\u00e1s operaciones sobre los vol\u00famenes, estudiaremos algunas de ellas en apartados posteriores: <code>vol-clone</code>: para clonar el volumen, <code>vol-resize</code>: para redimensionar, <code>vol-download</code>: para descargar el volumen en un fichero, <code>vol-upload</code>: para cargar informaci\u00f3n a un volumen desde un fichero,...</p> <p>Nota: Hay que recordar que todas estas operaciones se realizan sobre vol\u00famenes, y por tanto el medio de almacenamiento que gestionan depender\u00e1n del tipo del pool con el que estemos trabajando. De esta forma, un <code>vol-create-as</code> en un pool de tipo logical crear\u00eda un volumen l\u00f3gico LVM.</p>"},{"location":"01.-KVM/05.-Almacenamiento/04.-Gesti%C3%B3n%20de%20vol%C3%BAmenes%20de%20almacenamiento%20con%20libvirt/#gestion-de-volumenes-de-almacenamiento-con-virt-manager","title":"Gesti\u00f3n de vol\u00famenes de almacenamiento con virt-manager","text":"<p>Desde la pesta\u00f1a Almacenamiento de los Detalles de la conexi\u00f3n podemos ver los pools y los vol\u00famenes que tenemos creados y podemos gestionarlos:</p> <p></p> <p>Tenemos las siguientes opciones relacionadas con los vol\u00famenes:</p> <ul> <li>Bot\u00f3n 1: A\u00f1adir un nuevo volumen en el pool seleccionado.</li> <li>Bot\u00f3n 2: Refrescar el pool seleccionado. Actualiza el contenido del pool para incluir los vol\u00famenes que se han creado o modificado con herramientas espec\u00edficas.</li> <li>Bot\u00f3n 3: Eliminar el volumen seleccionado.</li> </ul> <p>Si creamos un nuevo volumen, vemos la siguiente pantalla donde indicamos la siguiente informaci\u00f3n (la informaci\u00f3n solicitada depender\u00e1 del tipo de pool con el que estemos trabajando):</p> <ul> <li>El nombre del volumen.</li> <li>El formato: qcow2 o raw.</li> <li>Backing store: Nos proporciona la caracter\u00edstica de crear vol\u00famenes a partir de un volumen base o imagen base. Lo estudiaremos m\u00e1s adelante en el curso.</li> <li>Capacidad: Indicamos el tama\u00f1o del volumen. Por defecto, si usamos el formato qcow2 obtendremos la caracter\u00edstica de aprovisionamiento ligero, el tama\u00f1o indicado ser\u00e1 el que ve la m\u00e1quina virtual, pero no lo que se ocupa realmente en el disco del host. Si elegimos la opci\u00f3n Allocate entire volume now, se perder\u00e1 esa caracter\u00edstica y se ocupara el disco la capacidad total elegida.</li> </ul> <p></p>"},{"location":"01.-KVM/05.-Almacenamiento/05.-Gesti%C3%B3n%20de%20vol%C3%BAmenes%20de%20almacenamiento%20con%20herramientas%20espec%C3%ADficas/","title":"05.-Gesti\u00f3n de vol\u00famenes de almacenamiento con herramientas espec\u00edficas","text":"<p>En este apartado vamos a gestionar los vol\u00famenes con herramienta especificas. Es decir, si estamos trabajando con un pool de tipo dir y con vol\u00famenes que corresponde a ficheros de im\u00e1genes de disco, vamos a trabajar con la herramienta <code>qemu-img</code>. Esta potente herramienta nos permite la gesti\u00f3n completa de los ficheros de im\u00e1genes de disco.</p>"},{"location":"01.-KVM/05.-Almacenamiento/05.-Gesti%C3%B3n%20de%20vol%C3%BAmenes%20de%20almacenamiento%20con%20herramientas%20espec%C3%ADficas/#gestion-de-imagenes-de-disco-con-qemu-img","title":"Gesti\u00f3n de im\u00e1genes de disco con qemu-img","text":"<p>La herramienta <code>qemu-img</code> es una utilidad para gestionar ficheros de imagen de disco. Puedes profundizar en el uso de esta herramienta consultando la documentaci\u00f3n oficial: QEMU disk image utility.</p> <p>Vamos a crear un nuevo fichero de imagen llamado <code>vol2.qcow2</code>, con el formato <code>qcow2</code>, con un tama\u00f1o de 2GB, en el directorio <code>/srv/images</code>, correspondiente al pool <code>vm-images</code>, que creamos en un apartado anterior (si quisi\u00e9ramos trabajar con el pool <code>default</code> trabajar\u00edamos en el directorio <code>/var/lib/libvirt/images</code>).</p> <pre><code>cd /srv/images/\nqemu-img create -f qcow2 vol2.qcow2 2G\nFormatting 'vol2.qcow2', fmt=qcow2 cluster_size=65536 extended_l2=off compression_type=zlib size=2147483648 lazy_refcounts=off refcount_bits=16\n\n</code></pre> <p>Podemos obtener informaci\u00f3n de la imagen que hemos creado, ejecutando en el mismo directorio:</p> <pre><code>qemu-img info vol2.qcow2\nimage: vol2.qcow2\nfile format: qcow2\nvirtual size: 2 GiB (2147483648 bytes)\ndisk size: 196 KiB\ncluster_size: 65536\nFormat specific information:\n    compat: 1.1\n    compression type: zlib\n    lazy refcounts: false\n    refcount bits: 16\n    corrupt: false\n    extended l2: false\n</code></pre> <p>La creaci\u00f3n del fichero de imagen, no conlleva de forma autom\u00e1tica la creaci\u00f3n del volumen en el pool de almacenamiento. Si vemos la lista de vol\u00famenes en el pool <code>vm-images</code> comprobamos que no se ha creado:</p> <pre><code>virsh -c qemu:///system vol-list vm-images\n Nombre            Ruta\n------------------------------------------------------------\n</code></pre> <p>Para que se cree un nuevo volumen a partir del fichero que hemos creado, necesitamos refrescar el pool, para ello:</p> <pre><code>virsh -c qemu:///system pool-refresh vm-images\nEl grupo vm-images ha sido actualizado\n</code></pre> <p>Y comprobamos que ya tenemos el volumen creado ejecutando: <code>virsh -c qemu:///system vol-list vm-images</code>.</p> <p>Para refrescar un pool desde <code>virt-manager</code> usamos el siguiente bot\u00f3n:</p> <p></p> <p>La herramienta <code>qemu-img</code> es muy potente y nos permite realizar muchas operaciones: redimensionar el fichero de imagen, convertir entre formatos de im\u00e1genes, crear im\u00e1genes a a partir de im\u00e1genes base, crear instant\u00e1neas de im\u00e1genes, ... Utilizaremos algunas de estas funciones en apartados posteriores del curso.</p> <p>Nota: Si estuvi\u00e9ramos trabajando con otro tipo de Pool de Almacenamiento, tendr\u00e1imos que usar herramientas especificar para gestionar los medios de almacenamientos adecuados. Por ejemplo, si estuvi\u00e9ramos trabajando con un pool de tipo logical, usar\u00edamos las herramientas de comando de LVM para crear y gestionar los vol\u00famenes l\u00f3gicos que se corresponder\u00edan con los vol\u00famenes de este tipo de pool.</p>"},{"location":"01.-KVM/05.-Almacenamiento/06.-Trabajar%20con%20vol%C3%BAmenes%20en%20las%20m%C3%A1quinas%20virtuales/","title":"06.-Trabajar con vol\u00famenes en las m\u00e1quinas virtuales","text":"<p>En la creaci\u00f3n de las m\u00e1quinas virtuales que estudiamos en el m\u00f3dulo anterior, se creaba el volumen que se asociaba a la m\u00e1quina como disco principal.</p> <p>Sin embargo, en este apartado vamos a aprender algunas cosas nuevas: crear nuevas m\u00e1quinas virtuales pero usando vol\u00famenes que hayamos creado anteriormente, a\u00f1adir nuevos discos a las m\u00e1quinas virtuales y redimensioanrlos para aumentar el espacio de almacenamiento.</p>"},{"location":"01.-KVM/05.-Almacenamiento/06.-Trabajar%20con%20vol%C3%BAmenes%20en%20las%20m%C3%A1quinas%20virtuales/#creacion-de-maquinas-virtuales-usando-volumenes-existentes","title":"Creaci\u00f3n de m\u00e1quinas virtuales usando vol\u00famenes existentes","text":"<p>En apartados anterior creamos un volumen de 10 GB llamado <code>vol1.qcow2</code>. Vamos a crear una nueva m\u00e1quina virtual que tenga como disco duro este volumen.</p>"},{"location":"01.-KVM/05.-Almacenamiento/06.-Trabajar%20con%20vol%C3%BAmenes%20en%20las%20m%C3%A1quinas%20virtuales/#con-virt-install","title":"Con <code>virt-install</code>","text":"<p>Si los hacemos con <code>virt-install</code>:</p> <pre><code>virt-install --connect qemu:///system \\\n             --virt-type kvm \\\n             --name prueba4 \\\n             --cdrom ~/iso/debian-11.3.0-amd64-netinst.iso \\\n             --os-variant debian10 \\\n             --disk vol=default/vol1.qcow2 \\\n             --memory 1024 \\\n             --vcpus 1\n\n</code></pre> <p>Hemos utilizado la opci\u00f3n <code>--disk vol=default/vol1.qcow2</code>, indicando el volumen usando el formato <code>pool/volumen</code>. Otras opciones que podr\u00edamos poner ser\u00edan:</p> <ul> <li><code>--disk path=/var/lib/libvirt/images/vol1.qcow2</code>: Donde indicamos directamente la ruta donde se encuentra el fichero de imagen de disco.</li> <li><code>--pool wm-images,size=10</code>: En este caso no se reutiliza el volumen que tenemos creado, sino que se crear\u00eda un nuevo volumen de 10GB en el pool indicado.</li> </ul>"},{"location":"01.-KVM/05.-Almacenamiento/06.-Trabajar%20con%20vol%C3%BAmenes%20en%20las%20m%C3%A1quinas%20virtuales/#con-virt-manager","title":"Con <code>virt-manager</code>","text":"<p>Si utilizamos <code>virt-manager</code>, para crear la nueva m\u00e1quina, durante el asistente de creaci\u00f3n de la m\u00e1quina, elegimos el volumen que tenemos creado:</p> <p></p>"},{"location":"01.-KVM/05.-Almacenamiento/06.-Trabajar%20con%20vol%C3%BAmenes%20en%20las%20m%C3%A1quinas%20virtuales/#anadir-nuevos-discos-a-maquinas-virtuales","title":"A\u00f1adir nuevos discos a m\u00e1quinas virtuales","text":"<p>Para a\u00f1adir un disco a una m\u00e1quina virtual, vamos a modificar su definici\u00f3n XML. Podr\u00edamos usar <code>virsh edit</code> e incluir la definici\u00f3n XML del nuevo disco. Sin embargo, vamos a usar un comando de <code>virsh</code> que nos facilita la operaci\u00f3n de a\u00f1adir un nuevo disco y por tanto, la modificaci\u00f3n de la definici\u00f3n XML de la m\u00e1quina. Hay que indicar que esta modificaci\u00f3n se puede hacer \"en caliente\", con la m\u00e1quina funcionando.</p> <p>Por lo tanto, vamos a\u00f1adir el volumen <code>vol2.qcow2</code> que creamos en el apartado anterior, a la m\u00e1quina que hemos creado en estado de ejecuci\u00f3n, ejecutamos:</p> <pre><code>virsh -c qemu:///system attach-disk prueba4 /srv/images/vol2.qcow2 vdb --driver=qemu --type disk --subdriver qcow2 --persistent\nEl disco ha sido asociado exitosamente\n</code></pre> <p>Indicamos el nombre de la m\u00e1quina, el path del fichero de imagen, el dispositivo de bloque que se va a crear, indicamos el driver, el tipo que ser\u00e1 un disco, y el formato de la imagen que se va a a\u00f1adir. Por \u00faltimo, con la opci\u00f3n <code>--persistent</code> hacemos el cambio de forma persistente, para que en el pr\u00f3ximo reinicio de la m\u00e1quina se vuelva a a\u00f1adir el disco.</p> <p>Tambi\u00e9n lo podemos hacer desde <code>virt-manager</code>. Si a\u00f1adimos nuevo hardware en la vista detalle de la m\u00e1quina, podemos a\u00f1adir nuevo almacenamiento:</p> <p></p> <p>Como hemos comentado la m\u00e1quina <code>prueba4</code> est\u00e1 en ejecuci\u00f3n y podemos comprobar que se ha a\u00f1adido el disco:</p> <p></p> <p>Y podr\u00edamos formatear, montar y usar el nuevo disco:</p> <p></p> <p>Para desconectar un disco de una m\u00e1quina virtual podemos ejecutar:</p> <pre><code>virsh -c qemu:///system detach-disk prueba4 vdb --persistent\nEl disco ha sido desmontado exitosamente\n</code></pre> <p>Indicando la m\u00e1quina virtual, el dispositivo que se hab\u00eda creado y la opci\u00f3n para que sea un cambio persistente.</p> <p>Desde <code>virt-manager</code> simplemente pulsar\u00edamos con el bot\u00f3n derecho sobre el dispositivo de disco en la vista detalle, y pulsar\u00edamos sobre Eliminar Hardware.</p>"},{"location":"01.-KVM/05.-Almacenamiento/06.-Trabajar%20con%20vol%C3%BAmenes%20en%20las%20m%C3%A1quinas%20virtuales/#redimension-de-discos-en-maquinas-virtuales","title":"Redimensi\u00f3n de discos en m\u00e1quinas virtuales","text":"<p>Antes de desconectar el disco de la m\u00e1quina, vamos a realizar una operaci\u00f3n de redimensi\u00f3n. Vamos a aumentar el tama\u00f1o del volumen, por lo que la m\u00e1quina ver\u00e1 un disco m\u00e1s grande, pero hay que recordar que tambi\u00e9n tendremos que redimensionar el sistemas de ficheros.</p> <p>Para realizar la redimensi\u00f3n tenemos dos alternativas: o usar la API de libvirt usando, por ejemplo <code>virsh</code> o usar herramientas especificas, en este caso <code>qemu-img</code>.</p> <p>Para redimensionar el volumen de una m\u00e1quina que este parada, podemos usar <code>virsh</code>:</p> <pre><code>virsh -c qemu:///system vol-resize vol2.qcow2 3G --pool vm-images\nEl tama\u00f1o de volumen 'vol2.qcow2' se ha cambiado correctamente a 3G\n</code></pre> <p>O podemos usar <code>qemu-img</code>, se ejecuta con un usuario con privilegios o con <code>sudo</code>:</p> <pre><code>sudo qemu-img resize /srv/images/vol2.qcow2 3G\nImage resized.\n</code></pre> <p>Para hacer la redimensi\u00f3n \"en caliente\", con la m\u00e1quina encendida, podemos obtener informaci\u00f3n de los discos conectados a una m\u00e1quina:</p> <pre><code>virsh -c qemu:///system domblklist prueba4 \n Destino   Fuente\n-----------------------------------------------\n vda       /var/lib/libvirt/images/vol1.qcow2\n vdb       /srv/images/vol2.qcow2\n</code></pre> <p>Y continuaci\u00f3n redimensionamos el disco deseado:</p> <pre><code>virsh -c qemu:///system blockresize prueba4 /srv/images/vol2.qcow2 3G\nEl dispositivo de bloque '/srv/images/vol2.qcow2' cambi\u00f3 de tama\u00f1o\n</code></pre> <p>Podemos comprobar que se ha producido la redimensi\u00f3n en el disco de la m\u00e1quina:</p> <p></p> <ol> <li>El disco ahora tiene 3GB.</li> <li>Pero el sistema de archivo sigue teneido 2Gb. </li> <li>Desmontamos el disco, y lo redimensionamos con <code>resize2fs</code>.</li> <li>Volvemos a montarlo y comprobamos que ahora ya tiene los 3Gb.</li> </ol>"},{"location":"01.-KVM/05.-Almacenamiento/06.-Trabajar%20con%20vol%C3%BAmenes%20en%20las%20m%C3%A1quinas%20virtuales/#redimension-del-sistema-de-ficheros-de-una-imagen-de-disco","title":"Redimensi\u00f3n del sistema de ficheros de una imagen de disco","text":"<p>Otra alternativa para redimensionar el sistema de fichero de una imagen es usar la herramienta virt-resize. <code>virt-resize</code> no trabaja sobre im\u00e1genes de discos de m\u00e1quinas que se est\u00e9n ejecutando, adem\u00e1s no puede redimensionar sobre el mismo fichero de la imagen, por lo que vamos a hacer una copia del mismo.</p> <p>Si tenemos un fichero qcow2 que se llama <code>vol1.qcow</code>, podemos redimensionar el disco y su sistema de ficheros con al siguientes instrucciones:</p> <pre><code>qemu-img resize vol1.qcow2 10G\ncp vol1.qcow2 newvol1.qcow2\nvirt-resize --expand /dev/sda1 vol1.qcow2 newvol1.qcow2\nmv newvol1.qcow2 vol1.qcow2\n</code></pre> <p>Resimensionamos el disco, como vimos en el apartado anterior. Como hemos indicado <code>virt-resize</code> no trabaja sobre un fichero qcow2 directamente, es por ello que lo hemos copiado a otro fichero y hemos ejecutado el comando. Finalmente el fichero <code>nwevol1.qcow2</code> tendr\u00e1 un sistema de ficheros de 10Gb, por lo que terminamos copi\u00e1ndolo de nuevo (con el <code>mv</code>) sobre el disco original.</p>"},{"location":"01.-KVM/05.-Almacenamiento/07.-Compresi%C3%B3n%20de%20im%C3%A1genes/","title":"07.-Compresi\u00f3n de im\u00e1genes","text":""},{"location":"01.-KVM/05.-Almacenamiento/07.-Compresi%C3%B3n%20de%20im%C3%A1genes/#que-es-virt-sparsify","title":"\u00bfQu\u00e9 es <code>virt-sparsify</code>?","text":"<p><code>virt-sparsify</code> es una herramienta de la suite de virtualizaci\u00f3n <code>libguestfs</code> en Linux que se utiliza para reducir el tama\u00f1o de las im\u00e1genes de disco virtual, como las im\u00e1genes en formato QCOW2 o RAW. Esto se hace eliminando los bloques vac\u00edos o no utilizados en el disco, optimizando as\u00ed el espacio que ocupa la imagen en almacenamiento.</p>"},{"location":"01.-KVM/05.-Almacenamiento/07.-Compresi%C3%B3n%20de%20im%C3%A1genes/#por-que-usar-virt-sparsify","title":"\u00bfPor qu\u00e9 usar <code>virt-sparsify</code>?","text":"<p>En entornos de virtualizaci\u00f3n, las im\u00e1genes de disco pueden contener bloques vac\u00edos debido a archivos eliminados o a la expansi\u00f3n del sistema de archivos. Estos bloques vac\u00edos ocupan espacio en el almacenamiento f\u00edsico. <code>virt-sparsify</code> permite optimizar las im\u00e1genes eliminando estos bloques y creando una imagen \"esparcida\" que ocupa menos espacio en disco.</p>"},{"location":"01.-KVM/05.-Almacenamiento/07.-Compresi%C3%B3n%20de%20im%C3%A1genes/#instalacion","title":"Instalaci\u00f3n","text":"<p>Puedes instalar <code>virt-sparsify</code>, una herramienta de la suite <code>libguestfs</code>, mediante el paquete <code>libguestfs-tools</code> mediante:</p> <pre><code>sudo apt install libguestfs-tools\n</code></pre> <p>o bien en Arch con</p> <pre><code>sudo pacman -S guestfs-tools\n</code></pre>"},{"location":"01.-KVM/05.-Almacenamiento/07.-Compresi%C3%B3n%20de%20im%C3%A1genes/#uso-basico","title":"Uso B\u00e1sico","text":"<p>La sintaxis b\u00e1sica del comando <code>virt-sparsify</code> es:</p> <pre><code>virt-sparsify &lt;imagen-entrada&gt; &lt;imagen-salida&gt;\n</code></pre> <ul> <li><code>&lt;imagen-entrada&gt;</code>: La imagen original del disco virtual.</li> <li><code>&lt;imagen-salida&gt;</code>: La imagen optimizada (se recomienda especificar una nueva imagen para evitar sobrescribir la original).</li> </ul>"},{"location":"01.-KVM/05.-Almacenamiento/07.-Compresi%C3%B3n%20de%20im%C3%A1genes/#ejemplo-basico","title":"Ejemplo B\u00e1sico","text":"<pre><code>virt-sparsify disk.qcow2 disk-sparse.qcow2\n</code></pre> <p>En este ejemplo, <code>virt-sparsify</code> toma <code>disk.qcow2</code> como imagen de entrada y crea una nueva imagen optimizada llamada <code>disk-sparse.qcow2</code> que ocupa menos espacio.</p>"},{"location":"01.-KVM/05.-Almacenamiento/07.-Compresi%C3%B3n%20de%20im%C3%A1genes/#opciones-utiles","title":"Opciones \u00datiles","text":"<ol> <li><code>--compress</code></li> <li>Comprime la imagen de salida. Esto es \u00fatil si deseas reducir a\u00fan m\u00e1s el tama\u00f1o del archivo.</li> </ol> <p><code>bash    virt-sparsify --compress disk.qcow2 disk-sparse.qcow2</code></p> <ol> <li><code>--check-tmpdir</code></li> <li>Permite especificar un directorio temporal (en lugar del predeterminado <code>/tmp</code>). Esto es \u00fatil si no tienes suficiente espacio en <code>/tmp</code>.</li> </ol> <p><code>bash    virt-sparsify --tmp /ruta/a/tmpdir disk.qcow2 disk-sparse.qcow2</code></p> <ol> <li><code>--in-place</code></li> <li>Realiza la optimizaci\u00f3n en la misma imagen sin crear una nueva imagen de salida. Nota: Usar esta opci\u00f3n puede ser riesgoso, ya que modifica la imagen original.</li> </ol> <p><code>bash    virt-sparsify --in-place disk.qcow2</code></p> <ol> <li><code>--format</code></li> <li>Especifica el formato de la imagen de salida, \u00fatil si <code>virt-sparsify</code> no detecta correctamente el formato.</li> </ol> <p><code>bash    virt-sparsify --format qcow2 disk.qcow2 disk-sparse.qcow2</code></p>"},{"location":"01.-KVM/05.-Almacenamiento/07.-Compresi%C3%B3n%20de%20im%C3%A1genes/#consideraciones-importantes","title":"Consideraciones Importantes","text":"<ul> <li> <p>Requisitos de Espacio Temporal: <code>virt-sparsify</code> necesita espacio adicional para procesar el archivo. Si tu sistema carece de suficiente espacio en <code>/tmp</code>, usa la opci\u00f3n <code>--check-tmpdir</code> para especificar otra ubicaci\u00f3n.</p> </li> <li> <p>Soporte de Formato: Este comando funciona con muchos formatos de disco virtual, como QCOW2, RAW, VMDK, entre otros. Sin embargo, revisa la compatibilidad con tu sistema de virtualizaci\u00f3n.</p> </li> <li> <p>Acceso de Root: Para utilizar <code>virt-sparsify</code>, generalmente necesitas permisos de administrador.</p> </li> </ul>"},{"location":"01.-KVM/05.-Almacenamiento/07.-Compresi%C3%B3n%20de%20im%C3%A1genes/#ejemplo-completo-de-uso","title":"Ejemplo Completo de Uso","text":"<p>Imaginemos que tienes una imagen de disco <code>vm-disk.qcow2</code> que quieres optimizar:</p> <pre><code>virt-sparsify --compress --format qcow2 vm-disk.qcow2 vm-disk-sparse.qcow2\n</code></pre> <p>Este comando crear\u00e1 una imagen optimizada y comprimida en formato QCOW2, que deber\u00eda ocupar menos espacio en disco.</p>"},{"location":"01.-KVM/05.-Almacenamiento/07.-Compresi%C3%B3n%20de%20im%C3%A1genes/#resumen","title":"Resumen","text":"<ul> <li>virt-sparsify es ideal para reducir el tama\u00f1o de las im\u00e1genes de disco eliminando bloques vac\u00edos.</li> <li>Se recomienda hacer una copia de la imagen de entrada y usar una imagen de salida separada.</li> <li>Usa opciones como <code>--compress</code> para reducir a\u00fan m\u00e1s el tama\u00f1o o <code>--in-place</code> para realizar cambios directamente en la imagen.</li> </ul> <p>Este comando es \u00fatil para liberar espacio en el almacenamiento sin afectar el contenido o la funcionalidad de la imagen de disco virtual.</p>"},{"location":"01.-KVM/06.-Clonaci%C3%B3n%20y%20Snapshots/","title":"Index","text":"<p>En KVM/QEMU, la clonaci\u00f3n y los snapshots son herramientas esenciales para la administraci\u00f3n de m\u00e1quinas virtuales.</p> <ul> <li>Clonaci\u00f3n: Consiste en crear una copia exacta de una m\u00e1quina virtual (VM). Esta copia incluye tanto el estado del disco como la configuraci\u00f3n de la VM. Es \u00fatil para crear entornos de prueba, replicar configuraciones en nuevos servidores, o desplegar r\u00e1pidamente varias instancias de una misma VM.</li> <li>Snapshots: Son capturas del estado de una VM en un momento espec\u00edfico. Un snapshot guarda el estado del sistema, la memoria y los discos, permitiendo revertir a ese punto en caso de ser necesario. Esto es ideal para realizar cambios o actualizaciones en una VM sin arriesgarse a perder el estado actual.</li> </ul> <p>Ambas herramientas facilitan la gesti\u00f3n y recuperaci\u00f3n de m\u00e1quinas virtuales en entornos de virtualizaci\u00f3n KVM/QEMU, mejorando la eficiencia y la seguridad en la administraci\u00f3n de sistemas.</p>"},{"location":"01.-KVM/06.-Clonaci%C3%B3n%20y%20Snapshots/01.-Clonaci%C3%B3n%20de%20m%C3%A1quinas%20virtuales/","title":"01.-Clonaci\u00f3n de m\u00e1quinas virtuales","text":"<p>La clonaci\u00f3n de una m\u00e1quina virtual copia la configuraci\u00f3n XML de la m\u00e1quina de origen y sus im\u00e1genes de disco, y realiza ajustes en las configuraciones para asegurar la unicidad de la nueva m\u00e1quina. Esto incluye cambiar el nombre de la m\u00e1quina y asegurarse de que utiliza los clones de las im\u00e1genes de disco. No obstante, los datos almacenados en los discos virtuales del clon son id\u00e9nticos a los de la m\u00e1quina de origen. </p> <p>La clonaci\u00f3n nos permite crear nuevas m\u00e1quinas de forma muy sencilla, sin necesidad de pasar por el proceso de instalaci\u00f3n desde una imagen ISO.</p> <p>Para realizar la clonaci\u00f3n vamos a partir de una m\u00e1quina virtual que est\u00e9 apagada.</p>"},{"location":"01.-KVM/06.-Clonaci%C3%B3n%20y%20Snapshots/01.-Clonaci%C3%B3n%20de%20m%C3%A1quinas%20virtuales/#uso-virt-clone-para-realizar-la-clonacion","title":"Uso virt-clone para realizar la clonaci\u00f3n","text":"<p>Vamos a usar la aplicaci\u00f3n <code>virt-clone</code> para realizar la clonaci\u00f3n. Puedes profundizar en el uso de esta herramienta consultando la documentaci\u00f3n oficial: virt-clone. Veamos algunos casos de uso:</p> <pre><code>$ virt-clone --connect=qemu:///system --original prueba4 --auto-clone\nAsignando 'vol1-clone.qcow2'                               |  10 GB  00:15     \n\nEl clon 'prueba4-clone' ha sido creado exitosamente.\n</code></pre> <p>Es la forma m\u00e1s sencilla de crear una nueva m\u00e1quina. El par\u00e1metro <code>--auto-clone</code> asigna autom\u00e1ticamente:</p> <ul> <li>Un nuevo nombre para la m\u00e1quina virtual clonada si no se especifica uno.</li> <li>Nuevas direcciones MAC para las interfaces de red para evitar conflictos en la red.</li> <li>Una nueva ruta del disco para el almacenamiento del clon, evitando sobrescribir el disco existente.</li> </ul> <p>Si queremos indicar el nombre de la nueva m\u00e1quina: usamos el par\u00e1metro <code>--name</code> y si queremos indicar el nombre del nuevo volumen usamos <code>--file</code>:</p> <pre><code>virt-clone --connect=qemu:///system --original prueba4 --name prueba5 --file /var/lib/libvirt/images/vol_prueba5.qcow2 --auto-clone\n</code></pre>"},{"location":"01.-KVM/06.-Clonaci%C3%B3n%20y%20Snapshots/01.-Clonaci%C3%B3n%20de%20m%C3%A1quinas%20virtuales/#uso-de-virt-manager-para-realizar-la-clonacion","title":"Uso de virt-manager para realizar la clonaci\u00f3n","text":"<p>Si elegimos una m\u00e1quina virtual y pulsamos el bot\u00f3n derecho del rat\u00f3n tenemos a nuestra disposici\u00f3n la opci\u00f3n Clonar:</p> <p></p> <p>Donde podemos indicar el nombre de la nueva m\u00e1quina virtual, y si pulsamos sobre el bot\u00f3n Details... podemos cambiar el nombre del nuevo fichero de imagen donde se realiza la clonaci\u00f3n.</p>"},{"location":"01.-KVM/06.-Clonaci%C3%B3n%20y%20Snapshots/01.-Clonaci%C3%B3n%20de%20m%C3%A1quinas%20virtuales/#las-maquinas-virtuales-clonadas-son-iguales-a-las-originales","title":"Las m\u00e1quinas virtuales clonadas son iguales a las originales","text":"<p>La m\u00e1quina clon que hemos creado es igual a la original. La nueva m\u00e1quina contiene identificadores que deber\u00edan ser \u00fanicos (como el machine ID, direcciones MAC, claves SSH de host, hostname, ...).</p> <p></p> <p>Podemos acceder a la m\u00e1quina y cambiar el fichero <code>/etc/hostname</code> para cambiar el nombre de la m\u00e1quina, pero todav\u00eda tendr\u00edamos mucha informaci\u00f3n repetida entre las dos m\u00e1quinas. </p> <p>Por lo tanto no vamos a realizar la clonaci\u00f3n de esta manera. En el siguiente apartado vamos a aprender a crear plantillas de m\u00e1quinas virtuales que nos permiten realizar la clonaci\u00f3n de forma adecuada.</p>"},{"location":"01.-KVM/06.-Clonaci%C3%B3n%20y%20Snapshots/02.-Plantillas%20de%20MV/","title":"02.-Plantillas de MV","text":"<p>Una plantilla de m\u00e1quina virtual, o simplemente plantilla es una imagen preconfigurada de un sistema operativo que puede utilizarse para desplegar r\u00e1pidamente m\u00e1quinas virtuales. El uso de plantillas permite evitar muchas tareas repetitivas de instalaci\u00f3n y configuraci\u00f3n. El resultado es la creaci\u00f3n de m\u00e1quinas virtuales totalmente instaladas y listas para funcionar en menos tiempo de lo que tardar\u00eda una instalaci\u00f3n manual.</p> <p>Con la herramienta <code>virt-clone</code> hemos creado un clon de una m\u00e1quina virtual, es decir, una copia de una m\u00e1quina. Una plantilla es una copia maestra que podemos utilizar para crear muchos clones.</p> <p>Una vez tengamos una plantilla, tendremos dos manera de crear las nuevas m\u00e1quinas:</p> <ul> <li>Clonaci\u00f3n completa (Full): Creamos una copia completa de la m\u00e1quina virtual que es totalmente independiente de la plantilla. Requiere el mismo espacio en disco que el original.</li> <li>Clonaci\u00f3n enlazada (Linked): Utiliza la imagen de la plantilla como imagen base en modo de s\u00f3lo lectura y vincula una imagen adicional de \"copia en escritura\" para almacenar los nuevos datos generados. Requiere menos espacio en disco, pero no puede ejecutarse sin acceso a la imagen de plantilla base.</li> </ul>"},{"location":"01.-KVM/06.-Clonaci%C3%B3n%20y%20Snapshots/02.-Plantillas%20de%20MV/#creacion-de-plantillas","title":"Creaci\u00f3n de plantillas","text":"<p>Tendr\u00edamos que realizar tres pasos fundamentales:</p>"},{"location":"01.-KVM/06.-Clonaci%C3%B3n%20y%20Snapshots/02.-Plantillas%20de%20MV/#1-crear-e-instalar","title":"1. Crear e instalar","text":"<p>Hemos de crear una nueva m\u00e1quina virtual e instalarle todo el software necesario. A partir de esa m\u00e1quina vamos a crear la plantilla.</p>"},{"location":"01.-KVM/06.-Clonaci%C3%B3n%20y%20Snapshots/02.-Plantillas%20de%20MV/#2generalizar-la-imagen","title":"2.Generalizar la imagen","text":"<p>Vamos a eliminar toda la informaci\u00f3n que deber\u00eda ser \u00fanica en una m\u00e1quina ya que contiene identificadores que deber\u00edan ser \u00fanicos (como el ID de la m\u00e1quina, direcciones MAC, claves SSH de host, hostname, ...). De tal forma, que las m\u00e1quinas clonadas, regenerar\u00e1n esta informaci\u00f3n de forma \u00fanica al iniciarlas.</p> <p>En m\u00e1quinas Linux vamos a usar la utilidad <code>virt-sysprep</code>; para m\u00e1quinas Windows podemos usar los mecanismos propios de generalizaci\u00f3n que posee: sysprep. Para poder utilizar <code>virt-sysprep</code> tenemos que instalar el siguiente paquete:</p> <pre><code>    $ apt-get install libguestfs-tools\n</code></pre> <p>En distribuciones basadas en Arch puede que el paquete se encuentre en <code>guestfs-tools</code>.</p> <pre><code>    $ pacman -S guestfs-tools\n</code></pre> <p><code>virt-sysprep</code> puede trabajar con un fichero de imagen, usando la opci\u00f3n <code>-a</code>, pero en nuestro caso vamos indicarle una m\u00e1quina virtual, usando el par\u00e1metro <code>-d</code>.</p> <p>Vamos a suponer que vamos a convertir en plantilla nuestra m\u00e1quina <code>VM</code> que tiene un sistema GNU/Linux Ubuntu Server instalado. Nuestra m\u00e1quina original tiene que estar parada. Y para generalizarla, ejecutamos como superusuario:</p> <pre><code>\n    $ sudo virt-sysprep -d VM --hostname TplUbuntuServer\n\n    [   0.0] Examining the guest ...\n    ...\n</code></pre> <p>En <code>virt-sysprep</code> tienes muchas opciones de configuraci\u00f3n, hemos usado el par\u00e1metro <code>-hostname</code> para cambiar el nombre de la m\u00e1quina de la plantilla.</p>"},{"location":"01.-KVM/06.-Clonaci%C3%B3n%20y%20Snapshots/02.-Plantillas%20de%20MV/#3-configurar-maquina-de-solo-lectura","title":"3. Configurar m\u00e1quina de s\u00f3lo lectura","text":"<p>En \u00faltimo lugar, tenemos que evitar ejecutar esta m\u00e1quina de nuevo, ya que la generalizaci\u00f3n que hemos hecho se perder\u00eda. Para conseguirlo vamos a configurar la imagen original de solo lectura, de esta manera al intentar ejecutar la plantilla nos dar\u00e1 un error. Para ello, como superusuario ejecutamos:</p> <pre><code>    /var/lib/libvirt/images# sudo chmod -w VM.qcow2 \n</code></pre> <p>Adem\u00e1s, vamos a cambiar el nombre a la m\u00e1quina para recordar que es un plantilla:</p> <pre><code>$ virsh -c qemu:///system domrename VM TplUbuntuServer\nDomain successfully renamed\n</code></pre> <p>Este cambio tambi\u00e9n se podr\u00eda hacer con <code>virt-manager</code>.</p> <p>Si intentamos ejecutar la plantilla, nos dar\u00e1 un error: </p> <p>En cualquier momento podemos cambiar la configuraci\u00f3n de la plantilla. Todas las nuevas m\u00e1quinas clonadas a partir de ella tendr\u00e1n la misma configuraci\u00f3n.</p> <p>Ya tenemos la plantilla lista para ser clonada. Lo veremos en los siguientes apartados.</p>"},{"location":"01.-KVM/06.-Clonaci%C3%B3n%20y%20Snapshots/03.-Clonaci%C3%B3n%20completa%20con%20plantillas/","title":"03.-Clonaci\u00f3n completa con plantillas","text":"<p>La clonaci\u00f3n completa a partir de una plantilla es similar a la clonaci\u00f3n de m\u00e1quinas virtuales que vimos en un punto anterior.</p>"},{"location":"01.-KVM/06.-Clonaci%C3%B3n%20y%20Snapshots/03.-Clonaci%C3%B3n%20completa%20con%20plantillas/#uso-virt-clone-para-realizar-la-clonacion","title":"Uso virt-clone para realizar la clonaci\u00f3n","text":"<p>Podemos usar el siguiente comando para realizar la clonaci\u00f3n:</p> <pre><code>virt-clone --connect=qemu:///system --original TplUbuntuServer --name VM --auto-clone --file VM.qcow2\n</code></pre> <p>Recuerda que puedes usar el par\u00e1metro <code>--file</code> para indicar el nombre de la imagen de la nueva m\u00e1quina que clonamos.</p> <p>El proceso puede ser lento, ya que se hace una copia completa de la imagen original a la de la nueva m\u00e1quina virtual.</p>"},{"location":"01.-KVM/06.-Clonaci%C3%B3n%20y%20Snapshots/03.-Clonaci%C3%B3n%20completa%20con%20plantillas/#uso-de-virt-manager-para-realizar-la-clonacion","title":"Uso de virt-manager para realizar la clonaci\u00f3n","text":"<p>Si elegimos la plantilla y pulsamos el bot\u00f3n derecho del rat\u00f3n tenemos a nuestra disposici\u00f3n la opci\u00f3n Clonar:</p> <p></p> <p>Donde podemos indicar el nombre de la nueva m\u00e1quina virtual, y si pulsamos sobre el bot\u00f3n Details... podemos cambiar el nombre del nuevo fichero de imagen donde se realiza la clonaci\u00f3n.</p>"},{"location":"01.-KVM/06.-Clonaci%C3%B3n%20y%20Snapshots/03.-Clonaci%C3%B3n%20completa%20con%20plantillas/#problemas-de-acceso-por-ssh","title":"Problemas de acceso por SSH","text":"<p>Si intentamos acceder por SSH a la nueva m\u00e1quina vamos a comprobar que no nos lo permite. Para realizar la conexi\u00f3n por SSH vamos a averiguar la IP de la m\u00e1quina, para ello podemos ejecutar:</p> <pre><code>virsh -c qemu:///system domifaddr clone1\n Nombre     direcci\u00f3n MAC       Protocol     Address\n-------------------------------------------------------------------------------\n vnet0      52:54:00:6d:b5:da    ipv4         192.168.122.253/24\n</code></pre> <p>O usando <code>virt-manager</code> vemos el detalle de la interfaz de red:</p> <p></p> <p>Si desde el host intentamos acceder por SSH, obtenemos:</p> <pre><code>ssh usuario@192.168.122.253\nssh: connect to host 192.168.122.253 port 22: Connection refuse\n</code></pre> <p>Esto es debido a que cuando ejecutamos el <code>virt-sysprep</code> uno de los datos que se eliminaron fueron las claves SSH de la m\u00e1quina para que no fueran los mismos que los de la m\u00e1quina original. Por lo tanto tenemos que regenerar estas claves en la nueva m\u00e1quina ejecutando el comando <code>ssh-keygen -A</code>, y de paso le vamos a cambiar el <code>hostname</code>:</p> <p></p> <p>Una reiniciada la m\u00e1quina ya podemos acceder por SSH desde el host:</p> <pre><code>ssh usuario@192.168.122.253\n...\n\nusuario@clone1:~$ \n</code></pre>"},{"location":"01.-KVM/06.-Clonaci%C3%B3n%20y%20Snapshots/04.-Clonaci%C3%B3n%20enlazada%20con%20plantillas/","title":"04.-Clonaci\u00f3n enlazada con plantillas","text":"<p>En este tipo de clonaci\u00f3n la imagen de la m\u00e1quina clonada utiliza la imagen de la plantilla como imagen base (backing store) en modo de s\u00f3lo lectura, en la imagen de la nueva m\u00e1quina s\u00f3lo se guardan los cambios del sistema de archivo. Requiere menos espacio en disco, pero no puede ejecutarse sin acceso a la imagen de plantilla base. </p> <p>El mecanismo es un poco m\u00e1s complejo, tenemos que realziar dos pasos:</p> <ol> <li>Creaci\u00f3n del nuevo volumen a a partir de la imagen base de la plantilla (backing store).</li> <li>Creaci\u00f3n de la nueva m\u00e1quina usando <code>virt-install</code>, <code>virt-manager</code> o <code>virt-clone</code>.</li> </ol>"},{"location":"01.-KVM/06.-Clonaci%C3%B3n%20y%20Snapshots/04.-Clonaci%C3%B3n%20enlazada%20con%20plantillas/#creacion-de-imagenes-de-disco-con-backing-store","title":"Creaci\u00f3n de im\u00e1genes de disco con backing store","text":"<p>Para no complicar la creaci\u00f3n de vol\u00famenes con backing store vamos a indicar el tama\u00f1o del nuevo volumen igual al de la imagen base. Como la imagen base ya tiene guardado un sistema de archivos con un tama\u00f1o determinado, el hecho de que creemos una nueva imagen con m\u00e1s tama\u00f1o no conlleva el redimensionado del sistema de archivo. Este cambio de tama\u00f1o se podr\u00eda realizar, pero con operaciones un poco m\u00e1s complejas.</p> <p>Para asegurarnos de crear un volumen del mismo tama\u00f1o que la imagen base vamos comprobar su tama\u00f1o:</p> <pre><code>\nvirsh -c qemu:///system domblkinfo plantilla-prueba1 vda --human\nCapacidad:      10,000 GiB\n...\n</code></pre> <p>Tambi\u00e9n lo podemos ver con <code>virt-manager</code>:</p> <p></p> <p>Para crear la nueva imagen basada en la imagen base de la plantilla, podemos crear el volumen con <code>virsh</code>:</p> <pre><code>virsh -c qemu:///system vol-create-as default clone2.qcow2 10G --format qcow2 --backing-vol prueba1.qcow2 --backing-vol-format qcow2\n</code></pre> <p>O podemos usar la aplicaci\u00f3n <code>qemu-img</code> y posterior refrescamos el pool <code>default</code>:</p> <pre><code>cd /var/lib/libvirt/images\nsudo qemu-img create -f qcow2 -b prueba1.qcow2 -F qcow2 clone2.qcow2 10G\nvirsh -c qemu:///system pool-refresh default\n</code></pre> <p>Otra opci\u00f3n es usando <code>virt-manager</code>, creando un nuevo volumen e indicando durante la direcci\u00f3n el volumen base:</p> <p></p>"},{"location":"01.-KVM/06.-Clonaci%C3%B3n%20y%20Snapshots/04.-Clonaci%C3%B3n%20enlazada%20con%20plantillas/#informacion-sobre-imagenes-de-con-disco-con-backing-store","title":"Informaci\u00f3n sobre im\u00e1genes de con disco con backing store","text":"<p>Para comprobar que un volumen est\u00e1 creado con una imagen base podemos usar <code>virsh</code>:</p> <pre><code>virsh -c qemu:///system vol-dumpxml clone2.qcow2 default\n...\n&lt;backingStore&gt;\n    &lt;path&gt;/var/lib/libvirt/images/prueba1.qcow2&lt;/path&gt;\n    &lt;format type='qcow2'/&gt;\n    &lt;permissions&gt;\n    ...\n</code></pre> <p>O usando el comando <code>qemu-img</code>:</p> <pre><code>sudo qemu-img info /var/lib/libvirt/images/clone2.qcow2\n...\nbacking file: prueba1.qcow2\nbacking file format: qcow2\n...\n</code></pre>"},{"location":"01.-KVM/06.-Clonaci%C3%B3n%20y%20Snapshots/04.-Clonaci%C3%B3n%20enlazada%20con%20plantillas/#creacion-de-la-nueva-maquina-a-partir-de-la-imagen-con-backing-store-con-virt-install","title":"Creaci\u00f3n de la nueva m\u00e1quina a partir de la imagen con backing store con virt-install","text":"<p>En este caso podemos usar la herramienta <code>virt-install</code> pero sin indicar el medio de instalaci\u00f3n.</p> <pre><code>virt-install --connect qemu:///system \\\n             --virt-type kvm \\\n             --name nueva_prueba \\\n             --os-variant debian10 \\\n             --disk path=/var/lib/libvirt/images/prueba6.qcow2 \\\n             --memory 1024 \\\n             --vcpus 1 \\\n             --import\n</code></pre> <p>Usamos la opci\u00f3n <code>--import</code> para que no te pida que indique el medio de instalaci\u00f3n, simplemente va a usar el volumen indicado como disco de la m\u00e1quina virtual.</p>"},{"location":"01.-KVM/06.-Clonaci%C3%B3n%20y%20Snapshots/04.-Clonaci%C3%B3n%20enlazada%20con%20plantillas/#creacion-de-la-nueva-maquina-a-partir-de-la-imagen-con-backing-store-con-virt-manager","title":"Creaci\u00f3n de la nueva m\u00e1quina a partir de la imagen con backing store con virt-manager","text":"<p>Si utilizamos <code>virt-manager</code>, para crear la nueva m\u00e1quina, durante el asistente de creaci\u00f3n de la m\u00e1quina, elegimos la opci\u00f3n Manual install, ya que no vamos a usar una imagen ISO:</p> <p></p> <p>Y posteriormente, escogemos el volumen que tenemos creado:</p> <p></p> <p>Otra forma, ser\u00eda escogiendo la opci\u00f3n Importar imagen de disco existente en la creaci\u00f3n de la m\u00e1quina:</p> <p></p> <p>Y eligiendo el volumen en siguiente paso:</p> <p></p>"},{"location":"01.-KVM/06.-Clonaci%C3%B3n%20y%20Snapshots/04.-Clonaci%C3%B3n%20enlazada%20con%20plantillas/#creacion-de-la-nueva-maquina-a-partir-de-la-imagen-con-backing-store-con-virt-clone","title":"Creaci\u00f3n de la nueva m\u00e1quina a partir de la imagen con backing store con virt-clone","text":"<p>Una vez que tenemos creado el volumen basada en el imagen base de la plantilla, podemos crear un nuevo clon con <code>virt-clone</code>, para ello ejecutamos:</p> <pre><code>virt-clone --connect=qemu:///system --original plantilla-prueba1 --name clone2 --file /var/lib/libvirt/images/clone2.qcow2 --preserve-data\n</code></pre> <p>Indicamos como fichero el volumen que hemos creado, pero con la opci\u00f3n <code>--preserve-data</code> no se copia el volumen original al nuevo, simplemente se usa. Se puede comprobar que la clonaci\u00f3n no tarda nada de tiempo, no se est\u00e1 copiando un volumen en otro.</p>"},{"location":"01.-KVM/06.-Clonaci%C3%B3n%20y%20Snapshots/05.-Snapshots%20de%20MV/","title":"05.-Snapshots de MV","text":"<p>Un snapshot (instant\u00e1nea) nos posibilita guardar el estado de una m\u00e1quina virtual en un determinado momento. Se guarda el estado del disco y el estado de la memoria. De esta forma en el futuro puedo volver a un estado anterior de la misma. No todos los formatos y medios de almacenamiento nos posibilitan esta caracter\u00edsticas. Un fichero de imagen de disco con formato <code>qcow2</code> si nos permite la realizaci\u00f3n de instant\u00e1neas.</p>"},{"location":"01.-KVM/06.-Clonaci%C3%B3n%20y%20Snapshots/05.-Snapshots%20de%20MV/#gestion-de-instantaneas-con-virsh","title":"Gesti\u00f3n de instant\u00e1neas con virsh","text":"<p>Vamos a trabajar con la m\u00e1quina <code>prueba2</code> donde tenemos una instalaci\u00f3n de Ubuntu 22.04. </p> <p>Hemos hecho un cambio significativo en nuestra m\u00e1quina (en el ejemplo hemos creado una carpeta). </p> <p></p> <p>Ahora es el momento de crear una instant\u00e1nea, de esta manera podremos volver a este estado en un momento futuro:</p> <pre><code>virsh -c qemu:///system snapshot-create-as prueba2 --name instant\u00e1nea1 --description \"Creada carpeta importante\" --atomic\nHa sido creada la captura instant\u00e1nea instant\u00e1nea1 del dominio\n</code></pre> <p>Se recomienda utilizar la opci\u00f3n <code>--atomic</code> para evitar cualquier corrupci\u00f3n mientras se toma la instant\u00e1nea. Para ver las instant\u00e1neas que tiene creada la m\u00e1quina podemos ejecutar:</p> <pre><code>virsh -c qemu:///system snapshot-list prueba2\n  Nombre         Hora de creaci\u00f3n            Estado\n -----------------------------------------------------\n  instant\u00e1nea1   2022-05-28 18:13:46 +0200   running\n</code></pre> <p>Tambi\u00e9n podemos ver las instant\u00e1neas de un fichero de imagen con la herramienta <code>qemu-img</code> (la m\u00e1quina debe estar parada):</p> <pre><code>sudo qemu-img info /var/lib/libvirt/images/prueba2.qcow2\nimage: /var/lib/libvirt/images/prueba2.qcow2\nfile format: qcow2\nvirtual size: 20 GiB (21474836480 bytes)\ndisk size: 11.9 GiB\ncluster_size: 65536\nSnapshot list:\nID        TAG               VM SIZE                DATE     VM CLOCK     ICOUNT\n1         instant\u00e1nea1     1.79 GiB 2022-05-28 18:13:46 00:16:12.485    \n...\n</code></pre> <p>Los snapshot son otro recurso de libvirt cuya definici\u00f3n se guarda en formato XML. Podr\u00edamos usar el comando <code>snapshot-dumpxml</code> para ver su definici\u00f3n. Tenemos m\u00e1s comandos relacionados con las instant\u00e1neas: para obtener informaci\u00f3n de una instant\u00e1nea usamos <code>snapshot-info</code>, <code>snapshot-delete</code> para borrar una instant\u00e1nea ,... </p> <p>Si hemos tenido un problema en nuestra m\u00e1quina y hemos eliminado nuestra carpeta importante:</p> <p></p> <p>Podemos volver al estado de una determinada instant\u00e1nea ejecutando:</p> <pre><code>virsh -c qemu:///system snapshot-revert prueba2 instant\u00e1nea1\n</code></pre> <p>Y comprobamos que hemos vuelto al estado de la m\u00e1quina donde ten\u00edamos creada la carpeta:</p> <p></p>"},{"location":"01.-KVM/06.-Clonaci%C3%B3n%20y%20Snapshots/05.-Snapshots%20de%20MV/#gestion-de-instantaneas-con-virt-manager","title":"Gesti\u00f3n de instant\u00e1neas con virt-manager","text":"<p>Accediendo a la Vista Instant\u00e1neas obtenemos la ventana para gestionar las instant\u00e1neas:</p> <p></p> <p>Tenemos botones para las opci\u00f3n m\u00e1s comunes:</p> <ul> <li>Bot\u00f3n 1: Crear instant\u00e1nea.</li> <li>Bot\u00f3n 2: Volver al estado de la instant\u00e1nea seleccionada.</li> <li>Bot\u00f3n 3: Refrescar la lista de instant\u00e1neas.</li> <li>Bot\u00f3n 4: Borrar la instant\u00e1nea seleccionada.</li> </ul> <p>Al crear una instant\u00e1nea, podemos indicar el nombre, la descripci\u00f3n y se guarda una captura de pantalla de la m\u00e1quina.</p> <p></p>"},{"location":"01.-KVM/06.-Clonaci%C3%B3n%20y%20Snapshots/05.-Snapshots%20de%20MV/#conclusion","title":"Conclusi\u00f3n","text":"<p>Puede ser muy interesante tomar instant\u00e1neas peri\u00f3dicamente a una m\u00e1quina virtual. Si tenemos cualquier problema con la m\u00e1quina podemos volver a un estado estable anterior. Esta caracter\u00edstica puede ser muy \u00fatil, ya que nos permite experimentar con la m\u00e1quina, y si tenemos alg\u00fan problema, podemos volver al estado original y no tener que eliminar la m\u00e1quina.</p>"},{"location":"01.-KVM/07.-Redes/01.-Introduccion/","title":"01.-Introduccion","text":"<p>libvirt nos proporciona las herramientas necesarias para gestionar las redes virtuales a las que se conectan nuestras m\u00e1quinas virtuales.</p> <p>Tenemos dos grandes grupos de redes que podemos configurar:</p> <ul> <li>Redes Virtuales (Privadas): Son redes privadas que podemos configurar para que tengan distintas caracter\u00edsticas.</li> <li>Redes Puente (P\u00fablicas): Las podemos considerar como redes p\u00fablicas, desde el punto de vista que las m\u00e1quinas virtuales estar\u00e1n conectadas a la misma red a la que est\u00e1 conectada el host.</li> </ul> <p>Recordemos un puente o bridge/switch es un dispositivo de interconexi\u00f3n de redes. La gesti\u00f3n de redes de libvirt se basa en el concepto de switch virtual, para ello utiliza Linux Bridge, que es un software que nos permite crear bridge virtuales con la misma funcionalidad que un bridge f\u00edsico.</p>"},{"location":"01.-KVM/07.-Redes/01.-Introduccion/#tipos-de-redes-virtuales-privadas","title":"Tipos de Redes Virtuales (Privadas)","text":"<p>La clasificaci\u00f3n depender\u00e1 de la configuraci\u00f3n que hagamos a la Red Virtual:</p>"},{"location":"01.-KVM/07.-Redes/01.-Introduccion/#redes-virtuales-de-tipo-nat","title":"Redes Virtuales de tipo NAT","text":"<p>Es un Red Virtual Privada, las m\u00e1quinas virtual tendr\u00e1n un direccionamiento privado y se nos proporciona un mecanismo de router/nat para que tengan conectividad al exterior.</p> <p></p> <p>La red <code>default</code> con la que hemos trabajado es de este tipo. Veamos sus caracter\u00edsticas:</p> <ul> <li>Crea un bridge virtual donde se conectan las m\u00e1quinas virtuales. En el caso de la red <code>default</code> se llama <code>vmbr0</code>. A este bridge tambi\u00e9n est\u00e1 conectado el host.</li> <li>Las m\u00e1quinas virtuales se configuraran de forma din\u00e1mica por medio de un servidor DHCP. En el caso de la red <code>default</code>, el rango de direcciones es <code>192.168.122.2</code> - <code>192.168.122.254</code>. La puerta de enlace de las m\u00e1quinas se configura con la direcci\u00f3n IP <code>192.168.122.1</code> que corresponde al host. El servidor DHCP esta configurado en el host. </li> <li>En el host tambi\u00e9n se configura un servidor DNS que es el que se configura en las m\u00e1quinas virtuales.</li> <li> <p>El host hace la funci\u00f3n de router/nat de tal manera que las m\u00e1quinas virtuales tienen conectividad al exterior, usando la direcci\u00f3n IP de la interfaz de red del host que est\u00e1 conectada al exterior.</p> <p>Existen otros mecanismos para que las m\u00e1quinas virtuales tengan acceso al exterior:</p> <ul> <li>Modo bridge: Donde se usan rutas de encaminamiento en el host. En este modo hay que configurar con rutas est\u00e1ticas los elementos de enrutamiento de la red local para que funcione de manera adecuada.</li> <li>Modo abierto: Similar a la anterior, excepto que no se a\u00f1aden reglas de firewall para asegurar que cualquier tr\u00e1fico pase o no. Se asume que, o bien no son necesarias, o bien se configuran fuera del \u00e1mbito de libvirt.</li> </ul> <p>En este curso vamos a trabajar con Redes Virtuales de tipo NAT.</p> </li> </ul>"},{"location":"01.-KVM/07.-Redes/01.-Introduccion/#redes-virtuales-aisladas-isolated","title":"Redes Virtuales aisladas (Isolated)","text":"<p>Es un Red Virtual Privada, donde las m\u00e1quinas virtuales tomas direccionamiento privado. No tenemos un mecanismo de router/nat, por lo que las m\u00e1quinas virtuales no tienen conectividad con el exterior. </p> <p></p> <p>Por lo tanto tienen las mismas caracter\u00edsticas que una Red Virtual de tipo NAT, pero sin la caracter\u00edstica de router/nat. Se gestiona un bridge virtual donde se conectan las m\u00e1quinas virtuales y el host, seguimos teniendo un servidor DNS y es posible tener un servidor DHCP en el host que asigna din\u00e1micamente un direccionamiento privado a las m\u00e1quinas.</p>"},{"location":"01.-KVM/07.-Redes/01.-Introduccion/#redes-virtuales-muy-aisladas-very-isolated","title":"Redes Virtuales muy aisladas (Very Isolated)","text":"<p>Es un Red Virtual Aislada, en la que el host no est\u00e1 conectado a las m\u00e1quians virtuales. Por lo tanto,no tenemos servidor DNS ni DHCP para ser utilizados por las m\u00e1quinas. Al ser aislada, tampoco tienen salida al exterior.</p> <p></p> <p>En este tipo de red se suele configurar la red de las m\u00e1quinas virtuales de forma est\u00e1tica.</p>"},{"location":"01.-KVM/07.-Redes/01.-Introduccion/#tipos-de-redes-puente-publicas","title":"Tipos de Redes Puente (P\u00fablicas)","text":"<p>La clasificaci\u00f3n depende de la forma utilizada para conectar las m\u00e1quinas virtuales al exterior.</p>"},{"location":"01.-KVM/07.-Redes/01.-Introduccion/#redes-puente-conectadas-a-un-bridge-externo","title":"Redes Puente conectadas a un bridge externo","text":"<p>En este caso necesitamos crear un bridge virtual (normalmente llamado <code>br0</code>) al que conectaremos la m\u00e1quina f\u00edsica y las m\u00e1quinas virtuales. En este caso las m\u00e1quinas virtuales estar\u00e1n en la misma red red que el host y estar\u00e1n conectadas directamente al router de esta red, tomando la configuraci\u00f3n dhcp (si la hubiera) del mismo modo que la toma el host.</p> <p></p>"},{"location":"01.-KVM/07.-Redes/01.-Introduccion/#redes-puente-compartiendo-la-interfaz-fisica-del-host","title":"Redes Puente compartiendo la interfaz f\u00edsica del host","text":"<p>En este caso vamos a usar una conexi\u00f3n macvtap, que nos permite conectarnos a la red f\u00edsica directamente a trav\u00e9s de una interfaz f\u00edsica del host (sin usar un dispositivo bridge). Al igual que con la red anterior, las m\u00e1quinas virtuales estar\u00e1n conectados directamente a la red f\u00edsica, por lo que sus direcciones IP estar\u00e1n todas en la subred de la red f\u00edsica. Existe una una limitaci\u00f3n en la implementaci\u00f3n de macvtap: estas conexiones no permiten la comunicaci\u00f3n directa entre el host y los invitados.</p> <p></p>"},{"location":"01.-KVM/07.-Redes/02.-Definic%C3%B3n%20de%20RV%20%28Privadas%29/","title":"02.-Definic\u00f3n de RV (Privadas)","text":"<p>Las redes que gestiona libvirt se definen con el formato XML. Puedes profundizar en el formato XML con los que se definen las redes consultando el documento Network XML format. </p>"},{"location":"01.-KVM/07.-Redes/02.-Definic%C3%B3n%20de%20RV%20%28Privadas%29/#definicion-de-redes-virtuales-de-tipo-nat","title":"Definici\u00f3n de Redes Virtuales de tipo NAT","text":"<p>La red <code>default</code> con la que hemos trabajado es de este tipo. La configuraci\u00f3n de la red <code>default</code> la podemos encontrar en el fichero <code>/usr/share/libvirt/networks/default.xml</code>:</p> <pre><code>&lt;network&gt;\n  &lt;name&gt;default&lt;/name&gt;\n  &lt;bridge name='virbr0'/&gt;\n  &lt;forward/&gt;\n  &lt;ip address='192.168.122.1' netmask='255.255.255.0'&gt;\n    &lt;dhcp&gt;\n      &lt;range start='192.168.122.2' end='192.168.122.254'/&gt;\n    &lt;/dhcp&gt;\n  &lt;/ip&gt;\n&lt;/network&gt;\n</code></pre> <p>Veamos las etiquetas:</p> <ul> <li><code>&lt;name&gt;</code>: Nombre de la red.</li> <li><code>&lt;bridge&gt;</code>: Indicamos el nombre del bridge virtual que se va a utilizar.</li> <li><code>&lt;forward&gt;</code>: Indica que las m\u00e1quinas virtuales van a tener conectividad con el exterior. Por defecto, si no se indicada nada, el tipo es nat: <code>&lt;forward mode=\"nat\"/&gt;</code>. El modo tambi\u00e9n puede ser:<ul> <li><code>router</code>: Las redes tipo router tambi\u00e9n dan acceso a las m\u00e1quinas virtuales al exterior, pero en ese caso no se utiliza el mecanismo de NAT, sino que se usan rutas de encaminamiento en el host.</li> <li><code>open</code>: Similar a la anterior, excepto que no se a\u00f1aden reglas de firewall para asegurar que cualquier tr\u00e1fico pase o no. </li> </ul> </li> <li><code>&lt;ip&gt;</code>: Donde se indica la direcci\u00f3n IP y la mascara de red de la direcci\u00f3n del host en la red. Es decir, el host est\u00e1 conectado al bridge virtual con esa direcci\u00f3n.<ul> <li><code>&lt;dhcp&gt;</code>: Este elemento es optativo. Si queremos tener un servidor DHCP configurado en el host lo configuramos en esta etiqueta, por ejemplo poniendo el rango en la etiqueta <code>&lt;range&gt;</code>. </li> </ul> </li> </ul>"},{"location":"01.-KVM/07.-Redes/02.-Definic%C3%B3n%20de%20RV%20%28Privadas%29/#definicion-de-redes-virtuales-aisladas","title":"Definici\u00f3n de Redes Virtuales Aisladas","text":"<p>La definici\u00f3n de una Red Virtual Aislada es igual a la de tipo NAT, pero quitando la etiqueta <code>&lt;forward&gt;</code> para deshabilitar la caracter\u00edstica de que el host haga router/nat. La definici\u00f3n podr\u00eda quedar de este modo:</p> <pre><code>&lt;network&gt;\n  &lt;name&gt;red_aislada&lt;/name&gt;\n  &lt;bridge name='virbr1'/&gt;\n  &lt;ip address='192.168.123.1' netmask='255.255.255.0'&gt;\n    &lt;dhcp&gt;\n      &lt;range start='192.168.123.2' end='192.168.123.254'/&gt;\n    &lt;/dhcp&gt;\n  &lt;/ip&gt;\n&lt;/network&gt;\n</code></pre>"},{"location":"01.-KVM/07.-Redes/02.-Definic%C3%B3n%20de%20RV%20%28Privadas%29/#definicion-de-redes-virtuales-muy-aisladas","title":"Definici\u00f3n de Redes Virtuales muy Aisladas","text":"<p>Son similares a la anterior, pero el host no se conecta a la red. Por lo tanto no tenemos ni servidor DNS, ni DHCP. Al crear este tipo de red, simplemente se creara un bridge virtual donde se conectar\u00e1n las m\u00e1quinas virtuales, que se configurar\u00e1n de forma est\u00e1tica su direccionamiento. Por lo tanto la definici\u00f3n ser\u00e1:</p> <pre><code>&lt;network&gt;\n  &lt;name&gt;red_muy_aislada&lt;/name&gt;\n  &lt;bridge name='virbr2'/&gt;\n&lt;/network&gt;\n</code></pre>"},{"location":"01.-KVM/07.-Redes/03.-Gesti%C3%B3n%20de%20RV/","title":"03.-Gesti\u00f3n de RV","text":"<p>En este apartado vamos  a estudiar como trabajar con las redes virtuales con <code>virsh</code> y <code>virt-manager</code>.</p>"},{"location":"01.-KVM/07.-Redes/03.-Gesti%C3%B3n%20de%20RV/#gestion-de-redes-virtuales-con-virsh","title":"Gesti\u00f3n de Redes Virtuales con virsh","text":"<p>Podemos ver las redes que tenemos definidas ejecutando:</p> <pre><code>virsh -c qemu:///system net-list --all\n Nombre    Estado   Inicio autom\u00e1tico   Persistente\n-----------------------------------------------------\n default   activo   si                  si\n</code></pre> <p>Utilizamos la opci\u00f3n <code>--all</code> para listar las redes iniciadas y paradas.</p> <p>Las redes se crean a partir de su definici\u00f3n XML que tenemos guardado en un fichero. En este caso tenemos el fichero <code>red-nat.xml</code>, donde tenemos la definici\u00f3n de una red virtual de tipo NAT, con el siguiente contenido:</p> <pre><code>&lt;network&gt;\n  &lt;name&gt;red_nat&lt;/name&gt;\n  &lt;bridge name='virbr1'/&gt;\n  &lt;forward/&gt;\n  &lt;ip address='192.168.123.1' netmask='255.255.255.0'&gt;\n    &lt;dhcp&gt;\n      &lt;range start='192.168.123.2' end='192.168.123.254'/&gt;\n    &lt;/dhcp&gt;\n  &lt;/ip&gt;\n&lt;/network&gt;\n</code></pre> <p>Para crear la nueva red, ejecutamos:</p> <pre><code>virsh -c qemu:///system net-define red-nat.xml\nLa red red_nat se encuentra definida desde red-nat.xml\n</code></pre> <p>Si utilizamos el comando <code>virsh create</code> estar\u00edamos creando la red de forma temporal, no persistente.</p> <p>La red no se puede utilizar hasta que no se inicie, para ello:</p> <pre><code>virsh -c qemu:///system net-start red_nat\nLa red red_nat se ha iniciado\n</code></pre> <p>Si vamos a usar esta red con mucha frecuencia es recomendable activar la propiedad de autoiniciar para que se inicie de forma autom\u00e1tica al iniciar el host. Para ello:</p> <pre><code>virsh -c qemu:///system net-autostart red_nat\nLa red red_nat ha sido marcada para iniciarse autom\u00e1ticamente\n</code></pre> <p>Podemos obtener informaci\u00f3n de la red ejecutando:</p> <pre><code>virsh -c qemu:///system net-info red_nat\nNombre:         red_nat\nUUID:           af756f61-9ffd-44d0-850f-90a75db773c1\nActivar:        si\nPersistente:    si\nAutoinicio:     si\nPuente:         virbr1\n</code></pre> <p>Al iniciar podemos comprobar que se ha creado el bridge virtual y una nueva interfaz de red en el host.</p> <pre><code>sudo brctl show\nbridge name bridge id       STP enabled interfaces\nvirbr0      8000.525400aea33d   yes     \nvirbr1      8000.5254002daec2   yes \n</code></pre> <p>En el host, el bridge virtual aparece como una interfaz de red:</p> <pre><code>ip a\n...\n4: virbr0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN group default qlen 1000\n    link/ether 52:54:00:ae:a3:3d brd ff:ff:ff:ff:ff:ff\n    inet 192.168.122.1/24 brd 192.168.122.255 scope global virbr0\n       valid_lft forever preferred_lft forever\n5: virbr1: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN group default qlen 1000\n    link/ether 52:54:00:2d:ae:c2 brd ff:ff:ff:ff:ff:ff\n    inet 192.168.123.1/24 brd 192.168.123.255 scope global virbr1\n       valid_lft forever preferred_lft forever\n</code></pre> <p>Podemos considerar que la interfaz de red del bridge virtual corresponde a la conexi\u00f3n del host con el bridge.</p> <p>Para ver la definici\u00f3n XML de la red que hemos creado, ejecutamos:</p> <pre><code>virsh -c qemu:///system net-dumpxml red_nat\n</code></pre> <p>Podemos crear tambi\u00e9n una red muy aislada de la que tenemos guardada la definici\u00f3n XML en el fichero <code>red-muy-aislada.xml</code>, con el contenido:</p> <pre><code>&lt;network&gt;\n  &lt;name&gt;red_muy_aislada&lt;/name&gt;\n  &lt;bridge name='virbr2'/&gt;\n&lt;/network&gt;\n</code></pre> <p>Y si la creamos y la iniciamos:</p> <pre><code>virsh -c qemu:///system net-define red-muy-aislada.xml\nLa red red_muy_aislada se encuentra definida desde red-muy-aislada.xml\n\nvirsh -c qemu:///system net-start red_muy_aislada\nLa red red_muy_aislada se ha iniciado\n</code></pre> <p>Comprobamos que se ha creado el bridge virtual. </p> <pre><code>sudo brctl show\nbridge name bridge id       STP enabled interfaces\nvirbr0      8000.525400aea33d   yes     \nvirbr1      8000.5254002daec2   yes     \nvirbr2      8000.525400d51f31   yes\n</code></pre> <p>Pero al ser una red muy aislada, el host no est\u00e1 conectado al bridge, y por lo tanto no tiene direcci\u00f3n IP asignada:</p> <pre><code>ip a\n...\n6: virbr2: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN group default qlen 1000\n    link/ether 52:54:00:d5:1f:31 brd ff:ff:ff:ff:ff:\n</code></pre> <p>Finalmente indicar que para parar una red utilizamos el comando <code>virsh net-stop</code> y para eliminarla el comando <code>virsh undefined</code>.</p>"},{"location":"01.-KVM/07.-Redes/03.-Gesti%C3%B3n%20de%20RV/#gestion-de-redes-virtuales-con-virt-manager","title":"Gesti\u00f3n de Redes Virtuales con virt-manager","text":"<p>Desde la pesta\u00f1a Redes virtuales de los Detalles de la conexi\u00f3n podemos ver las redes que tenemos creadas y podemos gestionarlas:</p> <p></p> <p>Tenemos las siguientes opciones:</p> <ul> <li>Bot\u00f3n 1: A\u00f1adir una nueva red.</li> <li>Bot\u00f3n 2: Iniciar la red seleccionada.</li> <li>Bot\u00f3n 3: Parar la red seleccionada.</li> <li>Bot\u00f3n 4: Eliminar la red seleccionada.</li> </ul> <p>Si creamos una red, indicamos un nombre, el tipo y la configuraci\u00f3n. Por ejemplo, vamos a crear una red de tipo aislada con servidor DHCP:</p> <p></p> <p>Una vez creado, observamos que est\u00e1 iniciado y que tiene marcada como activa la propiedad de autoiniciar. Adem\u00e1s observamos que el nombre del bridge lo ah asignado de forma autom\u00e1tica:</p> <p></p> <p>Por \u00faltimo, recordar que desde <code>virt-manager</code> podemos ver la definici\u00f3n XML de los recursos con los que trabajamos:</p> <p></p>"},{"location":"01.-KVM/07.-Redes/04.-Creaci%C3%B3n%20de%20un%20Puerte%20Externo%20con%20Linux%20Bridge/","title":"04.-Creaci\u00f3n de un Puerte Externo con Linux Bridge","text":"<p>Un bridge externo es un bridge virtual que estar\u00e1 conectado al router de la red local. El bridge se crear\u00e1 en el servidor donde estamos virtualizando (host). El host estar\u00e1 conectado a este bridge para tener conectividad al exterior. Veamos un esquema:</p> <p></p> <ul> <li>El bridge que vamos a crear lo vamos a llamar <code>br0</code>.</li> <li>En el host aparecer\u00e1 una interfaz de red con el mismo nombre que representa la conexi\u00f3n al bridge. Est\u00e1 interfaz de red se configurar\u00e1 de forma est\u00e1tica o din\u00e1mica (si la red local tiene un servidor DHCP).</li> <li>En el ejemplo vemos que la interfaz f\u00edsica de red es <code>eth0</code> que estar\u00e1 conectada a <code>br0</code> para que el host tenga conectividad al exterior. Esa interfaz de red no tendr\u00e1 asignada direcci\u00f3n IP.</li> <li>Posteriormente veremos como podemos conectar las m\u00e1quinas virtuales a este bridge de tal manera que tomaran direcciones IP en el mismo direccionamiento que el host.</li> </ul> <p>Nota: Si conectamos al bridge una interfaz de tipo wifi podemos tener problemas de conectividad. No todas las tarjetas inal\u00e1mbricas permiten la conexi\u00f3n a puentes virtuales.</p> <p>Nos aseguremos que tenemos instalado el siguiente paquete que nos permite trabajar con Linux Bridge:</p> <pre><code>apt install bridge-utils\n</code></pre>"},{"location":"01.-KVM/07.-Redes/04.-Creaci%C3%B3n%20de%20un%20Puerte%20Externo%20con%20Linux%20Bridge/#creacion-de-un-bridge-externo-con-networkmanager","title":"Creaci\u00f3n de un bridge externo con NetworkManager","text":"<p>NetworkManager es una utilidad de gr\u00e1fica para simplificar el uso de redes en sistemas Linux. Normalmente la tenemos instaladas con sistemas Linux con entornos gr\u00e1ficos como Gnome. Junto a esa utilidad tenemos otra que se puede ejecutar con el comando <code>nm-connection-editor</code>, y que se llama Configuraci\u00f3n avanzada de redes:</p> <p></p> <p>Si lo ejecutamos accedemos a la siguiente pantalla:</p> <p></p> <p>Donde vemos la conexi\u00f3n de red cableada (o de wifi) que tenemos y los bridge virtuales que se han creado cuando hemos estado trabajando con las redes en libvirt. Pulsando el bot\u00f3n +, podemos de alta nueva conexi\u00f3n. A\u00f1adiremos una conexi\u00f3n de tipo Puente:</p> <p></p> <p>Y podemos indicar el nombre de la conexi\u00f3n, el nombre del puente que estamos creando, y a continuaci\u00f3n vamos a a\u00f1adirle una conexi\u00f3n al bridge que ser\u00e1 la interfaz de red f\u00edsica del host que est\u00e1 actualmente conectada al exterior.</p> <p></p> <p>A\u00f1adimos un conexi\u00f3n Cableada que ser\u00e1 la interfaz f\u00edsica del host (en mi caso <code>enp1s0</code>):</p> <p></p> <p></p> <p>Finalmente borramos la conexi\u00f3n cableada que tenemos actualmente:</p> <p></p> <p>Y en unos segundos, se conectar\u00e1 de forma autom\u00e1tica a la conexi\u00f3n Puente Externo:</p> <p> </p> <p>Comprobamos la configuraci\u00f3n de red del host:</p> <pre><code>$ ip a\n2: enp1s0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast master br0 state UP group default qlen 1000\n    link/ether 52:54:00:22:d7:3f brd ff:ff:ff:ff:ff:ff\n...\n7: br0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000\n    link/ether 92:d8:69:79:60:69 brd ff:ff:ff:ff:ff:ff\n    inet 192.168.121.168/24 brd 192.168.121.255 scope global dynamic noprefixroute br0\n       valid_lft 3459sec preferred_lft 3459sec\n...\n</code></pre> <p>Comprobamos que la interfaz f\u00edsica <code>enp1s0</code> no tiene direcci\u00f3n IP, ya que est\u00e1 conectada al bridge. La interfaz de red <code>br0</code> representa la conexi\u00f3n del bridge que ha tomado una ip del servidor DHCP de la red local (esta direcci\u00f3n IP ser\u00e1 diferente a la que ten\u00eda anteriormente la interfaz f\u00edsica).</p> <p>Si tenemos instalado el paquete <code>bridge-utils</code> podremos ver los puentes virtuales y las interfaces que tienen conectadas, ejecutando como superusuario:</p> <pre><code>brctl show\nbridge name bridge id       STP enabled interfaces\nbr0     8000.92d869796069   yes     enp1s0\nvirbr0      8000.525400aea33d   yes     \nvirbr1      8000.5254002daec2   yes     \nvirbr3      8000.52540052838e   yes\n</code></pre>"},{"location":"01.-KVM/07.-Redes/04.-Creaci%C3%B3n%20de%20un%20Puerte%20Externo%20con%20Linux%20Bridge/#creacion-de-un-bridge-externo-en-debian","title":"Creaci\u00f3n de un bridge externo en Debian","text":"<p>Si estamos trabajando en un servidor con Linux Debian instalado y no tenemos instalado NetworkManager, la configuraci\u00f3n se har\u00e1 directamente en el fichero de configuraci\u00f3n de red <code>/etc/network/intefaces</code>:</p> <pre><code>auto lo\niface lo inet loopback\n\nauto enp1s0\niface enp1s0 inet manual\n\nauto br0\niface br0 inet dhcp\n        bridge-ports enp1s0\n</code></pre> <p>Donde vemos como hemos configurado la interfaz f\u00edsica <code>enp1s0</code> de tipo <code>manual</code> para que no tome direccionamiento. Adem\u00e1s hemos declarado nuestro puente <code>br0</code> para que tome direccionamiento de forma din\u00e1mica y hemos indicado que tendr\u00e1 una interfaz conectada (<code>bridge-ports</code>) que ser\u00e1 la f\u00edsica (<code>enp1s0</code>).</p> <p>Finalmente, reiniciamos la red como superusuario:</p> <pre><code>ifdown enp1s0\nsystemctl restart networking.service\n</code></pre> <p>Y comprobamos:</p> <pre><code>ip a\n...\n2: enp1s0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast master br0 state UP group default qlen 1000\n    link/ether 52:54:00:22:d7:3f brd ff:ff:ff:ff:ff:ff\n3: br0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000\n    link/ether 92:d8:69:79:60:69 brd ff:ff:ff:ff:ff:ff\n    inet 192.168.121.169/24 brd 192.168.121.255 scope global dynamic br0\n       valid_lft 3595sec preferred_lft 3595sec\n</code></pre> <p>Podemos comprobar los puentes que tenemos creados y las interfaces que est\u00e1n conectados a \u00e9l, ejecutando la siguiente instrucci\u00f3n:</p> <pre><code>brctl show\nbridge name bridge id       STP enabled interfaces\nbr0     8000.7eb448933f70   no      enp1s0\n</code></pre>"},{"location":"01.-KVM/07.-Redes/04.-Creaci%C3%B3n%20de%20un%20Puerte%20Externo%20con%20Linux%20Bridge/#creacion-de-un-bridge-externo-en-ubuntu","title":"Creaci\u00f3n de un bridge externo en Ubuntu","text":"<p>En Ubuntu vamos a configurar el fichero <code>/etc/netplan/01-network-manager-all.yaml</code> de la siguiente forma:</p> <pre><code># Let NetworkManager manage all devices on this system\nnetwork:\n  version: 2\n  renderer: networkd\n  ethernets:\n    enp1s0:\n      dhcp4: no\n  bridges:\n    br0:\n      dhcp4: yes\n      interfaces:\n             - enp1s0\n</code></pre> <p>Y reiniciamos la red ejecutando:</p> <pre><code>sudo netplan apply\n</code></pre>"},{"location":"01.-KVM/07.-Redes/05.-Gesti%C3%B3n%20de%20Redes%20Puentes%20%28P%C3%BAblicas%29/","title":"05.-Gesti\u00f3n de Redes Puentes (P\u00fablicas)","text":"<p>En este apartado vamos  a estudiar como trabajar con las redes puentes.</p>"},{"location":"01.-KVM/07.-Redes/05.-Gesti%C3%B3n%20de%20Redes%20Puentes%20%28P%C3%BAblicas%29/#gestion-de-redes-puentes-conectadas-a-un-bridge-externo-con-virsh","title":"Gesti\u00f3n de Redes Puentes conectadas a un bridge externo con virsh","text":"<p>Partimos de que en el host tenemos creado un bridge virtual (que se suele llamar <code>br0</code>) al que est\u00e1 conectado el host. Las m\u00e1quinas virtuales se conectar\u00e1n en ese bridge y tomar\u00e1n configuraci\u00f3n de red de la misma red a la que est\u00e1 conectada el host. La definici\u00f3n quedar\u00eda de la siguiente manera.</p> <p>La configuraci\u00f3n la tenemos en el fichero <code>red-bridge.xml</code>, con el contenido:</p> <pre><code>&lt;network&gt;\n  &lt;name&gt;red_bridge&lt;/name&gt;\n  &lt;forward mode=\"bridge\"/&gt;\n  &lt;bridge name=\"br0\"/&gt;\n&lt;/network&gt;\n</code></pre> <ul> <li>El modo de forward se indica como <code>bridge</code>.</li> <li>Y en la etiqueta <code>bridge</code> se pone el nombre del bridge virtual que estamos usando.</li> </ul> <p>Para crear esta nueva red, ejecutamos:</p> <pre><code>virsh -c qemu:///system net-define red-bridge.xml \nLa red red_bridge se encuentra definida desde red-bridge.xml\n</code></pre> <p>La iniciamos:</p> <pre><code>virsh -c qemu:///system net-start red_bridge\nLa red red_bridge se ha iniciado\n</code></pre> <p>Y podemos ver que se ha creado:</p> <pre><code>virsh -c qemu:///system net-list --all\n Nombre            Estado     Inicio autom\u00e1tico   Persistente\n---------------------------------------------------------------\n default           activo     si                  si\n red_aislada       activo     si                  si\n red_bridge        inactivo   no                  si\n red_muy_aislada   inactivo   no                  si\n red_nat           activo     si                  si\n</code></pre> <p>Desde <code>virt-manager</code> no podemos crear una red de este tipo. De todas formas veremos que podemos conectar una m\u00e1quina virtual directamente al bridge <code>br0</code> con lo que ser\u00e1 lo mismo que usar la red.</p>"},{"location":"01.-KVM/07.-Redes/05.-Gesti%C3%B3n%20de%20Redes%20Puentes%20%28P%C3%BAblicas%29/#redes-puente-compartiendo-la-interfaz-fisica-del-host","title":"Redes Puente compartiendo la interfaz f\u00edsica del host","text":"<p>En este caso vamos a usar una conexi\u00f3n macvtap, que nos permite conectarnos a la red f\u00edsica directamente a trav\u00e9s de una interfaz f\u00edsica del host (sin usar un dispositivo bridge). Al igual que con la red anterior, las m\u00e1quinas virtuales estar\u00e1n conectados directamente a la red f\u00edsica, por lo que sus direcciones IP estar\u00e1n todas en la subred de la red f\u00edsica.  La definici\u00f3n de este tipo de red le hemos guardado en el fichero <code>red-interface.xml</code> y ser\u00eda la siguiente:</p> <pre><code>&lt;network&gt;\n  &lt;name&gt;red_interface&lt;/name&gt;\n  &lt;forward mode=\"bridge\"&gt;\n    &lt;interface dev=\"enp1s0\"/&gt;\n  &lt;/forward&gt;\n&lt;/network&gt;\n</code></pre> <p>Es similar a la anterior, pero se utiliza la etiqueta <code>&lt;interface&gt;</code> para indicar el nombre de la interfaz de red f\u00edsica que vamos a utilizar.</p> <p>Para utilizar este tipo de red, la interfaz que utilicemos no puede estar conectado a un puente virtual.</p>"},{"location":"01.-KVM/07.-Redes/06.-Configuraci%C3%B3n%20de%20red%20en%20MV/","title":"06.-Configuraci\u00f3n de red en MV","text":"<p>Todas las m\u00e1quinas que hemos creado durante el curso se han conectado de forma predeterminada a la red <code>default</code>. </p> <p>Sin embargo, en este apartado vamos a aprender algunas cosas nuevas: a crear m\u00e1quinas virtuales conectadas a otras redes definidas por el usuario y a a\u00f1adir interfaces de red a m\u00e1quinas virtuales ya existentes.</p>"},{"location":"01.-KVM/07.-Redes/06.-Configuraci%C3%B3n%20de%20red%20en%20MV/#crear-maquinas-virtuales-conectada-a-una-red-existente","title":"Crear m\u00e1quinas virtuales conectada a una red existente","text":"<p>Para crear una m\u00e1quina virtual conectada, por ejemplo, a la red <code>red_nat</code>, podemos usar <code>virt-install</code>:</p> <pre><code>virt-install --connect qemu:///system \\\n             --virt-type kvm \\\n             --name prueba5 \\\n             --cdrom ~/iso/debian-11.3.0-amd64-netinst.iso \\\n             --os-variant debian10 \\\n             --network network=red_nat \\\n             --disk size=10 \\\n             --memory 1024 \\\n             --vcpus 1\n</code></pre> <ul> <li>Con la opci\u00f3n <code>--network network=red_nat</code> indicamos que la m\u00e1quina tendr\u00e1 una interfaz de red conectada a la red cuyo nombre es <code>red_nat</code>.</li> <li>Para conectar una m\u00e1quina a una red tambi\u00e9n podemos indicar el bridge virtual al que queremos conectarla. en este caso utilizar\u00edamos la opci\u00f3n <code>--network bridge=virbr1</code>. <code>vribr1</code> es el bridge virtual que gestiona la red <code>red_nat</code>.</li> <li>Si indicamos varios par\u00e1metros <code>--network</code>, estar\u00edamos a\u00f1adiendo a la nueva m\u00e1quina varias interfaces de red.</li> </ul> <p>Si utilizamos <code>virt-manager</code>, para crear la nueva m\u00e1quina, durante el asistente de creaci\u00f3n de la m\u00e1quina, el el \u00faltimo paso, podemos escoger la red a la que nos vamos a conectar:</p> <p></p> <p>Tambi\u00e9n podemos escoger el puente virtual al que nos queremos conectar:</p> <p></p>"},{"location":"01.-KVM/07.-Redes/06.-Configuraci%C3%B3n%20de%20red%20en%20MV/#anadir-nuevas-interfaces-de-red-a-maquinas-virtuales","title":"A\u00f1adir nuevas interfaces de red a m\u00e1quinas virtuales","text":"<p>Para a\u00f1adir una nueva interfaz de red a una m\u00e1quina virtual, vamos a modificar su definici\u00f3n XML. Podr\u00edamos usar <code>virsh edit</code> e incluir la definici\u00f3n XML de la nueva interfaz. Sin embargo, vamos a usar un comando de <code>virsh</code> que nos facilita la operaci\u00f3n de a\u00f1adir una nueva interfaz de red y por tanto, la modificaci\u00f3n de la definici\u00f3n XML de la m\u00e1quina. Es recomendable hacer esta operaci\u00f3n con la m\u00e1quina parada.</p> <p>Por lo tanto, vamos a a\u00f1adir a la m\u00e1quina <code>prueba4</code> una interfaz de red conectada a la red <code>red_nat</code>. Para ello, ejecutamos:</p> <pre><code>virsh -c qemu:///system attach-interface prueba4 network red_nat --model virtio --persistent\nLa interfaz ha sido asociada exitosamente\n</code></pre> <p>Si la m\u00e1quina virtual no tiene entorno gr\u00e1fico y por tanto no tiene instalado el programa <code>NetworkManager</code> habr\u00e1 que acceder a ella y configurar la nueva interfaz de red.</p> <p>En nuestro caso es una m\u00e1quina virtual con Debian 11, donde se ha creado un  interfaz con el nombre <code>enp10s0</code>. Para configurarla modificamos el fichero <code>/etc/network/interfaces</code>:</p> <p></p> <p>Levantamos la interfaz y comprobamos que la nueva interfaz de red ha tomado configuraci\u00f3n de red en el direccionamiento que hab\u00edamos configura en la red <code>red_nat</code>:</p> <p></p> <p>Adem\u00e1s, podr\u00edamos ver la configuraci\u00f3n de las interfaces de red con el comando <code>virsh</code>:</p> <pre><code>virsh -c qemu:///system domifaddr prueba4\n Nombre     direcci\u00f3n MAC       Protocol     Address\n-------------------------------------------------------------------------------\n vnet7      52:54:00:d6:0a:19    ipv4         192.168.122.201/24\n vnet8      52:54:00:2a:37:fc    ipv4         192.168.123.225/24\n</code></pre> <p>Podr\u00edamos a\u00f1adir una nueva interfaz de red indicando el puente virtual al que queremos realizar la conexi\u00f3n. En este caso tendr\u00edamos que ejecutar la misma instrucci\u00f3n pero el tipo de la conexi\u00f3n ser\u00e1 <code>bridge</code>:</p> <pre><code>virsh -c qemu:///system attach-interface prueba4 bridge virbr1 --model virtio --persistent\nLa interfaz ha sido asociada exitosamente\n</code></pre> <p>Y comprobamos que tenemos una tercera interfaz:</p> <pre><code>virsh -c qemu:///system domiflist prueba4\n Interfaz   Tipo      Fuente    Modelo   MAC\n------------------------------------------------------------\n -          network   default   virtio   52:54:00:d6:0a:19\n -          network   red_nat   virtio   52:54:00:2a:37:fc\n -          bridge    virbr1    virtio   52:54:00:0c:06:2a\n</code></pre> <p>Por \u00faltimo indicar que si queremos desconectar una interfaz de red tenemos que indicar el tipo (<code>network</code> o <code>bridge</code>) y la direcci\u00f3n MAC:</p> <pre><code>virsh -c qemu:///system detach-interface prueba4 bridge --mac 52:54:00:0c:06:2a --persistent \nLa interfaz ha sido desmontada exitosamente\n</code></pre> <p>Tambi\u00e9n lo podemos hacer desde <code>virt-manager</code>. Si a\u00f1adimos nuevo hardware en la vista detalle de la m\u00e1quina, podemos a\u00f1adir una nueva conexi\u00f3n indicando la red:</p> <p></p> <p>O indicando el puente virtual donde nos vamos a conectar:</p> <p></p> <p>Tambi\u00e9n podemos modificar en cualquier momento a la red o al puente al que estamos conectado, modificando la interfaz de red desde la vista detalles:</p> <p></p> <p>Para eliminar la interfaz de red desde <code>virt-manager</code> simplemente pulsar\u00edamos con el bot\u00f3n derecho sobre el dispositivo de red en la vista detalle, y pulsar\u00edamos sobre Eliminar Hardware.</p>"},{"location":"01.-KVM/07.-Redes/06.-Configuraci%C3%B3n%20de%20red%20en%20MV/#consideraciones-finales","title":"Consideraciones finales","text":"<ul> <li>Si conectamos una m\u00e1quina virtual a una Red de tipo Aislada, tendremos que configurar de forma est\u00e1tica la interfaz y poner el mismo direccionamiento que hemos configurado para el host. Por ejemplo, para la red <code>red_aislada</code> usamos el direccionamiento <code>192.168.123.0/224</code> y la direcci\u00f3n que le asignamos al host fue <code>192.168.123.1</code>. Otras m\u00e1quinas conectadas a esta red tendr\u00e1n que estar configurada con el mismo direccionamiento.</li> <li>Si conectamos una m\u00e1quina virtual a una Red de tipo Muy Aislada, tendremos que configurar de forma est\u00e1tica la interfaz y poner el direccionamiento que nos interese. Normalmente todas las m\u00e1quinas conectada a esta red tendr\u00e1n el mismo direccionamiento para que tengan conectividad entre ellas.</li> <li> <p>Si conectamos a una Red de tipo Bridge conectada a un bridge externo, la m\u00e1quina virtual se configurar\u00e1 con el mismo direccionamiento que el host. En mis caso, trabajo con la red local <code>172.22.0.0/16</code>, si conecto la m\u00e1quina <code>prueba2</code> (tiene instalada un Ubuntu con NetworkManager) al bridge externo <code>br0</code>, tomar\u00e1 la siguiente configuraci\u00f3n:</p> <p><code>virsh -c qemu:///system attach-interface prueba2 bridge br0 --model virtio --persistent La interfaz ha sido asociada exitosamente</code></p> <p>Iniciamos la m\u00e1quina y comprobamos como la interfaz que acabamos de a\u00f1adir se configura con el direccionamiento de la red local. Esta en la misma red que el host:</p> <p></p> </li> <li> <p>Finalmente, si conectamos a una Red de tipo Bridge compartiendo la interfaz f\u00edsica del host tambi\u00e9n se debe configurar en la misma red local del host. Para realizar la conexi\u00f3n podr\u00edamos conectarnos a la red <code>red_interface</code> como hemos anteriormente. Desde <code>virt-manager</code> tambi\u00e9n podemos hacer la conexi\u00f3n indicando el dispositivo f\u00edsico que vamos a usar:</p> <p></p> <p>Iniciamos la m\u00e1quina y comprobamos:</p> <p></p> </li> </ul>"},{"location":"01.-KVM/08.-LXC/01.-Introduccion%20a%20LXC/","title":"01.-Introduccion a LXC","text":"<p>LinuX Containers, tambi\u00e9n conocido por el acr\u00f3nimo LXC, es una tecnolog\u00eda de virtualizaci\u00f3n ligera o por contenedores, que es un m\u00e9todo de virtualizaci\u00f3n en el que, sobre el n\u00facleo del sistema operativo se ejecuta una capa de virtualizaci\u00f3n que permite que existan m\u00faltiples instancias aisladas de espacios de usuario, en lugar de solo uno. A estas instancias la llamamos contenedores.</p> <p>LXC pertenece a los denominados contenedores de sistemas, su gesti\u00f3n y ciclo de vida es similar al de una m\u00e1quina virtual tradicional. Est\u00e1 mantenido por Canonical y la p\u00e1gina oficial es linuxcontainers.org.</p>"},{"location":"01.-KVM/08.-LXC/01.-Introduccion%20a%20LXC/#instalacion-de-lxc","title":"Instalaci\u00f3n de LXC","text":"<p>Vamos a trabajar sobre una distribuci\u00f3n GNU/Linux Debian 11. Para la instalaci\u00f3n de LXC ejecutamos:</p> <pre><code>apt install lxc\n</code></pre> <p>Podemos crear contenedores LXC privilegiados (ejecutados como root) y no privilegiados (ejecutados por un usuario normal). En este curso vamos a trabajar con contenedores privilegiados.</p>"},{"location":"01.-KVM/08.-LXC/02.-Creaci%C3%B3n%20y%20gesti%C3%B3n%20de%20contenedores/","title":"02.-Creaci\u00f3n y gesti\u00f3n de contenedores","text":"<p>Al crear un contenedor se bajar\u00e1 el sistema de archivos que formar\u00e1 parte de \u00e9l. La primera vez que bajamos con <code>debootstrap</code> una versi\u00f3n de un sistema operativo se descargar\u00e1 un sistema de archivo m\u00ednimo del sistema (que llamamos plantilla) que servir\u00e1 para crear todos los contenedores que creemos de la misma versi\u00f3n del sistema.</p> <p>La creaci\u00f3n de un contenedor con la \u00faltima versi\u00f3n de debian, se realiza con la instrucci\u00f3n (ejecutada como <code>root</code>):</p> <pre><code>$ lxc-create -n contenedor1 -t debian -- -r bullseye\n</code></pre> <ul> <li><code>-n</code>: Nombre del contenedor.</li> <li><code>-t</code>: Nombre de la plantilla.</li> <li><code>-r</code>: Es una opci\u00f3n de la plantilla. Es el nombre de la versi\u00f3n del sistema operativo. Para ver m\u00e1s opciones de una plantilla ejecutamos: <code>lxc-create -t debian -h</code>.</li> </ul> <p>Podemos comprobar que se ha creado un contenedor, ejecutando:</p> <pre><code>$ lxc-ls\ncontenedor1 \n</code></pre> <p>La plantilla que hemos descargado se guarda en <code>/var/cache/lxc/debian/rootfs-bullseye-amd64/</code>. Esta copia del sistema de archivo se utilizar\u00e1 cuando creemos otro contenedor con el mismo sistema operativo. El sistema de archivo del <code>contenedor1</code> se guarda en <code>/var/lib/lxc/contenedor1/rootfs/</code>.</p> <p>Ahora podemos iniciar la ejecuci\u00f3n del contenedor, comprobar que est\u00e1 funcionando y acceder a \u00e9l:</p> <pre><code>$ lxc-start contenedor1\n$ lxc-ls -f\nNAME        STATE   AUTOSTART GROUPS IPV4       IPV6 UNPRIVILEGED \ncontenedor1 RUNNING 0         -      10.0.3.180 -    false        \n$ lxc-attach contenedor1\nroot@contenedor1:~# \n</code></pre> <p>Iniciamos el contenedor con <code>lxc-start</code>, comprobamos los contenedores que tenemos creados con <code>lxc-ls</code> con la opci\u00f3n <code>-f</code> nos da m\u00e1s informaci\u00f3n (vemos que est\u00e1 ejecut\u00e1ndose, que no se ejecuta al inicio, que ha tomado una direcci\u00f3n ip y que es privilegiado). Por \u00faltimo nos hemos conectado al contenedor con <code>lxc-attach</code>.</p> <p>Podemos parar el contenedor con <code>lxc-stop</code> y eliminar el contenedor con <code>lxc-destroy</code>.</p> <p>Para visualizar todas las plantillas que podemos descargar, ejecutamos:</p> <pre><code>$ ls /usr/share/lxc/templates/\nlxc-alpine    lxc-archlinux  lxc-centos  lxc-debian    lxc-fedora     lxc-gentoo  lxc-oci       lxc-opensuse  lxc-plamo  lxc-sabayon    lxc-sparclinux  lxc-ubuntu    lxc-voidlinux\nlxc-altlinux  lxc-busybox    lxc-cirros  lxc-download  lxc-fedora-legacy  lxc-local   lxc-openmandriva  lxc-oracle    lxc-pld    lxc-slackware  lxc-sshd    lxc-ubuntu-cloud\n</code></pre> <p>Tambi\u00e9n puedes obtener la lista de plantillas en la p\u00e1gina Image server for LXC and LXD.</p>"},{"location":"01.-KVM/08.-LXC/02.-Creaci%C3%B3n%20y%20gesti%C3%B3n%20de%20contenedores/#ejecucion-de-comandos-en-un-contenedor","title":"Ejecuci\u00f3n de comandos en un contenedor","text":"<p>Podemos ejecutar un comando en un contenedor que se est\u00e9 ejecutando de la siguiente manera:</p> <pre><code>$ lxc-attach contenedor1 -- ls -al\n</code></pre> <p>si el contenedor est\u00e1 apagado, lo har\u00edamos de la siguiente forma:</p> <pre><code>$ lxc-stop contenedor1\n$ lxc-execute contenedor1 -- ls -al\n</code></pre>"},{"location":"01.-KVM/08.-LXC/02.-Creaci%C3%B3n%20y%20gesti%C3%B3n%20de%20contenedores/#eliminar-un-contenedor","title":"Eliminar un contenedor","text":"<p>Para eliminar un contenedor podemos ejecutar la siguiente instrucci\u00f3n con el contenedor parado:</p> <pre><code>$ lxc-destroy contendor1\n</code></pre> <p>Si el contenedor est\u00e1 inicado podemos usar el par\u00e1metro <code>-f</code> de la instracci\u00f3n <code>lxc-destroy</code> para eliminarlo.</p>"},{"location":"01.-KVM/08.-LXC/03.-Configuraci%C3%B3n%20de%20contenedores%20LXC/","title":"03.-Configuraci\u00f3n de contenedores LXC","text":"<p>El fichero <code>/etc/lxc/default.conf</code> contiene la configuraci\u00f3n general que van a tener los contenedores que creemos. Su contenido es el siguiente:</p> <pre><code>lxc.net.0.type = veth\nlxc.net.0.link = lxcbr0\nlxc.net.0.flags = up\n\nlxc.apparmor.profile = generated\nlxc.apparmor.allow_nesting = 1\n</code></pre> <p>Como vemos se indica a qu\u00e9 red se va a conectar (<code>lxc.net.</code>). Una vez creado un contenedor, el contenido de este fichero se copia a su fichero de configuraci\u00f3n (al que se a\u00f1aden otras configuraciones por defecto). Por ejemplo el fichero de configuraci\u00f3n del contenedor <code>contenedor1</code> lo encontramos en el fichero <code>/var/lib/lxc/contenedor1/config</code>. en este caso, su contenido es:</p> <pre><code>lxc.net.0.type = veth\nlxc.net.0.hwaddr = 00:16:3e:cf:8f:c3\nlxc.net.0.link = lxcbr0\nlxc.net.0.flags = up\nlxc.apparmor.profile = generated\nlxc.apparmor.allow_nesting = 1\nlxc.rootfs.path = dir:/var/lib/lxc/contenedor1/rootfs\n\n# Common configuration\nlxc.include = /usr/share/lxc/config/debian.common.conf\n\n# Container specific configuration\nlxc.tty.max = 4\nlxc.uts.name = contenedor1\nlxc.arch = amd64\nlxc.pty.max = 1024\n</code></pre> <p>Vemos que se han copiado los par\u00e1metros de la configuraci\u00f3n general (<code>/etc/lxc/default.conf</code>) y se han a\u00f1adido nuevos par\u00e1metros: n\u00famero m\u00e1ximo de terminales (<code>lxc.tty.max</code>,<code>lxc.pty.max</code>), nombre del contenedor (<code>lxc.uts.name</code>), arquitectura (<code>lxc.arch</code>), ubicaci\u00f3n del sistema de fichero (<code>lxc.rootfs.path</code>), ...</p> <p>Puedes ver los distintos par\u00e1metros que podemos incluir en la documentaci\u00f3n oficial. Por ejemplo si queremos que los contenedores se inicien autom\u00e1ticamente al iniciar el host podr\u00edamos:</p> <pre><code>lxc.start.auto = 1\n</code></pre> <p>Recuerda que tenemos dos opciones:</p> <ol> <li>Si escribimos el par\u00e1metro en la configuraci\u00f3n general, en el fichero <code>/etc/lxc/default.conf</code>, afectar\u00e1 a los contenedores que se creen nuevos.</li> <li>Si queremos modificar la configuraci\u00f3n de un contenedor ya creado, tenemos que incluir el par\u00e1metro en su fichero de configuraci\u00f3n, por ejemplo para el <code>contenedor1</code> en <code>/var/lib/lxc/contenedor1/config</code>.</li> </ol>"},{"location":"01.-KVM/08.-LXC/03.-Configuraci%C3%B3n%20de%20contenedores%20LXC/#obteniendo-informacion-de-un-contenedor","title":"Obteniendo informaci\u00f3n de un contenedor","text":"<p>Para obtener informaci\u00f3n de un contenedor podemos ejecutar:</p> <pre><code>$ lxc-info contenedor1\nName:           contenedor1\nState:          RUNNING\nPID:            12587\nIP:             10.0.3.180\nLink:           vethuLaHzY\n TX bytes:      1.70 KiB\n RX bytes:      3.80 KiB\n Total bytes:   5.50 KiB\n</code></pre> <p>Con la opci\u00f3n <code>-i</code> s\u00f3lo nos da  la direcci\u00f3n ip, con la opci\u00f3n <code>-S</code> nos da la estad\u00edstica de informaci\u00f3n enviada y recibida por la interfaz de red y con la opci\u00f3n <code>-s</code> nos da informaci\u00f3n del estado.</p>"},{"location":"01.-KVM/08.-LXC/03.-Configuraci%C3%B3n%20de%20contenedores%20LXC/#limitando-los-recursos-para-los-contenedores-lxc","title":"Limitando los recursos para los contenedores LXC","text":"<p>Por defectos los contenedores LXC pueden usar todos los recursos de CPU, RAM, disco del host. Podemos limitar estos recursos. El componente del n\u00facleo que posibilita limitar los recursos para cada contenedor son los Grupos de control cgroups, en concreto en Debian 11 y Debian 12 se utiliza cgroupsv2.</p> <p>Lo primero es que tenemos que habilitar la modificaci\u00f3n de la memoria en los Grupos de control (cgroups). Para ello tenemos que a\u00f1adir al fichero <code>/etc/default/grub</code> la siguiente informaci\u00f3n: a\u00f1adimos al par\u00e1metro <code>GRUB_CMDLINE_LINUX_DEFAULT</code> el valor <code>cgroup_enable=memory</code>. Para que tenga este cambio efecto, reiniciamos la m\u00e1quina.</p> <p>Vamos a limitar el uso de memoria RAM (512Mb) y de n\u00famero de procesadores (1 CPU: la CPU 0) (en la m\u00e1quina donde estoy corriendo los contenedores tenemos 2Gb de RAM y 2 CPUs), para ello en el fichero de configuraci\u00f3n del <code>contenedor1</code> indicamos los siguientes par\u00e1metros:</p> <pre><code>lxc.cgroup2.memory.max = 512M\nlxc.cgroup2.cpuset.cpus = 0\n</code></pre> <p>Reiniciamos el contenedor y comprobamos que se ha llevado a efecto el cambio:</p> <pre><code>$ lxc-stop contenedor1\n$ lxc-start contenedor1\n\n$ lxc-attach contenedor1 -- free -h\n               total        used        free      shared  buff/cache   available\nMem:           512Mi       6.0Mi       505Mi       0.0Ki       0.0Ki       505Mi\n\n$ lxc-attach contenedor1 -- cat /proc/cpuinfo \nprocessor   : 0\n...\n</code></pre> <p>Aparece un s\u00f3lo procesador.</p>"},{"location":"01.-KVM/08.-LXC/04.-Redes%20en%20LXC/","title":"04.-Redes en LXC","text":"<p>LXC nos ofrece distintos mecanismos para conectar nuestros contenedores a una red. En este curso nos vamos a centrar en las conexiones de tipo bridge. Tenemos dos posibilidades:</p> <ul> <li>Podemos crear manualmente el bridge o usar libvirt para su creaci\u00f3n (podemos crear distintos tipos de redes con libvirt).</li> <li>Podemos usar <code>lxc-net</code>, servicio ofrecido por LXC, que nos facilita la creaci\u00f3n de un bridge, que por defecto se llama <code>lxcbr0</code>, y que nos ofrece una red de tipo NAT con los servicios de DHCP y DNS.</li> </ul>"},{"location":"01.-KVM/08.-LXC/04.-Redes%20en%20LXC/#redes-con-lxc-net","title":"Redes con lxc-net","text":"<p>Veamos en primer lugar la segunda opci\u00f3n. El servicio <code>lxc-net</code>  crea un bridge llamado <code>lxcbr0</code> que nos ofrece una red de tipo NAT con los servicios DHCP y DNS. Por defecto nos ofrece una red con direccionamiento <code>10.0.3.0/24</code>.</p>"},{"location":"01.-KVM/08.-LXC/04.-Redes%20en%20LXC/#conexion-de-los-contenedores-a-lxcbr0","title":"Conexi\u00f3n de los contenedores a <code>lxcbr0</code>","text":"<p>La configuraci\u00f3n por defecto posibilita que los contenedores que creemos se conecten a esta red. Lo podemos ver en la configuraci\u00f3n general, en el fichero <code>/etc/lxc/default.conf</code>:</p> <pre><code>lxc.net.0.type = veth\nlxc.net.0.link = lxcbr0\nlxc.net.0.flags = up\n...\n</code></pre> <p>Si hemos creado un contenedor llamado <code>contenedor1</code> recibir\u00e1 esta configuraci\u00f3n que podremos encontrar en su fichero de configuraci\u00f3n <code>/var/lib/lxc/contenedor1/config</code>:</p> <pre><code>lxc.net.0.type = veth\nlxc.net.0.hwaddr = 00:16:3e:cf:8f:c3\nlxc.net.0.link = lxcbr0\nlxc.net.0.flags = up\n...\n</code></pre> <p>Por lo tanto podemos comprobar que el <code>contenedor1</code> est\u00e1 conectado a esa red. Por ejemplo, si mostramos los contenedores que hemos creado, vemos que ha recibido una ip en ese rango:</p> <pre><code>$ lxc-ls -f\nNAME        STATE   AUTOSTART GROUPS IPV4       IPV6 UNPRIVILEGED \ncontenedor1 RUNNING 1         -      10.0.3.180 -    false        \n</code></pre> <p>Si accedemos al contenedor podemos hacer varias comprobaciones:</p> <pre><code>$ lxc-attach contenedor1\nroot@contenedor1:~# ip a\n...\n2: eth0@if4: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000\n    inet 10.0.3.180/24 brd 10.0.3.255 scope global dynamic eth0\n...\n\nroot@contenedor1:~# ip r\ndefault via 10.0.3.1 dev eth0 \n10.0.3.0/24 dev eth0 proto kernel scope link src 10.0.3.180 \n\nroot@contenedor1:~# cat /etc/resolv.conf \nnameserver 10.0.3.1\n\nroot@contenedor1:~# apt install iputils-ping\n...\nroot@contenedor1:~# ping www.josedomingo.org\nPING endor.josedomingo.org (37.187.119.60) 56(84) bytes of data.\n64 bytes from ns330309.ip-37-187-119.eu (37.187.119.60): icmp_seq=1 ttl=49 time=28.7 ms\n...\n</code></pre> <ol> <li>Comprobamos que se ha configurado con la ip <code>10.0.3.180</code>.</li> <li>Vemos que la puerta de enlace es la <code>10.0.3.1</code> que corresponde a nuestra m\u00e1quina f\u00edsica.</li> <li>Del mismo modo la m\u00e1quina f\u00edsica es el servidor DNS.</li> <li>Hemos instalado la herramienta <code>ping</code> y comprobamos que tenemos resoluci\u00f3n y acceso al exterior.</li> </ol>"},{"location":"01.-KVM/08.-LXC/04.-Redes%20en%20LXC/#conexion-de-los-contenedores-a-un-bridge-existente","title":"Conexi\u00f3n de los contenedores a un bridge existente","text":"<p>Imaginemos que tenemos en nuestro host instalado libvirt para manejar los recursos de KVM/QEMU y hemos creado una red con <code>virsh</code> de tipo NAT, que ha creado un bridge llamado <code>virbr0</code>, con las siguientes caracter\u00edsticas:</p> <pre><code>$ virsh net-dumpxml default\n&lt;network&gt;\n  &lt;name&gt;default&lt;/name&gt;\n  &lt;uuid&gt;c411a5a1-f998-42a9-bc8a-9a9052fc36f6&lt;/uuid&gt;\n  &lt;forward mode='nat'&gt;\n    &lt;nat&gt;\n      &lt;port start='1024' end='65535'/&gt;\n    &lt;/nat&gt;\n  &lt;/forward&gt;\n  &lt;bridge name='virbr0' stp='on' delay='0'/&gt;\n  &lt;mac address='52:54:00:fc:32:a2'/&gt;\n  &lt;ip address='192.168.122.1' netmask='255.255.255.0'&gt;\n    &lt;dhcp&gt;\n      &lt;range start='192.168.122.2' end='192.168.122.254'/&gt;\n    &lt;/dhcp&gt;\n  &lt;/ip&gt;\n&lt;/network&gt;\n</code></pre> <p>Podemos modificar el fichero de configuraci\u00f3n por defecto <code>/etc/lxc/default.conf</code>, indicando el bridge <code>virbr0</code>:</p> <pre><code>lxc.net.0.type = veth\nlxc.net.0.link = virbr0\nlxc.net.0.flags = up\n...\n</code></pre> <p>Todos los nuevos contenedores que creemos se conectar\u00e1n a la red <code>default</code>:</p> <pre><code>$ lxc-create -n contenedor2 -t debian -- -r bullseye\n$ lxc-start contenedor2\n$ lxc-ls -f\nNAME        STATE   AUTOSTART GROUPS IPV4            IPV6 UNPRIVILEGED \ncontenedor1 RUNNING 1         -      10.0.3.10       -    false        \ncontenedor2 RUNNING 1         -      192.168.122.228 -    false        \n</code></pre> <p>Vemos como el <code>contenedor2</code> ha tomado en una ip de la red <code>default</code>.</p> <p>Si quisi\u00e9ramos cambiar la conexi\u00f3n del un contenedor ya existente deber\u00edamos hacer la modificaci\u00f3n en su fichero de configuraci\u00f3n: <code>/var/lib/lxc/&lt;NOMBRE_CONTENEDOR&gt;/config</code> y reiniciar el contenedor.</p> <p>Tambi\u00e9n podr\u00edamos conectar el <code>contenedor1</code> a la red <code>default</code>, para ello vamos a a\u00f1adir la informaci\u00f3n de la conexi\u00f3n en su fichero de configuraci\u00f3n <code>/var/lib/lxc/contenedor1/config</code>:</p> <pre><code>lxc.net.0.type = veth\nlxc.net.0.hwaddr = 00:16:3e:cf:8f:c3\nlxc.net.0.link = lxcbr0\nlxc.net.0.flags = up\n\nlxc.net.1.type = veth\nlxc.net.1.hwaddr = 00:16:3e:cf:8f:d3\nlxc.net.1.link = virbr0\nlxc.net.1.flags = up\n...\n</code></pre> <p>Indicamos la segunda conexi\u00f3n utilizando el nombre de los par\u00e1metros como <code>lxc.net.1.*</code>. Adem\u00e1s hemos cambiado la mac de la segunda tarjeta de red. Ahora reiniciamos y accedemos al contenedor:</p> <pre><code>$ lxc-stop -r contenedor1\n$ lxc-attach contenedor1\nroot@contenedor1:~# apt install nano\nroot@contenedor1:~# nano /etc/network/interfaces\n</code></pre> <p>Configuramos la segunda interfaz de red:</p> <pre><code>auto lo\niface lo inet loopback\n\nauto eth0\niface eth0 inet dhcp\n\nauto eth1\niface eth1 inet dhcp\n</code></pre> <p>Y obtenemos una nueva direcci\u00f3n ip en la nueva red:</p> <pre><code>root@contenedor1:~# ifup eth1\nroot@contenedor1:~# ip a\n...\n2: eth0@if13: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000\n...\n    inet 10.0.3.10/24 brd 10.0.3.255 scope global dynamic eth0\n...\n3: eth1@if14: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000\n...\n    inet 192.168.122.196/24 brd 192.168.122.255 scope global dynamic eth1\n...\n</code></pre> <p>Si listamos los contenedores que tenemos, podemos ver las dos direcciones ip:</p> <pre><code>$ lxc-ls -f\nNAME        STATE   AUTOSTART GROUPS IPV4                        IPV6 UNPRIVILEGED \ncontenedor1 RUNNING 1         -      10.0.3.10, 192.168.122.196  -    false        \ncontenedor2 RUNNING 1         -      192.168.122.228             -    false    \n</code></pre>"},{"location":"01.-KVM/08.-LXC/05.-Almacenamiento%20en%20LXC/","title":"05.-Almacenamiento en LXC","text":"<p>Veamos c\u00f3mo montar un directorio del host en un contenedor. Imaginemos que tenemos el directorio <code>/opt/contenedor1</code> con un fichero <code>index.html</code> y lo queremos montar en el <code>contenedor1</code> en el directorio <code>/srv/www</code>. Tenemos que tener en cuenta los siguiente:</p> <p>El directorio de montaje debe existir en el contenedor:</p> <pre><code>$ lxc-attach contenedor1\nroot@contenedor1:~# cd /srv\nroot@contenedor1:/srv# mkdir www\n</code></pre> <p>En el fichero de configuraci\u00f3n del contenedor (<code>/var/lib/lxc/contenedor1/config</code>) a\u00f1adimos la siguiente l\u00ednea:</p> <pre><code>lxc.mount.entry=/opt/contenedor1 srv/www none bind 0 0\n</code></pre> <p>Hay que tener en cuenta que al indicar el directorio de montaje hay que usar una ruta relativa (es relativa al directorio donde se encuentra el sistema de fichero del contenedor, en este caso <code>/var/lib/lxc/contenedor1/rootfs/</code>).</p> <p>Reiniciamos el contenedor y comprobamos que se ha montado el directorio de forma correcta:</p> <pre><code>$ lxc-stop contenedor1\n$ lxc-start contenedor1\n$ lxc-attach contenedor1\nroot@contenedor1:~# cd /srv/www\nroot@contenedor1:/srv/www# ls\nindex.html\n</code></pre>"},{"location":"01.-KVM/08.-LXC/06.-Introducci%C3%B3n%20a%20LXD/","title":"06.-Introducci\u00f3n a LXD","text":"<p>LXD, Linux Container Daemon, es una herramienta de gesti\u00f3n de los contenedores y m\u00e1quinas virtuales del sistema operativo Linux, desarrollada por Canonical.</p> <p>Internamente usa LXC para la gesti\u00f3n de contenedores, pero facilita el uso de los contenedores a\u00f1adiendo nuevas funcionalidades.</p> <ul> <li>LXD no trabaja con plantillas, trabaja con im\u00e1genes de sistemas operativos para crear los contenedores. Lista de im\u00e1genes.</li> <li>No ofrece soporte para diferentes backends de almacenamiento y tipos de red. Facilitando la gesti\u00f3n de red y almacenamiento.</li> <li>LXD ofrece una REST API que podemos usar con una simple herramienta de l\u00ednea de comandos o con herramientas de terceros.</li> <li>LXD gestiona instancias, que pueden ser de tipos: contenedores, usando LXC internamente, y m\u00e1quinas virtuales usando QEMU internamente.</li> </ul>"},{"location":"01.-KVM/08.-LXC/06.-Introducci%C3%B3n%20a%20LXD/#instalacion-de-lxd","title":"Instalaci\u00f3n de LXD","text":"<p>Vamos a usar el gestor de paquetes snap (si est\u00e1s trabajando con la distribuci\u00f3n Debian 11 debes instalar el paquete <code>snapd</code>).</p> <pre><code>sudo snap install lxd\n</code></pre> <p>En la versi\u00f3n Debian 12 lo podemos instalar con <code>apt</code>:</p> <pre><code>apt install lxd\n</code></pre> <p>Antes de ejecutar una instancia (contenedor o m\u00e1quina virtual) tenemos que hacer una configuraci\u00f3n inicial de LXD, para ello ejecutamos como root:</p> <pre><code>lxd init\n</code></pre> <p>Interactivamente nos va preguntando distintos par\u00e1metros que nos permitir\u00e1n realizar la configuraci\u00f3n inicial:</p> <pre><code>Would you like to use LXD clustering? (yes/no) [default=no]: \nDo you want to configure a new storage pool? (yes/no) [default=yes]: \nName of the new storage pool [default=default]: \nName of the storage backend to use (cephobject, dir, lvm, btrfs, ceph) [default=btrfs]: dir\nWould you like to connect to a MAAS server? (yes/no) [default=no]: \nWould you like to create a new local network bridge? (yes/no) [default=yes]: \nWhat should the new bridge be called? [default=lxdbr0]: \nWhat IPv4 address should be used? (CIDR subnet notation, \u201cauto\u201d or \u201cnone\u201d) [default=auto]: \nWhat IPv6 address should be used? (CIDR subnet notation, \u201cauto\u201d or \u201cnone\u201d) [default=auto]: \nWould you like the LXD server to be available over the network? (yes/no) [default=no]: \nWould you like stale cached images to be updated automatically? (yes/no) [default=yes]: \nWould you like a YAML \"lxd init\" preseed to be printed? (yes/no) [default=no]: \n</code></pre> <p>Hemos dejado todos los valores por defecto, a excepci\u00f3n del tipo de pool de almacenamiento que he indicado que sea un directorio (dir). Tambi\u00e9n ha creado una red puente para conectar los contenedores.</p>"},{"location":"01.-KVM/08.-LXC/06.-Introducci%C3%B3n%20a%20LXD/#creacion-de-un-contenedor","title":"Creaci\u00f3n de un contenedor","text":"<p>Para crear un contenedor, ejecutamos:</p> <pre><code>lxc launch &lt;image_server&gt;:&lt;image_name&gt; &lt;instance_name&gt;\n</code></pre> <p>Por ejemplo:</p> <pre><code>lxc launch images:ubuntu/20.04 ubuntu-container\n</code></pre>"},{"location":"01.-KVM/08.-LXC/06.-Introducci%C3%B3n%20a%20LXD/#creacion-de-maquinas-virtuales","title":"Creaci\u00f3n de m\u00e1quinas virtuales","text":"<p>Para crear una m\u00e1quina virtual, ejecutamos:</p> <pre><code>lxc launch &lt;image_server&gt;:&lt;image_name&gt; &lt;instance_name&gt; --vm\n</code></pre> <p>Por ejemplo:</p> <pre><code>lxc launch images:ubuntu/20.04 ubuntu-vm --vm\n</code></pre> <p>Y comprobamos que hemos creado un contenedor y una m\u00e1quina virtual:</p> <pre><code>lxc list\n+------------------+---------+-------------------------+-------------------------------------------------+-----------------+-----------+\n|       NAME       |  STATE  |          IPV4           |                      IPV6                       |      TYPE       | SNAPSHOTS |\n+------------------+---------+-------------------------+-------------------------------------------------+-----------------+-----------+\n| ubuntu-container | RUNNING | 10.242.154.69 (eth0)    | fd42:40c4:7788:440e:216:3eff:fe61:66b0 (eth0)   | CONTAINER       | 0         |\n+------------------+---------+-------------------------+-------------------------------------------------+-----------------+-----------+\n| ubuntu-vm        | RUNNING | 10.242.154.119 (enp5s0) | fd42:40c4:7788:440e:216:3eff:fea3:8748 (enp5s0) | VIRTUAL-MACHINE | 0         |\n+------------------+---------+-------------------------+-------------------------------------------------+-----------------+-----------+\n</code></pre>"},{"location":"01.-KVM/08.-LXC/06.-Introducci%C3%B3n%20a%20LXD/#gestion-de-imagenes","title":"Gesti\u00f3n de im\u00e1genes","text":"<p>En la creaci\u00f3n de las dos instancias hemos descargado dos im\u00e1genes que podemos gestionar con el subcomando <code>lxc image</code>, por ejemplo para ver las im\u00e1genes que hemos descargado:</p> <pre><code>lxc image  list\n+-------+--------------+--------+-------------------------------------+--------------+-----------------+----------+------------------------------+\n| ALIAS | FINGERPRINT  | PUBLIC |             DESCRIPTION             | ARCHITECTURE |      TYPE       |   SIZE   |         UPLOAD DATE          |\n+-------+--------------+--------+-------------------------------------+--------------+-----------------+----------+------------------------------+\n|       | 3aa3fa64e5d0 | no     | Ubuntu focal amd64 (20220911_07:42) | x86_64       | VIRTUAL-MACHINE | 230.98MB | Sep 12, 2022 at 7:28am (UTC) |\n+-------+--------------+--------+-------------------------------------+--------------+-----------------+----------+------------------------------+\n|       | 7628425e768e | no     | Ubuntu focal amd64 (20220911_07:42) | x86_64       | CONTAINER       | 110.65MB | Sep 12, 2022 at 7:22am (UTC) |\n+-------+--------------+--------+-------------------------------------+--------------+-----------------+----------+------------------------------+\n</code></pre> <p>Para m\u00e1s informaci\u00f3n ejecuta <code>lxc image --help</code>.</p>"},{"location":"01.-KVM/08.-LXC/06.-Introducci%C3%B3n%20a%20LXD/#gestion-de-instancia","title":"Gesti\u00f3n de instancia","text":"<p>Vamos a usar la utilidad de l\u00ednea de comandos <code>lxc</code>, para ver todas las funcionalidades puedes ejecutar <code>lxc --help</code>. Veamos algunas de ella:</p> <ul> <li><code>lxc list</code>: Listar instancias. Podemos filtrar la lista, por ejemplo <code>lxc list type=container</code> o <code>lxc list ubuntu.*</code>.</li> <li><code>lxc info</code>: Nos da informaci\u00f3n de una instancia. Con la opci\u00f3n <code>--show-log</code> nos muestra los logs de la instancia.</li> <li><code>lxc start</code>: Inicia una instancia.</li> <li><code>lxc stop</code>: Detiene una instancia.</li> <li><code>lxc delete</code>: Borra una instancia.</li> </ul> <p>Si queremos ejecutar un comando en una instancia, ejecutamos:</p> <pre><code>lxc exec &lt;instance_name&gt; -- &lt;command&gt;\n</code></pre> <p>Por ejemplo:</p> <pre><code>lxc exec ubuntu-container -- apt update\n</code></pre> <p>Si queremos acceder a una shell de la instancia:</p> <pre><code>lxc exec ubuntu-container -- /bin/bash\n</code></pre> <p>Si queremos conectarnos a una instancia por una consola, ejecutamos:</p> <pre><code>lxc console &lt;instance_name&gt;\n</code></pre> <p>Nota: Deber\u00edamos configurar una contrase\u00f1a para un usuario anteriormente accediendo al bash de la instancia.</p>"},{"location":"01.-KVM/08.-LXC/06.-Introducci%C3%B3n%20a%20LXD/#configuracion-de-las-instancias","title":"Configuraci\u00f3n de las instancias","text":"<p>Tenemos muchos par\u00e1metros de configuraci\u00f3n de las instancias, que podemos devivir en tres bloques: propiedades de las instancias, openciones de las instancias y dispositivos de las instancias.</p> <p>Al crear una instancia podemos indicar los par\u00e1metros de configuraci\u00f3n deseados, por ejemplo, si queremos limitar el n\u00famero de CPU y la memoria de un contenedor, podemos ejecutar:</p> <pre><code>lxc launch images:ubuntu/20.04 ubuntu-limited -c limits.cpu=1 -c limits.memory=192MiB\n</code></pre> <p>Con el subcomando <code>lxc config</code> podemos gestionar la configuraci\u00f3n de las instancias, por ejemplo para mostrar la configuraci\u00f3n de una instancia, ejecutamos:</p> <pre><code>lxc config show ubuntu-container\n</code></pre> <p>Por ejemplo, para cambiar un par\u00e1metro:</p> <pre><code>lxc config set ubuntu-container limits.memory=128MiB\n</code></pre>"},{"location":"01.-KVM/08.-LXC/06.-Introducci%C3%B3n%20a%20LXD/#para-seguir-profundizando","title":"Para seguir profundizando","text":"<ul> <li>M\u00e1s informaci\u00f3n sobre la configuraci\u00f3n de instancias.</li> <li>M\u00e1s informaci\u00f3n sobre la gesti\u00f3n de im\u00e1genes.</li> <li>Con el subcomando <code>lxc network</code> gestionamos las redes. M\u00e1s informaci\u00f3n.</li> <li>Con el subcomando <code>lxc storage</code> gestionamos los pools de almacenamiento. M\u00e1s informaci\u00f3n.</li> </ul>"},{"location":"01.-KVM/09.-Anexos/01.-Uso%20de%20los%20puertos%20USB%20en%20KVM/","title":"01.-Uso de los puertos USB en KVM","text":""},{"location":"01.-KVM/09.-Anexos/01.-Uso%20de%20los%20puertos%20USB%20en%20KVM/#tutorial-uso-de-un-puerto-usb-en-una-maquina-virtual-kvmqemu","title":"Tutorial: Uso de un puerto USB en una m\u00e1quina virtual KVM/QEMU","text":""},{"location":"01.-KVM/09.-Anexos/01.-Uso%20de%20los%20puertos%20USB%20en%20KVM/#requisitos-previos","title":"Requisitos previos","text":"<ul> <li>Tienes instalado y configurado KVM y QEMU en tu m\u00e1quina host.</li> <li>Tienes una m\u00e1quina virtual (MV) ya creada y en funcionamiento en tu sistema de virtualizaci\u00f3n KVM/QEMU.</li> <li>El puerto USB y los dispositivos que quieres conectar deben estar f\u00edsicamente accesibles en tu host.</li> </ul>"},{"location":"01.-KVM/09.-Anexos/01.-Uso%20de%20los%20puertos%20USB%20en%20KVM/#pasos-para-usar-un-puerto-usb-en-una-mv-kvmqemu","title":"Pasos para usar un puerto USB en una MV KVM/QEMU","text":""},{"location":"01.-KVM/09.-Anexos/01.-Uso%20de%20los%20puertos%20USB%20en%20KVM/#1-verificar-dispositivos-usb-en-el-host","title":"1. Verificar dispositivos USB en el host","text":"<p>Primero, debemos identificar los dispositivos USB conectados en el host que queremos pasar a la m\u00e1quina virtual.</p> <ol> <li>Abre una terminal en el host.</li> <li>Ejecuta el comando:    <code>bash    lsusb</code>    Esto listar\u00e1 todos los dispositivos USB conectados. El formato de salida se ver\u00e1 algo como esto:    <code>Bus 001 Device 003: ID 0951:16a4 Kingston Technology    Bus 001 Device 002: ID 8087:0024 Intel Corp. Integrated Rate Matching Hub</code></li> </ol> <p>Toma nota del Bus y Device ID del dispositivo USB que deseas conectar a tu m\u00e1quina virtual (en este caso, <code>Bus 001 Device 003</code>).</p>"},{"location":"01.-KVM/09.-Anexos/01.-Uso%20de%20los%20puertos%20USB%20en%20KVM/#2-anadir-el-dispositivo-usb-a-la-mv-con-virt-manager","title":"2. A\u00f1adir el dispositivo USB a la MV con virt-manager","text":"<p>Si prefieres una interfaz gr\u00e1fica, puedes usar virt-manager para a\u00f1adir el dispositivo USB a tu MV.</p> <ol> <li>Abre virt-manager:    <code>bash    virt-manager</code></li> <li>Selecciona la m\u00e1quina virtual a la que deseas conectar el USB.</li> <li>Haz clic en el bot\u00f3n de Detalles de la MV (icono de herramientas).</li> <li>Navega a la pesta\u00f1a Add Hardware (Agregar Hardware).</li> <li>Selecciona USB Host Device en la lista y elige el dispositivo USB que aparece en la lista (ej. \"Kingston Technology\").</li> <li>Haz clic en Finish o Apply para a\u00f1adir el dispositivo USB a la m\u00e1quina virtual.</li> </ol>"},{"location":"01.-KVM/09.-Anexos/01.-Uso%20de%20los%20puertos%20USB%20en%20KVM/#3-anadir-el-dispositivo-usb-a-la-mv-desde-la-linea-de-comandos-virsh","title":"3. A\u00f1adir el dispositivo USB a la MV desde la l\u00ednea de comandos (virsh)","text":"<p>Si prefieres trabajar con la terminal, puedes a\u00f1adir el dispositivo USB usando el comando <code>virsh</code>.</p> <ol> <li> <p>Aseg\u00farate de que tu MV est\u00e9 detenida antes de agregar el dispositivo USB:    <code>bash    virsh shutdown &lt;nombreMV&gt;</code></p> </li> <li> <p>Agrega el dispositivo USB usando el comando <code>virsh attach-device</code>:    <code>bash    virsh attach-device &lt;nombreMV&gt; --file &lt;path_al_xml_del_dispositivo&gt;</code></p> </li> </ol> <p>El archivo XML debe tener la siguiente estructura:    <code>xml    &lt;hostdev mode='subsystem' type='usb'&gt;      &lt;source&gt;        &lt;vendor id='0x0951'/&gt;        &lt;product id='0x16a4'/&gt;      &lt;/source&gt;    &lt;/hostdev&gt;</code></p> <p>Donde <code>vendor id</code> y <code>product id</code> son los valores que obtuviste con <code>lsusb</code>. En este caso, <code>0951</code> es el vendor id de Kingston, y <code>16a4</code> es el product id.</p> <ol> <li>Inicia la m\u00e1quina virtual de nuevo:    <code>bash    virsh start &lt;nombreMV&gt;</code></li> </ol>"},{"location":"01.-KVM/09.-Anexos/01.-Uso%20de%20los%20puertos%20USB%20en%20KVM/#4-verificar-el-dispositivo-usb-en-la-mv","title":"4. Verificar el dispositivo USB en la MV","text":"<p>Una vez que hayas agregado el dispositivo USB, inicia sesi\u00f3n en tu m\u00e1quina virtual (por ejemplo, mediante <code>virt-manager</code> o SSH). Luego:</p> <ol> <li>Abre una terminal en la MV.</li> <li>Ejecuta el comando:    <code>bash    lsusb</code>    El dispositivo USB deber\u00eda aparecer en la lista dentro de la MV.</li> </ol>"},{"location":"01.-KVM/09.-Anexos/01.-Uso%20de%20los%20puertos%20USB%20en%20KVM/#notas-adicionales","title":"Notas adicionales:","text":"<ul> <li> <p>Desconectar el dispositivo USB: Para desconectar el dispositivo USB de la MV mientras est\u00e1 en funcionamiento, puedes usar el siguiente comando:   <code>bash   virsh detach-device &lt;nombreMV&gt; &lt;path_al_xml_del_dispositivo&gt;</code></p> </li> <li> <p>Acceso exclusivo: Cuando conectas un dispositivo USB a una MV, este dispositivo ya no estar\u00e1 accesible desde el host hasta que se desasocie de la MV.</p> </li> <li> <p>Compatibilidad: Aseg\u00farate de que los drivers necesarios para el dispositivo USB est\u00e1n instalados tanto en el host como en la m\u00e1quina virtual para evitar problemas de compatibilidad.</p> </li> </ul>"},{"location":"01.-KVM/09.-Anexos/02.-Copiar%20y%20Pegar/","title":"Tutorial: Configurar KVM para permitir copiar y pegar entre m\u00e1quinas virtuales","text":""},{"location":"01.-KVM/09.-Anexos/02.-Copiar%20y%20Pegar/#configuracion-para-los-modos-graficos","title":"Configuraci\u00f3n para los modos gr\u00e1ficos","text":""},{"location":"01.-KVM/09.-Anexos/02.-Copiar%20y%20Pegar/#requisitos-previos","title":"Requisitos previos","text":"<ul> <li>Tienes KVM y QEMU instalados y funcionando correctamente en tu m\u00e1quina host.</li> <li>Tienes una m\u00e1quina virtual (MV) creada y en funcionamiento.</li> </ul>"},{"location":"01.-KVM/09.-Anexos/02.-Copiar%20y%20Pegar/#pasos-para-habilitar-la-funcionalidad-de-copiar-y-pegar-portapapeles-compartido","title":"Pasos para habilitar la funcionalidad de copiar y pegar (Portapapeles compartido)","text":"<p>Para poder copiar y pegar texto entre el host y las m\u00e1quinas virtuales, debes instalar y configurar un conjunto de herramientas llamado Spice. Spice es un protocolo que, entre otras cosas, permite habilitar la compartici\u00f3n del portapapeles.</p>"},{"location":"01.-KVM/09.-Anexos/02.-Copiar%20y%20Pegar/#paso-1-instalar-spice-en-el-host","title":"Paso 1: Instalar Spice en el host","text":"<ol> <li>Abre una terminal en tu host.</li> <li>Aseg\u00farate de que tienes instalado el paquete <code>spice-vdagent</code> en el host. Ejecuta:  <code>bash  sudo apt update  sudo apt install spice-vdagent</code></li> </ol> <p>En otras distribuciones, puedes utilizar el gestor de paquetes de tu sistema (por ejemplo, <code>dnf</code> en Fedora).</p>"},{"location":"01.-KVM/09.-Anexos/02.-Copiar%20y%20Pegar/#paso-2-configurar-la-maquina-virtual-en-virt-manager","title":"Paso 2: Configurar la m\u00e1quina virtual en <code>virt-manager</code>","text":"<ol> <li>Abre virt-manager en tu host:  <code>bash  virt-manager</code></li> <li>Selecciona la m\u00e1quina virtual a la que deseas agregar la funcionalidad de copiar y pegar.</li> <li>Haz clic en el bot\u00f3n de Detalles de la MV (icono de herramientas).</li> <li>En el men\u00fa de la izquierda, selecciona la opci\u00f3n Display Spice (o Display en algunas versiones).</li> <li>Aseg\u00farate de que el servidor de Spice est\u00e9 seleccionado para la visualizaci\u00f3n y no VNC.</li> <li>Navega a la pesta\u00f1a de Video dentro de la configuraci\u00f3n de la m\u00e1quina virtual y selecciona el controlador QXL como el dispositivo de video.</li> <li>Guarda los cambios y arranca la m\u00e1quina virtual.</li> </ol>"},{"location":"01.-KVM/09.-Anexos/02.-Copiar%20y%20Pegar/#paso-3-instalar-spice-y-spice-vdagent-en-la-maquina-virtual","title":"Paso 3: Instalar Spice y <code>spice-vdagent</code> en la m\u00e1quina virtual","text":"<p>Dependiendo del sistema operativo que est\u00e9s utilizando en la m\u00e1quina virtual, necesitar\u00e1s instalar el spice-vdagent para habilitar la funcionalidad de portapapeles compartido.</p>"},{"location":"01.-KVM/09.-Anexos/02.-Copiar%20y%20Pegar/#en-linux-debianubuntu","title":"En Linux (Debian/Ubuntu)","text":"<ol> <li>Abre una terminal dentro de la m\u00e1quina virtual.</li> <li>Instala el paquete <code>spice-vdagent</code> ejecutando:  <code>bash  sudo apt update  sudo apt install spice-vdagent</code></li> <li>Reinicia la m\u00e1quina virtual para que los cambios surtan efecto.</li> </ol>"},{"location":"01.-KVM/09.-Anexos/02.-Copiar%20y%20Pegar/#en-windows","title":"En Windows","text":"<ol> <li>Descarga e instala los Spice Guest Tools desde este enlace.</li> <li>Sigue el asistente de instalaci\u00f3n para agregar los controladores de Spice a tu sistema Windows.</li> <li>Reinicia la m\u00e1quina virtual.</li> </ol>"},{"location":"01.-KVM/09.-Anexos/02.-Copiar%20y%20Pegar/#paso-4-probar-copiar-y-pegar","title":"Paso 4: Probar copiar y pegar","text":"<ol> <li>Una vez reiniciada la m\u00e1quina virtual, intenta copiar texto desde el host (por ejemplo, selecciona texto y presiona <code>Ctrl+C</code>).</li> <li>Luego, ve a la m\u00e1quina virtual, selecciona un \u00e1rea de texto y presiona <code>Ctrl+V</code> para pegar.</li> <li>Verifica que el texto copiado se haya transferido correctamente.</li> </ol>"},{"location":"01.-KVM/09.-Anexos/02.-Copiar%20y%20Pegar/#notas-adicionales","title":"Notas adicionales:","text":"<ul> <li> <p>Spice-vdagent es el agente responsable de la compartici\u00f3n del portapapeles, entre otras funciones (como la redirecci\u00f3n de dispositivos USB).</p> </li> <li> <p>Adem\u00e1s de copiar y pegar texto, tambi\u00e9n puedes redimensionar autom\u00e1ticamente la ventana de la m\u00e1quina virtual si usas el controlador de video QXL.</p> </li> <li> <p>En virt-manager, aseg\u00farate siempre de que est\u00e1s utilizando Spice en lugar de VNC para habilitar estas funciones avanzadas.</p> </li> </ul>"},{"location":"01.-KVM/09.-Anexos/02.-Copiar%20y%20Pegar/#opciones-para-copiar-y-pegar-en-modo-texto","title":"Opciones para copiar y pegar en modo texto","text":"<p>Si est\u00e1s utilizando dos m\u00e1quinas virtuales con Ubuntu Server o cualquier sistema operativo sin entorno gr\u00e1fico, las funciones de Spice relacionadas con el portapapeles compartido (copiar y pegar) no estar\u00e1n disponibles. Esto es porque Spice est\u00e1 dise\u00f1ado para trabajar con entornos gr\u00e1ficos, y depende del agente Spice (<code>spice-vdagent</code>), que requiere una interfaz gr\u00e1fica para habilitar la funcionalidad de copiar y pegar, junto con otras caracter\u00edsticas como la redimensi\u00f3n de pantalla.</p> <p>Dado que en servidores o sistemas en modo texto (sin GUI) no hay un entorno gr\u00e1fico, el agente Spice y los controladores de video como QXL no se pueden usar.</p>"},{"location":"01.-KVM/09.-Anexos/02.-Copiar%20y%20Pegar/#alternativas-para-copiar-y-pegar-entre-maquinas-virtuales-sin-entorno-grafico","title":"Alternativas para copiar y pegar entre m\u00e1quinas virtuales sin entorno gr\u00e1fico:","text":"<p>Aunque Spice no funcionar\u00e1 en este caso, hay varias maneras de transferir texto y archivos entre m\u00e1quinas virtuales en modo texto:</p>"},{"location":"01.-KVM/09.-Anexos/02.-Copiar%20y%20Pegar/#ssh-con-acceso-directo-o-redireccionamiento-de-comandos","title":"SSH con acceso directo o redireccionamiento de comandos:","text":"<p>Puedes conectarte entre las m\u00e1quinas virtuales o entre la m\u00e1quina host y las m\u00e1quinas virtuales usando SSH. Esto te permite copiar texto o archivos sin necesidad de un portapapeles compartido.</p> <p>Para copiar un archivo desde el host a la m\u00e1quina virtual:</p> <pre><code>scp archivo.txt usuario@direccion_ip_maquina_virtual:/ruta/destino/\n</code></pre> <p>Para copiar directamente un texto como un comando:</p> <pre><code>ssh usuario@direccion_ip_maquina_virtual 'echo \"Texto a copiar\" &gt; archivo.txt'\n</code></pre> <p>Esto es particularmente \u00fatil para transferir grandes bloques de texto o scripts entre m\u00e1quinas.</p>"},{"location":"01.-KVM/09.-Anexos/02.-Copiar%20y%20Pegar/#directorio-compartido-con-nfs-o-samba","title":"Directorio compartido con NFS o Samba:","text":"<p>Puedes configurar un sistema de archivos compartido entre las m\u00e1quinas virtuales utilizando NFS o Samba. Esto te permite copiar archivos o contenido en un directorio com\u00fan al que ambas m\u00e1quinas virtuales puedan acceder.</p> <p>Configura un directorio compartido en una m\u00e1quina y monta ese directorio en la otra. Todo lo que copies o crees en ese directorio ser\u00e1 accesible en ambas m\u00e1quinas. Esto es \u00fatil para transferir archivos grandes o colaborar en proyectos entre m\u00e1quinas.</p>"},{"location":"01.-KVM/09.-Anexos/02.-Copiar%20y%20Pegar/#uso-de-herramientas-como-tmux-o-screen","title":"Uso de herramientas como tmux o screen:","text":"<p>Si necesitas trabajar simult\u00e1neamente en ambas m\u00e1quinas virtuales desde la terminal, puedes usar herramientas como <code>tmux</code> o <code>screen</code>, que permiten compartir sesiones de terminal entre m\u00e1quinas o usuarios.</p> <p>Una sesi\u00f3n compartida de <code>tmux</code> te permite acceder a una misma terminal desde dos ubicaciones diferentes (como desde las dos m\u00e1quinas virtuales). Esto puede simular un flujo de trabajo de copiar y pegar, aunque no es exactamente lo mismo que un portapapeles compartido.</p>"},{"location":"01.-KVM/09.-Anexos/02.-Copiar%20y%20Pegar/#redireccionamiento-de-puertos-o-utilizacion-de-herramientas-como-rsync","title":"Redireccionamiento de Puertos o Utilizaci\u00f3n de Herramientas como rsync","text":"<p>Si la sincronizaci\u00f3n de archivos o carpetas es un tema recurrente, puedes usar herramientas como rsync para sincronizar directorios y archivos entre las m\u00e1quinas virtuales. Esto tambi\u00e9n es \u00fatil para mantener el contenido actualizado en tiempo real entre ambas m\u00e1quinas.</p> <p>Ejemplo con rsync:</p> <pre><code>rsync -avz /ruta/origen usuario@direccion_ip_maquina_virtual:/ruta/destino\n</code></pre>"},{"location":"01.-KVM/09.-Anexos/02.-Copiar%20y%20Pegar/#conclusion","title":"Conclusi\u00f3n","text":"<p>Para servidores sin entorno gr\u00e1fico (como Ubuntu Server), la funcionalidad de Spice para copiar y pegar no es aplicable. En su lugar, puedes usar herramientas como SSH, scp, rsync, directorio compartido o <code>tmux</code> para transferir texto, archivos y comandos entre m\u00e1quinas virtuales. Estas alternativas son ideales para entornos sin GUI.</p>"},{"location":"01.-KVM/10.-Pr%C3%A1cticas/","title":"Ejercicios KVM","text":""},{"location":"01.-KVM/10.-Pr%C3%A1cticas/#ejercicio-1-verificacion-del-soporte-de-virtualizacion-en-el-host","title":"Ejercicio 1: Verificaci\u00f3n del Soporte de Virtualizaci\u00f3n en el Host","text":"<p>Tarea: Ejecuta el comando <code>egrep -E -c '(vmx|svm)' /proc/cpuinfo</code> en tu m\u00e1quina host para verificar si el procesador soporta virtualizaci\u00f3n por hardware (Intel VT o AMD-V).</p> <p>Instrucciones:</p> <ul> <li>Abre una terminal en tu sistema Linux.</li> <li>Ejecuta el comando indicado.</li> <li>Si el resultado es mayor que 0, la virtualizaci\u00f3n est\u00e1 habilitada.  Objetivo: Verificar que el hardware soporta la creaci\u00f3n de m\u00e1quinas virtuales con KVM.</li> </ul>"},{"location":"01.-KVM/10.-Pr%C3%A1cticas/#ejercicio-2-instalacion-de-kvm-y-herramientas-de-virtualizacion","title":"Ejercicio 2: Instalaci\u00f3n de KVM y Herramientas de Virtualizaci\u00f3n","text":"<p>Tarea: Instala el paquete qemu-kvm, libvirt-bin, y virt-manager en una distribuci\u00f3n Linux (por ejemplo, Ubuntu) y habilita el servicio de libvirtd.</p> <p>Instrucciones:</p> <ul> <li> <p>Ejecuta <code>apt install qemu-system libvirt-clients libvirt-daemon-system</code>.</p> </li> <li> <p>Habilita el servicio con <code>sudo systemctl enable libvirtd</code> y luego in\u00edcialo con sudo <code>systemctl start libvirtd</code>.</p> </li> <li> <p>Verifica la correcta instalaci\u00f3n ejecutando <code>virsh list --all</code>.</p> </li> </ul> <p>Objetivo: Preparar el sistema para crear y administrar m\u00e1quinas virtuales.</p>"},{"location":"01.-KVM/10.-Pr%C3%A1cticas/#ejercicio-3-creacion-de-una-maquina-virtual-desde-la-cli","title":"Ejercicio 3: Creaci\u00f3n de una M\u00e1quina Virtual desde la CLI","text":"<p>Tarea: Utiliza el comando <code>virt-install</code> para crear una m\u00e1quina virtual Ubuntu desde la l\u00ednea de comandos con un disco de 10GB y 2GB de RAM.</p> <p>Instrucciones:</p> <ul> <li>Descarga una imagen de Ubuntu Server (ISO).</li> <li>Ejecuta el siguiente comando:</li> </ul> <pre><code>sudo virt-install --name UbuntuVM \\\n  --ram 2048 \\\n  --vcpus 2 \\\n  --disk path=/var/lib/libvirt/images/ubuntu.qcow2,size=10 \\\n  --location ~/&lt;nombre_distribuci\u00f3n&gt;,kernel=casper/vmlinuz,initrd=casper/initrd \\\n  --os-variant ubuntu24.04 \\\n  --network bridge=virbr0 \\\n  --graphics none \\\n  --console pty,target_type=serial \\\n  --extra-args 'console=ttyS0,115200n8 serial'\n</code></pre> <p>Sigue el proceso de instalaci\u00f3n a trav\u00e9s de la consola.</p> <p>Objetivo: Crear y administrar una m\u00e1quina virtual usando solo la CLI.</p>"},{"location":"01.-KVM/10.-Pr%C3%A1cticas/#ejercicio-4-creacion-de-un-disco-virtual-adicional-para-una-mv-existente","title":"Ejercicio 4: Creaci\u00f3n de un Disco Virtual Adicional para una MV Existente","text":"<p>Tarea: A\u00f1adir un segundo disco virtual de 5GB a una m\u00e1quina virtual existente. Instrucciones:</p> <ul> <li> <p>Det\u00e9n la m\u00e1quina virtual con <code>virsh shutdown &lt;nombreMV&gt;</code>.</p> </li> <li> <p>Usa el comando <code>virsh edit &lt;nombreMV&gt;</code> para editar la configuraci\u00f3n XML de la m\u00e1quina.</p> </li> <li> <p>A\u00f1ade la siguiente secci\u00f3n en el archivo XML:</p> </li> </ul> <pre><code>&lt;disk type='file' device='disk'&gt;\n   &lt;driver name='qemu' type='qcow2'/&gt;\n   &lt;source file='/var/lib/libvirt/images/disk2.qcow2'/&gt;\n   &lt;target dev='vdb' bus='virtio'/&gt;\n&lt;/disk&gt;\n</code></pre> <ul> <li>Guarda el archivo y arranca la MV de nuevo.</li> </ul> <p>Objetivo: Familiarizarse con la administraci\u00f3n de almacenamiento adicional en una MV. \u00a1 OJO !:: Debes crear el disco virtual previamente. </p>"},{"location":"01.-KVM/10.-Pr%C3%A1cticas/#ejercicio-5-migracion-en-vivo-de-una-mv-a-otro-host","title":"Ejercicio 5: Migraci\u00f3n en Vivo de una MV a Otro Host","text":"<p>Tarea: Realizar una migraci\u00f3n en vivo de una m\u00e1quina virtual desde un host KVM a otro sin detenerla. Instrucciones: - Aseg\u00farate de que ambos hosts est\u00e1n configurados correctamente para permitir la migraci\u00f3n. - Ejecuta el siguiente comando desde el host origen:</p> <pre><code>$ virsh migrate --live &lt;nombreMV&gt; qemu+ssh://user@destination/system\n</code></pre> <ul> <li>Verifica que la MV sigue ejecut\u00e1ndose en el host destino con virsh list.</li> </ul> <p>Objetivo: Ejecutar una migraci\u00f3n en vivo para mejorar la disponibilidad y el mantenimiento de sistemas.</p> <p>\u00a1 OJO !: Antes de realizar la migraci\u00f3n en vivo, aseg\u00farate de que los siguientes aspectos est\u00e1n configurados correctamente en ambos hosts (origen y destino):</p> <ul> <li>Ambos hosts deben usar KVM/QEMU con libvirt.</li> <li>SSH sin contrase\u00f1a: Configura la autenticaci\u00f3n sin contrase\u00f1a entre el host origen y destino mediante claves SSH.</li> <li>Almacenamiento compartido o accesible: Aseg\u00farate de que el almacenamiento de la m\u00e1quina virtual (im\u00e1genes de disco) est\u00e1 accesible desde ambos hosts (por ejemplo, a trav\u00e9s de NFS, iSCSI, etc.). La migraci\u00f3n en vivo requiere que los archivos de disco de la VM sean accesibles desde el host de destino.</li> <li>Ambos hosts deben tener las mismas versiones de QEMU/KVM y libvirt para asegurar la compatibilidad.</li> </ul>"},{"location":"01.-KVM/10.-Pr%C3%A1cticas/#ejercicio-6-uso-de-snapshots-en-mvs","title":"Ejercicio 6: Uso de Snapshots en MVs","text":"<p>Tarea: Crear un snapshot de una m\u00e1quina virtual en funcionamiento y restaurarla a ese punto despu\u00e9s de realizar cambios en el sistema operativo. Instrucciones:</p> <ul> <li>Para crear un snapshot:</li> </ul> <pre><code>$virsh snapshot-create-as --domain &lt;nombreMV&gt; --name \"snapshot1\" --description \"Estado limpio antes de actualizaciones\"\n</code></pre> <p>Realiza algunos cambios en la MV, como instalar software o modificar configuraciones. Restaura el estado anterior usando:</p> <pre><code>virsh snapshot-revert &lt;nombreMV&gt; snapshot1\n</code></pre> <p>Objetivo: Aprender a utilizar snapshots para la recuperaci\u00f3n r\u00e1pida de MVs.</p>"},{"location":"01.-KVM/10.-Pr%C3%A1cticas/#ejercicio-7-configuracion-de-nat-en-la-red-virtual","title":"Ejercicio 7: Configuraci\u00f3n de NAT en la Red Virtual","text":"<p>Tarea: Configurar NAT para las m\u00e1quinas virtuales, permitiendo que accedan a Internet a trav\u00e9s del host.</p> <p>Instrucciones:</p> <ul> <li>Edita el archivo de red default con el siguiente comando:</li> </ul> <pre><code>virsh net-edit default\n</code></pre> <ul> <li>Configura el modo de red en NAT, verificando la conectividad de la MV hacia el exterior.</li> </ul> <p>Usa <code>ping</code> desde la MV para verificar que puede acceder a Internet.</p> <p>Objetivo: Configurar redes virtuales para conectar MVs con redes externas.</p>"},{"location":"01.-KVM/10.-Pr%C3%A1cticas/#ejercicio-8-creacion-de-una-maquina-virtual-con-virt-manager","title":"Ejercicio 8: Creaci\u00f3n de una M\u00e1quina Virtual con Virt-Manager","text":"<p>Tarea: Utiliza la interfaz gr\u00e1fica virt-manager para crear una m\u00e1quina virtual Windows 10 con 4GB de RAM y un disco de 20GB. Instrucciones:</p> <ul> <li>Abre virt-manager y selecciona la opci\u00f3n para crear una nueva m\u00e1quina.</li> <li>Sigue las instrucciones para elegir la imagen de instalaci\u00f3n y configurar los recursos de la m\u00e1quina.</li> <li>Inicia la instalaci\u00f3n de Windows desde la interfaz gr\u00e1fica.</li> </ul> <p>Objetivo: Familiarizarse con la administraci\u00f3n de MVs desde la interfaz gr\u00e1fica.</p>"},{"location":"01.-KVM/10.-Pr%C3%A1cticas/#ejercicio-9-clonacion-de-una-maquina-virtual","title":"Ejercicio 9: Clonaci\u00f3n de una M\u00e1quina Virtual","text":"<p>Tarea: Clona una m\u00e1quina virtual existente y c\u00e1mbiale el nombre y la direcci\u00f3n MAC de la interfaz de red. Instrucciones:</p> <ul> <li>Ejecuta el comando:</li> </ul> <pre><code>$ virt-clone --original &lt;nombreMV&gt; --name &lt;nombreClon&gt; --file /var/lib/libvirt/images/&lt;nombreClon&gt;.qcow2\n</code></pre> <p>Edita la direcci\u00f3n MAC para evitar conflictos de red:</p> <pre><code>$ virsh edit &lt;nombreClon&gt;\n</code></pre> <ul> <li>Busca la secci\u00f3n de la interfaz de red y cambia el valor de la direcci\u00f3n MAC.</li> </ul> <p>Objetivo: Dominar la clonaci\u00f3n y personalizaci\u00f3n de m\u00e1quinas virtuales.</p>"},{"location":"01.-KVM/10.-Pr%C3%A1cticas/#ejercicio-10-implementacion-de-contenedores-lxc","title":"Ejercicio 10: Implementaci\u00f3n de Contenedores LXC","text":"<p>Tarea: Crear un contenedor LXC en el entorno KVM, configurando las capacidades de red compartida con el host. Instrucciones: - Instala LXC con sudo apt install lxc. - Crea un contenedor b\u00e1sico:</p> <pre><code>lxc-create -n mycontainer -t ubuntu\n</code></pre> <ul> <li>Configura el acceso a la red compartida entre el contenedor y el host.</li> <li>Inicia el contenedor con lxc-start.</li> </ul> <p>Objetivo: Integrar la tecnolog\u00eda de contenedores dentro del entorno de virtualizaci\u00f3n KVM.</p>"},{"location":"01.-KVM/10.-Pr%C3%A1cticas/01.-Instrucciones%20para%20la%20captura/","title":"01.-Instrucciones para la captura","text":""},{"location":"01.-KVM/10.-Pr%C3%A1cticas/01.-Instrucciones%20para%20la%20captura/#ejercicio-1-verificacion-del-soporte-de-virtualizacion-en-el-host","title":"Ejercicio 1: Verificaci\u00f3n del soporte de virtualizaci\u00f3n en el host","text":"<p>Instrucciones para la captura:</p> <ol> <li> <p>Abre una terminal en tu sistema Linux.</p> </li> <li> <p>Ejecuta el comando: <code>bash    egrep -c '(vmx|svm)' /proc/cpuinfo</code></p> </li> <li> <p>Aseg\u00farate de que el resultado del comando sea visible en la terminal.</p> </li> <li> <p>Haz una captura de pantalla mostrando claramente la terminal con el comando ejecutado y el resultado visible.</p> </li> </ol>"},{"location":"01.-KVM/10.-Pr%C3%A1cticas/01.-Instrucciones%20para%20la%20captura/#ejercicio-2-instalacion-de-kvm-y-herramientas-de-virtualizacion","title":"Ejercicio 2: Instalaci\u00f3n de KVM y herramientas de virtualizaci\u00f3n","text":"<p>Instrucciones para la captura:</p> <ol> <li> <p>Abre una terminal.</p> </li> <li> <p>Ejecuta el siguiente comando para mostrar que los paquetes necesarios est\u00e1n instalados:     <code>bash    dpkg -l | grep -E 'qemu-kvm|libvirt-bin|virt-manager'</code></p> </li> <li> <p>Aseg\u00farate de que la salida de los paquetes instalados se vea completa en la terminal.</p> </li> <li> <p>Haz una captura de pantalla mostrando el resultado en la terminal con el comando ejecutado.</p> </li> </ol>"},{"location":"01.-KVM/10.-Pr%C3%A1cticas/01.-Instrucciones%20para%20la%20captura/#ejercicio-3-creacion-de-una-maquina-virtual-desde-la-cli","title":"Ejercicio 3: Creaci\u00f3n de una m\u00e1quina virtual desde la CLI","text":"<p>Instrucciones para la captura:</p> <ol> <li> <p>Tras haber creado la m\u00e1quina virtual usando el comando <code>virt-install</code>, abre una terminal.</p> </li> <li> <p>Ejecuta el comando para listar las m\u00e1quinas virtuales:    <code>bash    virsh list --all</code></p> </li> <li> <p>Aseg\u00farate de que el nombre de la MV que has creado est\u00e9 en la lista.</p> </li> <li> <p>Haz una captura de pantalla de la terminal mostrando el comando y la salida con la MV visible.</p> </li> </ol>"},{"location":"01.-KVM/10.-Pr%C3%A1cticas/01.-Instrucciones%20para%20la%20captura/#ejercicio-4-creacion-de-un-disco-virtual-adicional-para-una-mv-existente","title":"Ejercicio 4: Creaci\u00f3n de un disco virtual adicional para una MV existente","text":"<p>Instrucciones para la captura:</p> <ol> <li> <p>Abre una terminal y ejecuta el siguiente comando para verificar que el segundo disco ha sido a\u00f1adido correctamente:    <code>bash    virsh domblklist &lt;nombreMV&gt;</code></p> </li> <li> <p>Aseg\u00farate de que la salida muestre tanto el disco principal como el disco adicional (<code>vdb</code>).</p> </li> <li> <p>Haz una captura de pantalla de la terminal con el comando ejecutado y los discos listados.</p> </li> </ol>"},{"location":"01.-KVM/10.-Pr%C3%A1cticas/01.-Instrucciones%20para%20la%20captura/#ejercicio-5-migracion-en-vivo-de-una-mv-a-otro-host-opcional","title":"Ejercicio 5: Migraci\u00f3n en vivo de una MV a otro host (Opcional)","text":"<p>Instrucciones para la captura:</p> <ol> <li> <p>Realiza la migraci\u00f3n en vivo de la MV a otro host.</p> </li> <li> <p>En el host de origen, ejecuta el comando:    <code>bash    virsh list --all</code></p> </li> <li> <p>Aseg\u00farate de que la MV ya no est\u00e9 en la lista del host de origen.</p> </li> <li> <p>En el host de destino, ejecuta el mismo comando <code>virsh list --all</code> y aseg\u00farate de que la MV aparece en la lista.</p> </li> <li> <p>Haz una captura de pantalla de ambas terminales (host origen y host destino) mostrando la migraci\u00f3n completada.</p> </li> </ol>"},{"location":"01.-KVM/10.-Pr%C3%A1cticas/01.-Instrucciones%20para%20la%20captura/#ejercicio-6-uso-de-snapshots-en-mvs","title":"Ejercicio 6: Uso de Snapshots en MVs","text":"<p>Instrucciones para la captura:</p> <ol> <li> <p>Tras crear el snapshot, ejecuta el siguiente comando para listar los snapshots de la m\u00e1quina virtual:    <code>bash    virsh snapshot-list &lt;nombreMV&gt;</code></p> </li> <li> <p>Aseg\u00farate de que el snapshot creado est\u00e9 en la lista.</p> </li> <li> <p>Haz una captura de pantalla de la terminal con el comando ejecutado y el snapshot visible.</p> </li> </ol>"},{"location":"01.-KVM/10.-Pr%C3%A1cticas/01.-Instrucciones%20para%20la%20captura/#ejercicio-7-configuracion-de-nat-en-la-red-virtual","title":"Ejercicio 7: Configuraci\u00f3n de NAT en la Red Virtual","text":"<p>Instrucciones para la captura:</p> <ol> <li> <p>Abre una terminal y edita la red predeterminada con el comando:    <code>bash    virsh net-edit default</code></p> </li> <li> <p>Captura la ventana mostrando la configuraci\u00f3n de la red en modo de edici\u00f3n.</p> </li> <li> <p>Luego, ejecuta el comando:    <code>bash    virsh net-list</code></p> </li> <li> <p>Aseg\u00farate de que la red NAT est\u00e9 activa.</p> </li> <li> <p>Haz una captura de pantalla mostrando la configuraci\u00f3n y el estado de la red.</p> </li> </ol>"},{"location":"01.-KVM/10.-Pr%C3%A1cticas/01.-Instrucciones%20para%20la%20captura/#ejercicio-8-creacion-de-una-mv-con-virt-manager","title":"Ejercicio 8: Creaci\u00f3n de una MV con Virt-Manager","text":"<p>Instrucciones para la captura:</p> <ol> <li> <p>Abre <code>virt-manager</code> y navega hasta la m\u00e1quina virtual que creaste con esta herramienta.</p> </li> <li> <p>Muestra la ventana de la MV donde se vea su nombre, los recursos asignados (RAM, disco, etc.), y que est\u00e1 en ejecuci\u00f3n.</p> </li> <li> <p>Haz una captura de pantalla de la interfaz de <code>virt-manager</code> con estos detalles visibles.</p> </li> </ol>"},{"location":"01.-KVM/10.-Pr%C3%A1cticas/01.-Instrucciones%20para%20la%20captura/#ejercicio-9-clonacion-de-una-maquina-virtual","title":"Ejercicio 9: Clonaci\u00f3n de una M\u00e1quina Virtual","text":"<p>Instrucciones para la captura:</p> <ol> <li> <p>Despu\u00e9s de haber clonado la MV, ejecuta en una terminal:    <code>bash    virsh list --all</code></p> </li> <li> <p>Aseg\u00farate de que tanto la m\u00e1quina original como el clon est\u00e1n en la lista, mostrando claramente los dos nombres.</p> </li> <li> <p>Haz una captura de pantalla de la terminal con ambos nombres de m\u00e1quinas visibles.</p> </li> </ol>"},{"location":"01.-KVM/10.-Pr%C3%A1cticas/01.-Instrucciones%20para%20la%20captura/#ejercicio-10-implementacion-de-contenedores-lxc","title":"Ejercicio 10: Implementaci\u00f3n de Contenedores LXC","text":"<p>Instrucciones para la captura:</p> <ol> <li> <p>Despu\u00e9s de crear el contenedor LXC, ejecuta el siguiente comando para verificar que el contenedor est\u00e1 en funcionamiento:    <code>bash    lxc-ls --fancy</code></p> </li> <li> <p>Aseg\u00farate de que el contenedor que has creado est\u00e9 listado con su nombre y estado.</p> </li> <li> <p>Haz una captura de pantalla mostrando el comando y la lista de contenedores.</p> </li> </ol>"},{"location":"01.-KVM/10.-Pr%C3%A1cticas/02.-Solucionario/","title":"02.-Solucionario","text":""},{"location":"01.-KVM/10.-Pr%C3%A1cticas/02.-Solucionario/#ejercicio-1-verificacion-del-soporte-de-virtualizacion-en-el-host","title":"Ejercicio 1: Verificaci\u00f3n del soporte de virtualizaci\u00f3n en el host","text":"<ul> <li> <p>Abro una terminal en el host.</p> </li> <li> <p>Ejecuto el comando:</p> </li> </ul> <pre><code>egrep -c '(vmx|svm)' /proc/cpuinfo\n</code></pre> <p>Resultado:  </p> <pre><code>2\n</code></pre> <p>Esto indica que la CPU del host soporta virtualizaci\u00f3n por hardware.</p>"},{"location":"01.-KVM/10.-Pr%C3%A1cticas/02.-Solucionario/#ejercicio-2-instalacion-de-kvm-y-herramientas-de-virtualizacion","title":"Ejercicio 2: Instalaci\u00f3n de KVM y herramientas de virtualizaci\u00f3n","text":"<ul> <li>Abro una terminal en el host.</li> <li>Ejecuto los siguientes comandos para instalar KVM y las herramientas necesarias:</li> </ul> <pre><code>sudo apt update\nsudo apt upgrade\nsudo apt install qemu-system libvirt-clients libvirt-daemon-system\n\n</code></pre> <p>Resultado:  </p> <p>KVM y <code>virt-manager</code> est\u00e1n instalados exitosamente.</p> <ul> <li>Verifico que el servicio de <code>libvirtd</code> est\u00e1 activo:</li> </ul> <pre><code>sudo systemctl status libvirtd\n</code></pre> <p>Resultado: El servicio de <code>libvirtd</code> est\u00e1 corriendo y habilitado.</p>"},{"location":"01.-KVM/10.-Pr%C3%A1cticas/02.-Solucionario/#ejercicio-3-creacion-de-una-maquina-virtual-desde-la-cli","title":"Ejercicio 3: Creaci\u00f3n de una m\u00e1quina virtual desde la CLI","text":"<ul> <li>Descargo una imagen ISO de Ubuntu Server.</li> <li>Creo una m\u00e1quina virtual desde la CLI usando el siguiente comando:</li> </ul> <pre><code>sudo virt-install \\\n  --name UbuntuVM \\\n  --ram 2048 \\\n  --vcpus 2 \\\n  --disk path=/var/lib/libvirt/images/ubuntu.qcow2,size=10 \\\n  --cdrom /home/tu_usuario/Descargas/ubuntu-20.04.iso \\\n  --os-variant ubuntu20.04 \\\n  --network bridge=virbr0 \\\n  --graphics none \\\n  --console pty,target_type=serial \\\n  --extra-args 'console=ttyS0,115200n8 serial'\n</code></pre> <ul> <li>Verifico que la MV est\u00e1 creada:</li> </ul> <pre><code>$ virsh list --all\n</code></pre> <p>Resultado: La m\u00e1quina virtual <code>UbuntuVM</code> aparece en la lista con el estado apagada o running si se ha iniciado correctamente.</p>"},{"location":"01.-KVM/10.-Pr%C3%A1cticas/02.-Solucionario/#ejercicio-4-creacion-de-un-disco-virtual-adicional-para-una-mv-existente","title":"Ejercicio 4: Creaci\u00f3n de un disco virtual adicional para una MV existente","text":"<ul> <li>Detengo la m\u00e1quina virtual:</li> </ul> <pre><code>virsh shutdown UbuntuVM\n</code></pre> <ul> <li>Crear un Disco Virtual con <code>qemu-img</code> y A\u00f1adirlo con <code>virsh</code></li> </ul> <pre><code>qemu-img create -f qcow2 /var/lib/libvirt/images/disk1.qcow2 5G\n</code></pre> <ul> <li>Edici\u00f3n del archivo XML de la MV para agregar un segundo disco:</li> </ul> <pre><code>virsh edit UbuntuVM\n</code></pre> <ul> <li>Agrego el siguiente bloque XML para el disco adicional:</li> </ul> <pre><code>&lt;disk type='file' device='disk'&gt;\n  &lt;driver name='qemu' type='qcow2'/&gt;\n  &lt;source file='/var/lib/libvirt/images/disk1.qcow2'/&gt;\n  &lt;target dev='vdb' bus='virtio'/&gt;\n&lt;/disk&gt;\n</code></pre> <ul> <li>Tambi\u00e9n se puede hacer la asociaci\u00f3n usando el comando <code>virsh-attach-disk</code>del siguiente modo:</li> </ul> <pre><code>virsh attach-disk &lt;nombre-de-la-vm&gt; /var/lib/libvirt/images/disk1.qcow2 vdb --targetbus virtio --persistent\n</code></pre> <ul> <li>Inicio la MV de nuevo:</li> </ul> <pre><code>virsh start UbuntuVM\n</code></pre> <ul> <li>Verifico los discos conectados:</li> </ul> <pre><code>virsh domblklist UbuntuVM\n</code></pre> <p>Resultado: La MV muestra los discos conectados, incluyendo <code>vda</code> (disco original) y <code>vdb</code> (nuevo disco).</p>"},{"location":"01.-KVM/10.-Pr%C3%A1cticas/02.-Solucionario/#nota-aclaratoria","title":"Nota Aclaratoria:","text":"<ul> <li>\u00bfPor qu\u00e9 <code>virsh edit</code> abre un archivo ubicado en el directorio <code>/tmp</code>?</li> </ul> <p>Cuando ejecutas el comando:</p> <pre><code>virsh edit ubuntu_server\n</code></pre> <p>virsh realiza lo siguiente:</p> <ul> <li>Generaci\u00f3n del Archivo Temporal: Crea una copia de la configuraci\u00f3n XML actual de la m\u00e1quina virtual ubuntu_server en un archivo temporal dentro de /tmp. Esto permite que realices modificaciones sin afectar directamente el archivo de configuraci\u00f3n original.</li> <li>Edici\u00f3n de la Configuraci\u00f3n: Abre el archivo temporal en tu editor de texto predeterminado (como vi, nano, etc.). Aqu\u00ed puedes realizar los cambios que consideres necesarios.</li> <li>Validaci\u00f3n y Aplicaci\u00f3n de Cambios: Al guardar y cerrar el editor, virsh valida la sintaxis del XML modificado. Si la validaci\u00f3n es exitosa, libvirt aplica los cambios a la configuraci\u00f3n persistente de la m\u00e1quina virtual. El archivo temporal en /tmp se descarta autom\u00e1ticamente.</li> </ul>"},{"location":"01.-KVM/10.-Pr%C3%A1cticas/02.-Solucionario/#ejercicio-5-migracion-en-vivo-de-una-mv-a-otro-host","title":"Ejercicio 5: Migraci\u00f3n en vivo de una MV a otro host","text":""},{"location":"01.-KVM/10.-Pr%C3%A1cticas/02.-Solucionario/#configurar-la-autenticacion-ssh-sin-contrasena","title":"Configurar la Autenticaci\u00f3n SSH sin Contrase\u00f1a","text":"<ul> <li> <p>Primero, aseg\u00farate de que puedes acceder al host de destino desde el host de origen mediante SSH sin contrase\u00f1a.</p> </li> <li> <p>Genera una clave SSH en el host de origen (si no la tienes):</p> </li> </ul> <pre><code>ssh-keygen\n</code></pre> <ul> <li>Copia la clave p\u00fablica al host de destino:</li> </ul> <pre><code>ssh-copy-id user@destination_host\n</code></pre> <ul> <li>Ahora deber\u00edas poder conectarte al host de destino desde el host de origen sin que se te solicite una contrase\u00f1a.</li> </ul>"},{"location":"01.-KVM/10.-Pr%C3%A1cticas/02.-Solucionario/#verificar-que-el-almacenamiento-es-compartido-o-accesible","title":"Verificar que el Almacenamiento es Compartido o Accesible","text":"<ul> <li>Aseg\u00farate de que el almacenamiento de la m\u00e1quina virtual, como los discos virtuales (im\u00e1genes .qcow2, .img, etc.), es accesible por ambos hosts. Para ello, utiliza un sistema de archivos compartido como NFS o iSCSI.</li> </ul>"},{"location":"01.-KVM/10.-Pr%C3%A1cticas/02.-Solucionario/#verificar-que-los-hosts-estan-preparados-para-la-migracion","title":"Verificar que los Hosts est\u00e1n Preparados para la Migraci\u00f3n","text":"<ul> <li>En ambos hosts, verifica que el servicio libvirtd est\u00e9 ejecut\u00e1ndose:</li> </ul> <pre><code>sudo systemctl status libvirtd\n</code></pre> <ul> <li> <p>Tambi\u00e9n aseg\u00farate de que las m\u00e1quinas virtuales est\u00e1n accesibles mediante virsh list.</p> </li> <li> <p>En el host de origen, ejecuto:</p> </li> </ul> <pre><code>virsh migrate --live UbuntuVM qemu+ssh://user@destination/system\n</code></pre>"},{"location":"01.-KVM/10.-Pr%C3%A1cticas/02.-Solucionario/#verificar-que-la-mv-ha-sido-migrada-correctamente","title":"Verificar que la MV ha sido migrada correctamente","text":"<ul> <li>En el host de origen:   <code>bash   virsh list --all</code> Resultado:   La MV no aparece en el host de origen.</li> <li>En el host de destino:   <code>bash   virsh list --all</code> Resultado:   La MV <code>UbuntuVM</code> aparece en el host de destino y est\u00e1 corriendo.</li> </ul>"},{"location":"01.-KVM/10.-Pr%C3%A1cticas/02.-Solucionario/#ejercicio-6-uso-de-snapshots-en-mvs","title":"Ejercicio 6: Uso de Snapshots en MVs","text":"<ul> <li>Creo un snapshot de la m\u00e1quina virtual:</li> </ul> <pre><code>virsh snapshot-create-as --domain UbuntuVM --name \"snapshot1\" --description \"Estado limpio antes de actualizaciones\"\n</code></pre> <ul> <li>Listo los snapshots creados:</li> </ul> <pre><code>virsh snapshot-list UbuntuVM\n</code></pre> <p>Resultado: El snapshot <code>snapshot1</code> aparece en la lista. - Realizo algunos cambios en el sistema. - Restaura el snapshot:</p> <pre><code>virsh snapshot-revert UbuntuVM snapshot1\n</code></pre> <p>Resultado: La MV se ha revertido al estado del snapshot.</p>"},{"location":"01.-KVM/10.-Pr%C3%A1cticas/02.-Solucionario/#ejercicio-7-configuracion-de-nat-en-la-red-virtual","title":"Ejercicio 7: Configuraci\u00f3n de NAT en la Red Virtual","text":"<ul> <li>Edito la configuraci\u00f3n de la red predeterminada:</li> </ul> <pre><code>virsh net-edit default\n</code></pre> <ul> <li>Verifico que la red est\u00e1 configurada en modo NAT.</li> <li>Verifico que la red est\u00e1 activa:</li> </ul> <pre><code>virsh net-list\n</code></pre> <p>Resultado: La red <code>default</code> est\u00e1 activa y las m\u00e1quinas virtuales pueden acceder a Internet a trav\u00e9s de NAT.</p>"},{"location":"01.-KVM/10.-Pr%C3%A1cticas/02.-Solucionario/#ejercicio-8-creacion-de-una-mv-con-virt-manager","title":"Ejercicio 8: Creaci\u00f3n de una MV con Virt-Manager","text":"<ul> <li>Abro <code>virt-manager</code>.</li> <li>Creo una nueva m\u00e1quina virtual seleccionando la imagen ISO de Windows 10, asignando 4GB de RAM y un disco de 20GB.</li> <li>Inicio la instalaci\u00f3n y sigo las instrucciones.</li> <li>Verifico que la MV est\u00e1 creada y en ejecuci\u00f3n en <code>virt-manager</code>.</li> </ul>"},{"location":"01.-KVM/10.-Pr%C3%A1cticas/02.-Solucionario/#ejercicio-9-clonacion-de-una-maquina-virtual","title":"Ejercicio 9: Clonaci\u00f3n de una M\u00e1quina Virtual","text":"<ul> <li>Clono la MV <code>UbuntuVM</code>:</li> </ul> <pre><code>virt-clone --original UbuntuVM --name UbuntuClone --file /var/lib/libvirt/images/UbuntuClone.qcow2\n</code></pre> <ul> <li>Verifico que tanto la m\u00e1quina original como el clon est\u00e1n presentes:</li> </ul> <pre><code>virsh list --all\n</code></pre> <p>Resultado: Ambas m\u00e1quinas (<code>UbuntuVM</code> y <code>UbuntuClone</code>) aparecen en la lista.</p>"},{"location":"01.-KVM/10.-Pr%C3%A1cticas/02.-Solucionario/#ejercicio-10-implementacion-de-contenedores-lxc","title":"Ejercicio 10: Implementaci\u00f3n de Contenedores LXC","text":"<ul> <li>Creo un contenedor LXC en el entorno KVM:</li> </ul> <pre><code>lxc-create -n mycontainer -t ubuntu\n</code></pre> <ul> <li>Inicio el contenedor:</li> </ul> <pre><code>lxc-start -n mycontainer\n</code></pre> <ul> <li>Verifico que el contenedor est\u00e1 en ejecuci\u00f3n:</li> </ul> <pre><code>lxc-ls --fancy\n</code></pre> <p>Resultado: El contenedor <code>mycontainer</code> aparece en la lista y est\u00e1 corriendo.</p>"},{"location":"02.-SSH/","title":"SSH","text":"<p>SSH es esencial para la administraci\u00f3n de sistemas y DevOps, clave para el control remoto de servidores y la gesti\u00f3n segura de la infraestructura. Proporciona un acceso seguro y cifrado, fundamental para proteger datos sensibles y garantizar la seguridad de la comunicaci\u00f3n entre cliente y servidor. Adem\u00e1s, SSH permite realizar tareas administrativas desde cualquier lugar, lo cual es imprescindible para equipos de TI que gestionan infraestructuras en la nube o sistemas distribuidos.</p> <p>Con la configuraci\u00f3n adecuada, puedes mejorar la productividad y simplificar muchas tareas y, todo ello, en un entorno m\u00e1s seguro.</p> <p>Arqu\u00edmedes habr\u00eda dicho: \"Dame acceso por SSH y controlar\u00e9 el mundo.\"</p>"},{"location":"02.-SSH/02.-Instalaci%C3%B3n%20del%20entorno%20de%20pruebas/","title":"02.-Instalaci\u00f3n del entorno de pruebas","text":"<p>Habitualmente los equipos con alguna variedad de GNU/Linux traen un servidor <code>ssh</code> instalado, en el caso de los sistemas Debian y derivados el paquete que proporciona el servidor <code>ssh</code> se llama <code>openssh-server</code>.</p> <p>Podemos comprobar si ya est\u00e1 instalado mediante la instrucci\u00f3n:</p> <pre><code>dpkg -l | grep openssh-server\n</code></pre> <p>o si est\u00e1 en marcha con</p> <pre><code>systemctl status sshd\n</code></pre> <p>o con <code>ps</code></p> <pre><code>ps aux | grep sshd\n</code></pre> <p>o bien comprobando la escucha sobre el puerto 22 con</p> <pre><code>ss -lntp\n</code></pre> <p>En caso de no estarlo, podemos instalarlo con:</p> <pre><code>sudo apt-get install openssh-server\n</code></pre> <p>\u00f3 en Arch con </p> <pre><code>pacman -S openssh\n</code></pre> <p>El fichero de configuraci\u00f3n de este servicio se encuentra habitualmente en <code>/etc/ssh/sshd_config</code> y contiene las opciones de configuraci\u00f3n.</p> <p>Las opciones aplicadas las obtendr\u00edamos mediante:</p> <pre><code>grep -v '^$\\|^#' /etc/ssh/sshd_config\n\nChallengeResponseAuthentication no\nUsePAM yes\nX11Forwarding yes\nPrintMotd no\nAcceptEnv LANG LC_*\nSubsystem    sftp    /usr/lib/openssh/sftp-server\n</code></pre> <p>Sin embargo, en el caso de <code>ssh</code> hay muchas opciones que no vienen definidas y que se asume un valor por defecto, lo que puede resultar confuso. Sin embargo podemos utilizar la opci\u00f3n <code>-T: extended test mode</code> que comprueba la validez del fichero de configuraci\u00f3n y muestra las opciones efectivas que se aplican (las que est\u00e1n habilitadas de forma expl\u00edcita y las que tienen valores por defecto (en sistemas GNU/Linux <code>sshd</code> solo puede ejecutarlo un usuario privilegiado):</p> <pre><code>sshd -T\n...\nport 22\naddressfamily any\nlistenaddress [::]:22\nlistenaddress 0.0.0.0:22\nusepam yes\nlogingracetime 120\nx11displayoffset 10\nmaxauthtries 6\nmaxsessions 10\nclientaliveinterval 120\nclientalivecountmax 3\nstreamlocalbindmask 0177\npermitrootlogin without-password\nignorerhosts yes\nignoreuserknownhosts no\nhostbasedauthentication no\nhostbasedusesnamefrompacketonly no\npubkeyauthentication yes\nkerberosauthentication no\nkerberosorlocalpasswd yes\nkerberosticketcleanup yes\ngssapiauthentication no\ngssapikeyexchange no\ngssapicleanupcredentials yes\ngssapistrictacceptorcheck yes\ngssapistorecredentialsonrekey no\npasswordauthentication yes\nkbdinteractiveauthentication no\nchallengeresponseauthentication no\nprintmotd no\nprintlastlog yes\nx11forwarding yes\nx11uselocalhost yes\npermittty yes\npermituserrc yes\nstrictmodes yes\ntcpkeepalive yes\npermitemptypasswords no\npermituserenvironment no\ncompression yes\ngatewayports no\nusedns no\nallowtcpforwarding yes\nallowagentforwarding yes\ndisableforwarding no\nallowstreamlocalforwarding yes\nstreamlocalbindunlink no\nuseprivilegeseparation sandbox\nfingerprinthash SHA256\npidfile /run/sshd.pid\nxauthlocation /usr/bin/xauth\nciphers chacha20-poly1305@openssh.com,aes128-ctr, ...\nmacs umac-64-etm@openssh.com,umac-128-etm@openssh.com, ...\nversionaddendum none\nkexalgorithms curve25519-sha256,curve25519-sha256@libssh.org, ...\nhostbasedacceptedkeytypes ecdsa-sha2-nistp256-cert-v01@openssh.com, ...\nhostkeyalgorithms ecdsa-sha2-nistp256-cert-v01@openssh.com, ...\npubkeyacceptedkeytypes ecdsa-sha2-nistp256-cert-v01@openssh.com, ...\nloglevel INFO\nsyslogfacility AUTH\nauthorizedkeysfile .ssh/authorized_keys .ssh/authorized_keys2\nhostkey /etc/ssh/ssh_host_rsa_key\nhostkey /etc/ssh/ssh_host_ecdsa_key\nhostkey /etc/ssh/ssh_host_ed25519_key\nacceptenv LANG\nacceptenv LC_*\nauthenticationmethods any\nsubsystem sftp /usr/lib/openssh/sftp-server\nmaxstartups 10:30:100\npermittunnel no\nipqos lowdelay throughput\nrekeylimit 0 0\npermitopen any\n</code></pre> <p>Muchas m\u00e1quinas vienen con un servidor <code>ssh</code> que s\u00f3lo permite acceder con clave p\u00fablica, por lo que no funciona inicialmente si nos intentamos conectar con usuario/contrase\u00f1a. Para poder hacerlo se debe descomentar el siguiente par\u00e1metro del fichero de configuraci\u00f3n <code>/etc/ssh/sshd_config</code>:</p> <pre><code>PasswordAuthentication yes\n</code></pre> <p>Y reiniciar el servidor <code>ssh</code> con:</p> <pre><code>systemctl restart ssh\n</code></pre>"},{"location":"02.-SSH/01.-Introducci%C3%B3n/01.-Caracter%C3%ADsticas%20Principales/01.-Precedentes.%20%60telnet%60%2C%20%60rlogin%60%20y%20%60rsh%60/","title":"01.-Precedentes. `telnet`, `rlogin` y `rsh`","text":"<ul> <li> <p>Shell remota</p> <ul> <li> <p>Remote login: <code>rlogin</code></p> </li> <li> <p>Remote shell: <code>rsh</code></p> </li> </ul> </li> <li> <p>Ejecuci\u00f3n remota de instrucciones</p> </li> <li> <p>Muy utilizado desde los a\u00f1os 70</p> </li> <li> <p>Autenticaci\u00f3n no cifrada</p> <ul> <li>La seguridad no era una preocupaci\u00f3n</li> </ul> </li> </ul>"},{"location":"02.-SSH/01.-Introducci%C3%B3n/01.-Caracter%C3%ADsticas%20Principales/02.-Cifrado%20Completo/","title":"02.-Cifrado Completo","text":"<ul> <li>Se cifra todo el proceso, tanto la autenticaci\u00f3n como toda la comunicaci\u00f3n</li> </ul>"},{"location":"02.-SSH/01.-Introducci%C3%B3n/01.-Caracter%C3%ADsticas%20Principales/03.-Historia%20de%20%60ssh%60/","title":"03.-Historia de `ssh`","text":"<ul> <li> <p>En 1995, Tatu Yl\u00f6nen crea <code>ssh</code></p> </li> <li> <p>Posteriormente funda SSH Communications Security (ssh.com)</p> </li> <li> <p>En 1999 se desarrolla OpenSSH</p> </li> </ul>"},{"location":"02.-SSH/01.-Introducci%C3%B3n/01.-Caracter%C3%ADsticas%20Principales/04.-OpenSSH/","title":"04.-OpenSSH","text":"<ul> <li> <p>Desarrollado en OpenBSD</p> </li> <li> <p>Escrito en C</p> </li> <li> <p>Licencia BSD simple, dominio p\u00fablico</p> </li> <li> <p>Ampliamente extendida</p> </li> <li> <p>Utilizada en BSD, GNU/Linux y UNIX</p> </li> <li> <p>Se apoya en el proyecto LibreSSL (Fork de OpenSSL tras heartbleed)</p> <ul> <li>OpenSSL es la biblioteca de seguridad en comunicaciones que utilizaba <code>openssh</code></li> </ul> </li> <li> <p>Programas</p> <ul> <li><code>ssh</code>, <code>scp</code>, <code>sftp</code>, <code>ssh-keygen</code>, <code>ssh-agent</code>, <code>sshd</code>, <code>ssh-keyscan</code></li> </ul> </li> <li> <p>Versiones</p> <ul> <li> <p>SSH-1</p> </li> <li> <p>SSH-2 incompatible con SSH-1. Incluye importantes mejoras:</p> <ul> <li> <p>D-H para intercambiar claves</p> </li> <li> <p>Verificaci\u00f3n de integridad mediante Message authentication code (MAC)</p> </li> <li> <p>M\u00faltiples sesiones en una conexi\u00f3n</p> </li> <li> <p>Actualmente s\u00f3lo se usa SSH-2</p> </li> </ul> </li> </ul> </li> </ul>"},{"location":"02.-SSH/01.-Introducci%C3%B3n/02.-Criptograf%C3%ADa/","title":"Index","text":"<p>Arte y t\u00e9cnica de escribir con procedimientos o claves secretas o de un modo enigm\u00e1tico, de tal forma que lo escrito solamente sea inteligible para quien sepa descifrarlo.</p> <p>En castellano son sin\u00f3nimos cifrar y encriptar, as\u00ed como las acciones inversas descifrar y desencriptar.</p>"},{"location":"02.-SSH/01.-Introducci%C3%B3n/02.-Criptograf%C3%ADa/01.-Criptograf%C3%ADa%20de%20clave%20sim%C3%A9trica/","title":"01.-Criptograf\u00eda de clave sim\u00e9trica","text":"<p>Se utiliza la misma clave para cifrar y descifrar</p> <ul> <li> <p>Algoritmos:</p> <ul> <li> <p>DES</p> </li> <li> <p>3DES</p> </li> <li> <p>IDEA</p> </li> <li> <p>Blowfish</p> </li> <li> <p>CAST5</p> </li> <li> <p>AES (Rijndael)</p> </li> </ul> </li> <li> <p>Mecanismo \u00e1mpliamente utilizado</p> </li> <li> <p>Principal limitaci\u00f3n:</p> <ul> <li>Comunicaci\u00f3n de la clave</li> </ul> </li> </ul>"},{"location":"02.-SSH/01.-Introducci%C3%B3n/02.-Criptograf%C3%ADa/02.-Clave%20asim%C3%A9trica%20o%20de%20clave%20p%C3%BAblica/","title":"02.-Clave asim\u00e9trica o de clave p\u00fablica","text":"<ul> <li> <p>Se crean dos claves relacionadas</p> <ul> <li> <p>clave privada</p> </li> <li> <p>clave p\u00fablica</p> </li> </ul> </li> <li> <p>La privada descifra lo cifrado por la p\u00fablica y al contrario</p> </li> <li> <p>Evita el problema del cifrado sim\u00e9trico</p> </li> <li> <p>Limitaciones</p> <ul> <li> <p>M\u00e1s complejo</p> </li> <li> <p>Menos algoritmos disponibles</p> </li> </ul> </li> <li> <p>Funcionamiento:</p> <ul> <li> <p>idea (International Data Encryption Algorithm)</p> </li> <li> <p>Algoritmos</p> <ul> <li> <p>Factorizaci\u00f3n de n\u00fameros primos (antiguos)</p> <ul> <li> <p>RSA (Antes protegido por patente ahora caducada)</p> </li> <li> <p>DSA</p> </li> <li> <p>Curvas el\u00edpticas (modernos: m\u00e1s r\u00e1pidos) ECDSA Ed25519</p> </li> </ul> </li> </ul> </li> </ul> </li> </ul>"},{"location":"02.-SSH/01.-Introducci%C3%B3n/02.-Criptograf%C3%ADa/03.-Funciones%20Hash/","title":"03.-Funciones Hash","text":"<p>Operaciones matem\u00e1ticas con las siguientes propiedades:</p> <ul> <li> <p>Mismo tama\u00f1o de resultado</p> </li> <li> <p>Unidireccionales</p> </li> <li> <p>No muestran informaci\u00f3n del origen</p> </li> <li> <p>Difieren con cualquier modificaci\u00f3n del origen</p> </li> </ul> <p>Funciones hash habituales</p> <ul> <li>CRC, MD5, Whirpool, Tiger, SHA-1, SHA-256, SHA-512, SHA-3</li> </ul>"},{"location":"02.-SSH/01.-Introducci%C3%B3n/03.-M%C3%A9todos%20de%20autenticaci%C3%B3n/","title":"Index","text":"<p>La autenticaci\u00f3n en el entorno de conexiones SSH (Secure Shell) es un proceso cr\u00edtico para asegurar el acceso remoto a servidores y dispositivos, utilizando m\u00e9todos robustos que garantizan la confidencialidad e integridad de la comunicaci\u00f3n. Existen varios tipos de autenticaci\u00f3n en conexiones SSH, cada uno con sus caracter\u00edsticas y niveles de seguridad.</p>"},{"location":"02.-SSH/01.-Introducci%C3%B3n/03.-M%C3%A9todos%20de%20autenticaci%C3%B3n/01.-Contrase%C3%B1a/","title":"01.-Contrase\u00f1a","text":"<ul> <li> <p>M\u00e9todo b\u00e1sico</p> </li> <li> <p>Usamos la contrase\u00f1a del usuario en el sistema remoto</p> </li> </ul>"},{"location":"02.-SSH/01.-Introducci%C3%B3n/03.-M%C3%A9todos%20de%20autenticaci%C3%B3n/02.-Clave%20P%C3%BAblica/","title":"02.-Clave P\u00fablica","text":"<ul> <li> <p>El usuario genera un par de claves p\u00fablica/privada</p> </li> <li> <p>Ubica la clave p\u00fablica en el equipo remoto</p> </li> <li> <p>Accede a su sesi\u00f3n sin contrase\u00f1a</p> </li> </ul>"},{"location":"02.-SSH/01.-Introducci%C3%B3n/03.-M%C3%A9todos%20de%20autenticaci%C3%B3n/03.-Kerberos/","title":"03.-Kerberos","text":"<ul> <li> <p>Principalmente en entornos corporativos</p> </li> <li> <p>Se solicita un ticket al servidor kerberos</p> </li> <li> <p>Kerberos proporciona SSO (Single Sign-On sesi\u00f3n de inicio \u00fanica)</p> </li> <li> <p>Permite comunicarse con cualquier servidor <code>ssh</code> kerberizado</p> </li> </ul>"},{"location":"02.-SSH/01.-Introducci%C3%B3n/03.-M%C3%A9todos%20de%20autenticaci%C3%B3n/04.-GSSAPI/","title":"04.-GSSAPI","text":"<ul> <li> <p>GSSAPI (Generic Security Services Application Program Interface) es una API est\u00e1ndar que proporciona servicios de autenticaci\u00f3n y seguridad a aplicaciones distribuidas. GSSAPI permite a las aplicaciones autenticarse entre s\u00ed utilizando mecanismos de seguridad sin tener que preocuparse por los detalles espec\u00edficos de cada uno de ellos. </p> </li> <li> <p>GSSAPI abstrae estos mecanismos para ofrecer una forma consistente de autenticaci\u00f3n y establecer una conexi\u00f3n segura. Es com\u00fanmente usado en combinaci\u00f3n con Kerberos, que es el mecanismo m\u00e1s utilizado para autenticaci\u00f3n en entornos empresariales.</p> </li> <li> <p>En el contexto de SSH, GSSAPI permite autenticarse en servidores sin necesidad de introducir manualmente credenciales, ya que puede utilizar los tickets de autenticaci\u00f3n de Kerberos que ya est\u00e9n disponibles en el sistema. Esto facilita la autenticaci\u00f3n \u00fanica (Single Sign-On) en entornos de red corporativos, mejorando la experiencia del usuario y la seguridad.</p> </li> <li> <p>Por ejemplo, si tienes configurado Kerberos en tu organizaci\u00f3n y habilitado GSSAPI para SSH, podr\u00edas acceder a servidores sin necesidad de escribir una contrase\u00f1a cada vez, porque el ticket de Kerberos ya proporciona las credenciales necesarias.</p> </li> </ul>"},{"location":"02.-SSH/01.-Introducci%C3%B3n/04.-Funcionamiento/","title":"Index","text":"<p>A continuaci\u00f3n se describen las principales fases del protocolo SSH, que permiten establecer una conexi\u00f3n segura y autenticada entre el cliente y el servidor, garantizando la confidencialidad e integridad de los datos intercambiados.</p>"},{"location":"02.-SSH/01.-Introducci%C3%B3n/04.-Funcionamiento/01.-Fase%201%20%28Negociaci%C3%B3n%29/","title":"01.-Fase 1 (Negociaci\u00f3n)","text":"<ul> <li> <p>El cliente se conecta al servidor</p> </li> <li> <p>El servidor muestra su versi\u00f3n de <code>ssh</code></p> </li> <li> <p>El cliente muestra su versi\u00f3n de <code>ssh</code></p> </li> <li> <p>El servidor env\u00eda su clave p\u00fablica</p> </li> <li> <p>El cliente verifica la huella de la clave p\u00fablica entre las que tiene guardadas</p> </li> <li> <p>Negocian qu\u00e9 algoritmo y semilla utilizar</p> </li> <li> <p>Ambos generan las claves de la sesi\u00f3n e intercambian la p\u00fablica para verificar que la otra parte lo ha hecho igual</p> </li> </ul>"},{"location":"02.-SSH/01.-Introducci%C3%B3n/04.-Funcionamiento/02.-Fase%202%20%28Autenticaci%C3%B3n%29/","title":"02.-Fase 2 (Autenticaci\u00f3n)","text":"<ul> <li> <p>Una vez establecida la clave de sesi\u00f3n se utiliza para cifrar toda la comunicaci\u00f3n</p> </li> <li> <p>El servidor ofrece en orden los m\u00e9todos de autenticaci\u00f3n disponibles</p> </li> <li> <p>El cliente los rechaza hasta que encuentra uno a utilizar</p> </li> <li> <p>Cuando el usuario se ha autenticado satisfactoriamente se abre una sesi\u00f3n en el equipo remoto</p> </li> </ul>"},{"location":"02.-SSH/03.-Uso%20de%20ssh/01.-Autenticaci%C3%B3n%20con%20usuario%20y%20contrase%C3%B1a/","title":"01.-Autenticaci\u00f3n con usuario y contrase\u00f1a","text":"<p>cd El m\u00e9todo inicial de autenticaci\u00f3n se basa en utilizar los usuarios del sistema y sus contrase\u00f1as que est\u00e1n almacenadas en \u00e9l. A SSH no le afecta la forma en la que el sistema las almacena (fichero, LDAP, etc.).</p> <p>Las opciones de configuraci\u00f3n que afectan en este caso son las siguientes:</p> <pre><code>passwordauthentication yes|no\nchallengeresponseauthentication yes|no\npermitemptypasswords yes|no\n</code></pre> <p>Te\u00f3ricamente <code>challengeresponseauthentication</code> es un mecanismo m\u00e1s complejo que permite preguntar al usuario otras cuestiones, no s\u00f3lo la contrase\u00f1a, pero en la pr\u00e1ctica se suele preguntar la contrase\u00f1a.</p> <p>En sistemas GNU/Linux se a\u00f1ade la opci\u00f3n</p> <pre><code>usepam yes\n</code></pre> <p>Que permite utilizar el subsistema PAM como mecanismo de autenticaci\u00f3n.</p>"},{"location":"02.-SSH/03.-Uso%20de%20ssh/01.-Autenticaci%C3%B3n%20con%20usuario%20y%20contrase%C3%B1a/#311-ejercicio-simple-de-acceso-con-usuariocontrasena","title":"3.1.1 Ejercicio simple de acceso con usuario/contrase\u00f1a","text":"<p>Accedemos a un servidor remoto con:</p> <pre><code>ssh usuario@172.22.200.175\nThe authenticity of host '172.22.200.175 (172.22.200.175)' can't be established.\nECDSA key fingerprint is SHA256:Bsv9OS7Qf94ANguOiDLNPHn7J+XlwisWZydmfqa4QMo.\nAre you sure you want to continue connecting (yes/no)?\n</code></pre> <p>Para verificar el servidor, en lugar de mostrarnos la clave p\u00fablica completa, nos muestra la huella (fingerprint) de la clave p\u00fablica del servidor, que no es m\u00e1s que un hash de la clave p\u00fablica, en este caso utlizando SHA256. Podemos comprobar la correspondencia entre la clave p\u00fablica y la huella mediante la instrucci\u00f3n:</p> <pre><code>ssh-keygen -l -E sha256 -f fichero_con_clave_publica\n</code></pre> <p>Se podr\u00eda hablar con detalle de la forma efectiva de verificar las claves p\u00fablicas, pero en este momento se aceptar\u00e1 la clave que se ofrece y por tanto se teclear\u00e1 \u201cyes\u201d y a continuaci\u00f3n se pide la contrase\u00f1a de acceso, se introduce y se accede a una shell en el equipo remoto:</p> <pre><code>Warning: Permanently added '172.22.200.175' (ECDSA) to the list of known hosts.\nusuario@172.22.200.175's password: **********\nLast login: Fri Feb 16 17:34:41 2018 from 172.23.0.22\nusuario@host:~$\n</code></pre>"},{"location":"02.-SSH/03.-Uso%20de%20ssh/01.-Autenticaci%C3%B3n%20con%20usuario%20y%20contrase%C3%B1a/#312-ejecucion-remota","title":"3.1.2 Ejecuci\u00f3n remota","text":"<p>SSH permite ejecutar una orden remotamente de forma no interactiva, lo que resulta muy c\u00f3modo cuando hay que realizar tareas muy espec\u00edficas en un equipo remoto. Por ejemplo:</p> <pre><code>ssh usuario@172.22.200.175 sudo apt update\n</code></pre> <p>Tambi\u00e9n se pueden encadenar varias \u00f3rdenes o ejecutar un script:</p> <pre><code>ssh usuario@172.22.200.175 'sudo apt update &amp;&amp; sudo apt upgrade'\n</code></pre>"},{"location":"02.-SSH/03.-Uso%20de%20ssh/01.-Autenticaci%C3%B3n%20con%20usuario%20y%20contrase%C3%B1a/#313-consideraciones-acerca-de-root","title":"3.1.3 Consideraciones acerca de root","text":"<p>Se puede restringir el acceso con el usuario root utilizando contrase\u00f1a, aspecto importante desde el punto de vista de seguridad, por lo que hoy en d\u00eda habitualmente se utiliza la opcion:</p> <pre><code>PermitRootLogin without-password\n</code></pre> <p>En caso de que quisi\u00e9ramos permitir acceder con el usuario root y contrase\u00f1a, deber\u00edamos poner esta opci\u00f3n a yes.</p>"},{"location":"02.-SSH/03.-Uso%20de%20ssh/01.-Autenticaci%C3%B3n%20con%20usuario%20y%20contrase%C3%B1a/#314-otras-opciones","title":"3.1.4 Otras opciones","text":"<p>No espec\u00edficas del acceso con usuario y contrase\u00f1a, pero adecuadas para empezar:</p> <pre><code>PrintLastLog yes|no\nPrintMotd yes|no\nBanner Ruta_a_fichero\n</code></pre>"},{"location":"02.-SSH/03.-Uso%20de%20ssh/02.-Autenticaci%C3%B3n%20con%20claves%20p%C3%BAblica-privada/","title":"02.-Autenticaci\u00f3n con claves p\u00fablica-privada","text":"<p>Aunque el mecanismo m\u00e1s f\u00e1cil de entender al utilizar <code>ssh</code> es la autenticaci\u00f3n del usuario mediante la contrase\u00f1a en el equipo remoto, el mecanismo m\u00e1s \u201cnatural\u201d y probablemente m\u00e1s habitual es la autenticaci\u00f3n mediante un par de claves p\u00fablica/privada.</p>"},{"location":"02.-SSH/03.-Uso%20de%20ssh/02.-Autenticaci%C3%B3n%20con%20claves%20p%C3%BAblica-privada/#321-creacion-de-la-clave-privada","title":"3.2.1 Creaci\u00f3n de la clave privada","text":"<p>Para crear la clave privada utilizaremos la herramienta <code>ssh-keygen</code>, especificando el algoritmo que deseamos utilizar mediante el par\u00e1metro -t (dsa | ecdsa | ed25519 | rsa | rsa1), por ejemplo:</p> <pre><code>ssh-keygen -t ecdsa\n</code></pre> <p>Se crear\u00e1 un di\u00e1logo mediante el cual nos pedir\u00e1 una frase de paso para proteger la clave privada, paso que se ignorar\u00e1 de momento y se explicar\u00e1 con detalle en la siguiente secci\u00f3n:</p> <pre><code>Generating public/private ecdsa key pair.\nEnter file in which to save the key (/home/alberto/.ssh/id_ecdsa): [ENTER]\nEnter passphrase (empty for no passphrase): [ENTER]\nEnter same passphrase again: [ENTER]\nYour identification has been saved in /home/alberto/.ssh/id_ecdsa.\nYour public key has been saved in /home/alberto/.ssh/id_ecdsa.pub.\nThe key fingerprint is:\nSHA256:QQ0bm3FBXKhLyWUfa7teeHgufwLPdK8nIu0UlMCJ6/M alberto@mut\nThe key's randomart image is:\n+---[ECDSA 256]---+\n|        =B==.    |\n|       ..BO...   |\n|       .=* .oo   |\n|        *. .+    |\n|       oS. ...   |\n|        +   o+. .|\n|         o .+*+..|\n|          E.=== +|\n|           +o++* |\n+----[SHA256]-----+\n</code></pre> <p>En este caso hemos optado por dejar el nombre de la clave por defecto (~/.ssh/idecdsa). Si vamos al directorio ~/.ssh veremos que existen dos nuevos ficheros, que se corresponden con la clave p\u00fablica y la privada:</p> <pre><code>-rw------- 1 alberto alberto   227 feb 18 09:16 id_ecdsa\n-rw-r--r-- 1 alberto alberto   173 feb 18 09:16 id_ecdsa.pub\n</code></pre> <p>L\u00f3gicamente la clave privada se ha protegido en el sistema de forma que s\u00f3lo el propietario puede leerla o modificarla, mientras que la p\u00fablica puede leerla cualquier usuario y en general podr\u00e1 estar accesible en cualquier sitio sin restricciones, ya que no es posible obtener la clave privada a partir de ella.</p> <p>Vemos el contenido de estas claves (obviamente se muestran aqu\u00ed a modo de ejemplo y se trata de claves que no se van a utilizar nunca en un entorno real):</p> <pre><code>~/.ssh/id_ecdsa\n-----BEGIN EC PRIVATE KEY-----\nMHcCAQEEIN53r8/ghcQ94wjNPtvz0VvSFsuU7ePsPkriWPhpC137oAoGCCqGSM49\nAwEHoUQDQgAEXJKU4yRlIdnKGG8qQA2PXpfCPVz9xpbB3TXOh9ymC9XtjgP3ZCwU\ntdNnLTQNJm8PO4MHtFZBTxeFE39lD7WVYQ==\n-----END EC PRIVATE KEY-----\n\n~/.ssh/id_ecdsa.pub \necdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAy\\\nNTYAAABBBFySlOMkZSHZyhhvKkANj16Xwj1c/caWwd01zofcpgvV7Y4D92QsFLXT\\\nZy00DSZvDzuDB7RWQU8XhRN/ZQ+1lWE= alberto@mut\n</code></pre>"},{"location":"02.-SSH/03.-Uso%20de%20ssh/02.-Autenticaci%C3%B3n%20con%20claves%20p%C3%BAblica-privada/#322-copia-de-la-clave-publica-en-el-equipo-remoto","title":"3.2.2 Copia de la clave p\u00fablica en el equipo remoto","text":"<p>Para que se pueda utilizar este mecanismo de autenticaci\u00f3n es preciso que la clave p\u00fablica del usuario se encuentre en la cuenta que \u00e9ste posee en el equipo remoto, de forma m\u00e1s concreta, dentro del fichero <code>~/.ssh/authorized_keys</code>, por lo que debemos utilizar alg\u00fan m\u00e9todo para ubicarla all\u00ed:</p> <ul> <li>Accedemos con contrase\u00f1a y copiamos y pegamos la clave p\u00fablica</li> <li>Accedemos con otra clave p\u00fablica que hubi\u00e9semos copiado previamente y pegamos la nueva clave p\u00fablica</li> <li>Utilizamos cualquier sistema en el arranque de la m\u00e1quina que obtenga la clave p\u00fablica y la ubique en su sitio (muy habitual en cloud computing)</li> <li>Utilizamos la herramienta <code>ssh-copy-id</code></li> </ul> <p>Vamos a ver el \u00faltimo m\u00e9todo:</p> <pre><code>ssh-copy-id -i ~/.ssh/id_ecdsa debian@172.22.200.175\n\n/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: \"/home/alberto/.ssh/id_ecdsa.pub\"\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\ndebian@172.22.200.175's password: \n\nNumber of key(s) added: 1\n\nNow try logging into the machine, with:   \"ssh 'debian@172.22.200.175'\"\nand check to make sure that only the key(s) you wanted were added.\n</code></pre> <p>Si accedemos al equipo remoto, podremos comprobar que la clave p\u00fablica que hemos exportado se encuentra en el fichero<code>~/.ssh/authorized_keys</code>.</p>"},{"location":"02.-SSH/03.-Uso%20de%20ssh/02.-Autenticaci%C3%B3n%20con%20claves%20p%C3%BAblica-privada/#323-clave-privada-con-nombre-no-estandar","title":"3.2.3 Clave privada con nombre no est\u00e1ndar","text":"<p>En el caso anterior hemos creado un par de claves con nombre est\u00e1ndar (<code>idecdsa</code> e <code>idecdsa.pub</code>), pero es posible definir cualquier nombre a la hora de crear el par de claves, por ejemplo:</p> <pre><code>ssh-keygen -t ed25519\nGenerating public/private ed25519 key pair.\nEnter file in which to save the key (/home/debian/.ssh/id_ed25519): openwebinars\nEnter passphrase (empty for no passphrase): \nEnter same passphrase again: \nYour identification has been saved in openwebinars.\nYour public key has been saved in openwebinars.pub.\nThe key fingerprint is:\nSHA256:HzEVg7wVelxLpuHrv+BUG8QG4bI0AsED7PnUvzFdlCI debian@asd\nThe key's randomart image is:\n+--[ED25519 256]--+\n|   ..oo. . .O++. |\n|    . o.  E*oXo. |\n|   . . o. B+*o=  |\n|    o . .o.B +.  |\n|     o  S.o...o  |\n|      .  .+o.. o |\n|          .++ .  |\n|          .o o   |\n|            . o. |\n+----[SHA256]-----+\n</code></pre> <p>Proceder\u00edamos de igual forma que en el caso anterior, aunque ahora para utilizar la clave en cualquier sesi\u00f3n <code>ssh</code>, deber\u00edamos indicarlo de forma expl\u00edcita:</p> <pre><code>ssh -i ~/.ssh/openwebinars debian@172.22.200.175\n</code></pre>"},{"location":"02.-SSH/03.-Uso%20de%20ssh/02.-Autenticaci%C3%B3n%20con%20claves%20p%C3%BAblica-privada/#324-utilizacion-en-cloud-computing","title":"3.2.4 Utilizaci\u00f3n en cloud computing","text":"<p>Hoy en d\u00eda es cada vez m\u00e1s habitual la utilizaci\u00f3n de m\u00e1quinas virtuales en alg\u00fan proveedor de nube de infraestructura p\u00fablica o privada (AWS, Azure, OpenStack, etc.), en estos casos es imprescindible utilizar este mecanismo de clave p\u00fablica/privada para acceder a estas m\u00e1quinas virtuales.</p>"},{"location":"02.-SSH/03.-Uso%20de%20ssh/02.-Autenticaci%C3%B3n%20con%20claves%20p%C3%BAblica-privada/#325-generacion-de-una-clave-publica-a-partir-de-la-privada","title":"3.2.5 Generaci\u00f3n de una clave p\u00fablica a partir de la privada","text":"<p>Aunque habitualmente se generan ambas claves, en diferentes circunstancias puede ocurrir que tengamos la clave privada, pero no la correspondiente clave p\u00fablica, en ese caso podemos utilizar <code>ssh-keygen</code> para obtenerla:</p> <pre><code>ssh-keygen -y -f clave &gt;&gt; clave.pub\n</code></pre> <p>Evidentemente si tenemos la clave p\u00fablica y no la privada, no podemos hacer el proceso inverso.</p>"},{"location":"02.-SSH/03.-Uso%20de%20ssh/02.-Autenticaci%C3%B3n%20con%20claves%20p%C3%BAblica-privada/#326-utilizacion-en-procesos-no-interactivos","title":"3.2.6 Utilizaci\u00f3n en procesos no interactivos","text":"<p>Puesto que teniendo acceso a la clave privada el acceso se puede realizar al equipo remoto sin ninguna intervenci\u00f3n, este mecanismo es ideal para su utilizaci\u00f3n en procesos que no requieran intervenci\u00f3n humana, como muchas conexiones que pueden realizarse entre diferentes equipos. La conexi\u00f3n es segura y autenticada, aunque es muy importante custodiar adecuadamente las claves privadas.</p>"},{"location":"02.-SSH/03.-Uso%20de%20ssh/03.-Autenticaci%C3%B3n%20con%20claves%20p%C3%BAblica-privada%20y%20frase%20de%20paso/","title":"03.-Autenticaci\u00f3n con claves p\u00fablica-privada y frase de paso","text":"<p>La autenticaci\u00f3n con clave privada tiene importantes ventajas respecto al acceso con contrase\u00f1a, pero tiene el inconveniente de la custodia de la clave privada. Cualquier usuario que obtuviese nuestra clave privada podr\u00eda entrar en nuestra cuenta de cualquier equipo en el que tuvi\u00e9semos exportada la correspondiente clave p\u00fablica. Para aumentar la seguridad en esta situaci\u00f3n se utiliza una frase de paso para proteger la clave privada, frase que se introduce al crear la clave privada o que puede modificarse a posteriori. Vamos a crear una nueva clave, pero en este caso protegida con frase de paso:</p> <pre><code>ssh-keygen -t ecdsa\nGenerating public/private ecdsa key pair.\nEnter file in which to save the key (/home/alberto/.ssh/id_ecdsa): \nEnter passphrase (empty for no passphrase): &lt;- Teclear frase de paso -&gt;\nEnter same passphrase again: &lt;- Teclear frase de paso de nuevo -&gt;\nYour identification has been saved in /home/alberto/.ssh/id_ecdsa.\nYour public key has been saved in /home/alberto/.ssh/id_ecdsa.pub.\nThe key fingerprint is:\nSHA256:mvCLrZMvdUDOorOkvd/1iosAZmhGS2fWPQmjAVMjjtk alberto@mut\nThe key's randomart image is:\n+---[ECDSA 256]---+\n| +o+ o           |\n|ooo = = .        |\n|o+E= = +         |\n|+ = . + .        |\n|o* ... .S        |\n|=.+  o.o.        |\n| +.o o+..        |\n|. o.+= + .       |\n|  .o==B....      |\n+----[SHA256]-----+\n</code></pre> <p>De esta forma la clave privada no es \u00fatil a menos que se conozca la frase de paso.</p> <p>Procedemos de igual forma que en el caso anterior, exportando la clave p\u00fablica, aunque ahora cada vez que accedamos nos solicitar\u00e1 la frase de paso de la clave privada:</p> <pre><code>ssh -i ~/.ssh/id_ecdsa debian@172.22.200.175\nEnter passphrase for key '/home/alberto/.ssh/id_ecdsa':\n</code></pre> <p>Hemos ganado en seguridad, pero hemos perdido en usabilidad, porque ahora tenemos que escribir la frase de paso cada vez que accedamos al equipo remoto y adem\u00e1s no es v\u00e1lido para procesos no interactivos. Para solucionar este inconveniente usaremos <code>ssh-agent</code> en una secci\u00f3n posterior.</p>"},{"location":"02.-SSH/03.-Uso%20de%20ssh/04.-%60ssh-agent%60/","title":"04.-`ssh-agent`","text":"<p><code>ssh-agent</code> es un programa que permite almacenar las claves privadas de una sesi\u00f3n y es muy \u00fatil cuando usamos claves con frase de paso, ya que podemos a\u00f1adir la clave privada al agente ssh y s\u00f3lo tendremos que poner la frase de paso una vez, permitiendo utilizar <code>ssh</code> de forma transparente sin volver a introducir la frase de paso todo el tiempo que dure la sesi\u00f3n del usuario (realmente se puede limitar a una cantidad de tiempo menor si se desea).</p> <p><code>ssh-agent</code> se suele ejecutar autom\u00e1ticamente en las sesiones gr\u00e1ficas de los sistemas, como podemos verificar mediante:</p> <pre><code>env |grep SSH\n...\nSSH_AUTH_SOCK=/run/user/1001/keyring/ssh\nSSH_AGENT_PID=2743\n</code></pre> <p>O a trav\u00e9s de ps:</p> <pre><code>ps aux |grep ssh-agent\nalberto   2743  .... ..... 0:00 /usr/bin/ssh-agent x-session-manager\n</code></pre> <p>De hecho, si tuvi\u00e9ramos alguna clave privada sin frase de paso se habr\u00eda cargado autom\u00e1ticamente en el agente ssh y podr\u00edamos utilizarla de forma totalmente transparente.</p>"},{"location":"02.-SSH/03.-Uso%20de%20ssh/04.-%60ssh-agent%60/#341-anadir-una-clave-privada-a-ssh-agent","title":"3.4.1 A\u00f1adir una clave privada a <code>ssh-agent</code>","text":"<p>Mediante la herramienta <code>ssh-add</code> podemos a\u00f1adir una clave al agente ssh, por ejemplo:</p> <pre><code>ssh-add ~/.ssh/openwebinars\n</code></pre> <p>Si la clave est\u00e1 protegida por una frase de paso, se nos pedir\u00e1 en ese momento, o se utilizar\u00e1 la aplicaci\u00f3n ssh-askpass si se tratase de una aplicaci\u00f3n gr\u00e1fica u otra que no tuviese asociada una terminal.</p> <p>Podemos ver las claves cargadas mediante:</p> <pre><code>ssh-add -L\n</code></pre> <p>Y sus huellas con:</p> <pre><code>ssh-add -l\n</code></pre> <p><code>ssh-agent</code> permite que cualquier otra aplicaci\u00f3n de la misma sesi\u00f3n utilice las claves privadas que almacena sin tener que volver a autenticarse, por lo que es importante controlar el uso de la sesi\u00f3n, bloque\u00e1ndola cuando no se est\u00e9 usando.</p> <p>Se pueden eliminar claves ssh del agente mediante:</p> <pre><code>ssh-add -d openwebinars\n</code></pre> <p>O incluso eliminar todas las claves con:</p> <pre><code>ssh-add -D\n</code></pre>"},{"location":"02.-SSH/03.-Uso%20de%20ssh/04.-%60ssh-agent%60/#342-ejecucion-de-ssh-agent","title":"3.4.2 Ejecuci\u00f3n de <code>ssh-agent</code>","text":"<p>En el caso de que utilicemos un sistema que no haya cargado autom\u00e1ticamente un agente ssh, podemos ejecutarlo directamente, habitualmente se har\u00eda abriendo una nueva shell:</p> <pre><code>ssh-agent /bin/bash\n</code></pre>"},{"location":"02.-SSH/03.-Uso%20de%20ssh/05.-Gesti%C3%B3n%20de%20ficheros.%20%60authorized_keys%60%20y%20%60known_hosts%60/","title":"05.-Gesti\u00f3n de ficheros. `authorized_keys` y `known_hosts`","text":""},{"location":"02.-SSH/03.-Uso%20de%20ssh/05.-Gesti%C3%B3n%20de%20ficheros.%20%60authorized_keys%60%20y%20%60known_hosts%60/#351-fichero-sshauthorized_keys","title":"3.5.1 Fichero ~/.ssh/authorized_keys","text":"<p>Se almacenan las claves p\u00fablicas de los usuarios que pueden acceder a esta cuenta mediante clave p\u00fablica/clave privada, el formato es:</p> <pre><code>&lt;algoritmo&gt; &lt;clavepublica&gt; &lt;comentario&gt;\n</code></pre> <p>Por ejemplo:</p> <pre><code>ssh-rsa AAAAB3NzaC1yc2EAA\u2026dPh alberto@mut\n</code></pre> <p>Si queremos que utilizar un par de claves para acceder a un equipo, debemos asegurarnos de que exista la clave p\u00fablica en este fichero y cuando ya dejemos de utilizarla debemos borrar la l\u00ednea correspondiente. Fichero ~/.ssh/knownhosts</p> <p>Se almacenan las claves p\u00fablicas de todos los equipos remotos a los que nos hemos conectado y que hemos aceptado, el formato es:</p> <pre><code>&lt;nombre o IP equipo&gt; &lt;algoritmo&gt; &lt;clavep\u00fablica&gt;\n</code></pre> <p>Actualmente es m\u00e1s habitual que no se guarde el nombre o direcci\u00f3n IP del equipo en claro, sino que se almacene el hash. Para encontrar un determinado equipo por nombre o direcci\u00f3n IP podemos utilizar la instrucci\u00f3n:</p> <pre><code>ssh-keygen -F 172.22.200.175\n1   lbA\u2026.9Lo= ecdsa-sha2-nistp256 AAAA\u2026..ynTO90=\n</code></pre> <p>Cambio de clave p\u00fablica del servidor</p> <p>Habitualmente se almacenan las claves p\u00fablicas de los servidores a los que nos hemos conectado previamente en el fichero ~/.ssh/knownhosts, por lo que se verifica cada vez que se conecta que el servidor ofrece la misma clave p\u00fablica. En caso de que no coincida veremos el siguiente mensaje:</p> <pre><code>ssh debian@172.22.200.175 @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ @ WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED! @ @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ IT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY! Someone could be eavesdropping on you right now (man-in-the-middle attack)! It is also possible that a host key has just been changed. The fingerprint for the ECDSA key sent by the remote host is SHA256:J9CMWSbavkqECRI1KWhy8s/D7UVJWDiysAocAbo1F6k. Please contact your system administrator. Add correct host key in home/alberto.ssh/knownhosts to get rid of this message. Offending ECDSA key in home/alberto.ssh/knownhosts:88 remove with: ssh-keygen -f \"home/alberto.ssh/knownhosts\" -R 172.22.200.175 ECDSA host key for 172.22.200.175 has changed and you have requested strict checking. Host key verification failed.\n</code></pre> <p>Es posible que se trate de una suplantaci\u00f3n y por tanto un problema de seguridad, pero tambi\u00e9n es posible que se haya realizado un cambio en el servidor que haya implicado un cambio en las claves del servicio ssh o una situaci\u00f3n muy habitual hoy en d\u00eda: estamos reutilizando la misma IP para un nuevo servidor.</p> <p>En caso de que estemos seguros de que no hay ning\u00fan problema de seguridad al acceder a ese equipo remoto, debemos eliminar la antigua clave asociada a la direcci\u00f3n IP (o al nombre), mediante la instrucci\u00f3n:</p> <pre><code>ssh-keygen -R 172.22.200.175\n\nhome/alberto.ssh/knownhosts updated. Original contents retained as home/alberto.ssh/knownhosts.old\n</code></pre>"},{"location":"02.-SSH/03.-Uso%20de%20ssh/05.-Gesti%C3%B3n%20de%20ficheros.%20%60authorized_keys%60%20y%20%60known_hosts%60/#352-fichero-sshauthorized_keys","title":"3.5.2 Fichero ~/.ssh/authorized_keys","text":"<p>Almacena las claves p\u00fablicas de los usuarios que pueden acceder a esta cuenta mediante clave p\u00fablica/clave privada, el formato es:</p> <pre><code>&lt;algoritmo&gt; &lt;clave_publica&gt; &lt;comentario&gt;\n</code></pre> <p>Por ejemplo:</p> <pre><code>ssh-rsa AAAAB3NzaC1yc2EAA...dPh alberto@mut\n</code></pre> <p>Si queremos utilizar un par de claves para acceder a un equipo, debemos asegurarnos de que exista la clave p\u00fablica en este fichero y cuando ya dejemos de utilizarla debemos borrar la l\u00ednea correspondiente.</p>"},{"location":"02.-SSH/03.-Uso%20de%20ssh/05.-Gesti%C3%B3n%20de%20ficheros.%20%60authorized_keys%60%20y%20%60known_hosts%60/#353-fichero-sshknownhosts","title":"3.5.3 Fichero ~/.ssh/knownhosts","text":"<p>Almacena las claves p\u00fablicas de todos los equipos remotos a los que nos hemos conectado y que hemos aceptado, el formato es:</p> <pre><code>nombre_o_IP_equipo algoritmo clave_p\u00fablica\n</code></pre> <p>Actualmente es m\u00e1s habitual que no se guarde el nombre o direcci\u00f3n IP del equipo en claro, sino que se almacene el hash. Para encontrar un determinado equipo por nombre o direcci\u00f3n IP podemos utilizar la instrucci\u00f3n:</p> <pre><code>ssh-keygen -F 172.22.200.175\n#Host 172.22.200.175 found: line 88 \n|1|lbA....9Lo= ecdsa-sha2-nistp256 AAAA.....ynTO90=\n</code></pre>"},{"location":"02.-SSH/03.-Uso%20de%20ssh/05.-Gesti%C3%B3n%20de%20ficheros.%20%60authorized_keys%60%20y%20%60known_hosts%60/#354-cambio-de-clave-publica-del-servidor","title":"3.5.4 Cambio de clave p\u00fablica del servidor","text":"<p>Habitualmente se almacenan las claves p\u00fablicas de los servidores a los que nos hemos conectado previamente en el fichero ~/.ssh/known_hosts, por lo que se verifica, cada vez que se conecta, que el servidor ofrece la misma clave p\u00fablica. En caso de que no coincida veremos el siguiente mensaje:</p> <pre><code>ssh debian@172.22.200.175\n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n@    WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!     @\n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\nIT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY!\nSomeone could be eavesdropping on you right now (man-in-the-middle attack)!\nIt is also possible that a host key has just been changed.\nThe fingerprint for the ECDSA key sent by the remote host is\nSHA256:J9CMWSbavkqECRI1KWhy8s/D7UVJWDiysAocAbo1F6k.\nPlease contact your system administrator.\nAdd correct host key in /home/alberto/.ssh/known_hosts to get rid of this message.\nOffending ECDSA key in /home/alberto/.ssh/known_hosts:88\n  remove with:\n  ssh-keygen -f \"/home/alberto/.ssh/known_hosts\" -R 172.22.200.175\nECDSA host key for 172.22.200.175 has changed and you have requested strict checking.\nHost key verification failed.\n</code></pre> <p>Es posible que se trate de una suplantaci\u00f3n y por tanto un problema de seguridad, pero tambi\u00e9n es posible que se haya realizado un cambio en el servidor que haya implicado un cambio en las claves del servicio ssh o una situaci\u00f3n muy habitual hoy en d\u00eda: estamos reutilizando la misma IP para un nuevo servidor.</p> <p>En caso de que estemos seguros de que no hay ning\u00fan problema de seguridad al acceder a ese equipo remoto, debemos eliminar la antigua clave asociada a la direcci\u00f3n IP (o al nombre), mediante la instrucci\u00f3n:</p> <pre><code>ssh-keygen -R 172.22.200.175\n#Host 172.22.200.175 found: line 88\n/home/alberto/.ssh/known_hosts updated.\nOriginal contents retained as /home/alberto/.ssh/known_hosts.old\n</code></pre>"},{"location":"02.-SSH/03.-Uso%20de%20ssh/06.-Forwarding/","title":"06.-Forwarding","text":""},{"location":"02.-SSH/03.-Uso%20de%20ssh/06.-Forwarding/#361-agent-forwarding","title":"3.6.1 Agent forwarding","text":"<p>Mediante esta t\u00e9cnica, es posible que el cliente ssh se comunique con un agente ssh que corre un una m\u00e1quina remota y sin necesidad de poner las claves privadas en \u00e9l, poder saltar a otro equipo remoto no accesible directamente. Es una t\u00e9cnica muy \u00fatil que permite no exponer directamente los servidores a los que realmente queremos acceder mediante ssh, sino que accedemos a ellos de forma transparente usando un equipo a modo de basti\u00f3n.</p> <p>Esta posibilidad debe estar habilitada en el servidor intermedio mediante la directiva:</p> <pre><code>allowagentforwarding yes\n</code></pre> <p>Que est\u00e1 habilitada por defecto.</p> <p>En el cliente es necesario habilitar el par\u00e1metro:</p> <pre><code>ForwardAgent yes\n</code></pre>"},{"location":"02.-SSH/03.-Uso%20de%20ssh/06.-Forwarding/#362-x11-forwarding","title":"3.6.2 X11 forwarding","text":"<p>A trav\u00e9s de la t\u00e9cnica de X11 forwarding podemos ver en nuestra pantalla aplicaciones gr\u00e1ficas que se ejecutan a trav\u00e9s de ssh en un equipo remoto (y viceversa).</p> <p>Aunque en primer lugar tiene que estar permitido en el servidor a trav\u00e9s de las directivas:</p> <pre><code>X11Forwarding yes\nX11DisplayOffset 10\n</code></pre> <p>El cliente para conectarse y utilizar esta funcionalidad, deber\u00e1 configurar adicionalmente la opci\u00f3n:</p> <pre><code>ForwardX11 yes\n</code></pre> <p>Al conectarnos por ssh podremos comprobar que est\u00e1 definida la variable DISPLAY con un valor definido a trav\u00e9s de la variable X11DisplayOffset, por ejemplo:</p> <pre><code>env |grep DISPLAY\nDISPLAY=localhost:10\n</code></pre> <p>Al ejecutar una aplicaci\u00f3n en el equipo remoto sobre la conexi\u00f3n ssh nos aparecer\u00e1 en nuestra pantalla.</p>"},{"location":"02.-SSH/04.-Configuraci%C3%B3n%20de%20ssh/01.-Configuraci%C3%B3n%20del%20cliente%20ssh/","title":"01.-Configuraci\u00f3n del cliente ssh","text":"<p>Existe el fichero <code>/etc/ssh/ssh_config</code> en el que se especifican los par\u00e1metros de configuraci\u00f3n generales que van a utilizar por defecto todos los clientes ssh que se ejecuten en esa m\u00e1quina.</p> <p>Los posibles par\u00e1metros que podemos definir en ese fichero se detallan en la p\u00e1gina 5 del manual de <code>ssh_config</code>. Algunos par\u00e1metros significativos</p>"},{"location":"02.-SSH/04.-Configuraci%C3%B3n%20de%20ssh/01.-Configuraci%C3%B3n%20del%20cliente%20ssh/#411-sendenv-lang-lc_","title":"4.1.1 SendEnv LANG LC_*","text":"<p>Mediante este par\u00e1metro se define en el equipo remoto los par\u00e1metros de localizaci\u00f3n del cliente, siempre que estos est\u00e9n definidos all\u00ed. Por ejemplo, supongamos que la variable local sea <code>LANG=es.ES.UTF-8</code>, seguir\u00e1 siendo en el equipo remoto siempre que exista, en caso contrario se pondr\u00e1 la localizaci\u00f3n por defecto del sistema:</p> <pre><code>usuario@cliente:~$ echo $LANG\nes_ES.UTF-8\nusuario@cliente:~$ ssh root@servidor1\n\nThe programs included with the Debian GNU/Linux system are free software;\nthe exact distribution terms for each program are described in the\nindividual files in /usr/share/doc/*/copyright.\n\nDebian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent\npermitted by applicable law.\nNo mail.\nLast login: Thu Feb 22 10:06:47 2018 from ...\nroot@servidor1:~# echo $LANG\nen_US.UTF-8\n</code></pre>"},{"location":"02.-SSH/04.-Configuraci%C3%B3n%20de%20ssh/01.-Configuraci%C3%B3n%20del%20cliente%20ssh/#412-hashknownhosts-yesno","title":"4.1.2 <code>HashKnownHosts yes|no</code>","text":"<p>Para ofuscar mediante un hash la IP o el nombre de los servidores de los que almacenamos las claves p\u00fablicas en el fichero ~/.ssh/known_hosts</p>"},{"location":"02.-SSH/04.-Configuraci%C3%B3n%20de%20ssh/01.-Configuraci%C3%B3n%20del%20cliente%20ssh/#413-gssapiauthentication-yesno","title":"4.1.3 <code>GSSAPIAuthentication yes|no</code>","text":"<p>Para habilitar este m\u00e9todo de autenticaci\u00f3n, en sistemas Debian viene habilitado, aunque s\u00f3lo es necesario en los casos en los que se vaya a usar este m\u00e9todo de autenticaci\u00f3n.</p>"},{"location":"02.-SSH/04.-Configuraci%C3%B3n%20de%20ssh/01.-Configuraci%C3%B3n%20del%20cliente%20ssh/#414-caracter-de-escape","title":"4.1.4 Car\u00e1cter de escape","text":"<p>En algunas ocasiones podemos tener problemas con nuestra conexi\u00f3n ssh y que la shell remota no responda a las instrucciones que mandamos, en esos casos siempre se podr\u00e1 cerrar la conexi\u00f3n mediante el car\u00e1cter de escape que hayamos definido en nuestro cliente ssh, este caracter por defecto es \u201c~\u201d:</p> <pre><code>EscapeChar ~\n</code></pre> <p>Para ejecutarlo escribir\u00edamos la secuencia \u201c~\u201d.</p>"},{"location":"02.-SSH/04.-Configuraci%C3%B3n%20de%20ssh/01.-Configuraci%C3%B3n%20del%20cliente%20ssh/#415forwardagent-forwardx11","title":"4.1.5<code>ForwardAgent</code>, <code>ForwardX11</code>","text":"<p>Explicados en la secci\u00f3n espec\u00edfica de forwarding</p>"},{"location":"02.-SSH/04.-Configuraci%C3%B3n%20de%20ssh/01.-Configuraci%C3%B3n%20del%20cliente%20ssh/#416-globalknownhostsfile-fichero","title":"4.1.6 <code>GlobalKnownHostsFile &lt;fichero&gt;</code>","text":"<p>Permite la utilizaci\u00f3n de un fichero knownhosts para todos los usuarios de un equipo.</p>"},{"location":"02.-SSH/04.-Configuraci%C3%B3n%20de%20ssh/01.-Configuraci%C3%B3n%20del%20cliente%20ssh/#417-numberofpasswordprompts","title":"4.1.7 <code>NumberOfPasswordPrompts</code>","text":"<p>N\u00famero de intentos de acceso con contrase\u00f1a. Por defecto es 3</p>"},{"location":"02.-SSH/04.-Configuraci%C3%B3n%20de%20ssh/01.-Configuraci%C3%B3n%20del%20cliente%20ssh/#418-stricthostkeychecking-yesaskno","title":"4.1.8 <code>StrictHostKeyChecking yes|ask|no</code>","text":"<p>Par\u00e1metro muy importante, utiliza para la gesti\u00f3n de las claves p\u00fablicas de los equipos remotos. La opci\u00f3n por defecto es \u201cask\u201d, de manera que si no se ha almacenado previamente la clave p\u00fablica se pregunta qu\u00e9 hacer. En el caso de ponerla en \u201cyes\u201d, se rechazar\u00e1 una conexi\u00f3n si no existe previamente la clave p\u00fablica y en caso de optar por la opci\u00f3n \u201cno\u201d, no se har\u00e1 ninguna verificaci\u00f3n.</p>"},{"location":"02.-SSH/04.-Configuraci%C3%B3n%20de%20ssh/01.-Configuraci%C3%B3n%20del%20cliente%20ssh/#419-userknownhostsfile-fichero","title":"4.1.9 <code>UserKnownHostsFile fichero</code>","text":"<p>Fichero knownhosts de usuario, por defecto ~/.ssh/knownhosts</p>"},{"location":"02.-SSH/04.-Configuraci%C3%B3n%20de%20ssh/01.-Configuraci%C3%B3n%20del%20cliente%20ssh/#4110-configuracion-por-usuario","title":"4.1.10 Configuraci\u00f3n por usuario","text":"<p>Salvo algunos par\u00e1metros generales, es poco probable que la mayor\u00eda de los par\u00e1metros que se pueden definir para el cliente ssh sean \u00fatiles para todos los usuarios de un equipo, es mucho m\u00e1s habitual que un usuario defina un fichero de configuraci\u00f3n con sus propios par\u00e1metros. Este fichero es <code>~/.ssh/config</code> y los par\u00e1metros aqu\u00ed definidos prevalecen sobre los generales.</p> <p>Se pueden definir par\u00e1metros para todos los equipos remotos, pero es tambi\u00e9n muy \u00fatil agruparlos con el par\u00e1metro Host como en el siguiente ejemplo:</p> <pre><code>GSSAPIAuthentication no\n\nHost 192.168.1.1\n     User root\n     Port 2022\n     ForwardAgent yes\n     Identityfile ~/.ssh/id_ecdsa\n     StrictHostKeyChecking yes\n\nHost *.example.com\n     StrictHostKeyChecking no\n     UserKnownHostsFile=/dev/null\n     LogLevel QUIET\n</code></pre>"},{"location":"02.-SSH/04.-Configuraci%C3%B3n%20de%20ssh/01.-Configuraci%C3%B3n%20del%20cliente%20ssh/#4111-utilizar-parametros-directamente","title":"4.1.11 Utilizar par\u00e1metros directamente","text":"<p>Independientemente de los par\u00e1metros que est\u00e9n definidos en cualquiera de las opciones anteriores, tambi\u00e9n es posible utilizar par\u00e1metros de forma expl\u00edcita en la propia l\u00ednea de comandos, pas\u00e1ndolos mediante el modificador \u201c-o\u201d, por ejemplo:</p> <pre><code>ssh -o \"ForwardAgent yes\" usuario@172.22.200.175\n</code></pre>"},{"location":"02.-SSH/04.-Configuraci%C3%B3n%20de%20ssh/02.-Configuraci%C3%B3n%20del%20servidor%20ssh/","title":"02.-Configuraci\u00f3n del servidor ssh","text":"<p>Tal como vimos en la instalaci\u00f3n y configuraci\u00f3n elemental del servidor ssh, podemos ver las opciones de configuraci\u00f3n que se aplican a nuestro servidor mediante:</p> <pre><code>sshd -T |less\n</code></pre> <p>Vamos a comentar algunas que pueden ser interesantes porque se modifican con cierta frecuencia.</p>"},{"location":"02.-SSH/04.-Configuraci%C3%B3n%20de%20ssh/02.-Configuraci%C3%B3n%20del%20servidor%20ssh/#421-port-22","title":"4.2.1 <code>Port 22</code>","text":"<p>Puerto tcp en el que va a escuchar peticiones el servidor ssh, por defecto es el 22/tcp, pero puede cambiarse sin problema.</p>"},{"location":"02.-SSH/04.-Configuraci%C3%B3n%20de%20ssh/02.-Configuraci%C3%B3n%20del%20servidor%20ssh/#422-addressfamily-anyinetinet6","title":"4.2.2 <code>AddressFamily any|inet|inet6</code>","text":"<p>El protocolo o protocolos de red a utilizar, puede ser inet(IPv4), inet6 (IPv6) o any(ambos) que es la opci\u00f3n por defecto.</p>"},{"location":"02.-SSH/04.-Configuraci%C3%B3n%20de%20ssh/02.-Configuraci%C3%B3n%20del%20servidor%20ssh/#423-listenaddress","title":"4.2.3 <code>ListenAddress</code>","text":"<p>Si queremos especificar que se permitan conexiones s\u00f3lo a trav\u00e9s de una direcci\u00f3n IP concreta (IPv4/IPv6).</p>"},{"location":"02.-SSH/04.-Configuraci%C3%B3n%20de%20ssh/02.-Configuraci%C3%B3n%20del%20servidor%20ssh/#424-logingracetime-maxauthtries-y-maxsessions","title":"4.2.4 <code>logingracetime</code>, <code>maxauthtries</code> y <code>maxsessions</code>","text":"<p>Para especificar el tiempo que se espera para que el usuario se acceda con \u00e9xito al sistema, el n\u00famero m\u00e1ximo de veces que puede introducir la contrase\u00f1a y el n\u00famero m\u00e1ximo de sesiones en la misma conexi\u00f3n.</p>"},{"location":"02.-SSH/04.-Configuraci%C3%B3n%20de%20ssh/02.-Configuraci%C3%B3n%20del%20servidor%20ssh/#425-loglevel-y-syslogfacility","title":"4.2.5 <code>loglevel</code> y <code>syslogfacility</code>","text":"<p>Para controlar el nivel de detalle que mostrar en los logs del sistema, as\u00ed como la \u201cfacility\u201d a utilizar.</p>"},{"location":"02.-SSH/04.-Configuraci%C3%B3n%20de%20ssh/02.-Configuraci%C3%B3n%20del%20servidor%20ssh/#426-hostkey","title":"4.2.6 <code>hostkey</code>","text":"<p>Fichero o ficheros que especifican la clave o claves privadas a utilizar por el servidor.</p>"},{"location":"02.-SSH/05.-Transferencia%20de%20ficheros%20a%20trav%C3%A9s%20de%20ssh/01.-Uso%20de%20%60scp%60/","title":"01.-Uso de `scp`","text":"<p>El cliente ssh incluye tambi\u00e9n el comando <code>scp</code> que permite copiar ficheros entre entre equipos mediante ssh y hacerlo de forma equivalente a la utilizaci\u00f3n local del cl\u00e1sico comando <code>cp</code>.</p> <p>No es necesario que el equipo origen o destino sea el equipo desde el que se ejecuta <code>scp</code>, tanto origen como destino pueden ser equipos a los que pueda acceder el usuario utilizando ssh.</p> <p>La sintaxis general de <code>scp</code> es:</p> <pre><code>scp [[user@]host1:]file1 [[user@]host2:]file2\n</code></pre>"},{"location":"02.-SSH/05.-Transferencia%20de%20ficheros%20a%20trav%C3%A9s%20de%20ssh/01.-Uso%20de%20%60scp%60/#511-transferir-un-fichero-local-a-un-equipo-remoto","title":"5.1.1 Transferir un fichero local a un equipo remoto","text":"<pre><code>scp  /etc/resolv.conf usuario@172.22.200.175:resolv.conf.local\n</code></pre> <p>El fichero remoto quedar\u00e1 como /home/usuario/resolv.conf.local ya que : indica el punto de acceso al equipo (/home/usuario/ en este caso) Transferir un fichero desde un equipo remoto a mi equipo local</p> <pre><code>scp root@172.22.200.175:/etc/shadow .\n</code></pre> <p>Que guardar\u00eda el fichero /etc/shadow del equipo remoto con el nombre shadow en el directorio en el que nos encontramos</p>"},{"location":"02.-SSH/05.-Transferencia%20de%20ficheros%20a%20trav%C3%A9s%20de%20ssh/01.-Uso%20de%20%60scp%60/#512-transferir-un-fichero-entre-dos-equipos-remotos","title":"5.1.2 Transferir un fichero entre dos equipos remotos","text":"<pre><code>scp root@172.22.200.175:/etc/hosts root@172.22.200.176:/etc/hosts\n</code></pre> <p>Esta opci\u00f3n es muy potente y permite crear sencillos scripts para unificar configuraciones, por ejemplo imaginemos que queremos tener la misma configuraci\u00f3n DNS en un conjunto de servidores, podr\u00edamos hacerlo de forma sencilla y potente con ssh mediante el siguiente script:</p> <pre><code>#!/bin/bash\n\nfor i in `seq 1 100`; do\n  scp root@servidor1:/etc/resolv.conf 192.168.1.$i:/etc/resolv.conf\ndone\n</code></pre>"},{"location":"02.-SSH/05.-Transferencia%20de%20ficheros%20a%20trav%C3%A9s%20de%20ssh/01.-Uso%20de%20%60scp%60/#513-bonus-track","title":"5.1.3 Bonus track","text":"<p>Si utilizamos pares de claves en las conexiones, <code>scp</code> autocompleta el fichero origen o destino utilizando el doble tabulador.</p>"},{"location":"02.-SSH/05.-Transferencia%20de%20ficheros%20a%20trav%C3%A9s%20de%20ssh/02.-Uso%20de%20%60sftp%60/","title":"02.-Uso de `sftp`","text":"<p>Al igual que <code>scp</code>, <code>sftp</code> permite transferir ficheros entre equipos remotos a trav\u00e9s de SSH, aunque su principal diferencia es que <code>sftp</code> permite utilizarlo de una forma interactiva, al igual que el tradicional ftp, incluyendo los mismos comandos que \u00e9ste. <code>scp</code> es mucho m\u00e1s habitual utilizarlo desde l\u00ednea de comandos, mientras que <code>sftp</code> se puede utilizar bien desde la l\u00ednea de comandos o a trav\u00e9s de uno de los m\u00faltiples clientes ftp que lo soportan.</p> <p>Es importante no confundir <code>sftp</code> (ssh ftp) con ftps que es una extensi\u00f3n del protocolo ftp a\u00f1adiendo ssl para el cifrado de la conexi\u00f3n.</p>"},{"location":"02.-SSH/06.-T%C3%BAneles%20SSH/","title":"Index","text":"<p>Esta t\u00e9cnica, tambi\u00e9n conocida como TCP forwarding o port forwarding, permite utilizar cualquier aplicaci\u00f3n de forma segura a trav\u00e9s de una conexi\u00f3n ssh (de ah\u00ed la utilizaci\u00f3n del t\u00e9rmino t\u00fanel).</p>"},{"location":"02.-SSH/06.-T%C3%BAneles%20SSH/01.-Local%20forwarding/","title":"01.-Local forwarding","text":"<p>Desde nuestra m\u00e1quina queremos acceder a un servicio, pero este servicio o bien no es accesible (por ejemplo por un cortafuegos que lo impide), o no es seguro hacerlo desde nuestra m\u00e1quina, pero tenemos acceso a otro equipo a trav\u00e9s de ssh y desde ese equipo s\u00ed podemos acceder al servicio que queremos o es seguro hacerlo.</p> <p>Vamos a verlo con un ejemplo: Queremos enviar un correo desde nuestro servidor de la empresa (puerto 25/tcp), pero estamos fuera y no queremos conectarnos de forma insegura, por lo que establecemos un t\u00fanel ssh de la siguiente forma:</p> <pre><code>ssh -f -L 1025:smtp.example.com:25 remoto.example.com -N\n</code></pre> <p>Esto abrir\u00e1 el puerto 1025/tcp en nuestra m\u00e1quina que podremos utilizar de forma segura para enviar correo, ya que se pasar\u00e1 a trav\u00e9s de ssh al equipo remoto.example.com y de ah\u00ed al servidor smtp.example.com.</p>"},{"location":"02.-SSH/06.-T%C3%BAneles%20SSH/02.-Remote%20forwarding/","title":"02.-Remote forwarding","text":"<p>Supongamos el caso contrario, en el que queremos que una m\u00e1quina remota utilice un servicio de nuestra m\u00e1quina, pero o bien no es accesible de forma directa o bien no es seguro hacerlo, por lo que podr\u00edamos definir una conexi\u00f3n ssh para realizarlo como la siguiente:</p> <pre><code>ssh -f -L 8080:localhost:80 remoto.example.com -N\n</code></pre> <p>De esa manera desde el equipo remoto, quien acceda al puerto 8080/tcp estar\u00e1 accediendo al puerto 80/tcp de nuestra m\u00e1quina a trav\u00e9s de un t\u00fanel ssh.</p> <p>La directiva <code>GatewayPorts yes|no</code> limita el puerto 8080 del caso anterior a que se pueda acceder s\u00f3lo desde el propio equipo remoto, o bien desde cualquier equipo.</p>"},{"location":"02.-SSH/06.-T%C3%BAneles%20SSH/03.-Forwarding%20din%C3%A1mico/","title":"03.-Forwarding din\u00e1mico","text":"<p>Mediante este mecanismo, lo que hacemos es crear un servidor SOCKS en nuestro equipo, que permite utilizar desde nuestra m\u00e1quina cualquier cliente que soporte este mecanismo, en particular un navegador web. Definir\u00edamos un servidor socks local que sale a trav\u00e9s de un t\u00fanel ssh con un equipo remoto de la siguiente forma:</p> <pre><code>ssh -D 8080 -f -C -q -N remote.example.com\n</code></pre>"},{"location":"02.-SSH/07.-Pr%C3%A1cticas/","title":"Pr\u00e1cticas","text":""},{"location":"02.-SSH/07.-Pr%C3%A1cticas/01.-Descripci%C3%B3n%20del%20laboratorio/","title":"01.-Descripci\u00f3n del laboratorio","text":""},{"location":"02.-SSH/07.-Pr%C3%A1cticas/01.-Descripci%C3%B3n%20del%20laboratorio/#1-maquinas-virtuales-necesarias","title":"1. M\u00e1quinas Virtuales Necesarias","text":"<p>El entorno estar\u00e1 compuesto por tres m\u00e1quinas virtuales (VM). Cada una tendr\u00e1 un rol espec\u00edfico dentro de la red.</p> <ul> <li>VM1 (Cliente): Esta m\u00e1quina actuar\u00e1 como la estaci\u00f3n de trabajo desde donde se realizar\u00e1n las conexiones SSH hacia los servidores.</li> <li>VM2 (Servidor 1): Servidor principal de destino de las conexiones SSH. Aqu\u00ed se configurar\u00e1n los t\u00faneles, las autenticaciones y otras tareas administrativas.</li> <li>VM3 (Servidor 2): Servidor adicional que se utilizar\u00e1 para las tareas de automatizaci\u00f3n y para simular un entorno m\u00e1s complejo.</li> </ul> <p>Ver los Anexos:</p> <ul> <li>C\u00f3mo cambiar el nombre del host en linux</li> </ul>"},{"location":"02.-SSH/07.-Pr%C3%A1cticas/01.-Descripci%C3%B3n%20del%20laboratorio/#2-configuracion-de-red","title":"2. Configuraci\u00f3n de Red","text":"<p>Las m\u00e1quinas virtuales deben estar en la misma red local virtualizada para permitir las conexiones SSH entre ellas. Se recomienda usar una red interna o una red NAT en el software de virtualizaci\u00f3n (como VirtualBox o KVM/QEMU) para que las m\u00e1quinas se puedan comunicar entre s\u00ed sin necesidad de conexi\u00f3n externa.</p>"},{"location":"02.-SSH/07.-Pr%C3%A1cticas/01.-Descripci%C3%B3n%20del%20laboratorio/#especificaciones-de-la-red","title":"Especificaciones de la red:","text":"<ul> <li>Rango de IP: Utiliza direcciones IP est\u00e1ticas dentro del rango 192.168.1.X</li> <li>VM1: <code>192.168.1.11</code></li> <li>VM2: <code>192.168.1.12</code></li> <li>VM3: <code>192.168.1.13</code></li> <li>M\u00e1scara de subred: <code>255.255.255.0</code></li> <li>Puerta de enlace (gateway): No es estrictamente necesario para la pr\u00e1ctica, ya que la comunicaci\u00f3n ser\u00e1 local.</li> <li>Por ejemplo, para establecer la direcci\u00f3n ip de la m\u00e1quina virtual VM1 debemos usar los comandos:</li> </ul> <pre><code>$ sudo nmcli connection modify ethernet-enp1s0-1 ipv4.addresses 192.168.1.11/24 ipv4.method manual\n$ sudo nmcli connection up ethernet-enp1s-1\n</code></pre> <ul> <li>Si queremos olvidarnos de las direcciones IP y utilizar los nombre de host en su lugar, debemos cambiar la configuraci\u00f3n de los ficheros <code>/etc/hosts</code> a\u00f1adiendo las entradas de los correspondientes equipos.</li> </ul> <pre><code>192.168.1.11 VM1\n192.168.1.12 VM2\n192.168.1.13 VM3\n</code></pre> <p>Documentaci\u00f3n:</p> <ul> <li>Recorrido hist\u00f3rico de la gesti\u00f3n de redes en Linux</li> <li>C\u00f3mo instalar NetworkManager</li> <li>Clonaci\u00f3n y Snapshots</li> </ul>"},{"location":"02.-SSH/07.-Pr%C3%A1cticas/01.-Descripci%C3%B3n%20del%20laboratorio/#configuracion-de-las-maquinas","title":"Configuraci\u00f3n de las m\u00e1quinas:","text":"<ul> <li>Aseg\u00farate de que todas las m\u00e1quinas tienen habilitado SSH y est\u00e1n configuradas para aceptar conexiones entrantes.</li> </ul>"},{"location":"02.-SSH/07.-Pr%C3%A1cticas/01.-Descripci%C3%B3n%20del%20laboratorio/#3-software-requerido","title":"3. Software Requerido","text":"<p>Cada una de las m\u00e1quinas virtuales deber\u00e1 disponer de los siguientes paquetes y servicios instalados:</p>"},{"location":"02.-SSH/07.-Pr%C3%A1cticas/01.-Descripci%C3%B3n%20del%20laboratorio/#vm1-cliente","title":"VM1 (Cliente):","text":"<ul> <li>Sistema Operativo: Ubuntu, CentOS, o cualquier distribuci\u00f3n GNU/Linux.</li> <li>Software necesario:</li> <li><code>openssh-client</code> (ya deber\u00eda estar instalado en la mayor\u00eda de distribuciones)</li> <li>Scripting: Herramientas de scripting como <code>bash</code> o <code>zsh</code>.</li> </ul>"},{"location":"02.-SSH/07.-Pr%C3%A1cticas/01.-Descripci%C3%B3n%20del%20laboratorio/#vm2-y-vm3-servidores","title":"VM2 y VM3 (Servidores):","text":"<ul> <li> <p>Sistema Operativo: Preferiblemente una distribuci\u00f3n GNU/Linux como Ubuntu Server, CentOS, Debian, etc.</p> </li> <li> <p>Software necesario:</p> </li> <li><code>openssh-server</code> para permitir conexiones SSH.</li> <li>Web Server: Para el ejercicio de t\u00faneles, puedes instalar un servidor como <code>nginx</code> o <code>apache2</code>.</li> </ul>"},{"location":"02.-SSH/07.-Pr%C3%A1cticas/02.-Ejercicios/","title":"02.-Ejercicios","text":""},{"location":"02.-SSH/07.-Pr%C3%A1cticas/02.-Ejercicios/#ejercicio-1-instalacion-y-verificacion-del-servicio-ssh","title":"Ejercicio 1: Instalaci\u00f3n y Verificaci\u00f3n del Servicio SSH","text":"<p>Objetivo:</p> <p>Comprobar la instalaci\u00f3n del servicio SSH y su estado en una m\u00e1quina virtual.</p> <p>Instrucciones:</p> <ul> <li>Verifica si el servicio <code>openssh-server</code> est\u00e1 instalado usando en VM2 y en VM3:</li> </ul> <pre><code>$ dpkg -l | grep openssh-server\n</code></pre> <ul> <li>Si no est\u00e1 instalado, procede a instalarlo con:</li> </ul> <pre><code>$ sudo apt-get install openssh-server\n</code></pre> <ul> <li>Confirma que el servicio est\u00e1 corriendo con:</li> </ul> <pre><code>$ systemctl status ssh\n</code></pre> <ul> <li>Arranca el servicio con:</li> </ul> <pre><code>$ systemctl start ssh\n</code></pre> <ul> <li> <p>Captura de pantalla solicitada:</p> </li> <li> <p>Captura el resultado del comando <code>systemctl status ssh</code> mostrando el estado del servicio SSH en ejecuci\u00f3n.</p> </li> </ul> <p>Soluci\u00f3n:</p> <ul> <li>Ejecuta los comandos indicados para verificar la instalaci\u00f3n y el estado del servicio.</li> <li>Si el servicio no est\u00e1 instalado, procede con la instalaci\u00f3n y aseg\u00farate de que est\u00e9 corriendo.</li> </ul>"},{"location":"02.-SSH/07.-Pr%C3%A1cticas/02.-Ejercicios/#ejercicio-2-conexion-basica-mediante-ssh","title":"Ejercicio 2: Conexi\u00f3n B\u00e1sica mediante SSH","text":"<p>Objetivo:</p> <p>Realizar una conexi\u00f3n SSH entre dos m\u00e1quinas virtuales.</p> <p>Instrucciones:</p> <ul> <li>Aseg\u00farate de que el servicio SSH est\u00e1 activo en ambas m\u00e1quinas.</li> <li>Con\u00e9ctate desde una m\u00e1quina a otra mediante SSH usando:</li> </ul> <pre><code>$ ssh usuario@ip_maquina_virtual\n</code></pre> <p>Captura de pantalla solicitada:</p> <ul> <li>Captura la terminal con el comando de conexi\u00f3n SSH y la pantalla resultante que muestre que has accedido a la segunda m\u00e1quina.</li> </ul> <p>Soluci\u00f3n:</p> <ul> <li>Verifica que el servicio SSH est\u00e1 habilitado en ambas m\u00e1quinas.</li> <li>Ejecuta el comando <code>ssh usuario@ip_maquina_virtual</code> y captura la pantalla donde se muestre la conexi\u00f3n exitosa.</li> </ul>"},{"location":"02.-SSH/07.-Pr%C3%A1cticas/02.-Ejercicios/#ejercicio-3-autenticacion-mediante-claves-ssh","title":"Ejercicio 3: Autenticaci\u00f3n mediante Claves SSH","text":"<p>Objetivo:</p> <p>Configurar autenticaci\u00f3n sin contrase\u00f1a utilizando claves SSH.</p> <p>Instrucciones:</p> <ul> <li>Genera un par de claves SSH en una m\u00e1quina:</li> </ul> <pre><code>$ ssh-keygen\n</code></pre> <ul> <li>Copia la clave p\u00fablica al servidor remoto usando <code>ssh-copy-id</code>:</li> </ul> <pre><code>$ ssh-copy-id usuario@ip_maquina_virtual\n</code></pre> <ul> <li>Verifica que ahora puedes conectarte sin usar la contrase\u00f1a.</li> </ul> <p>Captura de pantalla solicitada:</p> <ul> <li>Captura la terminal mostrando el uso del comando <code>ssh-copy-id</code> y el posterior intento de conexi\u00f3n sin contrase\u00f1a.</li> </ul> <p>Soluci\u00f3n:</p> <ul> <li>Genera el par de claves SSH usando <code>ssh-keygen</code>.</li> <li>Utiliza <code>ssh-copy-id</code> para copiar la clave al servidor remoto y aseg\u00farate de que la autenticaci\u00f3n funcione sin contrase\u00f1a.</li> </ul>"},{"location":"02.-SSH/07.-Pr%C3%A1cticas/02.-Ejercicios/#ejercicio-4-configuracion-avanzada-de-ssh-sshd_config","title":"Ejercicio 4: Configuraci\u00f3n Avanzada de SSH (sshd_config)","text":"<p>Objetivo:</p> <p>Modificar y ajustar la configuraci\u00f3n de SSH para mejorar la seguridad.</p> <p>Instrucciones:</p> <ul> <li>Edita el archivo <code>/etc/ssh/sshd_config</code> y realiza los siguientes cambios:<ul> <li>Deshabilita el acceso root directo: <code>PermitRootLogin no</code>.</li> <li>Cambia el puerto predeterminado a otro distinto al 22: <code>Port 2222</code>.</li> </ul> </li> <li>Reinicia el servicio SSH: </li> </ul> <pre><code>     $ sudo systemctl restart sshd\n</code></pre> <ul> <li>Prueba la conexi\u00f3n al nuevo puerto:</li> </ul> <pre><code>     $ ssh -p 2222 usuario@ip_maquina_virtual\n</code></pre> <p>Captura de pantalla solicitada:</p> <ul> <li>Captura el archivo de configuraci\u00f3n <code>/etc/ssh/sshd_config</code> modificado, y la terminal mostrando la conexi\u00f3n SSH exitosa a trav\u00e9s del nuevo puerto.</li> </ul> <p>Soluci\u00f3n:</p> <ul> <li>Modifica el archivo de configuraci\u00f3n de SSH (<code>sshd_config</code>) para restringir el acceso y cambiar el puerto.</li> <li>Reinicia el servicio y prueba la conexi\u00f3n con el nuevo puerto.</li> </ul>"},{"location":"02.-SSH/07.-Pr%C3%A1cticas/02.-Ejercicios/#ejercicio-5-tuneles-ssh","title":"Ejercicio 5: T\u00faneles SSH","text":"<p>Objetivo: </p> <p>Utilizar t\u00faneles SSH para redirigir puertos y acceder a servicios locales de forma segura.</p> <p>Instrucciones:</p> <ul> <li>Configura un servidor web en una de las m\u00e1quinas virtuales (por ejemplo, <code>nginx</code> en el puerto 80).</li> <li>Desde otra m\u00e1quina, crea un t\u00fanel SSH para redirigir el puerto 80 localmente:</li> </ul> <pre><code>     ssh -L 8080:localhost:80 usuario@ip_maquina_virtual\n</code></pre> <ul> <li>Accede al servicio web desde tu navegador apuntando a <code>http://localhost:8080</code>.</li> </ul> <p>Captura de pantalla solicitada:</p> <ul> <li>Captura el comando utilizado para crear el t\u00fanel SSH y una vista del navegador mostrando el acceso al servicio web redirigido.</li> </ul> <p>Soluci\u00f3n:</p> <ol> <li>Configura un servidor web en una m\u00e1quina y utiliza el comando <code>ssh -L</code> para crear el t\u00fanel SSH.</li> <li>Verifica el acceso a trav\u00e9s del t\u00fanel desde tu navegador web.</li> </ol>"},{"location":"02.-SSH/07.-Pr%C3%A1cticas/02.-Ejercicios/#ejercicio-6-automatizacion-de-conexiones-ssh-con-scripts","title":"Ejercicio 6: Automatizaci\u00f3n de Conexiones SSH con Scripts","text":"<p>Objetivo:</p> <p>Crear un script que automatice la conexi\u00f3n y ejecuci\u00f3n de comandos en m\u00faltiples servidores.</p> <p>Instrucciones:</p> <ul> <li>Crea un script que conecte autom\u00e1ticamente a 3 m\u00e1quinas virtuales y ejecute un comando (por ejemplo, listar directorios):</li> </ul> <pre><code>     #!/bin/bash\n     for ip in 192.168.1.10 192.168.1.11 192.168.1.12; do\n         ssh usuario@$ip \"ls -l /home/usuario/\"\n     done\n</code></pre> <ul> <li>Aseg\u00farate de que las claves SSH est\u00e1n configuradas en todas las m\u00e1quinas para la autenticaci\u00f3n sin contrase\u00f1a.</li> </ul> <p>Captura de pantalla solicitada:</p> <ul> <li>Captura el script utilizado y la salida del comando ejecutado en las m\u00e1quinas virtuales.</li> </ul> <p>Soluci\u00f3n:</p> <ul> <li>Escribe un script que recorra una lista de direcciones IP y ejecute el comando en cada m\u00e1quina.</li> <li>Aseg\u00farate de que la autenticaci\u00f3n sin contrase\u00f1a est\u00e9 configurada para facilitar la automatizaci\u00f3n.</li> </ul>"},{"location":"03.-DHCP/","title":"DHCP","text":"<p>El protocolo de configuraci\u00f3n din\u00e1mica de host DHCP (Dynamic Host Configuration Protocol) es un est\u00e1ndar TCP/IP que simplifica la administraci\u00f3n de la configuraci\u00f3n IP haci\u00e9ndola autom\u00e1tica. Un servidor gestiona la concesi\u00f3n de direcciones IP de un determinado segmento de red y mantiene una lista actualizada de la correspondencia entre estas direcciones IP y las direcciones MAC de los equipos que las han solicitado. En el protocolo DHCP, el servidor utiliza el puerto 67/udp y el cliente el 68/udp.</p>"},{"location":"03.-DHCP/01.-Introducci%C3%B3n%20a%20DHCP/","title":"01.-Introducci\u00f3n a DHCP","text":"<ul> <li>Definici\u00f3n: DHCP (Dynamic Host Configuration Protocol) es un protocolo de red que permite la asignaci\u00f3n autom\u00e1tica de direcciones IP y otros par\u00e1metros de configuraci\u00f3n a los dispositivos que se conectan a una red. Este protocolo es esencial para facilitar la administraci\u00f3n de direcciones IP, ya que los dispositivos conectados a una red necesitan una direcci\u00f3n IP para comunicarse adecuadamente. DHCP garantiza que cada dispositivo obtenga una IP sin intervenci\u00f3n manual, lo cual reduce significativamente el esfuerzo administrativo.</li> <li>Prop\u00f3sito: El objetivo principal de DHCP es reducir la carga administrativa de asignar manualmente direcciones IP, especialmente en redes grandes o din\u00e1micas. En una red extensa, la asignaci\u00f3n manual de direcciones IP puede ser un proceso engorroso y propenso a errores. DHCP automatiza esta tarea, asegurando que los dispositivos se configuren correctamente, lo cual es especialmente importante en redes con dispositivos que se conectan y desconectan frecuentemente.</li> </ul>"},{"location":"03.-DHCP/02.-Funcionamiento%20del%20Protocolo%20DHCP/","title":"02.-Funcionamiento del Protocolo DHCP","text":"<ul> <li> <p>Proceso: DHCP opera mediante un mecanismo en el que el servidor DHCP asigna direcciones IP a los dispositivos (clientes) que lo solicitan. Este proceso es completamente automatizado y permite que cada dispositivo reciba una direcci\u00f3n IP v\u00e1lida junto con otros par\u00e1metros necesarios para la comunicaci\u00f3n en la red. El ciclo de trabajo est\u00e1ndar de DHCP se describe mediante las fases DORA, que garantizan una asignaci\u00f3n efectiva y sin conflictos de las direcciones IP disponibles.</p> </li> <li> <p>DORA: Estas cuatro fases describen c\u00f3mo se establece la conexi\u00f3n entre el cliente y el servidor DHCP:</p> <ol> <li> <p>Discover: El cliente busca un servidor DHCP enviando un mensaje de difusi\u00f3n para solicitar una IP. Este mensaje se env\u00eda a toda la red y espera una respuesta de cualquier servidor DHCP disponible.</p> </li> <li> <p>Offer: El servidor DHCP responde ofreciendo una direcci\u00f3n IP disponible. La oferta tambi\u00e9n puede incluir otros par\u00e1metros de red, como la m\u00e1scara de subred y la puerta de enlace predeterminada, que son necesarios para que el dispositivo funcione correctamente en la red.</p> </li> <li> <p>Request: El cliente acepta la IP ofrecida y solicita asignarla. Este mensaje tambi\u00e9n se env\u00eda como una difusi\u00f3n para informar a otros servidores DHCP que el cliente ha seleccionado una oferta espec\u00edfica.</p> </li> <li> <p>Acknowledge: El servidor confirma la asignaci\u00f3n y el cliente puede usar la direcci\u00f3n IP. Esta fase finaliza el proceso y permite al dispositivo comenzar a comunicarse dentro de la red con los par\u00e1metros asignados.</p> </li> </ol> </li> </ul>"},{"location":"03.-DHCP/04.-Componentes%20del%20Servidor%20DHCP/","title":"04.-Componentes del Servidor DHCP","text":"<p>Un servidor DHCP no solo asigna direcciones IP, sino que tambi\u00e9n proporciona otros par\u00e1metros necesarios para la correcta configuraci\u00f3n del dispositivo en la red:</p> <ul> <li> <p>Direcci\u00f3n IP: Asigna IPs din\u00e1micas dentro de un rango definido. Estas direcciones son temporales y se asignan a los dispositivos por un periodo determinado, lo cual permite una mejor gesti\u00f3n del espacio de direcciones.</p> </li> <li> <p>M\u00e1scara de Subred: Define qu\u00e9 porci\u00f3n de la direcci\u00f3n IP corresponde a la red y cu\u00e1l a los dispositivos. Esto es fundamental para que los dispositivos sepan c\u00f3mo comunicarse dentro de la misma red y cu\u00e1ndo necesitan enviar tr\u00e1fico a trav\u00e9s de un enrutador.</p> </li> <li> <p>Puerta de Enlace Predeterminada (Gateway): Direcci\u00f3n del router a trav\u00e9s del cual los dispositivos pueden acceder a otras redes. Sin esta informaci\u00f3n, los dispositivos solo podr\u00edan comunicarse dentro de la red local, limitando su funcionalidad.</p> </li> <li> <p>Servidores DNS: Permiten que los dispositivos resuelvan nombres de dominio en direcciones IP. Esto es crucial para la navegaci\u00f3n por Internet, ya que permite que los usuarios accedan a sitios web mediante nombres en lugar de recordar direcciones IP.</p> </li> <li> <p>Lease Time: Tiempo durante el cual se asigna una direcci\u00f3n IP al dispositivo antes de que deba renovarse. Una vez expirado, el dispositivo debe solicitar una nueva IP o renovar la existente, lo cual permite al servidor recuperar IPs que ya no est\u00e1n en uso y reasignarlas a otros dispositivos.</p> </li> </ul>"},{"location":"03.-DHCP/05.-Configuraci%C3%B3n%20de%20un%20Servidor%20DHCP/","title":"05.-Configuraci\u00f3n de un Servidor DHCP","text":"<ul> <li> <p>Instalaci\u00f3n: Se requiere un servidor que soporte DHCP, que puede ser un servidor f\u00edsico, virtual o un dispositivo de red como un router. Esta flexibilidad permite que tanto redes peque\u00f1as como grandes puedan implementar DHCP de acuerdo a sus necesidades.</p> </li> <li> <p>Rangos de Direcciones IP: El administrador define un rango de direcciones que pueden ser asignadas din\u00e1micamente a los dispositivos. Este rango debe ser planificado cuidadosamente para evitar conflictos y garantizar que haya suficientes direcciones para todos los dispositivos conectados.</p> </li> <li> <p>Par\u00e1metros Adicionales: M\u00e1scara de subred, puerta de enlace, DNS, y otros par\u00e1metros de configuraci\u00f3n que se distribuyen a los clientes. Estos par\u00e1metros garantizan que los dispositivos puedan comunicarse de manera efectiva tanto dentro de la red como hacia el exterior.</p> </li> <li> <p>Tiempo de Concesi\u00f3n (Lease Time): Define el tiempo durante el cual una IP est\u00e1 asignada a un cliente. Una vez expirado, la IP puede reasignarse. Este par\u00e1metro es importante para optimizar el uso del espacio de direcciones IP, especialmente en redes con dispositivos que se conectan y desconectan frecuentemente.</p> </li> </ul>"},{"location":"03.-DHCP/06.-Ventajas%20de%20DHCP/","title":"06.-Ventajas de DHCP","text":"<ul> <li> <p>Automatizaci\u00f3n: Elimina la necesidad de asignar manualmente direcciones IP a cada dispositivo, lo que es especialmente \u00fatil en redes grandes o redes con dispositivos m\u00f3viles. La automatizaci\u00f3n de la asignaci\u00f3n de direcciones IP reduce significativamente la carga de trabajo del administrador de red y previene errores humanos comunes.</p> </li> <li> <p>Reducci\u00f3n de Errores: Minimiza errores humanos como la asignaci\u00f3n de IPs duplicadas, lo que puede causar conflictos en la red. Los conflictos de direcciones IP pueden hacer que los dispositivos sean incapaces de comunicarse, lo cual se evita mediante la gesti\u00f3n automatizada de DHCP.</p> </li> <li> <p>Escalabilidad: Facilita la expansi\u00f3n de redes al permitir una gesti\u00f3n centralizada de la asignaci\u00f3n de IPs y configuraci\u00f3n de red. Esto es particularmente importante en redes empresariales que crecen r\u00e1pidamente y necesitan una soluci\u00f3n de administraci\u00f3n flexible y eficiente.</p> </li> </ul>"},{"location":"03.-DHCP/07.-Escenarios%20de%20uso/","title":"07.-Escenarios de uso","text":"<ul> <li> <p>Redes Empresariales: En empresas con cientos o miles de dispositivos conectados a la red, DHCP permite una gesti\u00f3n centralizada y eficiente. Esta capacidad de gesti\u00f3n centralizada reduce la complejidad de mantener la red operativa y disminuye los costos de administraci\u00f3n.</p> </li> <li> <p>Proveedores de Servicios de Internet (ISP): Asignan din\u00e1micamente direcciones IP p\u00fablicas a sus clientes. Esto asegura que los recursos de IP se utilicen eficientemente, ya que las IP se asignan solo cuando los clientes se conectan.</p> </li> <li> <p>Redes Dom\u00e9sticas: Los routers caseros suelen actuar como servidores DHCP para gestionar los dispositivos de la red local. Esto simplifica la configuraci\u00f3n de la red para los usuarios finales, ya que no necesitan conocimientos t\u00e9cnicos para conectar dispositivos a la red.</p> </li> <li> <p>Dispositivos M\u00f3viles: Conexiones din\u00e1micas en redes Wi-Fi, donde los dispositivos se conectan y desconectan frecuentemente. DHCP permite que los dispositivos m\u00f3viles se conecten r\u00e1pidamente y sin intervenci\u00f3n del usuario, lo cual es esencial para la movilidad y flexibilidad de las redes modernas.</p> </li> </ul>"},{"location":"03.-DHCP/08.-Glosario%20de%20t%C3%A9rminos/","title":"08.-Glosario de t\u00e9rminos","text":"<ul> <li>\u00c1mbito del servidor DHCP: Agrupamiento administrativo de equipos o clientes de una subred que utilizan el servicio DHCP.</li> <li>Rango del servidor DHCP: Rango de direcciones que el servidor DHCP puede conceder.</li> <li>Tiempo de concesi\u00f3n: Periodo de tiempo durante el cual un equipo cliente puede utilizar una configuraci\u00f3n de red concedida.</li> <li>Reserva de direcciones IP: Direcciones IP utilizadas para asignarse siempre a los mismos equipos en la red local. Los equipos se identifican por la direcci\u00f3n MAC.</li> </ul>"},{"location":"03.-DHCP/09.-Conclusi%C3%B3n/","title":"09.-Conclusi\u00f3n","text":"<p>DHCP es un protocolo fundamental en la gesti\u00f3n eficiente de redes modernas. Su capacidad para asignar autom\u00e1ticamente direcciones IP y otros par\u00e1metros de red lo convierte en una herramienta crucial para reducir la complejidad de la administraci\u00f3n de redes, evitar errores y mejorar la escalabilidad. Gracias a DHCP, los administradores de red pueden gestionar eficientemente una gran cantidad de dispositivos sin preocuparse por la asignaci\u00f3n manual de direcciones IP, lo cual permite un mejor uso de los recursos de red y garantiza la conectividad de los dispositivos en todo momento. Esto es especialmente valioso en entornos con alta rotaci\u00f3n de dispositivos, como oficinas, universidades y redes p\u00fablicas, donde la simplicidad y eficiencia en la configuraci\u00f3n son esenciales para mantener una red estable y operativa.</p>"},{"location":"03.-DHCP/03.Fases%20del%20Proceso%20DHCP/01.-Discover%20%28Descubrimiento%29/","title":"01.-Discover (Descubrimiento)","text":"<p>El cliente env\u00eda una solicitud a la direcci\u00f3n de broadcast  255.255.255.255 para encontrar un servidor DHCP en la red. Este paso es esencial para identificar qu\u00e9 servidores DHCP est\u00e1n disponibles y pueden proporcionar una direcci\u00f3n IP al cliente. El mensaje de descubrimiento se env\u00eda a trav\u00e9s de un broadcast, ya que el cliente a\u00fan no tiene una direcci\u00f3n IP.</p>"},{"location":"03.-DHCP/03.Fases%20del%20Proceso%20DHCP/02.-Offer%20%28Oferta%29/","title":"02.-Offer (Oferta)","text":"<p>El servidor DHCP ofrece una direcci\u00f3n IP y par\u00e1metros de configuraci\u00f3n de red como la m\u00e1scara de subred, la puerta de enlace predeterminada, etc. al cliente identificado por su direcci\u00f3n MAC. Este mensaje contiene toda la informaci\u00f3n que el cliente necesita para integrarse a la red. En principio podr\u00eda terminar aqu\u00ed, pero hay dos pasos m\u00e1s para evitar conflictos en el caso de que hubiera m\u00e1s de un servidor DHCP en la red: Request (Solicitud) y Acknowledge (Confirmaci\u00f3n).</p>"},{"location":"03.-DHCP/03.Fases%20del%20Proceso%20DHCP/03.-Request%20%28Solicitud%29/","title":"03.-Request (Solicitud)","text":"<p>El cliente responde al servidor solicitando la direcci\u00f3n IP que se le ha ofrecido. Este mensaje tambi\u00e9n notifica a otros servidores que ya no es necesario ofrecer una direcci\u00f3n, ya que el cliente ha elegido una oferta espec\u00edfica.</p>"},{"location":"03.-DHCP/03.Fases%20del%20Proceso%20DHCP/04.-Acknowledge%20%28Confirmaci%C3%B3n%29/","title":"04.-Acknowledge (Confirmaci\u00f3n)","text":"<p>El servidor DHCP confirma la asignaci\u00f3n de la IP, y el cliente la acepta. Este mensaje asegura que el cliente puede comenzar a usar la direcci\u00f3n IP, y la asignaci\u00f3n queda registrada en el servidor para evitar conflictos futuros.</p>"},{"location":"03.-DHCP/10.-Pr%C3%A1cticas/01.-El%20servidor%20ISC%20DHCP/","title":"01.-El servidor ISC DHCP","text":"<p>El servidor ISC DHCP es una implementaci\u00f3n de servidor de DHCP desarrollada por el Internet Systems Consortium (ISC). Este software de c\u00f3digo abierto es ampliamente utilizado en entornos Unix y Linux para asignar autom\u00e1ticamente configuraciones de red a dispositivos, como direcciones IP, puertas de enlace y servidores DNS. Sus componentes clave y funcionalidades principales son:</p> <ol> <li> <p>Asignaci\u00f3n Autom\u00e1tica de IPs: Distribuye direcciones IP de un rango (o pool) definido a los clientes que lo soliciten, lo que facilita la gesti\u00f3n de direcciones en redes grandes y din\u00e1micas.</p> </li> <li> <p>Configuraci\u00f3n Avanzada de Subredes y Rutas: Permite configurar redes complejas, definiendo par\u00e1metros espec\u00edficos para subredes y agregando opciones de ruta para redes que necesitan configuraciones personalizadas.</p> </li> <li> <p>Soporte para BOOTP y PXE: Es compatible con BOOTP (Bootstrap Protocol) y PXE (Preboot Execution Environment), lo cual es \u00fatil en escenarios de red donde se necesita cargar un sistema operativo desde la red.</p> </li> <li> <p>Funciones de Logging y Monitorizaci\u00f3n: Ofrece opciones de registro detalladas para supervisar el tr\u00e1fico DHCP y solucionar problemas de asignaci\u00f3n de IP.</p> </li> <li> <p>Configuraci\u00f3n de Duraci\u00f3n de Leases: Permite definir cu\u00e1nto tiempo un cliente puede retener una IP asignada, ayudando a controlar el uso de direcciones en redes con clientes temporales.</p> </li> <li> <p>Escalabilidad y Flexibilidad: Es adecuado tanto para redes peque\u00f1as como para grandes despliegues empresariales, siendo compatible con entornos de alta disponibilidad.</p> </li> </ol> <p>ISC DHCP es muy popular en entornos empresariales y educativos que requieren un servidor de DHCP confiable en Linux o Unix. Tambi\u00e9n es ampliamente compatible con herramientas de gesti\u00f3n de configuraci\u00f3n como Ansible o Puppet para automatizaci\u00f3n y despliegue masivo.</p> <p>Sin embargo: ISC anunci\u00f3 el fin del mantenimiento de la ISC DHCP a finales de 2022.</p> <p>ISC seguir\u00e1 prestando servicios de apoyo profesional a los suscriptores existentes, pero no tiene la intenci\u00f3n de emitir m\u00e1s versiones de mantenimiento. Para recursos que puedan ayudar en la migraci\u00f3n de la implementaci\u00f3n existente del servidor ISC DHCP al nuevo servidor DHCP Kea, se puede consultar esta p\u00e1gina.</p> <p>ISC DHCP fue una soluci\u00f3n de c\u00f3digo abierto completo para la implementaci\u00f3n de servidores DHCP, agentes de rel\u00e9s y clientes.</p> <p>ISC ha desarrollado un nuevo servidor DHCP, Kea, que  reemplaza a ISC DHCP en la mayor\u00eda de las implementaciones de servidor. Se recomienda que las nuevas implementaciones usen Kea e implementen ISC DHCP s\u00f3lo si Kea no satisface las necesidades.</p>"},{"location":"03.-DHCP/10.-Pr%C3%A1cticas/02.-El%20servidor%20Kea%20DHCP/","title":"02.-El servidor Kea DHCP","text":""},{"location":"03.-DHCP/10.-Pr%C3%A1cticas/02.-El%20servidor%20Kea%20DHCP/#por-que-elegir-kea","title":"\u00bfPor qu\u00e9 elegir Kea?","text":"<p>ISC cuenta con DOS distribuciones de servidores DHCP basadas en normas de c\u00f3digo abierto y basadas en est\u00e1ndares: Kea DHCP e ISC DHCP. Kea incluye todas las caracter\u00edsticas m\u00e1s solicitadas, es nueva y est\u00e1 dise\u00f1ada para un entorno de red m\u00e1s moderno. ISC anunci\u00f3 el fin de Vida para el antiguo sistema ISC DHCP en 2022. Los usuarios de ISC DHCP pueden encontrar estos recursos \u00fatiles en la migraci\u00f3n de sus implementaciones de servidor DHCP al servidor Kea.</p>"},{"location":"03.-DHCP/10.-Pr%C3%A1cticas/02.-El%20servidor%20Kea%20DHCP/#que-diferencia-al-servidor-kea-dhcp-del-antiguo-isc-dhcp","title":"\u00bfQu\u00e9 diferencia al servidor Kea DHCP del antiguo ISC DHCP?","text":"<ol> <li> <p>Dise\u00f1o de componentes modulares, Extensible con M\u00f3dulos Hooks. La distribuci\u00f3n de Kea incluye demonios separados para un servidor DHCPv4, un servidor DHCPv6 y un m\u00f3dulo din\u00e1mico DNS (DDNS). Muchas caracter\u00edsticas opcionales est\u00e1n habilitadas con m\u00f3dulos de hooks, que solo se ejecutan si los se usan. Se puede escribir m\u00f3dulos de hooks (en C) propios o probar algunos de los ganchos que ofrecemos.</p> </li> <li> <p>Reconfiguraci\u00f3n en l\u00ednea con REST API. Kea utiliza un archivo de configuraci\u00f3n JSON que se puede modificar de forma remota a trav\u00e9s de comandos <code>set</code> y recargados sin detener y reiniciar el servidor, una operaci\u00f3n que podr\u00eda tomar bastante tiempo con ISC DHCP.</p> </li> <li> <p>Dise\u00f1ado para integrarse con sistemas existentes. Kea permite separar los datos del entorno de ejecuci\u00f3n, permitiendo nuevas opciones de implementaci\u00f3n. Sus datos de red - arrendamientos, definiciones de reservas de host, y la mayor\u00eda de los datos de configuraci\u00f3n - se pueden localizar por separado del servidor DHCP en s\u00ed, utilizando un Kea \"backend\".</p> </li> <li> <p>Dashboard gr\u00e1fico basado en la web. Kea ahora tiene un panel gr\u00e1fico para monitorizar varios servidores Kea. Este sistema, llamado Stork, utiliza agentes desplegados en los servidores Kea para transmitir informaci\u00f3n a una plataforma de gesti\u00f3n centralizada, proporcionando al administrador una visi\u00f3n r\u00e1pida del estado y la actividad del sistema f\u00e1cil de usar.</p> </li> </ol> <p>Kea es compatible con dos backends de base de datos; MySQL y PostgreSQL. Se puede elegir almacenar contratos de arrendamiento,  reservas de hosts o datos de configuraci\u00f3n compartida en una base de datos independiente. Entre los beneficios de esto figuran:</p> <ul> <li>Se integra m\u00e1s f\u00e1cilmente con otros sistemas -sistemas de aprovisionamiento, IPAMS y as\u00ed - mediante el almacenamiento de datos cr\u00edticos en una base de datos separada.</li> <li>Utilza las mismas reservas de backend de los hosts en m\u00faltiples servidores DHCP.</li> <li>Administrar las opciones globales de configuraci\u00f3n del backend de forma centralizada.</li> <li>Administrar grandes conjuntos de direcciones en una base de datos en lugar de un archivo de texto.</li> </ul>"},{"location":"03.-DHCP/10.-Pr%C3%A1cticas/03.-Escenario%20de%20pr%C3%A1cticas/","title":"Index","text":"<p>Vamos a crear una infraestructura con varias m\u00e1quinas virtuales y contenedores donde instalaremos un servidor DHCP para configurar de forma din\u00e1mica la configuraci\u00f3n de red.</p> <p> </p>"},{"location":"03.-DHCP/10.-Pr%C3%A1cticas/03.-Escenario%20de%20pr%C3%A1cticas/01.-Creaci%C3%B3n%20de%20la%20plantilla%20para%20las%20m%C3%A1quinas%20clientes/","title":"01.-Creaci\u00f3n de la plantilla para las m\u00e1quinas clientes","text":"<p>Vamos a crear una plantilla que utilizaremos para la creaci\u00f3n de las m\u00e1quinas que utilizaremos como clientes. Para ello:</p> <ul> <li>Crea con <code>virt-install</code> una m\u00e1quina virtual de Debian 12 con formato qcow2 y un tama\u00f1o de 3GiB.<ul> <li>La m\u00e1quina debe tener un usuario <code>debian</code> con contrase\u00f1a <code>debian</code> que puede utilizar <code>sudo</code> sin contrase\u00f1a.</li> <li>Instala el servidor ssh en la m\u00e1quina.</li> </ul> </li> <li>Convierte la m\u00e1quina virtual en una plantilla llamada plantilla-cliente. El hostname de la m\u00e1quina debe ser plantilla-cliente-tunombre. \u00bfCu\u00e1nto ocupa el volumen de la plantilla en disco?</li> <li>Utiliza la herramienta <code>virt-sparsify</code> para reducir el tama\u00f1o ocupado en disco del volumen. \u00bfCu\u00e1nto ocupa ahora el volumen de la plantilla en disco?</li> </ul>"},{"location":"03.-DHCP/10.-Pr%C3%A1cticas/03.-Escenario%20de%20pr%C3%A1cticas/01.-Creaci%C3%B3n%20de%20la%20plantilla%20para%20las%20m%C3%A1quinas%20clientes/#captura","title":"Captura","text":"<p>Captura de pantalla donde se demuestre que la plantilla no se puede ejecutar.</p>"},{"location":"03.-DHCP/10.-Pr%C3%A1cticas/03.-Escenario%20de%20pr%C3%A1cticas/01.-Creaci%C3%B3n%20de%20la%20plantilla%20para%20las%20m%C3%A1quinas%20clientes/#solucion","title":"Soluci\u00f3n","text":""},{"location":"03.-DHCP/10.-Pr%C3%A1cticas/03.-Escenario%20de%20pr%C3%A1cticas/01.-Creaci%C3%B3n%20de%20la%20plantilla%20para%20las%20m%C3%A1quinas%20clientes/#creacion-de-la-maquina-virtual","title":"Creaci\u00f3n de la m\u00e1quina virtual:","text":"<pre><code>  virt-install \\\n    --name plantilla-cliente-&lt;tunombre&gt; \\\n    --os-variant debian12 \\\n    --ram 1024 \\\n    --vcpus 1 \\\n    --disk path=/var/lib/libvirt/images/plantilla-cliente.qcow2,size=3 \\\n    --graphics none \\\n    --console pty,target_type=serial \\\n    --location 'http://deb.debian.org/debian/dists/bookworm/main/installer-amd64/' \\\n    --extra-args 'console=ttyS0,115200n8 serial'\n</code></pre>"},{"location":"03.-DHCP/10.-Pr%C3%A1cticas/03.-Escenario%20de%20pr%C3%A1cticas/01.-Creaci%C3%B3n%20de%20la%20plantilla%20para%20las%20m%C3%A1quinas%20clientes/#durante-la-instalacion-asegurate-de","title":"Durante la instalaci\u00f3n, aseg\u00farate de:","text":"<ul> <li>Configurar el usuario <code>debian</code> con contrase\u00f1a <code>debian</code>.     Habilitar <code>sudo</code> sin contrase\u00f1a para <code>debian</code> editando <code>/etc/sudoers</code> (consultar el comando sudo en los anexos) y agregando.</li> </ul> <pre><code>debian ALL=(ALL) NOPASSWD:ALL\n</code></pre> <ul> <li>Instalar el servidor SSH (puedes instalarlo ejecutando <code>apt install ssh</code> una vez creada la m\u00e1quina).</li> </ul> <p>Cambia el nombre de la m\u00e1quina a <code>plantilla-cliente-&lt;tunombre&gt;</code> en el archivo <code>/etc/hostname</code>.</p>"},{"location":"03.-DHCP/10.-Pr%C3%A1cticas/03.-Escenario%20de%20pr%C3%A1cticas/01.-Creaci%C3%B3n%20de%20la%20plantilla%20para%20las%20m%C3%A1quinas%20clientes/#conversion-a-plantilla","title":"Conversi\u00f3n a plantilla","text":"<p>Una vez configurada la m\u00e1quina, ap\u00e1gala y realiza un respaldo para reutilizarla como plantilla. Puedes hacerlo creando un snapshot o simplemente copiando la imagen.</p> <p>Para verificar el espacio en disco ocupado inicialmente, utiliza:</p> <pre><code>du -sh /var/lib/libvirt/images/plantilla-cliente.qcow2\n</code></pre>"},{"location":"03.-DHCP/10.-Pr%C3%A1cticas/03.-Escenario%20de%20pr%C3%A1cticas/01.-Creaci%C3%B3n%20de%20la%20plantilla%20para%20las%20m%C3%A1quinas%20clientes/#reduccion-de-tamano-con-virt-sparsify","title":"Reducci\u00f3n de tama\u00f1o con <code>virt-sparsify</code>","text":"<p>Usa <code>virt-sparsify</code> (Compresi\u00f3n de im\u00e1genes con <code>virt-sparsify</code>) para reducir el espacio en disco eliminado sectores vac\u00edos:</p> <pre><code>sudo virt-sparsify --compress /var/lib/libvirt/images/plantilla-cliente.qcow2 /var/lib/libvirt/images/plantilla-cliente-sparse.qcow2\n</code></pre> <p>El proceso tomar\u00e1 cierto tiempo... paciencia. Para verificar el nuevo tama\u00f1o del archivo reducido:</p> <pre><code>du -sh /var/lib/libvirt/images/plantilla-cliente-sparse.qcow2\n</code></pre>"},{"location":"03.-DHCP/10.-Pr%C3%A1cticas/03.-Escenario%20de%20pr%C3%A1cticas/02.-Creaci%C3%B3n%20del%20escenario/","title":"02.-Creaci\u00f3n del escenario","text":"<p>Todas las operaciones se tienen que hacer desde la l\u00ednea de comandos:</p>"},{"location":"03.-DHCP/10.-Pr%C3%A1cticas/03.-Escenario%20de%20pr%C3%A1cticas/02.-Creaci%C3%B3n%20del%20escenario/#1-crea-una-red-muy-aislada-que-se-llame-red_intra-que-creara-el-puente-br-intra-esta-red-se-tiene-que-iniciar-cada-vez-que-encendemos-el-host","title":"1.-Crea una red muy aislada, que se llame red_intra que crear\u00e1 el puente <code>br-intra</code>. Esta red se tiene que iniciar cada vez que encendemos el host.","text":""},{"location":"03.-DHCP/10.-Pr%C3%A1cticas/03.-Escenario%20de%20pr%C3%A1cticas/02.-Creaci%C3%B3n%20del%20escenario/#solucion","title":"Soluci\u00f3n","text":"<ul> <li>Se crea un puente de red llamado <code>br-intra</code>.</li> <li>Se configura para que arranque autom\u00e1ticamente al inicio del sistema.</li> <li>Finalmente, se activa manualmente para comprobar su funcionamiento o para habilitarlo de inmediato.</li> </ul>"},{"location":"03.-DHCP/10.-Pr%C3%A1cticas/03.-Escenario%20de%20pr%C3%A1cticas/02.-Creaci%C3%B3n%20del%20escenario/#ejecuta-estos-comandos-para-crear-la-red","title":"Ejecuta estos comandos para crear la red:","text":"<pre><code># Crear el bridge\nsudo nmcli connection add type bridge ifname br-intra con-name br-intra\n\n# Configurar el bridge para que se active autom\u00e1ticamente al inicio\nsudo nmcli connection modify br-intra connection.autoconnect yes\nsudo nmcli connection up br-intra\n</code></pre>"},{"location":"03.-DHCP/10.-Pr%C3%A1cticas/03.-Escenario%20de%20pr%C3%A1cticas/02.-Creaci%C3%B3n%20del%20escenario/#2-crea-con-virt-install-la-maquina-router-con-debian-12","title":"2.-Crea con <code>virt-install</code> la m\u00e1quina router con Debian 12:","text":"<ul> <li>Debe estar conectada a la red p\u00fablica (al bridge <code>br0</code>) y la red_intra.</li> <li>Esta m\u00e1quina utiliza un disco en formato raw de 10 Gb.</li> <li>El hostname de esta m\u00e1quina debe ser <code>router-tunombre</code>.</li> <li>Se debe poder acceder a ella por ssh con el usuario <code>user</code> sin que te pida contrase\u00f1a.</li> <li>El usuario <code>user</code> debe poder ejecutar el comando <code>sudo</code> sin que pida contrase\u00f1a.</li> <li>Debes configurar la segunda interfaz de red con direccionamiento est\u00e1tico para que tenga la direcci\u00f3n <code>192.168.200.1</code>.</li> <li>Esta m\u00e1quina se debe iniciar cada vez que arrancamos el host.</li> </ul> <p>Ver el anexo: El puente virbr0</p>"},{"location":"03.-DHCP/10.-Pr%C3%A1cticas/03.-Escenario%20de%20pr%C3%A1cticas/02.-Creaci%C3%B3n%20del%20escenario/#solucion_1","title":"Soluci\u00f3n","text":""},{"location":"03.-DHCP/10.-Pr%C3%A1cticas/03.-Escenario%20de%20pr%C3%A1cticas/02.-Creaci%C3%B3n%20del%20escenario/#usa-virt-install-para-crear-esta-maquina-con-debian-12-conectada-a-br0-red-publica-y-br-intra-red-interna","title":"Usa <code>virt-install</code> para crear esta m\u00e1quina con Debian 12 conectada a <code>br0</code> (red p\u00fablica) y <code>br-intra</code> (red interna):","text":"<pre><code>virt-install \\\n  --name router-&lt;tu_nombre&gt; \\\n  --os-variant debian12 \\\n  --ram 1024 \\\n  --vcpus 1 \\\n  --disk path=/var/lib/libvirt/images/router.raw,size=10,format=raw \\\n  --network bridge=br0 \\\n  --network bridge=br-intra \\\n  --graphics none \\\n  --console pty,target_type=serial \\\n  --location 'http://deb.debian.org/debian/dists/bookworm/main/installer-amd64/' \\\n  --extra-args 'console=ttyS0,115200n8 serial'\n</code></pre> <ul> <li>Una vez creada, sigue estos pasos de configuraci\u00f3n dentro de la m\u00e1quina:</li> </ul>"},{"location":"03.-DHCP/10.-Pr%C3%A1cticas/03.-Escenario%20de%20pr%C3%A1cticas/02.-Creaci%C3%B3n%20del%20escenario/#configura-el-usuario-y-ssh","title":"Configura el usuario y SSH:","text":"<p>Consulta el apartado de autenticaci\u00f3n con claves p\u00fablica-privada.</p>"},{"location":"03.-DHCP/10.-Pr%C3%A1cticas/03.-Escenario%20de%20pr%C3%A1cticas/02.-Creaci%C3%B3n%20del%20escenario/#anade-el-usuario-user","title":"A\u00f1ade el usuario <code>user</code>:","text":"<pre><code>sudo adduser user\n</code></pre>"},{"location":"03.-DHCP/10.-Pr%C3%A1cticas/03.-Escenario%20de%20pr%C3%A1cticas/02.-Creaci%C3%B3n%20del%20escenario/#dar-permisos-sudo-sin-contrasena","title":"Dar permisos <code>sudo</code> sin contrase\u00f1a:","text":"<pre><code>echo 'user ALL=(ALL) NOPASSWD:ALL' | sudo tee /etc/sudoers.d/user\n</code></pre>"},{"location":"03.-DHCP/10.-Pr%C3%A1cticas/03.-Escenario%20de%20pr%C3%A1cticas/02.-Creaci%C3%B3n%20del%20escenario/#configura-las-claves-publicas-para-el-acceso-sin-contrasena","title":"Configura las claves p\u00fablicas para el acceso sin contrase\u00f1a:","text":"<pre><code>sudo mkdir -p /home/user/.ssh\necho 'tu_clave_publica' | sudo tee -a /home/user/.ssh/authorized_keys\necho 'mi_clave_publica' | sudo tee -a /home/user/.ssh/authorized_keys\nsudo chown -R user:user /home/user/.ssh\nsudo chmod 600 /home/user/.ssh/authorized_keys\n</code></pre>"},{"location":"03.-DHCP/10.-Pr%C3%A1cticas/03.-Escenario%20de%20pr%C3%A1cticas/02.-Creaci%C3%B3n%20del%20escenario/#configura-la-ip-estatica-en-la-segunda-interfaz-de-red","title":"Configura la IP est\u00e1tica en la segunda interfaz de red:","text":"<ul> <li>Edita <code>/etc/network/interfaces</code> y agrega:</li> </ul> <pre><code>auto ensXX  # reemplaza \"ensXX\" por la interfaz de red interna\niface ensXX inet static\n    address 192.168.200.1\n    netmask 255.255.255.0\n</code></pre> <ul> <li>Configura el arranque autom\u00e1tico:</li> </ul> <pre><code>virsh autostart router-tunombre\n</code></pre>"},{"location":"03.-DHCP/10.-Pr%C3%A1cticas/03.-Escenario%20de%20pr%C3%A1cticas/02.-Creaci%C3%B3n%20del%20escenario/#3-crea-con-virt-install-la-maquina-servidornas-con-alpine-linux-320","title":"3.-Crea con <code>virt-install</code> la m\u00e1quina servidorNAS con Alpine Linux 3.20.","text":"<pre><code>- Est\u00e1 conectada a la red **red_intra**, su direcci\u00f3n IP debe ser la `192.168.200.2`.\n- La m\u00e1quina tendr\u00e1 un disco qcow2 de 15Gb.\n- El hostname de esta m\u00e1quina debe ser `nas-tunombre`.\n- Se debe poder acceder a ella por ssh con el usuario `user` sin que te pida contrase\u00f1a.\n- Est\u00e1 m\u00e1quina se debe iniciar cada vez que arrancamos el host.\n</code></pre>"},{"location":"03.-DHCP/10.-Pr%C3%A1cticas/03.-Escenario%20de%20pr%C3%A1cticas/02.-Creaci%C3%B3n%20del%20escenario/#solucion_2","title":"Soluci\u00f3n","text":""},{"location":"03.-DHCP/10.-Pr%C3%A1cticas/03.-Escenario%20de%20pr%C3%A1cticas/02.-Creaci%C3%B3n%20del%20escenario/#utiliza-virt-install-para-crear-esta-maquina-con-alpine-linux-320-y-asignarle-un-disco-de-15-gb","title":"Utiliza <code>virt-install</code> para crear esta m\u00e1quina con Alpine Linux 3.20 y asignarle un disco de 15 GB:","text":"<pre><code>virt-install \\\n  --name nas-tunombre \\\n  --os-variant alpine \\\n  --ram 512 \\\n  --vcpus 1 \\\n  --disk path=/var/lib/libvirt/images/nas.qcow2,size=15,format=qcow2 \\\n  --network bridge=br-intra \\\n  --graphics none \\\n  --console pty,target_type=serial \\\n  --location 'http://dl-cdn.alpinelinux.org/alpine/v3.20/releases/x86_64/'\n</code></pre>"},{"location":"03.-DHCP/10.-Pr%C3%A1cticas/03.-Escenario%20de%20pr%C3%A1cticas/02.-Creaci%C3%B3n%20del%20escenario/#dentro-de-servidornas-configura","title":"Dentro de <code>servidorNAS</code>, configura:","text":"<ul> <li>Usuario y SSH:     Crea el usuario <code>user</code> y permite el acceso por SSH sin contrase\u00f1a como en la m\u00e1quina <code>router</code>.</li> <li>Configura la IP est\u00e1tica:</li> </ul> <pre><code>ip addr add 192.168.200.2/24 dev eth0\n</code></pre> <ul> <li>Configura el arranque autom\u00e1tico:</li> </ul> <pre><code>virsh autostart nas-tunombre\n</code></pre>"},{"location":"03.-DHCP/10.-Pr%C3%A1cticas/03.-Escenario%20de%20pr%C3%A1cticas/02.-Creaci%C3%B3n%20del%20escenario/#4-crea-dos-contenedores-lxc-conectados-a-la-red-red_intra","title":"4.-Crea dos contenedores LXC conectados a la red red_intra.","text":"<ul> <li>servidorDHCP: Es un contador creado a partir de la plantilla Debian Bookworm. Configura su red de forma est\u00e1tica. Su direcci\u00f3n IP debe ser la <code>192.168.200.3</code>.</li> <li>servidorWeb: Es un contador creado a partir de la plantilla Ubuntu 22.04 Jammy. Configura su red de forma est\u00e1tica. Su direcci\u00f3n IP debe ser la <code>192.168.200.4</code>.</li> <li>Los contenedores se deben iniciar de forma autom\u00e1tica y se les debe limitar la memoria a 512Mb.</li> <li>A los contenedores se debe acceder por ssh, config\u00faralos para que podamos entrar con clave privada (configura tu clave p\u00fablica y la mia) por ssh con el usuario <code>root</code>.</li> </ul>"},{"location":"03.-DHCP/10.-Pr%C3%A1cticas/03.-Escenario%20de%20pr%C3%A1cticas/02.-Creaci%C3%B3n%20del%20escenario/#solucion_3","title":"Soluci\u00f3n","text":""},{"location":"03.-DHCP/10.-Pr%C3%A1cticas/03.-Escenario%20de%20pr%C3%A1cticas/02.-Creaci%C3%B3n%20del%20escenario/#instala-lxc","title":"Instala LXC:","text":"<pre><code>sudo apt install lxc -y\n</code></pre>"},{"location":"03.-DHCP/10.-Pr%C3%A1cticas/03.-Escenario%20de%20pr%C3%A1cticas/02.-Creaci%C3%B3n%20del%20escenario/#crea-los-contenedores-y-configura-sus-direcciones-ip","title":"Crea los contenedores y configura sus direcciones IP:","text":"<ul> <li>Servidor DHCP:</li> </ul> <pre><code>sudo lxc-create -n servidorDHCP -t debian -- --release bookworm\nsudo lxc-start -n servidorDHCP\nsudo lxc-attach -n servidorDHCP\n# Dentro del contenedor\nip addr add 192.168.200.3/24 dev eth0\n</code></pre> <ul> <li>Servidor Web:</li> </ul> <pre><code>sudo lxc-create -n servidorWeb -t ubuntu -- --release jammy\nsudo lxc-start -n servidorWeb\nsudo lxc-attach -n servidorWeb\n# Dentro del contenedor\nip addr add 192.168.200.4/24 dev eth0\n</code></pre> <ul> <li>Configurar el acceso SSH en ambos contenedores y asigna tu clave p\u00fablica en <code>/root/.ssh/authorized_keys</code>.</li> <li>Configurar el arranque autom\u00e1tico y l\u00edmites de memoria:</li> </ul> <pre><code>sudo lxc-autostart -n servidorDHCP\nsudo lxc-autostart -n servidorWeb\nsudo lxc-cgroup -n servidorDHCP memory.limit_in_bytes 512M\nsudo lxc-cgroup -n servidorWeb memory.limit_in_bytes 512M\n</code></pre>"},{"location":"03.-DHCP/10.-Pr%C3%A1cticas/03.-Escenario%20de%20pr%C3%A1cticas/02.-Creaci%C3%B3n%20del%20escenario/#5-configura-la-maquina-router-para-que-haga-snat-y-permita-que-los-contenedores-y-la-maquina-servidornas-tengan-acceso-al-exterior-la-configuracion-debe-ser-persistente","title":"5.-Configura la m\u00e1quina router para que haga SNAT y permita que los contenedores y la m\u00e1quina servidorNAS tengan acceso al exterior (la configuraci\u00f3n debe ser persistente).","text":""},{"location":"03.-DHCP/10.-Pr%C3%A1cticas/03.-Escenario%20de%20pr%C3%A1cticas/02.-Creaci%C3%B3n%20del%20escenario/#solucion_4","title":"Soluci\u00f3n","text":""},{"location":"03.-DHCP/10.-Pr%C3%A1cticas/03.-Escenario%20de%20pr%C3%A1cticas/02.-Creaci%C3%B3n%20del%20escenario/#activa-el-reenvio-de-paquetes","title":"Activa el reenv\u00edo de paquetes:","text":"<p>En <code>/etc/sysctl.conf</code>, a\u00f1ade:</p> <pre><code>net.ipv4.ip_forward=1\n</code></pre> <p>Aplica los cambios:</p> <pre><code>sudo sysctl -p\n</code></pre>"},{"location":"03.-DHCP/10.-Pr%C3%A1cticas/03.-Escenario%20de%20pr%C3%A1cticas/02.-Creaci%C3%B3n%20del%20escenario/#configura-la-regla-de-iptables-para-nat","title":"Configura la regla de iptables para NAT:","text":"<pre><code>sudo iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE\n</code></pre>"},{"location":"03.-DHCP/10.-Pr%C3%A1cticas/03.-Escenario%20de%20pr%C3%A1cticas/02.-Creaci%C3%B3n%20del%20escenario/#guarda-la-configuracion-de-iptables-para-que-sea-persistente","title":"Guarda la configuraci\u00f3n de iptables para que sea persistente:","text":"<pre><code>sudo apt install iptables-persistent\nsudo netfilter-persistent save\n</code></pre>"},{"location":"03.-DHCP/10.-Pr%C3%A1cticas/03.-Escenario%20de%20pr%C3%A1cticas/02.-Creaci%C3%B3n%20del%20escenario/#resumen","title":"Resumen","text":"<p>Con esta configuraci\u00f3n, habr\u00e1s creado una red aislada <code>red_intra</code>, configurado un <code>router</code> con NAT para acceso a Internet, y los contenedores podr\u00e1n conectarse hacia el exterior a trav\u00e9s de este.</p>"},{"location":"03.-DHCP/10.-Pr%C3%A1cticas/03.-Escenario%20de%20pr%C3%A1cticas/03.-Creaci%C3%B3n%20de%20las%20m%C3%A1quinas%20clientes/","title":"03.-Creaci\u00f3n de las m\u00e1quinas clientes","text":""},{"location":"03.-DHCP/10.-Pr%C3%A1cticas/03.-Escenario%20de%20pr%C3%A1cticas/03.-Creaci%C3%B3n%20de%20las%20m%C3%A1quinas%20clientes/#crear-una-nueva-maquina-virtual-llamada-cliente1-a-partir-de-la-plantilla-plantilla-cliente-que-tenga-un-volumen-de-5g","title":"Crear una nueva m\u00e1quina virtual llamada <code>cliente1</code> a partir de la plantilla <code>plantilla-cliente</code> que tenga un volumen de 5G.","text":"<p>A tener en cuenta:   </p> <ul> <li>Hay que redimensionar el sistema de ficheros para que ocupe el espacio completo del disco.</li> <li>La m\u00e1quina se conecta a la red <code>red_intra</code>.</li> <li>La m\u00e1quina tiene una configuraci\u00f3n est\u00e1tica de red.</li> <li>La m\u00e1quina debe tener el hostname <code>cliente1-&lt;tunombre&gt;</code>.</li> <li>En el usuario <code>debian</code> copia tu clave p\u00fablica y la m\u00eda para que podamos acceder sin introducir la contrase\u00f1a por ssh</li> </ul>"},{"location":"03.-DHCP/10.-Pr%C3%A1cticas/03.-Escenario%20de%20pr%C3%A1cticas/03.-Creaci%C3%B3n%20de%20las%20m%C3%A1quinas%20clientes/#acceder-a-cliente1-realizar-una-configuracion-estatica-de-la-red-y-comprobar-si-tiene-acceso-al-exterior","title":"Acceder a <code>cliente1</code>, realizar una configuraci\u00f3n est\u00e1tica de la red y comprobar si tiene acceso al exterior.","text":""},{"location":"03.-DHCP/10.-Pr%C3%A1cticas/04.-Instalaci%C3%B3n%20de%20servidor%20DHCP/","title":"Index","text":"<p>Vamos as seguir trabajando con el escenario que hemos construido en  la pr\u00e1ctica anterior. En esta pr\u00e1ctica vamos instalar y configurar servicios en las m\u00e1quinas creadas, en concreto un servidor dhcp y un  servidor web.</p>"},{"location":"03.-DHCP/10.-Pr%C3%A1cticas/04.-Instalaci%C3%B3n%20de%20servidor%20DHCP/01.-Instalaci%C3%B3n%20servidorDHCP/","title":"01.-Instalaci\u00f3n servidorDHCP","text":"<ol> <li> <p>Instala un servidor DHCP en el contenedor <code>servidorDHCP</code> con las siguientes caracter\u00edsticas</p> <ul> <li>Rango de direcciones: <code>192.168.200.10</code> - <code>192.168.200.200</code>.</li> <li>M\u00e1scara de red: <code>255.255.255.0</code></li> <li>Duraci\u00f3n de la concesi\u00f3n: 30 minutos</li> <li>Puerta de enlace: <code>192.168.200.1</code></li> <li>Servidor DNS: <code>172.22.0.1</code></li> </ul> </li> <li> <p>Configura la m\u00e1quina <code>cliente1</code> para que tome configuraci\u00f3n de red din\u00e1mica y puedas probar que realmente est\u00e1 funcionando el servidor.</p> </li> <li> <p>Conecta una m\u00e1quina Windows a la <code>red_intra</code> y comprueba que tambi\u00e9n toma direccionamiento din\u00e1mico.</p> </li> <li> <p>Realizar una captura, desde el servidor usando <code>tcpdump</code>, de los cuatro paquetes que corresponden a una concesi\u00f3n: <code>DISCOVER</code>, <code>OFFER</code>, <code>REQUEST</code>, <code>ACK</code>.</p> </li> <li> <p>Para hacer esta prueba configura un tiempo de concesi\u00f3n bajo. Los clientes toman una configuraci\u00f3n, y a continuaci\u00f3n apagamos el  servidor DHCP. \u00bfqu\u00e9 ocurre con el cliente windows? \u00bfY con el cliente  linux?. Comprueba el funcionamiento y razona el motivo.</p> </li> <li> <p>Los clientes toman una configuraci\u00f3n, y a continuaci\u00f3n cambiamos  la configuraci\u00f3n del servidor DHCP (por ejemplo el rango). \u00bfqu\u00e9  ocurrir\u00eda con un cliente windows? \u00bfY con el cliente linux?. Comprueba el funcionamiento y razona el motivo.</p> </li> <li> <p>Actualmente los servidores <code>servidorWeb</code> y <code>servidorNAS</code> tienen una configuraci\u00f3n de red est\u00e1tica. Vamos a configurar una  reserva para cada m\u00e1quina. Configura de forma adecuada el servidor dhcp  para que ofrezca a estos servidores la misma IP (reserva) que hab\u00edamos configurado de forma est\u00e1tica.</p> </li> <li> <p>Modifica la configuraci\u00f3n de red del servidorWeb y el servidorNAS para que tomen la configuraci\u00f3n de red de forma din\u00e1mica.</p> </li> </ol>"},{"location":"03.-DHCP/10.-Pr%C3%A1cticas/04.-Instalaci%C3%B3n%20de%20servidor%20DHCP/02.-Instalaci%C3%B3n%20del%20servidor%20Web/","title":"02.-Instalaci\u00f3n del servidor Web","text":"<ol> <li>Instala el servidor <code>apache2</code> en el contenedor <code>servidorWeb</code>.</li> <li>Instala el servidor <code>nfs</code> en la m\u00e1quina <code>servidorNAS</code>.</li> <li>Crea en el <code>servidorNAS</code> un directorio <code>/srv/web</code> con un fichero <code>index.html</code> y comp\u00e1rtelo con el contenedor <code>servidorWeb</code>.</li> <li>Monta ese directorio en el directorio <code>/var/www/html</code> del contenedor <code>servidorWeb</code>.</li> <li>Configura en el router una regla de DNAT para que podamos acceder al servidor Web desde el exterior. (La configuraci\u00f3n debe ser persistente.)</li> </ol>"},{"location":"03.-DHCP/10.-Pr%C3%A1cticas/04.-Instalaci%C3%B3n%20de%20servidor%20DHCP/03.-Script/","title":"03.-Script","text":"<p>Escribe un script llamado <code>crear_cliente.sh</code> que va a automatizar la tarea de crear m\u00e1quinas clientes a partir de la plantilla plantilla-cliente. Este script crear\u00e1 una nueva m\u00e1quina con el nombre que le indiquemos,  con un volumen con el tama\u00f1o que le indiquemos (y el sistema de ficheros redimensionado) y conectada a la red que le indiquemos. El script  cambiar\u00e1 el hostname de la m\u00e1quina para poner el mismo nombre que hemos  indicado como nombre de la m\u00e1quina virtual. Se deben a\u00f1adir las claves  ssh necesarias para el acceso por ssh. La nueva m\u00e1quina se debe iniciar. Utiliza la utilidad <code>virt-customize</code> para configurar la m\u00e1quina antes de crearla.</p> <p>Por lo tanto el script recibe los siguientes argumentos en la l\u00ednea de comandos:</p> <ul> <li>Nombre: nombre de la nueva m\u00e1quina y hostname.</li> <li>Tama\u00f1o del volumen: Tama\u00f1o del volumen que tendr\u00e1 la nueva m\u00e1quina.</li> <li>Nombre de la red a la que habr\u00e1 que conectar la m\u00e1quina.</li> </ul> <p>Para comprobar que funciona:</p> <ul> <li>Crea un nuevo cliente llamado cliente2 que tenga un volumen de 10G y que est\u00e9 conectado a la red_intra. La instrucci\u00f3n que debes ejecutar ser\u00e1:</li> </ul> <pre><code> $ sh crear_clientes.sh cliente2 10G red_intra\n</code></pre> <ul> <li>Comprueba que la m\u00e1quina est\u00e1 funcionando, y que ha tomado direccionamiento de red de forma din\u00e1mica.</li> </ul>"},{"location":"03.-DHCP/10.-Pr%C3%A1cticas/04.-Instalaci%C3%B3n%20de%20servidor%20DHCP/04.-Configuraci%C3%B3n%20de%20un%20nuevo%20%C3%A1mbito/","title":"04.-Configuraci\u00f3n de un nuevo \u00e1mbito","text":"<p>En este \u00faltimo punto vamos a modificar nuestra infraestructura para  que el servidor dhcp reparta otro direccionamiento para las m\u00e1quinas  conectadas a otra red, para ello realiza los siguientes puntos:</p> <ol> <li>Crea una red muy aislada, que se llame red_intra2 que crear\u00e1 el puente <code>br-intra2</code>. Esta red se tiene que iniciar cada vez que encendemos el host.</li> <li>Conecta la m\u00e1quina router a esta red, y configura la nueva interfaz con la direcci\u00f3n <code>172.16.0.1\\16</code>.</li> <li>Conecta el contenedor servidorDHCP a esta red, y configura la nueva interfaz con la direcci\u00f3n <code>172.16.0.2\\16</code>.</li> <li>Configura la m\u00e1quina router para que haga SNAT y permita que que las m\u00e1quinas conectadas a esta red tengan acceso al exterior.</li> <li>Configura el nuevo \u00e1mbito en el servidor dhcp con las siguientes caracter\u00edsticas.<ul> <li>Rango de direcciones: <code>172.16.0.3</code> - <code>172.16.255.254</code>.</li> <li>M\u00e1scara de red: <code>255.255.0.0</code></li> <li>Duraci\u00f3n de la concesi\u00f3n: 1 hora</li> <li>Puerta de enlace: <code>172.16.0.1</code></li> <li>Servidor DNS: <code>172.22.0.1</code></li> </ul> </li> <li>Para comprobar que funciona el nuevo \u00e1mbito, utiliza el script para crear una m\u00e1quina llamada otro_cliente con un volumen de 6G y conectada a la red_intra2.</li> </ol>"},{"location":"04.-DNS/","title":"DNS","text":"<p>En una red TCP/IP, los dispositivos se identifican mediante direcciones IP. Sin embargo, para las personas es m\u00e1s sencillo recordar nombres asociados a cada m\u00e1quina, conocidos como nombres de dominio. Estos nombres est\u00e1n vinculados a la red local donde se encuentra el dispositivo y ofrecen mayor estabilidad, ya que, aunque la direcci\u00f3n IP pueda cambiar, el nombre de dominio suele permanecer constante. Por ello, es necesario un mecanismo que traduzca estos nombres de dominio en direcciones IP.</p> <p>Inicialmente, las redes utilizaban el archivo HOSTS para asociar nombres de dominio con direcciones IP. Sin embargo, a medida que la red creci\u00f3, este m\u00e9todo se volvi\u00f3 poco pr\u00e1ctico, lo que llev\u00f3 al desarrollo del Sistema de Nombres de Dominio (DNS). </p> <p>DNS es una base de datos distribuida y jer\u00e1rquica que almacena informaci\u00f3n relacionada con nombres de dominio en redes como Internet.</p>"},{"location":"04.-DNS/07.-Comandos%20relacionados%20con%20el%20servicio%20DNS/","title":"07.-Comandos relacionados con el servicio DNS","text":""},{"location":"04.-DNS/07.-Comandos%20relacionados%20con%20el%20servicio%20DNS/#comandos-basicos-de-consulta-dns","title":"Comandos B\u00e1sicos de Consulta DNS","text":"<ol> <li><code>nslookup</code>: Consulta registros DNS de un dominio o direcci\u00f3n IP.<ul> <li>Ejemplo: <code>nslookup www.example.com</code></li> </ul> </li> <li><code>dig</code>: Realiza consultas DNS detalladas y permite especificar registros (A, MX, etc.).<ul> <li>Ejemplo: <code>dig example.com MX</code></li> </ul> </li> <li><code>host</code>: Resuelve nombres de dominio a direcciones IP y viceversa.<ul> <li>Ejemplo: <code>host www.example.com</code></li> </ul> </li> </ol>"},{"location":"04.-DNS/07.-Comandos%20relacionados%20con%20el%20servicio%20DNS/#comandos-para-resolucion-de-red","title":"Comandos para Resoluci\u00f3n de Red","text":"<ol> <li><code>ping</code>: Comprueba la conectividad de red con un dominio o direcci\u00f3n IP.<ul> <li>Ejemplo: <code>ping www.example.com</code></li> </ul> </li> <li><code>traceroute</code>(Linux) / <code>tracert</code>(Windows): Muestra la ruta que toman los paquetes hacia un dominio.<ul> <li>Ejemplo: <code>traceroute www.example.com</code></li> </ul> </li> </ol>"},{"location":"04.-DNS/07.-Comandos%20relacionados%20con%20el%20servicio%20DNS/#comandos-para-configuracion-de-red","title":"Comandos para Configuraci\u00f3n de Red","text":"<ol> <li><code>ipconfig</code>(Windows): Configura y muestra detalles de red, como cach\u00e9 DNS.<ul> <li>Ejemplo: <code>ipconfig /displaydns</code></li> </ul> </li> <li><code>ifconfig</code> (Linux/Unix): Configura interfaces de red (reemplazado por <code>ip</code> en distribuciones modernas).<ul> <li>Ejemplo: <code>ifconfig eth0</code></li> </ul> </li> <li><code>ip</code> (Linux): Herramienta moderna para gestionar interfaces y rutas de red.<ul> <li>Ejemplo: <code>ip addr show</code></li> </ul> </li> </ol>"},{"location":"04.-DNS/07.-Comandos%20relacionados%20con%20el%20servicio%20DNS/#comandos-para-captura-y-analisis","title":"Comandos para Captura y An\u00e1lisis","text":"<ol> <li><code>tcpdump</code> (Linux/Unix): Captura paquetes de red, \u00fatil para monitorear tr\u00e1fico DNS (puerto 53).<ul> <li>Ejemplo: <code>tcpdump -i eth0 port 53</code></li> </ul> </li> <li><code>wireshark</code>: Interfaz gr\u00e1fica para capturar y analizar tr\u00e1fico de red, incluyendo consultas DNS.</li> </ol>"},{"location":"04.-DNS/07.-Comandos%20relacionados%20con%20el%20servicio%20DNS/#comandos-para-monitoreo-y-estadisticas","title":"Comandos para Monitoreo y Estad\u00edsticas","text":"<ol> <li> <p><code>netstat</code>: Muestra conexiones de red activas y estad\u00edsticas.</p> <ul> <li>Ejemplo: <code>netstat -a</code></li> </ul> </li> <li> <p><code>ss</code>: Reemplazo moderno de <code>netstat</code>, muestra conexiones de red actuales.</p> <ol> <li>= Ejemplo: <code>ss -tuln</code></li> </ol> </li> </ol>"},{"location":"04.-DNS/07.-Comandos%20relacionados%20con%20el%20servicio%20DNS/#comandos-para-servidores-dns","title":"Comandos para Servidores DNS","text":"<ol> <li> <p><code>named-checkconf</code>: Verifica la configuraci\u00f3n de un servidor BIND.</p> <ul> <li>Ejemplo: <code>named-checkconf</code></li> </ul> </li> <li> <p><code>named-checkzone</code>: Verifica la configuraci\u00f3n de archivos de zona en BIND. </p> <ul> <li>Ejemplo: <code>named-checkzone example.com /etc/bind/db.example.com</code></li> </ul> </li> </ol>"},{"location":"04.-DNS/07.-Comandos%20relacionados%20con%20el%20servicio%20DNS/#comandos-adicionales","title":"Comandos Adicionales","text":"<ol> <li> <p><code>systemd-resolve</code> (Linux con systemd): Realiza consultas DNS y muestra configuraciones actuales.</p> <ul> <li>Ejemplo: <code>systemd-resolve www.example.com</code></li> </ul> </li> <li> <p><code>resolvectl</code>: Interact\u00faa con el resolvedor de systemd.</p> <ul> <li>Ejemplo: <code>resolvectl query www.example.com</code></li> </ul> </li> </ol>"},{"location":"04.-DNS/99.-Enlaces%20de%20inter%C3%A9s/","title":"99.-Enlaces de inter\u00e9s","text":""},{"location":"04.-DNS/99.-Enlaces%20de%20inter%C3%A9s/#protocolo-dns","title":"Protocolo DNS","text":"<ul> <li>\u00bfC\u00f3mo funciona el DNS?</li> <li>Ficheros importantes en la resoluci\u00f3n de nombres</li> </ul>"},{"location":"04.-DNS/99.-Enlaces%20de%20inter%C3%A9s/#dnsmasq","title":"DNSmasq","text":"<ul> <li>Fundamentos del servicio DNS</li> <li>HowTodnsmasq</li> </ul>"},{"location":"04.-DNS/99.-Enlaces%20de%20inter%C3%A9s/#bind9","title":"bind9","text":"<ul> <li>Servidor dns: Bind9</li> <li>Esquema: Servidor DNS [jpg]</li> <li>Servidores DNS esclavos (1\u00aa parte)</li> <li>Servidores DNS esclavos (2\u00aa parte)</li> <li>Configurar subdominios en bind9</li> <li>Servidor DNS din\u00e1mico</li> <li>Esquema: Proceso DNS din\u00e1mico [jpg]</li> <li>DNS din\u00e1mico (Desde lo alto del cerro)</li> </ul>"},{"location":"04.-DNS/01.-Historia/","title":"Historia","text":""},{"location":"04.-DNS/01.-Historia/01.-Historia%20del%20archivo%20HOSTS%20y%20su%20uso%20en%20redes/","title":"01.-Historia del archivo HOSTS y su uso en redes","text":"<ul> <li> <p>Or\u00edgenes en ARPANET: En la d\u00e9cada de los 70, la red ARPANET, precursora de Internet, contaba con un n\u00famero reducido de servidores. La asociaci\u00f3n entre nombres y direcciones IP se gestionaba a trav\u00e9s de un fichero de texto denominado HOSTS.</p> </li> <li> <p>Gesti\u00f3n centralizada: El mantenimiento del archivo HOSTS estaba a cargo del Network Information Center (NIC) del Stanford Research Institute (SRI-NIC). Los administradores de red enviaban los cambios en la red al NIC por correo, y \u00e9ste los incorporaba al archivo maestro.</p> </li> <li> <p>Distribuci\u00f3n del archivo: Los administradores de red eran responsables de descargar regularmente la versi\u00f3n m\u00e1s reciente del archivo HOSTS y actualizar las m\u00e1quinas bajo su gesti\u00f3n.</p> </li> <li> <p>Caracter\u00edsticas del archivo HOSTS:</p> <ul> <li>Es un fichero plano donde cada l\u00ednea contiene una direcci\u00f3n IP y el nombre asociado, separados por espacios o tabuladores.</li> <li>En sistemas UNIX, este archivo se encuentra en <code>/etc/hosts</code>.</li> <li>En sistemas Windows, se localiza en <code>%SYSTEMROOT%\\system32\\drivers\\etc\\hosts</code>.</li> <li>Resoluci\u00f3n de nombres: La traducci\u00f3n entre nombres de dominio y direcciones IP se realizaba localmente en cada ordenador, utilizando la versi\u00f3n m\u00e1s reciente del archivo HOSTS.</li> <li>Ejemplo de fichero host:</li> </ul> </li> </ul> <pre><code># Archivo de configuraci\u00f3n del HOSTS en Linux\n# Direcci\u00f3n IP    Nombre del host    Alias\n\n# Entrada predeterminada para localhost\n127.0.0.1       localhost\n::1             localhost\n\n# Servidores en la red local\n192.168.1.1     router.local        router\n192.168.1.10    server01.local      server01\n192.168.1.11    server02.local      server02 backup-server\n192.168.1.20    nas.local           nas storage\n\n# Equipos de escritorio y port\u00e1tiles\n192.168.1.100   desktop01.local     desktop01 pc-main\n192.168.1.101   desktop02.local     desktop02\n192.168.1.102   laptop01.local      laptop01 work-laptop\n\n# Dispositivos IoT\n192.168.1.200   printer01.local     printer01 hp-printer\n192.168.1.201   thermostat.local    thermostat\n192.168.1.202   camera01.local      camera01 security-camera\n\n# Servidores externos (simulaci\u00f3n de acceso directo a dominios)\n203.0.113.10    web01.example.com   web01\n203.0.113.20    mail.example.com    mailserver\n203.0.113.30    database.example.com database db01\n\n# Servicios para pruebas locales\n127.0.0.2       test.local          dev-test\n127.0.0.3       staging.local       staging-env\n127.0.0.4       api.local           api-server\n\n# Comentario: Fin del archivo HOSTS\n</code></pre>"},{"location":"04.-DNS/01.-Historia/02.-Limitaciones%20del%20archivo%20HOSTS%20y%20transici%C3%B3n%20al%20DNS/","title":"02.-Limitaciones del archivo HOSTS y transici\u00f3n al DNS","text":"<p>Con el crecimiento exponencial de las redes, el sistema basado en el archivo HOSTS enfrent\u00f3 importantes limitaciones:</p> <ol> <li> <p>Gesti\u00f3n centralizada ineficiente:</p> <ul> <li>La necesidad de mantener un \u00fanico archivo maestro en el NIC y distribuirlo manualmente a cada administrador se volvi\u00f3 poco pr\u00e1ctica a medida que la red se expand\u00eda.</li> <li>El tiempo requerido para enviar cambios y sincronizar versiones causaba inconsistencias y retrasos.</li> </ul> </li> <li> <p>Escalabilidad limitada:</p> <ul> <li>Un archivo plano no era adecuado para manejar la creciente cantidad de dispositivos conectados.</li> <li>La b\u00fasqueda de entradas espec\u00edficas en un archivo grande se hac\u00eda m\u00e1s lenta y menos eficiente.</li> </ul> </li> <li> <p>Mantenimiento intensivo:</p> <ul> <li>Cada modificaci\u00f3n requer\u00eda la intervenci\u00f3n manual de los administradores de red, lo que incrementaba la probabilidad de errores y duplicaci\u00f3n de trabajo.</li> </ul> </li> <li> <p>Falta de robustez y flexibilidad:</p> <ul> <li>Cualquier fallo en la distribuci\u00f3n o en el mantenimiento del archivo HOSTS pod\u00eda causar interrupciones significativas en la resoluci\u00f3n de nombres.</li> </ul> </li> </ol>"},{"location":"04.-DNS/01.-Historia/02.-Limitaciones%20del%20archivo%20HOSTS%20y%20transici%C3%B3n%20al%20DNS/#introduccion-del-sistema-de-nombres-de-dominio-dns","title":"Introducci\u00f3n del Sistema de Nombres de Dominio (DNS)","text":"<p>Para abordar estas limitaciones, se desarroll\u00f3 el Sistema de Nombres de Dominio (DNS), que introdujo:</p> <ul> <li> <p>Jerarqu\u00eda frente a estructura plana:</p> <ul> <li>El DNS es un sistema jer\u00e1rquico que organiza los nombres de dominio en niveles (como <code>.com</code>, <code>.org</code>, <code>.es</code>), lo que facilita su gesti\u00f3n y distribuci\u00f3n.</li> </ul> </li> <li> <p>Base de datos distribuida:</p> <ul> <li>A diferencia del archivo HOSTS, el DNS almacena y resuelve nombres a trav\u00e9s de servidores distribuidos en todo el mundo, eliminando la dependencia de un \u00fanico archivo maestro.</li> </ul> </li> <li> <p>Automatizaci\u00f3n:</p> <ul> <li>Los servidores DNS pueden actualizarse autom\u00e1ticamente, sin intervenci\u00f3n manual constante, lo que reduce errores y mejora la eficiencia.</li> </ul> </li> </ul> <p>El DNS marc\u00f3 un hito en la evoluci\u00f3n de las redes al permitir una soluci\u00f3n escalable, eficiente y robusta para la resoluci\u00f3n de nombres en Internet y otras redes.</p>"},{"location":"04.-DNS/02.-Definici%C3%B3n%20y%20objetivos/","title":"Definici\u00f3n y objetivos","text":"<p>El Domain Name System (DNS) es un sistema fundamental en redes como Internet que funciona como una base de datos distribuida y jer\u00e1rquica, proporcionando un servicio esencial para la resoluci\u00f3n de nombres.</p> <p></p>"},{"location":"04.-DNS/02.-Definici%C3%B3n%20y%20objetivos/01.-Caracter%C3%ADsticas%20principales/","title":"01.-Caracter\u00edsticas principales","text":"<ol> <li>Uso principal:<ul> <li>Asignar nombres de dominio a direcciones IP.</li> <li>Localizar servidores de correo electr\u00f3nico asociados a cada dominio.</li> </ul> </li> <li> <p>Modelo cliente/servidor:</p> <ul> <li>El DNS opera bajo un esquema cliente/servidor, donde los clientes realizan consultas y los servidores responden con la informaci\u00f3n almacenada.</li> </ul> </li> <li> <p>Agrupaci\u00f3n en dominios:</p> <ul> <li>Los nombres de las m\u00e1quinas est\u00e1n organizados en dominios, que a su vez est\u00e1n estructurados jer\u00e1rquicamente.</li> </ul> </li> <li> <p>Estructura jer\u00e1rquica:</p> <ul> <li>La base de datos tiene forma de \u00e1rbol invertido, donde:<ul> <li>La ra\u00edz se encuentra en la parte superior y se representa como <code>\".\"</code>.</li> <li>Cada nodo del \u00e1rbol representa un dominio o subdominio.</li> </ul> </li> </ul> </li> <li> <p>Nombre completo (FQDN):</p> <ul> <li>El nombre de dominio completo de una m\u00e1quina, conocido como FQDN (Fully Qualified Domain Name), incluye:<ul> <li>El nombre de la m\u00e1quina.</li> <li>La concatenaci\u00f3n jer\u00e1rquica de dominios desde la hoja hasta la ra\u00edz (por ejemplo, <code>hielo.gsyc.urjc.es.</code>).</li> <li>Por convenci\u00f3n, un FQDN termina con un punto (<code>.</code>), aunque este se puede omitir en la mayor\u00eda de los casos, excepto en mapas DNS.</li> </ul> </li> </ul> </li> <li> <p>Dominios y subdominios:</p> <ul> <li>Cada nodo del \u00e1rbol puede representar un dominio.</li> <li>Los dominios pueden dividirse en subdominios seg\u00fan sea necesario, facilitando la organizaci\u00f3n y delegaci\u00f3n administrativa.</li> </ul> </li> </ol>"},{"location":"04.-DNS/02.-Definici%C3%B3n%20y%20objetivos/02.-Ejemplo%20pr%C3%A1ctico%20de%20un%20FQDN/","title":"02.-Ejemplo pr\u00e1ctico de un FQDN","text":""},{"location":"04.-DNS/02.-Definici%C3%B3n%20y%20objetivos/02.-Ejemplo%20pr%C3%A1ctico%20de%20un%20FQDN/#hielogsycurjces","title":"<code>hielo.gsyc.urjc.es.</code>","text":"<ul> <li><code>hielo</code>: Nombre de la m\u00e1quina.</li> <li><code>gsyc</code>: Subdominio.</li> <li><code>urjc</code>: Dominio principal.</li> <li><code>es</code>: Dominio de nivel superior (TLD).</li> <li><code>.</code>: Ra\u00edz del \u00e1rbol.</li> </ul>"},{"location":"04.-DNS/02.-Definici%C3%B3n%20y%20objetivos/03.-Ventajas/","title":"03.-Ventajas","text":"<ul> <li>Escalabilidad: Su dise\u00f1o distribuido permite manejar millones de dominios.</li> <li>Flexibilidad: Soporta delegaci\u00f3n administrativa y partici\u00f3n en subdominios.</li> <li>Eficiencia: Resuelve nombres de dominio de manera r\u00e1pida mediante cach\u00e9 y servidores jer\u00e1rquicos.</li> </ul> <p>El DNS es un componente esencial para el funcionamiento de Internet, facilitando la navegaci\u00f3n y comunicaci\u00f3n entre dispositivos en redes globales.</p>"},{"location":"04.-DNS/02.-Definici%C3%B3n%20y%20objetivos/04.-Objetivo/","title":"04.-Objetivo","text":"<p>El Sistema de Nombres de Dominio (DNS) permite asociar direcciones IP con nombres can\u00f3nicos (como <code>www.ejemplo.com</code>) para facilitar su uso y memorizaci\u00f3n. Adem\u00e1s, habilita la gesti\u00f3n de m\u00faltiples servicios en un \u00fanico servidor mediante asignaciones espec\u00edficas en el DNS.</p>"},{"location":"04.-DNS/02.-Definici%C3%B3n%20y%20objetivos/04.-Objetivo/#traduccion-de-direcciones-ip-a-nombres-canonicos","title":"Traducci\u00f3n de direcciones IP a nombres can\u00f3nicos","text":"<ul> <li>Prop\u00f3sito: Facilitar la memorizaci\u00f3n y uso de direcciones IP mediante nombres m\u00e1s legibles y significativos, como <code>www.ejemplo.com.</code>.</li> <li>Ejemplo:<ul> <li>Una direcci\u00f3n IP como <code>192.168.1.10</code> se traduce a un nombre can\u00f3nico para un sitio web: <code>www.ejemplo.com.</code>.</li> <li>Esto se realiza mediante un registro DNS del tipo A que asocia un nombre de dominio a una direcci\u00f3n IP.</li> </ul> </li> </ul>"},{"location":"04.-DNS/02.-Definici%C3%B3n%20y%20objetivos/04.-Objetivo/#uso-de-multiples-nombres-canonicos-para-una-sola-ip","title":"Uso de m\u00faltiples nombres can\u00f3nicos para una sola IP","text":"<ul> <li>En casos donde un servidor ofrece m\u00faltiples servicios (por ejemplo, FTP, web), se pueden asignar varias entradas DNS para una sola direcci\u00f3n IP.</li> <li>Ejemplo:<ul> <li>Direcci\u00f3n IP: <code>192.168.1.10</code></li> <li>Nombres can\u00f3nicos asociados:<ul> <li><code>ftp.ejemplo.com.</code> para el servicio FTP.</li> <li><code>www.ejemplo.com.</code> para el servidor web.</li> </ul> </li> </ul> </li> </ul>"},{"location":"04.-DNS/02.-Definici%C3%B3n%20y%20objetivos/04.-Objetivo/#configuracion-tipica-en-un-archivo-dns","title":"Configuraci\u00f3n t\u00edpica en un archivo DNS:","text":"<pre><code>ejemplo.com.      IN  A    192.168.1.10\nwww.ejemplo.com.  IN  CNAME ejemplo.com.\nftp.ejemplo.com.  IN  CNAME ejemplo.com.\n</code></pre> <ul> <li>Registros utilizados:<ul> <li>A: Relaciona un nombre de dominio con una direcci\u00f3n IP.</li> <li>CNAME: Define alias para un nombre can\u00f3nico existente.</li> </ul> </li> </ul>"},{"location":"04.-DNS/02.-Definici%C3%B3n%20y%20objetivos/04.-Objetivo/#ventajas-de-esta-configuracion","title":"Ventajas de esta configuraci\u00f3n","text":"<ol> <li>Facilidad de gesti\u00f3n:<ul> <li>Permite a los administradores centralizar la configuraci\u00f3n de servicios en un \u00fanico servidor.</li> </ul> </li> <li>Flexibilidad:<ul> <li>Proporciona nombres espec\u00edficos para cada servicio sin necesidad de m\u00faltiples direcciones IP.</li> </ul> </li> <li>Memorizaci\u00f3n y usabilidad:<ul> <li>Los usuarios finales pueden utilizar nombres como <code>ftp.ejemplo.com</code> o <code>www.ejemplo.com</code> en lugar de direcciones IP num\u00e9ricas.</li> </ul> </li> </ol> <p>El uso del DNS para traducir direcciones IP en nombres can\u00f3nicos y gestionar m\u00faltiples servicios en una sola direcci\u00f3n IP es esencial para la operaci\u00f3n eficiente de servidores en Internet.</p>"},{"location":"04.-DNS/03.-Estructura/","title":"Estructura","text":"<pre><code>graph TD\n    Root[\"Servidor Ra\u00edz (Root Servers)\"]\n    Root --&gt; TLD[\"Servidores TLD (Top-Level Domain)\"]\n    TLD --&gt; Authoritative[\"Servidores Autoritativos\"]\n    Authoritative --&gt; ZoneFile[\"Archivo de Zona (Zone Files)\"]\n    Authoritative --&gt; Records[\"Registros DNS (A, AAAA, MX, CNAME, etc.)\"]\n    User[\"Usuario/Cliente\"] --&gt; Resolver[\"Servidor Recursivo\"]\n    Resolver --&gt; Cache[\"Cach\u00e9 de DNS\"]\n    Resolver --&gt; Root\n    Resolver --&gt; TLD\n    Resolver --&gt; Authoritative\n</code></pre> <ol> <li> <p>Servidor Ra\u00edz (Root Servers):</p> <ul> <li>Primer nivel de la jerarqu\u00eda DNS.</li> <li>Redirige las consultas al servidor correspondiente del Top-Level Domain (TLD).</li> <li>Hay 13 grupos de servidores ra\u00edz distribuidos globalmente, identificados de \"a.root-servers.net\" a \"m.root-servers.net\".</li> </ul> </li> <li> <p>Servidores TLD:</p> <ul> <li>Administran los dominios de nivel superior, como <code>.com</code>, <code>.org</code>, <code>.net</code>, <code>.es</code>.</li> <li>Redirigen a los servidores autoritativos correspondientes al dominio solicitado.</li> </ul> </li> <li> <p>Servidores Autoritativos:</p> <ul> <li>Contienen la informaci\u00f3n final del dominio espec\u00edfico, como <code>ejemplo.com</code>.</li> <li>Almacenan registros DNS (A, AAAA, MX, etc.) y responden con la informaci\u00f3n solicitada.</li> </ul> </li> <li> <p>Servidor Recursivo:</p> <ul> <li>El intermediario que realiza la consulta completa por el cliente.</li> <li>Puede almacenar respuestas en su cach\u00e9 para acelerar consultas futuras.</li> </ul> </li> <li> <p>Cliente/Usuario:</p> <ul> <li>El dispositivo que inicia la consulta DNS, generalmente a trav\u00e9s de un navegador u otra aplicaci\u00f3n.</li> </ul> </li> </ol>"},{"location":"04.-DNS/03.-Estructura/#funcionamiento","title":"Funcionamiento:","text":"<ol> <li>El cliente env\u00eda la consulta al servidor recursivo.</li> <li>El servidor recursivo consulta los servidores en el siguiente orden:<ul> <li>Servidor Ra\u00edz, que redirige al servidor TLD.</li> <li>Servidor TLD, que redirige al servidor autoritativo del dominio solicitado.</li> <li>Servidor Autoritativo, que responde con el registro DNS solicitado (por ejemplo, una direcci\u00f3n IP).</li> </ul> </li> </ol> <p>Este modelo jer\u00e1rquico asegura la escalabilidad y redundancia del sistema DNS. Procedamos a estudiar detenidamente sus componentes.</p>"},{"location":"04.-DNS/03.-Estructura/01.-FQDN/","title":"01.-FQDN","text":"<p>El FQDN o nombre de dominio completamente cualificado describe la ruta completa dentro de la jerarqu\u00eda del \u00e1rbol de nombres de dominio desde un nodo espec\u00edfico hasta la ra\u00edz. Este nombre \u00fanico e inequ\u00edvoco se utiliza para identificar recursos en Internet.</p>"},{"location":"04.-DNS/03.-Estructura/01.-FQDN/#caracteristicas-principales-del-fqdn","title":"Caracter\u00edsticas principales del FQDN:","text":"<ol> <li> <p>Estructura jer\u00e1rquica:</p> <ul> <li>Est\u00e1 formado por las etiquetas que indican la trayectoria en el \u00e1rbol DNS desde un nodo hasta la ra\u00edz.</li> <li>Las etiquetas est\u00e1n separadas por puntos (<code>.</code>).</li> </ul> </li> <li> <p>Terminaci\u00f3n en un punto:</p> <ul> <li>Formalmente, un FQDN termina con un punto (<code>.</code>) que representa la ra\u00edz del \u00e1rbol DNS.</li> <li>Este punto final generalmente se omite en el uso cotidiano, excepto en configuraciones espec\u00edficas.</li> </ul> </li> <li> <p>Longitud m\u00e1xima:</p> <ul> <li>Un FQDN puede tener hasta 255 caracteres, incluidos los puntos separadores.</li> </ul> </li> <li> <p>Juego de caracteres permitido:</p> <ul> <li>Originalmente, las etiquetas del FQDN permit\u00edan:<ul> <li>Letras (<code>A-Z</code>, sin distinci\u00f3n entre may\u00fasculas y min\u00fasculas).</li> <li>D\u00edgitos (<code>0-9</code>).</li> <li>El guion (<code>-</code>), que no puede estar al principio ni al final de una etiqueta.</li> </ul> </li> <li>Desde 2004, se a\u00f1adieron caracteres internacionales como <code>\u00e4, \u00f6, \u00fc, \u00e9, \u00e0, \u00e8</code> o la <code>\u00f1</code> gracias a los nombres de dominio internacionalizados (IDN).</li> </ul> </li> <li> <p>Orden de lectura:</p> <ul> <li>Los nombres de dominio se escriben de derecha a izquierda, comenzando con el dominio de nivel superior (TLD) y terminando en la ra\u00edz.</li> <li>Ejemplo: <code>www.example.com.</code>:<ul> <li><code>.</code> (ra\u00edz del \u00e1rbol).</li> <li><code>com</code> (TLD o dominio de nivel superior).</li> <li><code>example</code> (dominio secundario).</li> <li><code>www</code> (subdominio).</li> </ul> </li> </ul> </li> <li> <p>Normas de sintaxis:</p> <ul> <li>La sintaxis est\u00e1 regulada por varios documentos RFC (Request for Comments):<ul> <li>RFC 1035: Especificaciones del DNS.</li> <li>RFC 1123: Requisitos para sistemas basados en Internet.</li> <li>RFC 2181: Clarificaciones sobre el DNS.</li> </ul> </li> </ul> </li> </ol>"},{"location":"04.-DNS/03.-Estructura/01.-FQDN/#ejemplo-de-un-fqdn","title":"Ejemplo de un FQDN","text":"<p>Nombre completo: <code>hielo.gsyc.urjc.es.</code></p> <ul> <li><code>hielo</code>: Nombre de la m\u00e1quina.</li> <li><code>gsyc</code>: Subdominio.</li> <li><code>urjc</code>: Dominio principal.</li> <li><code>es</code>: Dominio de nivel superior (TLD).</li> <li><code>.</code>: Ra\u00edz del \u00e1rbol.</li> </ul>"},{"location":"04.-DNS/03.-Estructura/02.-Jerarqu%C3%ADa%20de%20dominios/","title":"02.-Jerarqu\u00eda de dominios","text":"<p>La estructura del Sistema de Nombres de Dominio (DNS) es jer\u00e1rquica, organizada en niveles desde la ra\u00edz hasta los subdominios m\u00e1s espec\u00edficos.</p>"},{"location":"04.-DNS/03.-Estructura/02.-Jerarqu%C3%ADa%20de%20dominios/#1-dominio-root-raiz","title":"1. Dominio Root (Ra\u00edz)","text":"<ul> <li>Descripci\u00f3n:<ul> <li>Es el nivel m\u00e1s alto en la jerarqu\u00eda del DNS.</li> <li>Se representa como un punto (<code>.</code>), aunque suele ser impl\u00edcito y no visible en las consultas normales.</li> </ul> </li> <li>Gesti\u00f3n:<ul> <li>Est\u00e1 gestionado por ICANN (Internet Corporation for Assigned Names and Numbers) que a su vez delega los dominios de siguientes niveles en otras autoridades-servidores DNS. (p. ej: en espa\u00f1a\u00a0RED.es\u00a0se encarga del dominio <code>.es</code>)</li> </ul> </li> </ul> <ul> <li> <p>Servidores:</p> <ul> <li>Lo sirven Root Nameservers, que contienen referencias a los servidores de los dominios de primer nivel.</li> </ul> </li> <li> <p>Funci\u00f3n:</p> <ul> <li>Proporciona la base para la resoluci\u00f3n de nombres en toda la red.</li> </ul> </li> </ul>"},{"location":"04.-DNS/03.-Estructura/02.-Jerarqu%C3%ADa%20de%20dominios/#2-dominios-de-primer-nivel-tlds-top-level-domains","title":"2. Dominios de Primer Nivel (TLDs - Top-Level Domains)","text":"<ul> <li>Tipos:<ul> <li>Gen\u00e9ricos tradicionales (gTLDs):<ul> <li>Usados globalmente desde los inicios del DNS.</li> <li>Ejemplos: <code>com</code> (comercial), <code>edu</code> (educaci\u00f3n), <code>gov</code> (gobierno), <code>mil</code> (militar), <code>org</code> (organizaciones), <code>net</code> (redes), <code>int</code> (organismos internacionales) y <code>nato</code>(OTAN).</li> </ul> </li> <li>Gen\u00e9ricos modernos:<ul> <li>Introducidos posteriormente para diversificar las opciones de dominio.</li> <li>Ejemplos: <code>aero</code>, <code>biz</code>, <code>coop</code>, <code>info</code>, <code>museum</code>, <code>name</code>, <code>pro</code>, <code>jobs</code>, <code>mobi</code>, <code>tel</code>, <code>travel</code>, <code>cat</code> (Catalu\u00f1a), <code>asia</code>.</li> </ul> </li> <li>Dominio para la infraestructura del DNS:<ul> <li><code>arpa</code>: Usado para fines t\u00e9cnicos dentro de la infraestructura del DNS.</li> </ul> </li> <li>Dominios por c\u00f3digo de pa\u00eds (ccTLDs):<ul> <li>Basados en el c\u00f3digo ISO-3166 para cada pa\u00eds o territorio.</li> <li>Ejemplos: <code>uk</code> (Reino Unido), <code>mx</code> (M\u00e9xico), <code>ar</code> (Argentina), <code>de</code> (Alemania), <code>es</code> (Espa\u00f1a), <code>jp</code> (Jap\u00f3n).</li> </ul> </li> </ul> </li> </ul>"},{"location":"04.-DNS/03.-Estructura/02.-Jerarqu%C3%ADa%20de%20dominios/#3-dominios-de-segundo-nivel","title":"3. Dominios de Segundo Nivel","text":"<ul> <li>Descripci\u00f3n:<ul> <li>Son los nombres que se registran bajo un TLD, generalmente administrados por organizaciones o particulares.</li> </ul> </li> <li>Ejemplo:<ul> <li>En <code>example.com</code>, el dominio de segundo nivel es <code>example</code>.</li> </ul> </li> </ul>"},{"location":"04.-DNS/03.-Estructura/02.-Jerarqu%C3%ADa%20de%20dominios/#4-dominios-de-tercer-nivel","title":"4. Dominios de Tercer Nivel","text":"<ul> <li>Descripci\u00f3n:<ul> <li>Se utilizan para subdividir un dominio de segundo nivel en secciones o servicios.</li> </ul> </li> <li>Ejemplo:<ul> <li>En <code>www.example.com</code>, el dominio de tercer nivel es <code>www</code>.</li> <li>En <code>mail.example.com</code>, el dominio de tercer nivel es <code>mail</code>.</li> </ul> </li> </ul>"},{"location":"04.-DNS/03.-Estructura/02.-Jerarqu%C3%ADa%20de%20dominios/#5-dominios-de-cuarto-nivel-y-subniveles-adicionales","title":"5. Dominios de Cuarto Nivel y Subniveles Adicionales","text":"<ul> <li>Descripci\u00f3n:<ul> <li>Son subdivisiones adicionales para una mayor organizaci\u00f3n dentro de un dominio.</li> </ul> </li> <li>Ejemplo:<ul> <li>En <code>research.dept.university.edu</code>, los dominios de tercer y cuarto nivel ser\u00edan:<ul> <li><code>research</code>: Cuarto nivel.</li> <li><code>dept</code>: Tercer nivel.</li> <li><code>university</code>: Segundo nivel.</li> </ul> </li> </ul> </li> </ul>"},{"location":"04.-DNS/03.-Estructura/03.-Dominio%20y%20Zona/","title":"03.-Dominio y Zona","text":"<p>El concepto de dominio y zona es fundamental en la estructura jer\u00e1rquica del DNS, ya que permite delegar responsabilidades y organizar eficientemente la administraci\u00f3n de nombres dentro de una red.</p>"},{"location":"04.-DNS/03.-Estructura/03.-Dominio%20y%20Zona/#dominio","title":"Dominio","text":"<ul> <li> <p>Definici\u00f3n:</p> <ul> <li>Es una parte de la jerarqu\u00eda del DNS que agrupa nombres bajo un mismo identificador (como <code>ejemplo.com</code>).</li> </ul> </li> <li> <p>Administraci\u00f3n:</p> <ul> <li>La autoridad responsable de un dominio puede subdividirlo en subdominios para organizar mejor sus recursos.</li> <li>La administraci\u00f3n de los subdominios puede:<ul> <li>Permanecer bajo la misma autoridad del dominio principal.</li> <li>Ser delegada a otra organizaci\u00f3n o entidad.</li> </ul> </li> </ul> </li> <li> <p>Ejemplo:</p> <ul> <li>Una universidad con el dominio <code>universidad.edu</code> puede crear subdominios para cada departamento:<ul> <li><code>cs.universidad.edu</code> (Ciencias de la Computaci\u00f3n).</li> <li><code>bio.universidad.edu</code> (Biolog\u00eda).</li> <li><code>law.universidad.edu</code> (Derecho).</li> </ul> </li> <li>Los departamentos con conocimientos t\u00e9cnicos pueden administrar sus propios subdominios, mientras que los dem\u00e1s pueden ser gestionados por la universidad.</li> </ul> </li> </ul>"},{"location":"04.-DNS/03.-Estructura/03.-Dominio%20y%20Zona/#zona","title":"Zona","text":"<ul> <li> <p>Definici\u00f3n:</p> <ul> <li>Una zona es un sub\u00e1rbol del DNS que est\u00e1 bajo la administraci\u00f3n de una organizaci\u00f3n diferente al dominio padre.</li> <li>En t\u00e9rminos pr\u00e1cticos, una zona incluye los nombres de dominio y subdominios delegados que una autoridad espec\u00edfica gestiona directamente.</li> </ul> </li> <li> <p>Delegaci\u00f3n de zonas:</p> <ul> <li>La organizaci\u00f3n que administra el dominio principal puede delegar una parte de su dominio (sub\u00e1rbol) a otra autoridad.</li> <li>Esto se realiza configurando registros NS (Name Server) en el dominio principal para redirigir las consultas de los subdominios al servidor DNS del nuevo administrador.</li> </ul> </li> <li> <p>Ejemplo:</p> <ul> <li>La universidad con <code>universidad.edu</code> puede delegar:<ul> <li><code>cs.universidad.edu</code> a los administradores del departamento de Ciencias de la Computaci\u00f3n.</li> <li><code>bio.universidad.edu</code> a los administradores del departamento de Biolog\u00eda.</li> </ul> </li> <li>Cada subdominio delegado se convierte en una zona independiente, aunque sigue formando parte de la jerarqu\u00eda del dominio principal.</li> </ul> </li> </ul>"},{"location":"04.-DNS/03.-Estructura/03.-Dominio%20y%20Zona/#diferencias-entre-dominio-y-zona","title":"Diferencias entre Dominio y Zona","text":"Dominio Zona Parte de la jerarqu\u00eda del DNS. Sub\u00e1rbol del DNS bajo administraci\u00f3n independiente. Incluye nombres y subdominios. Gestiona una parte espec\u00edfica (subdominio delegado). Puede abarcar m\u00faltiples zonas. Representa una \u00fanica unidad administrativa."},{"location":"04.-DNS/03.-Estructura/03.-Dominio%20y%20Zona/#ejemplo-practico","title":"Ejemplo Pr\u00e1ctico","text":""},{"location":"04.-DNS/03.-Estructura/03.-Dominio%20y%20Zona/#estructura-del-dominio-universidadedu","title":"Estructura del dominio <code>universidad.edu</code>:","text":"<ul> <li>Dominio: <code>universidad.edu</code><ul> <li>Subdominios:<ul> <li><code>cs.universidad.edu</code></li> <li><code>bio.universidad.edu</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"04.-DNS/03.-Estructura/03.-Dominio%20y%20Zona/#delegacion-de-zonas","title":"Delegaci\u00f3n de zonas:","text":"<ol> <li><code>cs.universidad.edu</code>:<ul> <li>Administrado por el Departamento de Ciencias de la Computaci\u00f3n.</li> <li>Es una zona independiente del dominio padre.</li> </ul> </li> <li><code>bio.universidad.edu</code>:<ul> <li>Administrado por el Departamento de Biolog\u00eda.</li> <li>Tambi\u00e9n es una zona delegada.</li> </ul> </li> </ol>"},{"location":"04.-DNS/03.-Estructura/04.-Dominio%20Directo%20e%20Inverso/","title":"04.-Dominio Directo e Inverso","text":""},{"location":"04.-DNS/03.-Estructura/04.-Dominio%20Directo%20e%20Inverso/#dominio-directo-e-inverso-en-el-dns","title":"Dominio Directo e Inverso en el DNS","text":"<p>El Sistema de Nombres de Dominio (DNS) no solo permite traducir nombres de dominio en direcciones IP (dominio directo), sino que tambi\u00e9n soporta la traducci\u00f3n inversa, donde una direcci\u00f3n IP se resuelve a un nombre de dominio (dominio inverso).</p>"},{"location":"04.-DNS/03.-Estructura/04.-Dominio%20Directo%20e%20Inverso/#dominio-directo","title":"Dominio Directo","text":"<ul> <li>Funci\u00f3n:<ul> <li>Proporciona la direcci\u00f3n IP correspondiente a un nombre de dominio.</li> <li>Es la operaci\u00f3n m\u00e1s com\u00fan en el DNS.</li> </ul> </li> <li>Ejemplo:<ul> <li>Nombre de dominio: <code>www.example.com</code></li> <li>Direcci\u00f3n IP: <code>192.168.1.1</code></li> <li> <p>Registro DNS:</p> <p><code>www.example.com. IN A 192.168.1.1</code></p> </li> </ul> </li> </ul>"},{"location":"04.-DNS/03.-Estructura/04.-Dominio%20Directo%20e%20Inverso/#dominio-inverso","title":"Dominio Inverso","text":"<ul> <li> <p>Funci\u00f3n:</p> <ul> <li>Resuelve una direcci\u00f3n IP a su nombre de dominio asociado.</li> <li>Es \u00fatil para prop\u00f3sitos de autenticaci\u00f3n, auditor\u00edas y depuraci\u00f3n de problemas en la red.</li> </ul> </li> <li> <p>Dominio especial:</p> <ul> <li>El dominio inverso utiliza un espacio de nombres dedicado: in-addr.arpa.</li> <li>Cada direcci\u00f3n IP se representa como una porci\u00f3n de este dominio jer\u00e1rquico.</li> </ul> </li> <li> <p>Estructura:</p> <ul> <li>Para mantener la jerarqu\u00eda del DNS, las direcciones IP se escriben al rev\u00e9s.</li> <li>Ejemplo:<ul> <li>La direcci\u00f3n de red <code>138.117.0.0</code> se convierte en el dominio inverso <code>117.138.in-addr.arpa</code>.</li> </ul> </li> </ul> </li> <li> <p>Raz\u00f3n para invertir la direcci\u00f3n IP:</p> <ul> <li>En los nombres de dominio, las porciones m\u00e1s a la izquierda son las m\u00e1s espec\u00edficas.</li> <li>En las direcciones IP, las porciones m\u00e1s a la izquierda representan entidades m\u00e1s generales.</li> <li>Al invertir la direcci\u00f3n IP, se preserva la estructura jer\u00e1rquica del DNS.</li> </ul> </li> <li> <p>Ejemplo completo:</p> <ul> <li>Direcci\u00f3n IP: <code>192.168.1.10</code></li> <li>Dominio inverso: <code>10.1.168.192.in-addr.arpa</code></li> <li> <p>Registro DNS:</p> <p><code>10.1.168.192.in-addr.arpa. IN PTR www.example.com.</code></p> </li> </ul> </li> </ul>"},{"location":"04.-DNS/03.-Estructura/04.-Dominio%20Directo%20e%20Inverso/#comparacion-entre-dominio-directo-e-inverso","title":"Comparaci\u00f3n entre Dominio Directo e Inverso","text":"Dominio Directo Dominio Inverso Traduce nombres de dominio a direcciones IP. Traduce direcciones IP a nombres de dominio. Utiliza registros A o AAAA (IPv6). Utiliza registros PTR (Pointer Record). Ejemplo: <code>www.example.com \u2192 192.168.1.1</code>. Ejemplo: <code>192.168.1.1 \u2192 www.example.com</code>. Es el uso m\u00e1s frecuente del DNS. Es com\u00fan en autenticaci\u00f3n y diagn\u00f3stico."},{"location":"04.-DNS/03.-Estructura/04.-Dominio%20Directo%20e%20Inverso/#jerarquia-del-dominio-inverso","title":"Jerarqu\u00eda del Dominio Inverso","text":"<ul> <li>Cada nivel del dominio in-addr.arpa corresponde a un octeto de la direcci\u00f3n IP invertida.</li> <li>Ejemplo de red <code>138.117.0.0</code>:<ul> <li><code>117</code>: Subdominio para el segundo octeto.</li> <li><code>138</code>: Dominio para el primer octeto.</li> <li>Resultado: <code>117.138.in-addr.arpa</code>.</li> </ul> </li> </ul>"},{"location":"04.-DNS/03.-Estructura/05.-Root%20Nameservers/","title":"05.-Root Nameservers","text":"<p>Los root nameservers son los servidores fundamentales en la jerarqu\u00eda del Sistema de Nombres de Dominio (DNS). Su funci\u00f3n principal es proporcionar informaci\u00f3n sobre los servidores responsables de los dominios de primer nivel (TLDs Top-Level Domains) como <code>.com</code>, <code>.org</code>, <code>.es</code>, entre otros.</p>"},{"location":"04.-DNS/03.-Estructura/05.-Root%20Nameservers/#cantidad-y-distribucion","title":"Cantidad y distribuci\u00f3n","text":"<ul> <li> <p>13 Root Nameservers definidos:</p> <ul> <li>Aunque se mencionan 13 root nameservers, esto se refiere a 13 identificadores l\u00f3gicos (<code>A</code> a <code>M</code>), no a la cantidad de m\u00e1quinas f\u00edsicas.</li> </ul> </li> <li> <p>R\u00e9plicas globales:</p> <ul> <li>Hay m\u00faltiples copias de cada uno de estos 13 root nameservers distribuidas geogr\u00e1ficamente para garantizar:<ul> <li>Alta disponibilidad: Redundancia en caso de fallos.</li> <li>Rendimiento mejorado: Respuestas m\u00e1s r\u00e1pidas al reducir la latencia.</li> </ul> </li> <li>Actualmente, existen alrededor de 255 instancias de root nameservers en todo el mundo, utilizando tecnolog\u00edas como Anycast para distribuir las consultas entre servidores cercanos.</li> </ul> </li> </ul>"},{"location":"04.-DNS/03.-Estructura/05.-Root%20Nameservers/#actualizacion-del-dominio-raiz","title":"Actualizaci\u00f3n del dominio ra\u00edz","text":"<ul> <li>Los mapas del dominio ra\u00edz (<code>root zone file</code>) contienen la informaci\u00f3n sobre los TLDs y se actualizan regularmente.</li> <li>M\u00e9todo de transferencia:<ul> <li>La sincronizaci\u00f3n entre root nameservers se realiza mediante mecanismos externos al DNS, como:<ul> <li>Transferencia segura de archivos.</li> <li>Protocolos especializados que garantizan la integridad de los datos.</li> </ul> </li> <li>Esto asegura que todos los root nameservers mantengan una copia actualizada y consistente del archivo ra\u00edz.</li> </ul> </li> </ul>"},{"location":"04.-DNS/03.-Estructura/05.-Root%20Nameservers/#importancia-de-los-root-nameservers","title":"Importancia de los Root Nameservers","text":"<ol> <li> <p>Pilar del DNS:</p> <ul> <li>Act\u00faan como el primer punto de referencia para resolver nombres en Internet.</li> <li>Por ejemplo, si un cliente consulta <code>www.example.com</code>, el root nameserver le indicar\u00e1 cu\u00e1l es el servidor TLD (<code>.com</code>) responsable.</li> </ul> </li> <li> <p>Resiliencia global:</p> <ul> <li>La distribuci\u00f3n de instancias asegura que el sistema DNS pueda seguir funcionando incluso en caso de ataques o desastres regionales.</li> </ul> </li> <li> <p>Eficiencia y velocidad:</p> <ul> <li>Con el uso de Anycast, las consultas se redirigen autom\u00e1ticamente al servidor m\u00e1s cercano, optimizando el tiempo de respuesta.</li> </ul> </li> </ol>"},{"location":"04.-DNS/03.-Estructura/05.-Root%20Nameservers/#ejemplo-de-root-nameservers","title":"Ejemplo de Root Nameservers","text":"<p>Los 13 root nameservers tienen nombres identificativos como:</p> <ul> <li><code>a.root-servers.net</code></li> <li><code>b.root-servers.net</code></li> <li><code>c.root-servers.net</code></li> <li>... hasta <code>m.root-servers.net</code>.</li> </ul> <p>Cada uno de estos nombres tiene m\u00faltiples direcciones IP asociadas (IPv4 e IPv6), distribuidas estrat\u00e9gicamente por el mundo.</p> <p>Toda la informaci\u00f3n relativa a los Root Nameservers puedes encontrarla aqu\u00ed.</p>"},{"location":"04.-DNS/03.-Estructura/06.-Forwarders%20%28Reenviadores%29/","title":"06.-Forwarders (Reenviadores)","text":"<p>En el Sistema de Nombres de Dominio (DNS), los forwarders son servidores configurados para recibir consultas recursivas de otros servidores y realizar toda la cadena de b\u00fasquedas en su lugar. Este mecanismo optimiza la resoluci\u00f3n de nombres en ciertos escenarios.</p>"},{"location":"04.-DNS/03.-Estructura/06.-Forwarders%20%28Reenviadores%29/#funcionamiento","title":"Funcionamiento","text":"<ol> <li>Comportamiento de S1 (servidor principal):<ol> <li>Si S1 recibe una consulta recursiva:<ol> <li>Caso 1: S1 conoce la respuesta y la devuelve directamente.</li> <li>Caso 2: S1 no conoce la respuesta y la consulta se reenv\u00eda a otro servidor, S2, configurado como forwarder.</li> </ol> </li> </ol> </li> <li>Rol de S2 (forwarder):<ol> <li>S2 se encarga de realizar toda la cadena de b\u00fasquedas necesarias para resolver la consulta y devuelve la respuesta a S1.</li> <li>Este enfoque descarga la responsabilidad de S1, que act\u00faa \u00fanicamente como intermediario.</li> </ol> </li> </ol> <pre><code>graph TD\n    Client[\"Cliente/Usuario\"] --&gt; S1[\"S1 (Servidor Principal)\"]\n    S1 --&gt;|Caso 1 Consulta recursiva conocida| Cache[\"Cach\u00e9 de S1\"]\n    Cache --&gt; S1\n    S1 --&gt;|Caso 2 Consulta recursiva no conocida| S2[\"S2 (Servidor Forwarder)\"]\n    S2 --&gt; Root[\"Servidor Ra\u00edz\"]\n    Root --&gt; TLD[\"Servidores TLD\"]\n    TLD --&gt; Auth[\"Servidor Autoritativo\"]\n    Auth --&gt; S2\n    S2 --&gt; S1\n    S1 --&gt; Client\n\n    subgraph Resoluci\u00f3n por S2\n        S2 --&gt;|Cadena de b\u00fasquedas| Root\n        Root --&gt; TLD\n        TLD --&gt; Auth\n    end\n</code></pre>"},{"location":"04.-DNS/03.-Estructura/06.-Forwarders%20%28Reenviadores%29/#ventajas-del-uso-de-forwarders","title":"Ventajas del uso de Forwarders","text":"<ul> <li>Mejor conexi\u00f3n con Internet:<ul> <li>Si S1 tiene una mala conexi\u00f3n a Internet pero S2 no, redirigir las consultas a S2 mejora la eficiencia y reduce la latencia.</li> </ul> </li> <li>Aprovechamiento de la cach\u00e9:<ul> <li>Centralizar las consultas de m\u00faltiples servidores en un \u00fanico forwarder (S2) permite aprovechar su cach\u00e9 de respuestas DNS.</li> <li>Esto reduce el tiempo de resoluci\u00f3n y la cantidad de consultas que deben enviarse a los servidores DNS externos.</li> </ul> </li> <li>Simplificaci\u00f3n de la gesti\u00f3n:<ul> <li>Facilita la administraci\u00f3n al concentrar la l\u00f3gica de resoluci\u00f3n en un \u00fanico servidor.</li> </ul> </li> </ul>"},{"location":"04.-DNS/03.-Estructura/06.-Forwarders%20%28Reenviadores%29/#escenarios-de-uso","title":"Escenarios de Uso","text":"<ul> <li>Conexi\u00f3n limitada:    <ul> <li>Una sucursal con acceso limitado a Internet utiliza un servidor forwarder en la oficina central para resolver nombres.</li> </ul> </li> <li>Optimizaci\u00f3n de recursos:<ul> <li>Una red con m\u00faltiples servidores DNS distribuidos centraliza las consultas en un \u00fanico forwarder para reducir el tr\u00e1fico y aprovechar la cach\u00e9.</li> </ul> </li> <li>Pol\u00edticas de seguridad:<ul> <li>Las consultas DNS pasan primero por un forwarder configurado para aplicar reglas de filtrado o monitorizaci\u00f3n.</li> </ul> </li> </ul>"},{"location":"04.-DNS/04.-Administraci%C3%B3n/","title":"Administraci\u00f3n","text":"<p>El Sistema de Nombres de Dominio (DNS) organiza y administra la resoluci\u00f3n de nombres mediante zonas, que representan \u00e1reas de autoridad delegadas y gestionadas por servidores de nombres espec\u00edficos.</p>"},{"location":"04.-DNS/04.-Administraci%C3%B3n/01.-Zona%20de%20Autoridad%20y%20Zona/","title":"01.-Zona de Autoridad y Zona","text":""},{"location":"04.-DNS/04.-Administraci%C3%B3n/01.-Zona%20de%20Autoridad%20y%20Zona/#zona-de-autoridad","title":"Zona de Autoridad","text":"<ol> <li> <p>Definici\u00f3n:</p> <ul> <li>Es el \u00e1rea de influencia administrativa de una organizaci\u00f3n sobre un dominio o subdominio.</li> <li>Incluye la responsabilidad de mantener y operar los servidores de nombres asociados al dominio.</li> </ul> </li> <li> <p>Delegaci\u00f3n de subdominios:</p> <ul> <li>Una organizaci\u00f3n puede dividir su dominio en subdominios y delegar la administraci\u00f3n de estos a otras entidades.</li> <li>La delegaci\u00f3n permite distribuir la carga administrativa y t\u00e9cnica, manteniendo la escalabilidad.</li> </ul> </li> <li> <p>Flexibilidad en la divisi\u00f3n:</p> <ul> <li>La delegaci\u00f3n no tiene por qu\u00e9 abarcar dominios enteros; se pueden delegar porciones m\u00e1s peque\u00f1as del dominio, lo que da lugar a las zonas.</li> </ul> </li> <li> <p>Estructura:</p> <ul> <li>Los dominios no solo contienen subdominios, sino que tambi\u00e9n pueden incluir hosts individuales.</li> </ul> </li> </ol>"},{"location":"04.-DNS/04.-Administraci%C3%B3n/01.-Zona%20de%20Autoridad%20y%20Zona/#zona","title":"Zona","text":"<ol> <li> <p>Definici\u00f3n:</p> <ul> <li>Una zona es la parte del espacio de nombres DNS administrada por un servidor de nombres.</li> <li>Puede abarcar:<ul> <li>Todo un dominio (ejemplo: <code>example.com</code>).</li> <li>Parte de un dominio (ejemplo: <code>dept.example.com</code>).</li> </ul> </li> </ul> </li> <li> <p>Archivos de zona:</p> <ul> <li>Una zona se define en un archivo f\u00edsico en el servidor DNS.</li> <li>Este archivo contiene los registros de recursos (Resource Records - RR) para los nombres y direcciones IP asociados a la zona.</li> </ul> </li> <li> <p>Tipos de registros en los archivos de zona:</p> <ul> <li>A (Address Record): Asocia un nombre de dominio a una direcci\u00f3n IP.</li> <li>PTR (Pointer Record): Utilizado en zonas inversas para resolver direcciones IP en nombres de dominio.</li> <li>MX (Mail Exchange): Define los servidores de correo para un dominio.</li> <li>CNAME (Canonical Name): Alias para un nombre de dominio existente.</li> <li>NS (Name Server): Define los servidores responsables de la zona.</li> <li>SOA (Start of Authority): Contiene informaci\u00f3n sobre la zona, como el servidor principal y los par\u00e1metros de configuraci\u00f3n.</li> </ul> </li> <li> <p>Gesti\u00f3n de zonas en servidores DNS:</p> <ul> <li>Un servidor DNS puede administrar:<ul> <li>Zonas autoritativas: La zona est\u00e1 completamente gestionada por el servidor.</li> <li>Zonas delegadas: El servidor redirige las consultas a otros servidores responsables de esa parte del dominio.</li> </ul> </li> </ul> </li> </ol>"},{"location":"04.-DNS/04.-Administraci%C3%B3n/01.-Zona%20de%20Autoridad%20y%20Zona/#ejemplo-de-un-archivo-de-zona","title":"Ejemplo de un archivo de zona","text":"<pre><code>$TTL 86400         ; Tiempo de vida de los registros (24 horas)\n@    IN  SOA   ns1.example.com. admin.example.com. (\n             2023111801 ; N\u00famero de serie\n             3600       ; Actualizaci\u00f3n (1 hora)\n             900        ; Reintento (15 minutos)\n             1209600    ; Expiraci\u00f3n (2 semanas)\n             86400      ; Tiempo negativo de cach\u00e9 (1 d\u00eda)\n)\n\n     IN  NS    ns1.example.com.  ; Servidor de nombres primario\n     IN  NS    ns2.example.com.  ; Servidor de nombres secundario\n\nwww  IN  A     192.168.1.1       ; Direcci\u00f3n IP del host www\nftp  IN  A     192.168.1.2       ; Direcci\u00f3n IP del host ftp\nmail IN  MX    10 mail.example.com. ; Servidor de correo\n</code></pre>"},{"location":"04.-DNS/04.-Administraci%C3%B3n/01.-Zona%20de%20Autoridad%20y%20Zona/#caracteristicas-clave","title":"Caracter\u00edsticas Clave","text":"<ul> <li>Delegaci\u00f3n eficiente:<ul> <li>Zonas permiten delegar partes de un dominio a diferentes servidores, distribuyendo la carga de administraci\u00f3n.</li> </ul> </li> <li>Escalabilidad:<ul> <li>La divisi\u00f3n en zonas asegura que los dominios grandes puedan manejarse de manera eficiente.</li> </ul> </li> <li>Archivos de zona personalizados:<ul> <li>Contienen registros espec\u00edficos para satisfacer las necesidades de cada subdominio o host.</li> </ul> </li> </ul>"},{"location":"04.-DNS/04.-Administraci%C3%B3n/02.-Componentes%20del%20servicio%20DNS/","title":"02.-Componentes del servicio DNS","text":"<p>El servicio DNS utiliza un mecanismo Cliente/Servidor, donde programas llamados servidores de nombres contienen informaci\u00f3n acerca de un segmento de la base de datos <code>/etc/bind/dominio.db</code> y la ponen a disposici\u00f3n de los clientes.</p>"},{"location":"04.-DNS/04.-Administraci%C3%B3n/02.-Componentes%20del%20servicio%20DNS/#servidores-de-nombres","title":"Servidores de Nombres","text":"<p>El archivo de configuraci\u00f3n principal del DNS es <code>/etc/bind/named.conf</code>, pero este hace referencia a varios archivos adicionales, como:</p> <ul> <li>Archivo <code>named.conf</code>: Archivo principal de configuraci\u00f3n.</li> <li>Archivo <code>named.conf.options</code>: Contiene opciones gen\u00e9ricas.</li> <li>Archivo <code>named.conf.local</code>: Especificaci\u00f3n particular de este servidor DNS.</li> <li>Archivo <code>db.127</code>: Especificaci\u00f3n para la direcci\u00f3n de retorno (<code>127.0.0.1</code>).</li> <li>Archivo <code>db.root</code>: Contiene los DNS de nivel superior.</li> <li>Otros archivos comunes:<ul> <li><code>db.0</code></li> <li><code>db.255</code></li> <li><code>db.empty</code></li> <li><code>db.local</code></li> <li><code>rndc.conf</code></li> <li><code>rndc.key</code></li> <li><code>zones.rfc1918</code></li> </ul> </li> </ul>"},{"location":"04.-DNS/04.-Administraci%C3%B3n/02.-Componentes%20del%20servicio%20DNS/#clientes-resolvers","title":"Clientes (Resolvers)","text":"<p>La configuraci\u00f3n de los clientes se realiza en el archivo <code>/etc/resolv.conf</code>, donde se especifica la IP del servidor DNS.</p>"},{"location":"04.-DNS/04.-Administraci%C3%B3n/02.-Componentes%20del%20servicio%20DNS/#pruebas-de-resolucion","title":"Pruebas de Resoluci\u00f3n","text":"<ul> <li>Resoluci\u00f3n directa: Traduce un nombre de dominio a una direcci\u00f3n IP.<ul> <li>Comando de prueba:</li> </ul> </li> </ul> <pre><code>$ nslookup www.esi.es\n</code></pre> <ul> <li>Resoluci\u00f3n inversa: Traduce una direcci\u00f3n IP a un nombre de dominio.<ul> <li>Comando de prueba:</li> </ul> </li> </ul> <pre><code>nslookup 192.168.4.10\n</code></pre>"},{"location":"04.-DNS/04.-Administraci%C3%B3n/03.-Servidores%20de%20nombres/","title":"03.-Servidores de nombres","text":"<ul> <li>Almacenan informaci\u00f3n sobre el espacio de nombres de dominio.</li> <li>Contienen informaci\u00f3n sobre fragmentos de la base de datos, llamados zonas. Utilizan esta informaci\u00f3n para responder a las peticiones de los clientes y saben d\u00f3nde buscar datos que no administran.</li> <li>Mantienen informaci\u00f3n completa sobre una o varias zonas del espacio de nombres de dominio. Esto significa que poseen informaci\u00f3n autorizada para dichas zonas.</li> <li>En caso de delegaci\u00f3n de zonas, el servidor almacenar\u00e1 referencias a los servidores que contienen informaci\u00f3n autorizada para esas zonas.</li> </ul>"},{"location":"04.-DNS/04.-Administraci%C3%B3n/03.-Servidores%20de%20nombres/#tipos-de-servidores-de-nombres-en-dns","title":"Tipos de Servidores de Nombres en DNS","text":""},{"location":"04.-DNS/04.-Administraci%C3%B3n/03.-Servidores%20de%20nombres/#1-maestros-o-primarios","title":"1. Maestros o Primarios","text":"<ul> <li>Obtienen la informaci\u00f3n sobre zonas de los archivos contenidos en la m\u00e1quina donde se ejecutan.</li> <li>Contienen informaci\u00f3n autorizada para las zonas que administran.</li> </ul>"},{"location":"04.-DNS/04.-Administraci%C3%B3n/03.-Servidores%20de%20nombres/#2-esclavos-o-secundarios","title":"2. Esclavos o Secundarios","text":"<ul> <li>Obtienen la informaci\u00f3n sobre zonas desde otros servidores autorizados para esas zonas.</li> <li>Funcionamiento:<ul> <li>Al arrancar, el servidor secundario contacta con los servidores primarios necesarios y descarga toda la informaci\u00f3n sobre las zonas.</li> <li>Una vez en funcionamiento, el servidor secundario solicita peri\u00f3dicamente informaci\u00f3n actualizada sobre las zonas al servidor primario.</li> </ul> </li> <li>Ventajas del uso de secundarios:<ul> <li>Aumentan la disponibilidad del servicio.</li> <li>Mejoran la eficiencia, ya que reparten la carga de trabajo entre varios servidores.</li> </ul> </li> <li>Por cada zona, puede haber un servidor de nombres primario y uno o m\u00e1s secundarios.</li> </ul>"},{"location":"04.-DNS/04.-Administraci%C3%B3n/03.-Servidores%20de%20nombres/#3-servidores-locales-o-de-cache","title":"3. Servidores Locales o de Cach\u00e9","text":"<ul> <li>No tienen autoridad sobre ning\u00fan dominio.</li> <li>Se limitan a contactar con otros servidores para resolver las peticiones de los clientes DNS.</li> <li>Funcionamiento:<ul> <li>Mantienen una memoria cach\u00e9 con las \u00faltimas preguntas contestadas.</li> <li>Cuando un cliente DNS formula una consulta, el servidor:<ol> <li>Verifica si la respuesta est\u00e1 en su cach\u00e9.</li> <li>Si la encuentra, la devuelve al cliente.</li> <li>Si no, consulta a otros servidores, almacena la respuesta en su cach\u00e9 y se la comunica al cliente.</li> </ol> </li> </ul> </li> </ul>"},{"location":"04.-DNS/04.-Administraci%C3%B3n/04.-Clientes%20%28resolvers%29/","title":"04.-Clientes (resolvers)","text":"<ul> <li>Son programas o librer\u00edas de funciones que formulan consultas a los servidores DNS.</li> <li>El proceso mediante el cual el servidor encuentra la respuesta es transparente para los resolvers.</li> </ul>"},{"location":"04.-DNS/04.-Administraci%C3%B3n/04.-Clientes%20%28resolvers%29/#caracteristicas-de-los-resolvers","title":"Caracter\u00edsticas de los Resolvers","text":"<ul> <li>Los resolvers son los clientes del sistema DNS.</li> <li>Funcionamiento:<ol> <li>Consultan al servidor de DNS para obtener informaci\u00f3n.</li> <li>Interpretan la respuesta:<ul> <li>Si la respuesta no llega o es incorrecta, pueden volver a formular la consulta.</li> </ul> </li> <li>Devuelven la informaci\u00f3n al programa o sistema que realiz\u00f3 la solicitud.</li> </ol> </li> </ul>"},{"location":"04.-DNS/04.-Administraci%C3%B3n/04.-Clientes%20%28resolvers%29/#pasos-en-una-consulta-de-resolucion-de-nombres-gnulinux","title":"Pasos en una Consulta de Resoluci\u00f3n de Nombres (GNU/Linux)","text":"<ol> <li>Consulta en el archivo <code>/etc/hosts</code>:<ul> <li>Se revisa este archivo para buscar una resoluci\u00f3n local.</li> </ul> </li> <li>Consulta en un servidor DNS:<ul> <li>Si no se resuelve en <code>/etc/hosts</code>, se consulta un servidor DNS cuya direcci\u00f3n IP est\u00e1 configurada en <code>/etc/resolv.conf</code>.</li> </ul> </li> <li>Orden de b\u00fasqueda definido por <code>/etc/nsswitch.conf</code>:<ul> <li>Este archivo determina:<ul> <li>Si se consulta primero el archivo <code>/etc/hosts</code> y/o el servidor DNS.</li> <li>El orden en que se realizan las consultas.</li> </ul> </li> </ul> </li> </ol> <pre><code>graph LR\n    subgraph \"M\u00e1quina A\"\n        App[Aplicaci\u00f3n]\n        Resolver[Resolver]\n        Files[Ficheros:&lt;br&gt;/etc/nsswitch.conf&lt;br&gt;/etc/hosts&lt;br&gt;/etc/resolv.conf]\n        App --&gt;|gethostbyname| Resolver\n        Resolver --&gt;|return| App\n        Resolver --&gt; Files\n    end\n    Resolver --&gt;|Consulta| DNS[Servidor de DNS]\n    DNS --&gt;|Respuesta| Resolver\n    subgraph \"M\u00e1quina B\"\n        DNS\n    end\n</code></pre>"},{"location":"04.-DNS/04.-Administraci%C3%B3n/05.-Resoluciones%20de%20Nombre/","title":"05.-Resoluciones de Nombre","text":"<p>El proceso de resoluci\u00f3n de nombres consiste en buscar en el espacio de nombres de dominio la informaci\u00f3n asociada a un dominio concreto.</p> <ol> <li>Cuando un servidor recibe una consulta de un resolver, busca en sus registros la informaci\u00f3n correspondiente. Si la encuentra, la devuelve.</li> <li>Los servidores DNS pueden responder a dos tipos de consultas:<ul> <li>Consultas Iterativas (no recursivas)</li> <li>Consultas Recursivas</li> </ul> </li> </ol>"},{"location":"04.-DNS/04.-Administraci%C3%B3n/05.-Resoluciones%20de%20Nombre/#consultas-iterativas-no-recursivas","title":"Consultas Iterativas (No Recursivas)","text":"<p>Cuando un cliente formula una consulta iterativa a un servidor DNS, este servidor:</p> <ul> <li>Devuelve la direcci\u00f3n IP si la conoce.</li> <li>Si no la conoce, responde con la direcci\u00f3n de otro servidor que podr\u00eda resolver el nombre.</li> </ul> <p>Nota: Este m\u00e9todo de consulta es poco utilizado. En este caso, las consultas a los servidores adicionales (como NS2, NS3, etc.) son realizadas por el servidor local (por ejemplo, NS1).</p> <pre><code>graph TD\n    Cliente[Cliente] --&gt;|Consulta1| NS1[Servidor DNS Local NS1]\n    NS1 --&gt;|Consulta2| NS2[Servidor DNS NS2]\n    NS1 --&gt;|Consulta3| NS3[Servidor DNS NS3]\n    NS1 --&gt;|Respuesta4| Cliente\n    subgraph \"No recursiva, controlada por el servidor\"\n        NS1\n        NS2\n        NS3\n    end\n</code></pre> <ol> <li>El Cliente env\u00eda la consulta al servidor local (NS1).</li> <li>El servidor NS1 consulta a otros servidores DNS (NS2, NS3, etc.) seg\u00fan sea necesario.</li> <li>El servidor NS1 devuelve la respuesta al Cliente (ya sea la direcci\u00f3n IP o informaci\u00f3n adicional sobre otro servidor que puede resolver el nombre).</li> </ol> <p></p>"},{"location":"04.-DNS/04.-Administraci%C3%B3n/05.-Resoluciones%20de%20Nombre/#consultas-recursivas","title":"Consultas Recursivas","text":"<p>Cuando un cliente realiza una consulta recursiva a un servidor DNS, este:</p> <ul> <li>Debe intentar resolver la consulta por todos los medios posibles, incluso si eso implica consultar a otros servidores.</li> </ul> <p>Nota: Este es el m\u00e9todo de consulta m\u00e1s frecuente.</p> <pre><code>graph TD\n    Cliente[Cliente] --&gt;|Consulta 1| NS1[Servidor DNS Local NS1]\n    NS1 --&gt;|Consulta 2| NS2[Servidor DNS NS2]\n    NS2 --&gt;|Consulta 3| NS3[Servidor DNS NS3]\n    NS3 --&gt;|Respuesta 4| NS2\n    NS2 --&gt;|Respuesta 5| NS1\n    NS1 --&gt;|Respuesta 6| Cliente\n    subgraph \"Recursiva, controlada por el servidor\"\n        NS1\n        NS2\n        NS3\n    end\n</code></pre> <ol> <li>El Cliente env\u00eda una consulta al Servidor Local (NS1).</li> <li>El NS1 realiza la consulta al siguiente servidor DNS en la jerarqu\u00eda (NS2).</li> <li>El NS2 consulta al siguiente servidor (NS3) si no tiene la informaci\u00f3n solicitada.</li> <li>El NS3 responde con la informaci\u00f3n al NS2.</li> <li>El NS2 devuelve la informaci\u00f3n al NS1.</li> <li>Finalmente, el NS1 responde al Cliente con la informaci\u00f3n solicitada.</li> </ol> <p>Este flujo representa c\u00f3mo funciona una consulta recursiva, donde cada servidor intermedio realiza la consulta en lugar del cliente, simplificando el proceso desde la perspectiva del cliente.</p>"},{"location":"04.-DNS/05.-Zonas%20de%20autoridad/","title":"05.-Zonas de Autoridad","text":"<p>Un servidor DNS almacena informaci\u00f3n acerca de ciertas partes del espacio de nombres de dominio, conocidas como zonas.</p> <ul> <li>Una zona no necesariamente coincide con un dominio completo.</li> <li>Se dice que un servidor DNS tiene autoridad sobre una zona cuando administra dicha parte del espacio de nombres.</li> <li>Un servidor de nombres puede tener autoridad sobre varias zonas.</li> </ul>"},{"location":"04.-DNS/05.-Zonas%20de%20autoridad/#mapa-de-dominio-o-de-zona","title":"Mapa de Dominio o de Zona","text":"<p>La informaci\u00f3n relacionada con la resoluci\u00f3n de nombres de un dominio espec\u00edfico se guarda en un fichero llamado mapa del dominio o de zona.</p> <p>En el mapa de una zona o dominio, se encuentran, entre otros datos:</p> <ol> <li>Los nombres de las m\u00e1quinas del dominio, junto con sus respectivas direcciones IP.</li> <li>Los nombres de los subdominios directos, junto con las direcciones IP de los servidores DNS que gestionan esos subdominios.</li> </ol>"},{"location":"04.-DNS/05.-Zonas%20de%20autoridad/#administracion-del-mapa-de-dominio","title":"Administraci\u00f3n del Mapa de Dominio","text":"<ul> <li>El administrador de sistemas del dominio edita y mantiene el mapa de dominio.</li> <li>Este fichero se almacena en la m\u00e1quina que opera como servidor DNS del dominio.</li> </ul>"},{"location":"04.-DNS/05.-Zonas%20de%20autoridad/#servidor-dns-con-multiples-ficheros-de-zona","title":"Servidor DNS con M\u00faltiples Ficheros de Zona","text":"<p>Un servidor DNS que gestione varios ficheros de zona ser\u00e1 capaz de administrar todos los dominios correspondientes a dichos ficheros.</p>"},{"location":"04.-DNS/05.-Zonas%20de%20autoridad/01.-Introducci%C3%B3n/","title":"01.-Introducci\u00f3n","text":"<ul> <li>La informaci\u00f3n de cada Zona de Autoridad se almacena localmente en un fichero de texto en el Servidor DNS.</li> <li>Despu\u00e9s de crear una zona, es necesario agregarle registros de recursos (RR) adicionales.</li> <li>En realidad, la zona es un archivo que contiene registros de recursos (RR) de la base de datos del espacio de nombres de dominio.</li> </ul>"},{"location":"04.-DNS/05.-Zonas%20de%20autoridad/01.-Introducci%C3%B3n/#tipos-de-registros-dns","title":"Tipos de Registros DNS","text":"Tipo Prop\u00f3sito SOA Define informaci\u00f3n b\u00e1sica de la zona, como el servidor primario y el correo del administrador. A Asocia un nombre de dominio a una direcci\u00f3n IPv4. AAAA Asocia un nombre de dominio a una direcci\u00f3n IPv6. CNAME Crea un alias para otro dominio. MX Define los servidores de correo para el dominio y sus prioridades. NS Especifica los servidores DNS autoritativos para la zona. PTR Realiza la resoluci\u00f3n inversa (de direcci\u00f3n IP a nombre de dominio). TXT Almacena texto arbitrario, utilizado para configuraciones como SPF o verificaciones. SRV Define servicios espec\u00edficos y su ubicaci\u00f3n dentro del dominio. CAA Restringe qu\u00e9 autoridades de certificaci\u00f3n pueden emitir certificados para el dominio."},{"location":"04.-DNS/05.-Zonas%20de%20autoridad/01.-Introducci%C3%B3n/#delegacion-de-autoridad-en-dns","title":"Delegaci\u00f3n de Autoridad en DNS","text":"<p>La autoridad de una zona puede delegar la autoridad de una parte de su dominio en otro servidor DNS.</p> <ul> <li>Ejemplo:<ul> <li>La autoridad de la zona <code>kandemor.com</code> es el servidor DNS1.</li> <li>DNS1 delega la autoridad del subdominio <code>domi.kandemor.com</code> al servidor DNS2.</li> <li>A partir de este momento, para consultar los registros del dominio <code>domi.kandemor.com</code>, ser\u00e1 necesario consultar a DNS2.</li> </ul> </li> </ul>"},{"location":"04.-DNS/05.-Zonas%20de%20autoridad/01.-Introducci%C3%B3n/#que-implica-esta-delegacion","title":"\u00bfQu\u00e9 implica esta delegaci\u00f3n?","text":"<ol> <li>Nueva autoridad:<ul> <li>DNS2 se convierte en la autoridad del dominio delegado <code>domi.kandemor.com</code>.</li> </ul> </li> <li>Capacidad de creaci\u00f3n:<ul> <li>DNS2 puede crear subdominios bajo <code>domi.kandemor.com</code> y delegarlos seg\u00fan considere necesario.</li> </ul> </li> <li>Competencia limitada:<ul> <li>DNS1 ya no tiene autoridad sobre el dominio delegado.</li> <li>Su \u00fanica funci\u00f3n es mantener un puntero que indica qui\u00e9n es la autoridad para <code>domi.kandemor.com</code> (en este caso, DNS2).</li> </ul> </li> </ol>"},{"location":"04.-DNS/05.-Zonas%20de%20autoridad/01.-Introducci%C3%B3n/#zonas-en-un-servidor-dns","title":"Zonas en un Servidor DNS","text":"<p>En cualquier servidor DNS que contenga informaci\u00f3n de dominios, se definen al menos dos tipos de zonas que el servidor puede atender:</p>"},{"location":"04.-DNS/05.-Zonas%20de%20autoridad/01.-Introducci%C3%B3n/#1-zonas-de-busqueda-directa","title":"1. Zonas de B\u00fasqueda Directa","text":"<ul> <li>Estas zonas devuelven direcciones IP cuando se realizan b\u00fasquedas utilizando nombres FQDN (Fully Qualified Domain Name).</li> <li>Ejemplo:<ul> <li>B\u00fasqueda: <code>www.example.com</code></li> <li>Respuesta: <code>192.168.1.10</code></li> </ul> </li> </ul>"},{"location":"04.-DNS/05.-Zonas%20de%20autoridad/01.-Introducci%C3%B3n/#2-zonas-de-resolucion-inversa","title":"2. Zonas de Resoluci\u00f3n Inversa","text":"<ul> <li>Estas zonas devuelven nombres FQDN (Fully Qualified Domain Name) cuando se realizan b\u00fasquedas utilizando direcciones IP.</li> <li>Ejemplo:<ul> <li>B\u00fasqueda: <code>192.168.1.10</code></li> <li>Respuesta: <code>www.example.com</code></li> </ul> </li> </ul> <p>Ambas zonas son esenciales para garantizar que un servidor DNS pueda resolver nombres y direcciones en ambas direcciones (directa e inversa).</p>"},{"location":"04.-DNS/05.-Zonas%20de%20autoridad/02.-Registros%20de%20Recursos%20%28RRs%29/","title":"02.-Registros de Recursos (RRs)","text":"<p>Un mapa de dominio incluye un conjunto de Registros de Recursos (RRs), que son las unidades de consulta en un servidor DNS.</p>"},{"location":"04.-DNS/05.-Zonas%20de%20autoridad/02.-Registros%20de%20Recursos%20%28RRs%29/#estructura-de-un-registro-de-recurso-rr","title":"Estructura de un Registro de Recurso (RR)","text":"<p>Cada registro de recurso est\u00e1 compuesto por 5 campos:</p> Campo Descripci\u00f3n Nombre El nombre del registro que se est\u00e1 definiendo. Puede ser de tres formas:- FQDN de m\u00e1quina o dominio sobre el que trata el registro.- S\u00edmbolo @, que hace referencia al nombre de la zona configurada en el servidor (<code>/etc/named.conf.local</code>).- En blanco, que toma el valor del registro anterior definido con un propietario (FQDN o @). TTL (Time To Live) Tiempo en segundos que el registro permanece en la cach\u00e9 del cliente. Puede expresarse en:- D\u00edas (<code>d</code>), horas (<code>h</code>), minutos (<code>m</code>) y segundos (<code>s</code>). Ejemplo: 4h30m.- 0: Indica que el registro no debe almacenarse en cach\u00e9. Clase Define la familia de protocolos en uso. Normalmente ser\u00e1 IN para Internet (redes TCP/IP). Tipo Identifica el tipo de registro, seg\u00fan el recurso:- SOA: Inicio de autoridad. Identifica el servidor autoritario de la zona y sus par\u00e1metros de configuraci\u00f3n.- NS: Servidor de nombres. Identifica los servidores de nombres autorizados para la zona.- A: Direcci\u00f3n. Asocia un FQDN a una direcci\u00f3n IP.- PTR: Puntero. Asocia una direcci\u00f3n IP a un FQDN (usado en zonas de resoluci\u00f3n inversa).- MX: Identifica los servidores encargados de la entrega de correo en el dominio.- CNAME: Alias. Permite asignar un alias a un recurso ya definido con un FQDN.- Otros: Registros adicionales como <code>TXT</code> (texto), <code>SRV</code> (servicios espec\u00edficos), etc. Valor Informaci\u00f3n asociada al registro, depende del tipo:- A: Direcci\u00f3n IP del FQDN.- MX: Nombre del servidor de correo y su prioridad.- CNAME: FQDN del recurso al que se apunta.- PTR: FQDN correspondiente a la direcci\u00f3n IP."},{"location":"04.-DNS/05.-Zonas%20de%20autoridad/03.-Registro%20de%20recurso%20SOA/","title":"03.-Registro de recurso SOA","text":"<p>El registro de inicio de autoridad SOA(Start Of Authority) es el primer registro de recurso (RR) en cualquier archivo de zona DNS. Define que el servidor de nombres es la mejor fuente de informaci\u00f3n para el dominio y contiene datos esenciales para la gesti\u00f3n de la zona.</p>"},{"location":"04.-DNS/05.-Zonas%20de%20autoridad/03.-Registro%20de%20recurso%20SOA/#estructura-del-registro-soa","title":"Estructura del Registro SOA","text":"<pre><code>FQDN_dominio IN SOA FQDN_servidor correo_administrador (\n    num_serie ; comentario\n    actualizacion ; comentario\n    reintentos ; comentario\n    caducidad ; comentario\n    TTL ; comentario\n)\n</code></pre>"},{"location":"04.-DNS/05.-Zonas%20de%20autoridad/03.-Registro%20de%20recurso%20SOA/#descripcion-de-los-campos","title":"Descripci\u00f3n de los Campos","text":"Campo Descripci\u00f3n FQDN_dominio Nombre del dominio de la zona. Puede indicarse como FQDN, con <code>@</code> para el dominio completo, o en blanco (toma el valor anterior). FQDN_servidor Nombre del servidor DNS primario que controla la zona. correo_administrador Direcci\u00f3n de correo del administrador, con <code>.</code> en lugar de <code>@</code>. Ejemplo: <code>correo_admin.miempresa.com.</code> num_serie N\u00famero de versi\u00f3n de la zona. Sirve como referencia para indicar a los servidores secundarios si deben actualizarse. actualizacion Tiempo (en segundos) que el servidor secundario espera antes de consultar al primario por cambios. reintentos Tiempo (en segundos) que el servidor secundario espera antes de reintentar una transferencia fallida. caducidad Tiempo (en segundos) que los datos de la zona permanecen v\u00e1lidos en el secundario si no puede conectarse al primario. TTL Tiempo (en segundos) que los registros permanecen en cach\u00e9 antes de considerarse desactualizados."},{"location":"04.-DNS/05.-Zonas%20de%20autoridad/03.-Registro%20de%20recurso%20SOA/#detalles-de-los-campos","title":"Detalles de los Campos","text":""},{"location":"04.-DNS/05.-Zonas%20de%20autoridad/03.-Registro%20de%20recurso%20SOA/#numero-de-serie-num_serie","title":"N\u00famero de Serie (num_serie)","text":"<ul> <li>Indica la versi\u00f3n del archivo de zona.</li> <li>Si el n\u00famero de serie del secundario es menor que el del primario, se realiza una transferencia de zona para sincronizar los datos.</li> <li>Notaci\u00f3n com\u00fan: <code>AAAAMMDDNN</code> (A\u00f1o, Mes, D\u00eda, N\u00famero de cambio).<ul> <li>Ejemplo: <code>2024111901</code> (19 de noviembre de 2024, primer cambio del d\u00eda).</li> </ul> </li> <li>Nota: Se debe incrementar manualmente tras cada modificaci\u00f3n en el archivo de zona.</li> </ul>"},{"location":"04.-DNS/05.-Zonas%20de%20autoridad/03.-Registro%20de%20recurso%20SOA/#actualizacion-refresh-time","title":"Actualizaci\u00f3n (Refresh Time)","text":"<ul> <li>Tiempo que el secundario espera antes de consultar al primario por cambios.</li> <li>Se expresa en segundos, pero puede indicarse en d\u00edas (<code>D</code>), horas (<code>H</code>), o minutos (<code>M</code>).</li> </ul>"},{"location":"04.-DNS/05.-Zonas%20de%20autoridad/03.-Registro%20de%20recurso%20SOA/#reintentos-retry-time","title":"Reintentos (Retry Time)","text":"<ul> <li>Tiempo que el secundario espera antes de reintentar una transferencia fallida.</li> <li>Ejemplo: <code>3600</code> (1 hora).</li> </ul>"},{"location":"04.-DNS/05.-Zonas%20de%20autoridad/03.-Registro%20de%20recurso%20SOA/#caducidad-expire-time","title":"Caducidad (Expire Time)","text":"<ul> <li>Tiempo m\u00e1ximo que los datos de la zona permanecen v\u00e1lidos en el secundario si no logra conectarse con el primario.</li> <li>Ejemplo: <code>3600000</code> (1.000 horas).</li> </ul>"},{"location":"04.-DNS/05.-Zonas%20de%20autoridad/03.-Registro%20de%20recurso%20SOA/#ttl-time-to-live","title":"TTL (Time To Live)","text":"<ul> <li>Tiempo que los datos permanecen en cach\u00e9 antes de considerarse desactualizados.</li> <li>Valores t\u00edpicos: grandes, como 24 horas (<code>86400</code> segundos).</li> </ul>"},{"location":"04.-DNS/05.-Zonas%20de%20autoridad/03.-Registro%20de%20recurso%20SOA/#ejemplo-de-registro-soa","title":"Ejemplo de Registro SOA","text":"<pre><code>miempresa.com. IN SOA localhost.miempresa.com. correo_admin.miempresa.com. (\n    1998072701 ; Serial\n    86400 ; Refresh 24 hours\n    3600 ; Retry 1 hour\n    3600000 ; Expire 1000 hours\n    86400 ; Minimum TTL 24 hours\n)\n</code></pre>"},{"location":"04.-DNS/05.-Zonas%20de%20autoridad/03.-Registro%20de%20recurso%20SOA/#explicacion-del-ejemplo","title":"Explicaci\u00f3n del Ejemplo","text":"<ol> <li>Dominio: <code>miempresa.com</code> est\u00e1 controlado por el servidor localhost.miempresa.com.</li> <li>Correo del Administrador: <code>correo_admin@miempresa.com</code>.</li> <li>Actualizaci\u00f3n: Los servidores secundarios consultar\u00e1n al primario cada 24 horas.</li> <li>Reintentos: Si falla la transferencia, reintentar\u00e1 despu\u00e9s de 1 hora.</li> <li>Caducidad: Si no logra conectarse en 1.000 horas, dejar\u00e1 de responder a consultas.</li> <li>TTL: Si no hay conexi\u00f3n, descartar\u00e1 los datos de la zona tras 24 horas.</li> </ol>"},{"location":"04.-DNS/05.-Zonas%20de%20autoridad/04.-Registro%20de%20recurso%20NS/","title":"04.-Registro de recurso NS","text":"<p>Los registros NS son esenciales para establecer los servidores de nombres autorizados en una zona DNS.</p>"},{"location":"04.-DNS/05.-Zonas%20de%20autoridad/04.-Registro%20de%20recurso%20NS/#caracteristicas-de-los-registros-ns","title":"Caracter\u00edsticas de los Registros NS","text":"<ul> <li>Definici\u00f3n: Establecen los servidores de nombres autorizados para una zona.</li> <li>Requisitos:<ul> <li>Cada zona debe tener al menos un registro NS.</li> <li>Deben indicarse tanto los servidores de nombres primarios como los secundarios.</li> <li>Cada subdominio delegado debe contar con un registro NS.</li> </ul> </li> <li> <p>Formato general:</p> <p><code>FQDN_propietario IN NS FQDN_servidor</code></p> </li> </ul>"},{"location":"04.-DNS/05.-Zonas%20de%20autoridad/04.-Registro%20de%20recurso%20NS/#ejemplo-de-servidores-primario-y-secundario","title":"Ejemplo de Servidores Primario y Secundario","text":"<pre><code>mired.lan.       IN NS svdns.mired.lan.\nmired.lan.       IN NS svdnssec.mired.lan.\n</code></pre> <ul> <li><code>mired.lan.</code>: Dominio principal.</li> <li><code>svdns.mired.lan.</code>: Servidor primario.</li> <li><code>svdnssec.mired.lan.</code>: Servidor secundario.</li> </ul>"},{"location":"04.-DNS/05.-Zonas%20de%20autoridad/04.-Registro%20de%20recurso%20NS/#ejemplo-de-delegacion-de-subdominio","title":"Ejemplo de Delegaci\u00f3n de Subdominio","text":"<pre><code>dpto1.mired.lan. IN NS svdns.dpto1.mired.lan.\n</code></pre> <ul> <li>Subdominio: <code>dpto1.mired.lan.</code></li> <li>Servidor delegado: <code>svdns.dpto1.mired.lan.</code></li> </ul>"},{"location":"04.-DNS/05.-Zonas%20de%20autoridad/04.-Registro%20de%20recurso%20NS/#descripcion-de-los-campos","title":"Descripci\u00f3n de los Campos","text":"Campo Descripci\u00f3n FQDN_propietario El dominio o subdominio asociado al servidor indicado. Puede ser:- El dominio principal que define el servidor.- Un subdominio delegado.- Terminar en un punto (<code>.</code>) para indicar que se refiere al dominio ra\u00edz.- Empezar con <code>@</code> para referirse al nombre del dominio completo definido en la zona.- Estar en blanco, indicando que toma el valor definido en el registro anterior. FQDN_servidor Nombre de dominio completo (FQDN) del servidor que se define en el registro."},{"location":"04.-DNS/05.-Zonas%20de%20autoridad/05.-Registro%20de%20recurso%20A/","title":"05.-Registro de recurso A","text":"<p>El registro A (Address Record) establece una correspondencia entre un FQDN y una direcci\u00f3n IP. Es el registro m\u00e1s utilizado y numeroso en el sistema DNS.</p>"},{"location":"04.-DNS/05.-Zonas%20de%20autoridad/05.-Registro%20de%20recurso%20A/#caracteristicas","title":"Caracter\u00edsticas","text":"<ul> <li>Cada registro A identifica un nombre de m\u00e1quina, permitiendo al cliente DNS obtener su direcci\u00f3n IP.</li> <li>Si un host tiene m\u00e1s de una interfaz de red, debe tener un registro A por cada una de ellas.</li> <li>Todo nombre de host que sea resuelto por DNS debe estar especificado mediante un registro de direcci\u00f3n.</li> </ul>"},{"location":"04.-DNS/05.-Zonas%20de%20autoridad/05.-Registro%20de%20recurso%20A/#estructura-del-registro-a","title":"Estructura del Registro A","text":"<pre><code>FQDN_m\u00e1quina IN A dir_IP\n\n</code></pre>"},{"location":"04.-DNS/05.-Zonas%20de%20autoridad/05.-Registro%20de%20recurso%20A/#ejemplos","title":"Ejemplos","text":"<pre><code>pc01.mired.lan.       IN A 192.168.10.21\nwww.miempresa.com.    IN A 10.0.0.1\nftp.miempresa.com.    IN A 10.0.0.1\n</code></pre>"},{"location":"04.-DNS/05.-Zonas%20de%20autoridad/05.-Registro%20de%20recurso%20A/#explicacion","title":"Explicaci\u00f3n:","text":"<ul> <li><code>pc01.mired.lan.</code> tiene asignada la direcci\u00f3n IP <code>192.168.10.21</code>.</li> <li>Tanto <code>www.miempresa.com.</code> como <code>ftp.miempresa.com.</code> est\u00e1n asociados a la direcci\u00f3n IP <code>10.0.0.1</code>.</li> </ul>"},{"location":"04.-DNS/05.-Zonas%20de%20autoridad/05.-Registro%20de%20recurso%20A/#notas-importantes","title":"Notas Importantes","text":"<ul> <li>Cada FQDN debe tener un registro A para que pueda ser resuelto por DNS.</li> <li>En casos donde un servidor tiene varias interfaces de red, se requiere un registro A para cada direcci\u00f3n IP asociada.</li> <li>Es fundamental mantener consistencia entre los registros A y otros registros, como PTR (en zonas de resoluci\u00f3n inversa) o CNAME (alias).</li> </ul>"},{"location":"04.-DNS/05.-Zonas%20de%20autoridad/06.-Registro%20de%20Recurso%20PTR/","title":"06.-Registro de Recurso PTR","text":"<p>El registro PTR (puntero) se utiliza para la resoluci\u00f3n inversa en el sistema DNS, asignando una direcci\u00f3n IP a un nombre de dominio completo (FQDN). Es el opuesto al registro A.</p>"},{"location":"04.-DNS/05.-Zonas%20de%20autoridad/06.-Registro%20de%20Recurso%20PTR/#caracteristicas-del-registro-ptr","title":"Caracter\u00edsticas del Registro PTR","text":"<ul> <li>Este tipo de registro solo se usa en el archivo de zona de resoluci\u00f3n inversa.</li> <li>El sistema DNS utiliza un dominio especial llamado <code>in-addr.arpa</code> para definir la resoluci\u00f3n inversa.</li> <li>Los subdominios de <code>in-addr.arpa</code> tienen nombres num\u00e9ricos que corresponden a los valores decimales de las direcciones IP, pero en orden inverso.</li> </ul>"},{"location":"04.-DNS/05.-Zonas%20de%20autoridad/06.-Registro%20de%20Recurso%20PTR/#ejemplo-de-resolucion-inversa","title":"Ejemplo de Resoluci\u00f3n Inversa","text":""},{"location":"04.-DNS/05.-Zonas%20de%20autoridad/06.-Registro%20de%20Recurso%20PTR/#direccion-ip-1921681021","title":"Direcci\u00f3n IP: <code>192.168.10.21</code>","text":"<ul> <li>Su representaci\u00f3n en el dominio de resoluci\u00f3n inversa ser\u00eda:</li> </ul> <pre><code>21.10.168.192.in-addr.arpa.\n</code></pre> <ul> <li>Este dominio asignar\u00e1 la direcci\u00f3n IP al FQDN correspondiente.</li> </ul>"},{"location":"04.-DNS/05.-Zonas%20de%20autoridad/06.-Registro%20de%20Recurso%20PTR/#estructura-del-registro-ptr","title":"Estructura del Registro PTR","text":"<pre><code>FQDN_in-addr.arpa. IN PTR FQDN_m\u00e1quina\n</code></pre> <p>Ejemplo de Registro PTR</p> <pre><code>21.10.168.192.in-addr.arpa. IN PTR pc01.mired.lan.\n</code></pre> <ul> <li>IP: <code>192.168.10.21</code>.</li> <li>FQDN: <code>pc01.mired.lan.</code></li> </ul>"},{"location":"04.-DNS/05.-Zonas%20de%20autoridad/06.-Registro%20de%20Recurso%20PTR/#notas-importantes","title":"Notas Importantes","text":"<ol> <li> <p>Archivo de Zona de Resoluci\u00f3n Inversa:</p> <ul> <li>El registro PTR debe incluirse en el archivo de zona inversa correspondiente al rango de direcciones IP.</li> <li>Por ejemplo, si el rango es <code>192.168.10.x</code>, el archivo de zona inversa podr\u00eda llamarse <code>10.168.192.in-addr.arpa.zone</code>.</li> </ul> </li> <li> <p>Requerimiento por M\u00e1quina:</p> <ul> <li>Cada equipo en el dominio necesita un registro PTR en el archivo de zona inversa.</li> </ul> </li> <li> <p>Coherencia:</p> <ul> <li>Es fundamental que los registros PTR sean consistentes con los registros A en la zona directa.</li> </ul> </li> </ol>"},{"location":"04.-DNS/05.-Zonas%20de%20autoridad/07.-Registro%20de%20recursos%20CNAME/","title":"07.-Registro de recursos CNAME","text":""},{"location":"04.-DNS/05.-Zonas%20de%20autoridad/07.-Registro%20de%20recursos%20CNAME/#registro-de-nombre-canonico-cname","title":"Registro de Nombre Can\u00f3nico (CNAME)","text":"<p>El registro CNAME (Canonical Name Record) se utiliza para crear un alias de un FQDN existente. Permite asignar otro nombre a una m\u00e1quina o recurso que ya tiene un nombre de dominio completo.</p>"},{"location":"04.-DNS/05.-Zonas%20de%20autoridad/07.-Registro%20de%20recursos%20CNAME/#estructura","title":"Estructura","text":"<pre><code>FQDN_nuevo IN CNAME FQDN_existente\n</code></pre>"},{"location":"04.-DNS/05.-Zonas%20de%20autoridad/07.-Registro%20de%20recursos%20CNAME/#ejemplo","title":"Ejemplo","text":"<pre><code>mail.miempresa.com. IN CNAME www.miempresa.com.\n</code></pre> <p>En este caso:</p> <ul> <li>Alias: <code>mail.miempresa.com.</code></li> <li>FQDN existente: <code>www.miempresa.com.</code></li> <li>Ambos nombres comparten la misma direcci\u00f3n IP.</li> </ul>"},{"location":"04.-DNS/05.-Zonas%20de%20autoridad/07.-Registro%20de%20recursos%20CNAME/#registro-de-intercambio-de-correo-mx","title":"Registro de Intercambio de Correo (MX)","text":"<p>El registro MX (Mail Exchange) especifica qu\u00e9 m\u00e1quina o m\u00e1quinas son responsables de la entrega de correo en un dominio.</p>"},{"location":"04.-DNS/05.-Zonas%20de%20autoridad/07.-Registro%20de%20recursos%20CNAME/#caracteristicas","title":"Caracter\u00edsticas","text":"<ul> <li>Si un dominio tiene varios servidores de correo, se indica su prioridad mediante un valor num\u00e9rico.<ul> <li>Menor valor = Mayor prioridad.</li> <li>El correo se dirige al servidor con mayor prioridad (valor m\u00e1s bajo).</li> </ul> </li> </ul>"},{"location":"04.-DNS/05.-Zonas%20de%20autoridad/07.-Registro%20de%20recursos%20CNAME/#estructura_1","title":"Estructura","text":"<pre><code>FQDN_dominio IN MX prioridad FQDN_sv_correo\n</code></pre>"},{"location":"04.-DNS/05.-Zonas%20de%20autoridad/07.-Registro%20de%20recursos%20CNAME/#ejemplo_1","title":"Ejemplo","text":"<pre><code>mired.lan. IN MX 0 mail.mired.lan.\nmired.lan. IN MX 10 auxmail.mired.lan.\n</code></pre> <p>En este caso:</p> <ul> <li>Dominio: <code>mired.lan.</code></li> <li>Servidor principal: <code>mail.mired.lan.</code> (prioridad <code>0</code>).</li> <li>Servidor auxiliar: <code>auxmail.mired.lan.</code> (prioridad <code>10</code>).</li> </ul>"},{"location":"04.-DNS/05.-Zonas%20de%20autoridad/07.-Registro%20de%20recursos%20CNAME/#notas-importantes","title":"Notas Importantes","text":"<ol> <li> <p>CNAME:</p> <ul> <li>Un registro CNAME debe apuntar siempre a un FQDN y nunca directamente a una direcci\u00f3n IP.</li> <li>Se utiliza para proporcionar nombres alternativos (alias) a recursos existentes.</li> </ul> </li> <li> <p>MX:</p> <ul> <li>El registro MX indica a los clientes y servidores de correo c\u00f3mo enrutar los mensajes hacia el dominio.</li> <li>En caso de que el servidor principal falle, el correo se redirige al servidor con la siguiente prioridad.</li> </ul> </li> </ol>"},{"location":"04.-DNS/05.-Zonas%20de%20autoridad/08.-Registro%20de%20Recurso%20SRV/","title":"08.-Registro de Recurso SRV","text":"<p>El registro SRV especifica los servidores disponibles para un servicio o protocolo determinados, como www o ftp.</p>"},{"location":"04.-DNS/05.-Zonas%20de%20autoridad/08.-Registro%20de%20Recurso%20SRV/#estructura-del-registro-srv","title":"Estructura del Registro SRV","text":"<pre><code>servicio.protocolo.FQDN_dominio IN SRV prioridad peso puerto FQDN_servidor\n</code></pre>"},{"location":"04.-DNS/05.-Zonas%20de%20autoridad/08.-Registro%20de%20Recurso%20SRV/#descripcion-de-los-campos","title":"Descripci\u00f3n de los Campos","text":"Campo Descripci\u00f3n servicio Nombre del servicio (por ejemplo, http, ftp, telnet, etc.). protocolo Protocolo usado por el servicio (tcp, udp). FQDN_dominio Dominio en el que se define el registro. prioridad Valor num\u00e9rico similar al usado en registros MX, donde un valor menor indica mayor prioridad. peso Valor que permite un balanceo de carga, distribuyendo el trabajo equitativamente entre servidores. puerto Puerto de la m\u00e1quina donde se ofrece el servicio. FQDN_servidor Nombre de dominio completo del servidor que ofrece el servicio."},{"location":"04.-DNS/05.-Zonas%20de%20autoridad/08.-Registro%20de%20Recurso%20SRV/#ejemplo-de-registro-srv","title":"Ejemplo de Registro SRV","text":"<pre><code>http.tcp.mired.lan. IN SRV 0 0 80 www.mired.lan.\n</code></pre>"},{"location":"04.-DNS/05.-Zonas%20de%20autoridad/08.-Registro%20de%20Recurso%20SRV/#explicacion-del-ejemplo","title":"Explicaci\u00f3n del Ejemplo","text":"<ul> <li>Servicio: http</li> <li>Protocolo: tcp</li> <li>Dominio: mired.lan.</li> <li>Prioridad: 0 (m\u00e1xima prioridad).</li> <li>Peso: 0 (sin balanceo adicional).</li> <li>Puerto: 80 (puerto para el servicio HTTP).</li> <li>Servidor: www.mired.lan.</li> </ul> <p>Este registro indica que el servicio HTTP en el dominio <code>mired.lan.</code> est\u00e1 disponible en el servidor <code>www.mired.lan.</code> a trav\u00e9s del puerto 80.</p>"},{"location":"04.-DNS/05.-Zonas%20de%20autoridad/08.-Registro%20de%20Recurso%20SRV/#notas-importantes","title":"Notas Importantes","text":"<ul> <li> <p>Prioridad</p> <ul> <li>Similar al registro MX, los valores m\u00e1s bajos indican mayor prioridad. Se utilizar\u00e1 el servidor con menor prioridad, salvo que est\u00e9 inaccesible.</li> </ul> </li> <li> <p>Peso</p> <ul> <li>Permite el balanceo de carga entre servidores con la misma prioridad. Un valor mayor indica mayor probabilidad de que un servidor sea seleccionado.</li> </ul> </li> <li> <p>Puerto</p> <ul> <li>Especifica el puerto donde el servicio est\u00e1 disponible (como 80 para HTTP o 443 para HTTPS).</li> </ul> </li> <li> <p>Compatibilidad</p> <ul> <li>Este registro es \u00fatil para protocolos y servicios que necesitan localizar din\u00e1micamente servidores en un dominio.</li> </ul> </li> </ul>"},{"location":"04.-DNS/06.-Ejemplos/01.-Ejemplo%20de%20Fichero%20de%20Configuraci%C3%B3n%20DNS/","title":"01.-Ejemplo de Fichero de Configuraci\u00f3n DNS","text":"<p>Este es un ejemplo de configuraci\u00f3n para un dominio DNS <code>mired.lan</code> almacenado en el archivo <code>/etc/bind/db.mired.lan</code>.</p>"},{"location":"04.-DNS/06.-Ejemplos/01.-Ejemplo%20de%20Fichero%20de%20Configuraci%C3%B3n%20DNS/#contenido-del-fichero","title":"Contenido del Fichero","text":"<pre><code>; Fichero de Configuraci\u00f3n\n; Datos autorizados para mired.lan\n\nmired.lan. IN SOA servidor.mired.lan. correo_admin.mired.lan. (\n    2009112801 ; N\u00famero de serie\n    3H         ; Refrescar cada 3 horas\n    15M        ; Reintentos cada 15 minutos\n    1W         ; Caducidad 1 semana\n    1D         ; TTL por defecto 1 d\u00eda\n)\n\n; Servidores de correo\nmired.lan. IN MX mail.mired.lan.\n\n; Servidores de nombres\nmired.lan. IN NS dns.mired.lan.\nmired.lan. IN NS dns2.mired.lan.\n\n; Direcciones de hosts\nservidor.mired.lan. IN A 192.168.10.1\ndns.mired.lan.      IN A 192.168.10.11\ndns2.mired.lan.     IN A 192.168.10.12\nmail.mired.lan.     IN A 192.168.10.20\npc01.mired.lan.     IN A 192.168.10.101\npc02.mired.lan.     IN A 192.168.10.102\npc03.mired.lan.     IN A 192.168.10.103\n\n; Alias\nrouter.mired.lan. IN CNAME servidor.mired.lan.\nwww.mired.lan.    IN CNAME servidor.mired.lan.\n</code></pre>"},{"location":"04.-DNS/06.-Ejemplos/01.-Ejemplo%20de%20Fichero%20de%20Configuraci%C3%B3n%20DNS/#explicacion-del-contenido","title":"Explicaci\u00f3n del Contenido","text":""},{"location":"04.-DNS/06.-Ejemplos/01.-Ejemplo%20de%20Fichero%20de%20Configuraci%C3%B3n%20DNS/#zona-soa-start-of-authority","title":"Zona SOA (Start of Authority)","text":"<pre><code>mired.lan. IN SOA servidor.mired.lan. correo_admin.mired.lan. (\n    2009112801 ; N\u00famero de serie\n    3H         ; Refrescar cada 3 horas\n    15M        ; Reintentos cada 15 minutos\n    1W         ; Caducidad 1 semana\n    1D         ; TTL por defecto 1 d\u00eda\n)\n</code></pre> <ul> <li>Define el servidor de nombres autoritativo y par\u00e1metros b\u00e1sicos para la zona.</li> <li>Servidor primario: <code>servidor.mired.lan.</code></li> <li>Correo del administrador: <code>correo_admin@mired.lan.</code></li> </ul>"},{"location":"04.-DNS/06.-Ejemplos/01.-Ejemplo%20de%20Fichero%20de%20Configuraci%C3%B3n%20DNS/#servidores-de-correo-mx","title":"Servidores de Correo (MX)","text":"<pre><code>mired.lan. IN MX mail.mired.lan.\n</code></pre> <ul> <li>Servidor de correo: <code>mail.mired.lan.</code></li> </ul>"},{"location":"04.-DNS/06.-Ejemplos/01.-Ejemplo%20de%20Fichero%20de%20Configuraci%C3%B3n%20DNS/#servidores-de-nombres-ns","title":"Servidores de Nombres (NS)","text":"<ul> <li><code>mired.lan. IN NS dns.mired.lan.</code></li> <li><code>mired.lan. IN NS dns2.mired.lan.</code></li> </ul>"},{"location":"04.-DNS/06.-Ejemplos/01.-Ejemplo%20de%20Fichero%20de%20Configuraci%C3%B3n%20DNS/#servidores-dns-primario-y-secundario","title":"Servidores DNS primario y secundario:","text":"<ul> <li><code>dns.mired.lan</code></li> <li><code>dns2.mired.lan</code></li> </ul>"},{"location":"04.-DNS/06.-Ejemplos/01.-Ejemplo%20de%20Fichero%20de%20Configuraci%C3%B3n%20DNS/#direcciones-de-hosts-a","title":"Direcciones de Hosts (A)","text":"<pre><code>servidor.mired.lan. IN A 192.168.10.1\ndns.mired.lan.      IN A 192.168.10.11\ndns2.mired.lan.     IN A 192.168.10.12\nmail.mired.lan.     IN A 192.168.10.20\npc01.mired.lan.     IN A 192.168.10.101\npc02.mired.lan.     IN A 192.168.10.102\npc03.mired.lan.     IN A 192.168.10.103\n</code></pre> <ul> <li>Asigna direcciones IP a cada host del dominio.</li> </ul>"},{"location":"04.-DNS/06.-Ejemplos/01.-Ejemplo%20de%20Fichero%20de%20Configuraci%C3%B3n%20DNS/#alias-cname","title":"Alias (CNAME)","text":"<pre><code>router.mired.lan. IN CNAME servidor.mired.lan.\nwww.mired.lan.    IN CNAME servidor.mired.lan.\n</code></pre> <ul> <li>Alias:<ul> <li><code>router.mired.lan.</code> y <code>www.mired.lan.</code> apuntan a <code>servidor.mired.lan.</code></li> </ul> </li> </ul>"},{"location":"04.-DNS/06.-Ejemplos/01.-Ejemplo%20de%20Fichero%20de%20Configuraci%C3%B3n%20DNS/#comprobacion-del-fichero","title":"Comprobaci\u00f3n del Fichero","text":"<p>Verifica la configuraci\u00f3n con las siguientes herramientas:</p> <ul> <li>Verificar el archivo de configuraci\u00f3n:</li> </ul> <pre><code>named-checkconf\n</code></pre> <ul> <li>Verificar el archivo de zona:</li> </ul> <pre><code>named-checkzone mired.lan /etc/bind/db.mired.lan\n</code></pre>"},{"location":"04.-DNS/06.-Ejemplos/01.-Ejemplo%20de%20Fichero%20de%20Configuraci%C3%B3n%20DNS/#repeticiones-de-dominio","title":"Repeticiones de dominio","text":""},{"location":"04.-DNS/06.-Ejemplos/01.-Ejemplo%20de%20Fichero%20de%20Configuraci%C3%B3n%20DNS/#optimizacion-de-archivos-de-zona-dns-con-origin-y","title":"Optimizaci\u00f3n de Archivos de Zona DNS con <code>$ORIGIN</code> y <code>@</code>","text":"<ul> <li>No es habitual repetir m\u00faltiples veces el nombre del dominio, como <code>mired.lan.</code>, en un archivo de zona DNS.</li> <li>Para evitar esta repetici\u00f3n, se puede usar la directiva <code>$ORIGIN</code> al principio del archivo:</li> </ul> <pre><code>$ORIGIN mired.lan.\n</code></pre> <ul> <li>Con esta directiva, cualquier nombre que no termine en un punto (.) tendr\u00e1 autom\u00e1ticamente .mired.lan. a\u00f1adido al final para formar el FQDN.</li> </ul>"},{"location":"04.-DNS/06.-Ejemplos/01.-Ejemplo%20de%20Fichero%20de%20Configuraci%C3%B3n%20DNS/#uso-del-simbolo","title":"Uso del S\u00edmbolo @","text":"<ul> <li>El s\u00edmbolo @ hace referencia al nombre de la zona (como <code>mired.lan.</code>).</li> <li>Este valor se toma directamente de la configuraci\u00f3n del servidor DNS.</li> </ul>"},{"location":"04.-DNS/06.-Ejemplos/01.-Ejemplo%20de%20Fichero%20de%20Configuraci%C3%B3n%20DNS/#ventajas-de-origin-y","title":"Ventajas de <code>$ORIGIN</code> y <code>@</code>:","text":"<ul> <li>Menos repetici\u00f3n: Simplifica la escritura del archivo de zona.</li> <li>Mayor claridad: Hace que el archivo sea m\u00e1s legible y f\u00e1cil de mantener.</li> <li>Estandarizaci\u00f3n: Permite estructurar el archivo de forma consistente.</li> </ul>"},{"location":"04.-DNS/06.-Ejemplos/01.-Ejemplo%20de%20Fichero%20de%20Configuraci%C3%B3n%20DNS/#archivo-modificado","title":"Archivo modificado","text":"<pre><code>$ORIGIN mired.lan.   ; Se a\u00f1ade autom\u00e1ticamente a nombres no terminados en punto.\n$TTL 86400           ; TTL por defecto: 1 d\u00eda (1d o 24h).\n\n@ IN SOA servidor.mired.lan. correo_admin.mired.lan. (\n    2009112801       ; N\u00famero de serie\n    3H               ; Actualizaci\u00f3n: 3 horas\n    15M              ; Reintentos: 15 minutos\n    1W               ; Caducidad: 1 semana\n    1D               ; TTL: 1 d\u00eda\n)\n\n; Servidores de nombres\n    IN NS dns.mired.lan.\n    IN NS dns2.mired.lan.\n\n; Servidor de correo\n    IN MX 10 mail.mired.lan.\n\n; Direcciones de hosts\nservidor IN A 192.168.10.1\ndns      IN A 192.168.10.11\ndns2     IN A 192.168.10.12\nmail     IN A 192.168.10.20\npc01     IN A 192.168.10.101\npc02     IN A 192.168.10.102\npc03     IN A 192.168.10.103\n\n; Alias\nrouter   IN CNAME servidor.mired.lan.\nwww      IN CNAME servidor.mired.lan.\n</code></pre>"},{"location":"04.-DNS/06.-Ejemplos/01.-Ejemplo%20de%20Fichero%20de%20Configuraci%C3%B3n%20DNS/#explicacion","title":"Explicaci\u00f3n","text":"<ol> <li> <p>$ORIGIN:</p> <ul> <li>Define el dominio base (<code>mired.lan.</code>). Todos los nombres que no terminan con un punto (<code>.</code>) ser\u00e1n completados autom\u00e1ticamente con este dominio.</li> <li>Ejemplo: <code>servidor</code> ser\u00e1 interpretado como <code>servidor.mired.lan.</code>.</li> </ul> </li> <li> <p>$TTL:</p> <ul> <li>Define el tiempo de vida por defecto para todos los registros en el archivo: 86400 segundos (1 d\u00eda).</li> </ul> </li> <li> <p>Registros:</p> <ul> <li>SOA: Define el servidor principal y par\u00e1metros de la zona.</li> <li>NS: Indica los servidores de nombres autoritativos para la zona (<code>dns.mired.lan.</code> y <code>dns2.mired.lan.</code>).</li> <li>MX: Especifica el servidor de correo (<code>mail.mired.lan.</code>).</li> <li>A: Asigna direcciones IP a los hosts.</li> <li>CNAME: Define alias para otros FQDN.</li> </ul> </li> </ol>"},{"location":"04.-DNS/06.-Ejemplos/02.-Ejemplo%20de%20Archivo%20de%20Zona%20Inversa/","title":"02.-Ejemplo de Archivo de Zona Inversa","text":"<p>Los clientes DNS pueden realizar preguntas inversas, es decir, obtener el nombre de dominio asociado a una direcci\u00f3n IP dada.</p>"},{"location":"04.-DNS/06.-Ejemplos/02.-Ejemplo%20de%20Archivo%20de%20Zona%20Inversa/#caracteristicas","title":"Caracter\u00edsticas","text":"<ul> <li>Para manejar estas consultas, se utiliza un dominio especial llamado <code>in-addr.arpa</code>.</li> <li>Cuando un cliente desea conocer el nombre de dominio asociado a la direcci\u00f3n IP <code>w.x.y.z</code>, realiza una consulta inversa a <code>z.y.x.w.in-addr.arpa</code>.</li> <li>La inversi\u00f3n de los bytes es necesaria porque:<ul> <li>Los nombres de dominio son m\u00e1s gen\u00e9ricos hacia la derecha.</li> <li>Las direcciones IP son m\u00e1s gen\u00e9ricas hacia la izquierda.</li> </ul> </li> </ul>"},{"location":"04.-DNS/06.-Ejemplos/02.-Ejemplo%20de%20Archivo%20de%20Zona%20Inversa/#ejemplo-de-archivo-de-zona-inversa-etcbinddb10168192","title":"Ejemplo de Archivo de Zona Inversa (<code>/etc/bind/db.10.168.192</code>)","text":"<pre><code>$ORIGIN 10.168.192.in-addr.arpa.\n$TTL 86400           ; TTL por defecto: 1 d\u00eda\n\n@ IN SOA servidor.mired.lan. correo_admin.mired.lan. (\n    2009112801       ; N\u00famero de serie\n    3H               ; Actualizaci\u00f3n: 3 horas\n    15M              ; Reintentos: 15 minutos\n    1W               ; Caducidad: 1 semana\n    1D               ; TTL por defecto\n)\n\n; Servidores de nombres\n@   IN NS dns.mired.lan.\n@   IN NS dns2.mired.lan.\n\n; Registros PTR\n1    IN PTR servidor.mired.lan.\n1    IN PTR router.mired.lan.\n1    IN PTR www.mired.lan.\n11   IN PTR dns.mired.lan.\n12   IN PTR dns2.mired.lan.\n20   IN PTR mail.mired.lan.\n101  IN PTR pc01.mired.lan.\n102  IN PTR pc02.mired.lan.\n103  IN PTR pc03.mired.lan.\n</code></pre>"},{"location":"04.-DNS/06.-Ejemplos/02.-Ejemplo%20de%20Archivo%20de%20Zona%20Inversa/#explicacion-del-archivo","title":"Explicaci\u00f3n del Archivo","text":"<ol> <li> <p>$ORIGIN:</p> <ul> <li>Define la base del dominio inverso: <code>10.168.192.in-addr.arpa.</code></li> <li>Los registros que no terminan en punto (<code>.</code>) se completan autom\u00e1ticamente con este dominio.</li> </ul> </li> <li> <p>SOA (Start of Authority):</p> <ul> <li>Define el servidor principal de la zona y los par\u00e1metros b\u00e1sicos de configuraci\u00f3n.</li> </ul> </li> <li> <p>Servidores de nombres (NS):</p> <ul> <li><code>dns.mired.lan.</code> y <code>dns2.mired.lan.</code> son los servidores DNS autoritativos para la zona.</li> </ul> </li> <li> <p>Registros PTR:</p> <ul> <li>Relacionan direcciones IP con nombres de dominio completos (FQDN).</li> <li>Ejemplo:<ul> <li>La IP <code>192.168.10.1</code> (<code>1.10.168.192.in-addr.arpa.</code>) apunta a <code>servidor.mired.lan.</code>.</li> <li>La IP <code>192.168.10.101</code> (<code>101.10.168.192.in-addr.arpa.</code>) apunta a <code>pc01.mired.lan.</code>.</li> </ul> </li> </ul> </li> </ol>"},{"location":"04.-DNS/06.-Ejemplos/02.-Ejemplo%20de%20Archivo%20de%20Zona%20Inversa/#validacion-del-archivo","title":"Validaci\u00f3n del Archivo","text":"<p>Verifica el archivo de zona con las herramientas de BIND:</p> <ol> <li> <p>Verificar el archivo de configuraci\u00f3n general:</p> <p><code>named-checkconf</code></p> </li> <li> <p>Verificar el archivo de zona inversa:</p> <p><code>named-checkzone 10.168.192.in-addr.arpa /etc/bind/db.10.168.192</code></p> </li> </ol>"},{"location":"04.-DNS/06.-Ejemplos/03.-Peque%C3%B1o%20ejemplo%20completo/01.-Archivo%20ejemplo%20de%20configuraci%C3%B3n%20principal%20%60named.conf%60/","title":"01.-Archivo ejemplo de configuraci\u00f3n principal `named.conf`","text":"<ul> <li>Ubicaci\u00f3n predeterminada: <code>/etc/named.conf</code> o <code>/etc/bind/named.conf</code> (dependiendo de la distribuci\u00f3n).</li> <li>Este archivo es el principal para la configuraci\u00f3n del servidor BIND y contiene la definici\u00f3n de las zonas, opciones generales y configuraciones avanzadas.</li> <li>Si est\u00e1s usando configuraciones personalizadas, puedes especificar en el archivo <code>named.conf</code> una ruta distinta para los archivos de zona mediante la directiva <code>file</code>.</li> </ul> <pre><code>options {\n    directory \"/var/named\"; # Ruta donde se almacenan los archivos de zona.\n    allow-query { any; };   # Permitir consultas desde cualquier lugar.\n    recursion no;           # No permitir consultas recursivas (solo autoritativo).\n};\n\nzone \"iesromerovargas.com\" {\n    type master;            # Este servidor tiene autoridad sobre la zona.\n    file \"iesromerovargas.com.zone\"; # Archivo de zona.\n};\n\nzone \"0.168.192.in-addr.arpa\" {\n    type master;            # Autoridad para las consultas inversas.\n    file \"iesromerovargas.com.rev\"; # Archivo de zona inversa.\n};\n</code></pre> <ul> <li>Para configuracones personalizadas</li> </ul> <pre><code>zone \"iesromerovargas.com\" {\n    type master;\n    file \"/custom/path/iesromerovargas.com.zone\";\n};\n</code></pre>"},{"location":"04.-DNS/06.-Ejemplos/03.-Peque%C3%B1o%20ejemplo%20completo/02.-Archivo%20ejemplo%20de%20zona%20directa%20%60iesromerovargas.com.zone%60/","title":"02.-Archivo ejemplo de zona directa `iesromerovargas.com.zone`","text":"<ul> <li>Ubicaci\u00f3n predeterminada: <code>/var/named/iesromerovargas.com.zone</code> (CentOS/RHEL) o <code>/etc/bind/db.iesromerovargas.com</code> (Debian/Ubuntu).</li> <li>Este archivo almacena la informaci\u00f3n de resoluci\u00f3n directa (nombre de dominio \u2192 direcci\u00f3n IP).</li> </ul> <pre><code>$TTL 86400           ; Tiempo de vida de los registros (1 d\u00eda).\n@   IN  SOA ns1.iesromerovargas.com. admin.iesromerovargas.com. (\n        2024111901  ; N\u00famero de serie (formato AAAAMMDDXX).\n        3600        ; Refrescar (1 hora).\n        1800        ; Reintentar (30 minutos).\n        1209600     ; Expirar (2 semanas).\n        86400       ; TTL negativo (1 d\u00eda).\n)\n    IN  NS      ns1.iesromerovargas.com. ; Servidor DNS primario.\n    IN  NS      ns2.iesromerovargas.com. ; Servidor DNS secundario.\n\nns1 IN  A       192.168.0.1              ; Direcci\u00f3n IP del servidor primario.\nns2 IN  A       192.168.0.2              ; Direcci\u00f3n IP del servidor secundario.\n\nwww IN  A       192.168.0.10             ; Direcci\u00f3n IP del servidor web.\nmail IN  A      192.168.0.20             ; Direcci\u00f3n IP del servidor de correo.\n@   IN  MX 10   mail.iesromerovargas.com. ; Prioridad 10 para el servidor de correo.\n</code></pre>"},{"location":"04.-DNS/06.-Ejemplos/03.-Peque%C3%B1o%20ejemplo%20completo/03.-Archivo%20ejemplo%20de%20zona%20inversa%20%20%60iesromerovargas.com.rev%60/","title":"03.-Archivo ejemplo de zona inversa  `iesromerovargas.com.rev`","text":"<ul> <li>Ubicaci\u00f3n predeterminada: <code>/var/named/iesromerovargas.com.rev</code> (CentOS/RHEL) o <code>/etc/bind/db.192.168.0</code> (Debian/Ubuntu).</li> <li>Este archivo almacena la informaci\u00f3n de resoluci\u00f3n inversa (direcci\u00f3n IP \u2192 nombre de dominio).</li> </ul> <pre><code>$TTL 86400           ; Tiempo de vida de los registros (1 d\u00eda).\n@   IN  SOA ns1.iesromerovargas.com. admin.iesromerovargas.com. (\n        2024111901  ; N\u00famero de serie (formato AAAAMMDDXX).\n        3600        ; Refrescar (1 hora).\n        1800        ; Reintentar (30 minutos).\n        1209600     ; Expirar (2 semanas).\n        86400       ; TTL negativo (1 d\u00eda).\n)\n    IN  NS      ns1.iesromerovargas.com. ; Servidor DNS primario.\n    IN  NS      ns2.iesromerovargas.com. ; Servidor DNS secundario.\n\n1   IN  PTR     ns1.iesromerovargas.com. ; Resoluci\u00f3n inversa para ns1.\n2   IN  PTR     ns2.iesromerovargas.com. ; Resoluci\u00f3n inversa para ns2.\n10  IN  PTR     www.iesromerovargas.com. ; Resoluci\u00f3n inversa para www.\n20  IN  PTR     mail.iesromerovargas.com.; Resoluci\u00f3n inversa para mail.\n</code></pre>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/01.-Archivos%20de%20Zona%20DNS/","title":"01.-Archivos de Zona DNS","text":"<p>Comenta cada l\u00ednea de los siguientes archivos de zona.</p>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/01.-Archivos%20de%20Zona%20DNS/#archivo-de-zona-directa","title":"Archivo de Zona Directa","text":"<pre><code>; Start of Authority (SOA) record\nfoo.com. IN SOA dns.foo.com. dnsowner.foo.com. ( ; \n    19960105 ; \n    10800 ; \n    3600 ; \n    604800 ; \n    86400 ) ; \n\n; Name Server (NS) records.\nfoo.com.    IN  NS  dns.foo.com. ;\n    IN  NS  dns2.foo.com. ;\n\n; Mail Exchange (MX) records.\nfoo.com.    IN  MX  20  mail.foo.com. ;\n    IN  MX  40  mail2.foo.com. ;\n\n; Address (A) records.\nlocalhost.foo.com.  IN  A   127.0.0.1 ;\nrouter.foo.com. IN  A   192.168.210.1 ;\ndns.foo.com.    IN  A   192.168.210.2 ;\nmail2.foo.com.  IN  A   192.168.210.3 ;\ndns2.foo.com.   IN  A   192.168.210.3 ;\nmail.foo.com.   IN  A   192.168.210.4 ;\npc1.foo.com.    IN  A   192.168.210.5 ;\npc2.foo.com.    IN  A   192.168.210.6 ;\n\n; Aliases in Canonical Name (CNAME) records.\nftp.foo.com.    IN  CNAME    mail2.foo.com. ;\nwww.foo.com.    IN  CNAME   mail2.foo.com. ;\nsysman.foo.com.     IN  CNAME   pc2.foo.com. ;\n\n</code></pre>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/01.-Archivos%20de%20Zona%20DNS/#archivo-de-zona-inversa","title":"Archivo de Zona Inversa","text":"<pre><code>$ORIGIN 1.0.10.in-addr.arpa\n$TTL 86400\n@ IN SOA dns1.example.com. hostmaster.example.com. (\n    2001062501 ;    \n    21600 ; \n    3600 ; \n    604800 ; \n    86400 ) ; \n\n    IN  NS  dns1.example.com. ;\n    IN  NS  dns2.example.com. ;\n\n20  IN  PTR alice.example.com. ;\n21  IN  PTR betty.example.com. ;\n22  IN  PTR charlie.example.com. ;\n23  IN  PTR doug.example.com. ;\n24  IN  PTR ernest.example.com. ;\n25  IN  PTR fanny.example.com.  ;\n\n</code></pre>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/01.-Archivos%20de%20Zona%20DNS/#instrucciones","title":"Instrucciones:","text":"<ol> <li>Analiza cada l\u00ednea del archivo y comenta qu\u00e9 representa o para qu\u00e9 sirve.</li> <li>Usa los conocimientos sobre DNS, registros SOA, NS, MX, A, y PTR para explicar el prop\u00f3sito de cada registro.</li> </ol>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/02.-Consultas%20DNS/","title":"02.-Consultas DNS","text":""},{"location":"04.-DNS/08.-Pr%C3%A1cticas/02.-Consultas%20DNS/#dig","title":"<code>dig</code>","text":"<p>dig es una herramienta que permite hacer consultas a un servidor DNS desde la l\u00ednea de comandos, es el sustituto de los programas <code>nslookup</code> y <code>host</code>. La sintaxis es:</p> <pre><code>dig [-t tipo de registro] [@servidor DNS] Consulta DNS\n</code></pre> <p>El tipo de registro por defecto es ADDRESS y el servidor DNS por defecto es el definido en <code>/etc/resolv.conf</code>.</p> <p>Nota: si no funciona el comando dig, instalar el paquete <code>dnsutils</code> que lo incluye.</p>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/02.-Consultas%20DNS/#nslookup","title":"<code>nslookup</code>","text":"<p>Como realizar consultas DNS con el nslookup de Windows</p> <p>Utilizando el comando dig/nslookup realiza las siguientes consultas al servidor DNS:</p> <ul> <li>Preguntas a registros del tipo A: Obt\u00e9n la direcci\u00f3n ip de los siguientes dominios:</li> </ul> <pre><code>    www.iesromerovargas.com\n    www.us.es\n    es.wikipedia.org\n    www.ubuntu.com\n</code></pre> <ul> <li>Preguntas a registros tipo NS: Obt\u00e9n la direcci\u00f3n y los servidor DNS que corresponden a los siguientes dominios:</li> </ul> <pre><code>dominio ra\u00edz\ncom\norg\nes\nus.es\nwikipedia.org\nubuntu.com\n</code></pre> <ul> <li>Preguntas a registros MX: Obt\u00e9n el nombre y la direcci\u00f3n del ordenador al que se mandan los correos que se env\u00edan a los siguientes dominios:</li> </ul> <pre><code>iesromerovargas.com\nus.es\nwikipedia.org\nubuntu.com\n</code></pre> <ul> <li>\u00bfQu\u00e9 tipo de registro es el que resuelve las siguientes direcciones:</li> </ul> <pre><code>www.josedomingo.org\ninformatica.gonzalonazareno.org\n</code></pre> <p>Indica el nombre can\u00f3nico de las m\u00e1quinas a las que corresponden.</p>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/03.-Archivos%20de%20Zona%20DNS/","title":"03.-Archivos de Zona DNS","text":""},{"location":"04.-DNS/08.-Pr%C3%A1cticas/03.-Archivos%20de%20Zona%20DNS/#instrucciones","title":"Instrucciones","text":"<p>Crea los archivos de zona directa e inversa para la siguiente red.</p> <ol> <li>Primera parte: No uses <code>$ORIGIN</code>, <code>@</code> ni huecos en blanco. Usa registros CNAME siempre que sea posible.</li> <li>Segunda parte: Repite el ejercicio utilizando <code>$ORIGIN</code>, <code>$TTL</code>, <code>@</code> y huecos en blanco para simplificar los archivos.</li> </ol>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/03.-Archivos%20de%20Zona%20DNS/#especificaciones-de-la-red","title":"Especificaciones de la Red","text":"<ul> <li> <p>Dominio: <code>prueba.local</code></p> </li> <li> <p>Ubicaci\u00f3n del archivo de zona: En el ordenador <code>server.prueba.local</code></p> </li> <li> <p>Servidores DNS:</p> <ul> <li>Primario: <code>ns1.prueba.local</code></li> <li>Secundario: <code>ns2.prueba.local</code></li> <li>Actualizaci\u00f3n: Cada d\u00eda.</li> <li>Reintento: Si fracasa, reintenta cada hora.</li> <li>Caducidad: La informaci\u00f3n tiene validez durante tres d\u00edas.</li> <li>Registros en cach\u00e9: Validez de 12 horas.</li> <li>Servidor de correo: <code>mail.prueba.local</code></li> </ul> </li> </ul>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/03.-Archivos%20de%20Zona%20DNS/#listado-de-nombres-e-ips","title":"Listado de Nombres e IPs","text":"<ol> <li>IP: 192.168.1.1<ul> <li><code>server.prueba.local</code></li> <li><code>dns1.prueba.local</code></li> <li><code>mail.prueba.local</code></li> <li><code>www.prueba.local</code></li> <li><code>ftp.prueba.local</code></li> </ul> </li> <li>IP: 192.168.1.2<ul> <li><code>aux.prueba.local</code></li> <li><code>dns2.prueba.local</code></li> <li><code>www2.prueba.local</code></li> </ul> </li> <li>IP: 192.168.1.10x (x de 1 a 7)<ul> <li><code>pc0x.prueba.local</code> (donde <code>x</code> es el n\u00famero del equipo, de 1 a 7).</li> </ul> </li> </ol>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/03.-Archivos%20de%20Zona%20DNS/#ejercicio","title":"Ejercicio","text":""},{"location":"04.-DNS/08.-Pr%C3%A1cticas/03.-Archivos%20de%20Zona%20DNS/#primera-parte-sin-origin-ni-huecos-en-blanco","title":"Primera Parte: Sin <code>$ORIGIN</code>, <code>@</code> ni Huecos en Blanco","text":"<ol> <li>Zona Directa:<ul> <li>Define los registros A para los nombres e IPs proporcionados.</li> <li>Utiliza registros CNAME siempre que sea posible para alias.</li> </ul> </li> <li>Zona Inversa:<ul> <li>Crea los registros PTR para cada IP, resolviendo a sus respectivos nombres.</li> </ul> </li> </ol>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/03.-Archivos%20de%20Zona%20DNS/#segunda-parte-usando-origin-ttl-y-huecos-en-blanco","title":"Segunda Parte: Usando <code>$ORIGIN</code>, <code>$TTL</code>, <code>@</code> y Huecos en Blanco","text":"<ol> <li>Zona Directa:<ul> <li>Simplifica la configuraci\u00f3n utilizando <code>$ORIGIN</code> para el dominio base, <code>$TTL</code> para el tiempo de validez, y <code>@</code> para representar el dominio ra\u00edz.</li> <li> <ol> <li>Zona Inversa:</li> </ol> </li> </ul> </li> <li>Repite el archivo de zona inversa optimizando con <code>$ORIGIN</code> y huecos en blanco para evitar repeticiones innecesarias.</li> </ol>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/03.-Archivos%20de%20Zona%20DNS/#resultado-esperado","title":"Resultado Esperado","text":"<ul> <li> <p>Archivos de Zona Directa:</p> <ul> <li>Sin <code>$ORIGIN</code>, registros completamente expl\u00edcitos.</li> <li>Con <code>$ORIGIN</code>, registros simplificados.</li> </ul> </li> <li> <p>Archivos de Zona Inversa:</p> </li> <li>Sin <code>$ORIGIN</code>, registros expl\u00edcitos para cada direcci\u00f3n IP.</li> <li>Con <code>$ORIGIN</code>, simplificaci\u00f3n en los registros PTR.</li> </ul> <p>Entrega los archivos de zona en un formato limpio y validado. Si necesitas herramientas para verificar, utiliza:</p> <pre><code>named-checkconf\nnamed-checkzone\n</code></pre>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/04.-Uso%20de%20comandos%20DNS/","title":"04.-Uso de comandos DNS","text":"<p>Para realizar estos ejercicios puedes usar los comandos <code>dig</code>, <code>nslookup</code> o <code>host</code>, ya que tienen funcionalidades similares.</p> <ul> <li>Instrucciones:<ul> <li>Muestra el comando ejecutado para cada ejercicio.</li> <li>Acompa\u00f1a cada comando con una verificaci\u00f3n del resultado obtenido. Puedes incluir una imagen del terminal o el texto del resultado.</li> </ul> </li> </ul>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/04.-Uso%20de%20comandos%20DNS/#actividades","title":"Actividades","text":"<ol> <li>Realiza un tutorial completo de cada uno de los comandos que has utilizado.<ul> <li>Describe c\u00f3mo funcionan <code>dig</code>, <code>nslookup</code> y <code>host</code>.</li> <li>Incluye ejemplos pr\u00e1cticos y par\u00e1metros importantes.</li> </ul> </li> <li>Determina la direcci\u00f3n IP de la m\u00e1quina <code>www.mec.es</code>.</li> <li>Averigua qu\u00e9 m\u00e1quina tiene asignada la direcci\u00f3n IP <code>193.110.128.200</code>.</li> <li>Con relaci\u00f3n al dominio <code>abc.es</code>:<ul> <li>Averigua el nombre y la direcci\u00f3n IP de los servidores DNS.</li> <li>Identifica cu\u00e1l es el servidor primario y cu\u00e1les son secundarios.</li> </ul> </li> <li>Obt\u00e9n el registro SOA del dominio <code>abc.es</code>:<ul> <li>Haz la consulta al DNS local de la m\u00e1quina.</li> <li>Haz la consulta directamente al servidor primario del dominio <code>abc.es</code>.</li> <li>Comprueba y analiza las diferencias: \u00bfcu\u00e1l es informaci\u00f3n autorizada y cu\u00e1l no?</li> </ul> </li> <li>Si tuvieras un problema con el DNS de <code>abc.es</code>:<ol> <li>\u00bfA qu\u00e9 direcci\u00f3n de correo electr\u00f3nico deber\u00edas escribir al administrador?</li> </ol> </li> <li>Determina el nombre y la direcci\u00f3n IP del servidor de orreo mencionado en el punto anterior.</li> <li>Consulta el tiempo de almacenamiento en cach\u00e9 (TTL) para la direcci\u00f3n IP de <code>www.vanguardia.es</code>:<ul> <li>Pregunta varias veces a tu DNS local y observa los cambios en el TTL.</li> </ul> </li> <li>Repite la consulta anterior a un servidor DNS con la direcci\u00f3n IP <code>163.117.139.253</code>:<ul> <li>Verifica en el paquete de respuesta que este servidor no acepta consultas en modo recursivo.</li> </ul> </li> <li>Averigua cu\u00e1ntas m\u00e1quinas est\u00e1n realizando balanceo de carga para el servidor web <code>www.elmundo.es</code>:<ul> <li>\u00bfObtienes siempre las mismas m\u00e1quinas? \u00bfEn el mismo orden?</li> </ul> </li> <li>Consulta iterativamente para obtener la direcci\u00f3n IP de <code>www.timesonline.co.uk</code>:<ul> <li>Describe los pasos que seguiste.</li> </ul> </li> <li>Realiza lo mismo que en el ejercicio anterior usando la opci\u00f3n <code>+trace</code> de <code>dig</code>:<ul> <li>Compara los resultados obtenidos.</li> </ul> </li> <li>Obt\u00e9n informaci\u00f3n sobre los servidores de correo del dominio <code>it.uc3m.es</code>:<ul> <li>Determina el nombre y la direcci\u00f3n IP de las m\u00e1quinas.</li> </ul> </li> <li>Obt\u00e9n todos los registros de recurso de la zona <code>lab.it.uc3m.es</code>.</li> <li>Obt\u00e9n la direcci\u00f3n IP de <code>lavadora.gonzalonazareno.org</code>.</li> <li>Averigua a qu\u00e9 equipo est\u00e1 redirigido <code>informatica.gonzalonazareno.org</code>.</li> <li>Determina los nombres de los servidores DNS del dominio <code>gonzalonazareno.org</code>.</li> <li>Averigua a qu\u00e9 equipo se env\u00edan los correos <code>@gonzalonazareno.org</code>.</li> <li>Consulta a qu\u00e9 nombre est\u00e1 apuntando la direcci\u00f3n IP <code>80.59.1.152</code>.</li> </ol>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/04.-Uso%20de%20comandos%20DNS/#entrega","title":"Entrega","text":"<ul> <li>Responde a cada punto con el comando utilizado y los resultados obtenidos.</li> <li>Incluye capturas de pantalla o el texto de los resultados para justificar tus respuestas.</li> </ul>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/05.-DNS%20con%20Ubuntu%20Server/","title":"05.-DNS con Ubuntu Server","text":""},{"location":"04.-DNS/08.-Pr%C3%A1cticas/05.-DNS%20con%20Ubuntu%20Server/#objetivo","title":"Objetivo","text":"<p>Configurar una red con servidores y clientes DNS utilizando Ubuntu Server en m\u00e1quinas virtuales. Se debe construir una red DNS funcional basada en las siguientes especificaciones.</p>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/05.-DNS%20con%20Ubuntu%20Server/#especificaciones-de-la-red","title":"Especificaciones de la Red","text":"<ol> <li>Estructura de la red:<ul> <li>Cuatro m\u00e1quinas virtuales: M1, M2, M3 y M4 (todas con Ubuntu Server). <code>bash    virt-install \\ --name plantilla-cliente-&lt;tunombre&gt; \\ --os-variant debian12 \\ --ram 1024 \\ --vcpus 1 \\ --disk path=/var/lib/libvirt/images/plantilla-cliente.qcow2,size=3 \\ --graphics none \\ --console pty,target_type=serial \\ --location 'http://deb.debian.org/debian/dists/bookworm/main/installer-amd64/' \\ --extra-args 'console=ttyS0,115200n8 serial'</code></li> <li>Conexi\u00f3n de red:<ul> <li>M1: Dos tarjetas de red, una conectada a NAT para acceso a internet y otra al segmento de red virtual.</li> <li>M2, M3 y M4: Una tarjeta de red conectada al segmento de red virtual.</li> </ul> </li> <li>Direcciones IP:<ul> <li>Autom\u00e1tica para la conexi\u00f3n NAT de M1.</li> <li>Direcciones fijas para todas las dem\u00e1s conexiones.</li> </ul> </li> </ul> </li> <li> <p>Sistema DNS:</p> <ul> <li>Dominio: <code>2asir.edu</code></li> <li>Nombres can\u00f3nicos:<ul> <li>M1: <code>ns1.2asir.edu</code></li> <li>M2: <code>ns2.2asir.edu</code></li> <li>M3: <code>pc01.2asir.edu</code></li> <li>M4: <code>pc02.2asir.edu</code></li> </ul> </li> <li>Alias:<ul> <li><code>ns1</code> tambi\u00e9n ser\u00e1 <code>www</code> y <code>servidor</code>.</li> <li><code>ns2</code> tambi\u00e9n ser\u00e1 <code>pcprof</code>.</li> </ul> </li> <li>Servidores DNS:<ul> <li><code>ns1</code>: Servidor DNS maestro.</li> <li><code>ns2</code>: Servidor DNS esclavo, que sincronizar\u00e1 con <code>ns1</code>.</li> </ul> </li> </ul> </li> <li> <p>Todas las m\u00e1quinas usar\u00e1n como servidores de nombres a <code>ns1</code> y <code>ns2</code>.</p> </li> <li>Las consultas a nombres no resueltos deben redirigirse a un servidor DNS de internet (configurable).</li> <li>Las consultas al sistema DNS montado deben ser posibles solo desde la red local.</li> </ol>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/05.-DNS%20con%20Ubuntu%20Server/#resumen-de-pasos","title":"Resumen de Pasos","text":"<ol> <li> <p>Configuraci\u00f3n de Red:</p> <ul> <li>Asigna direcciones IP est\u00e1ticas para las conexiones virtuales.</li> <li>Establece los nombres (<code>/etc/hostname</code>) y actualiza <code>/etc/hosts</code>.</li> </ul> </li> <li> <p>Instalaci\u00f3n de <code>bind9</code>:</p> <ul> <li>Instala <code>bind9</code> en <code>ns1</code> y <code>ns2</code>.</li> <li>En M2, usa conexi\u00f3n NAT temporal para descargar e instalar <code>bind9</code>.</li> </ul> </li> <li> <p>Configuraci\u00f3n del Servidor Primario (<code>ns1</code>):</p> <ol> <li>Edita <code>/etc/bind/named.conf.local</code> para definir las zonas directa e inversa. Incluye restricciones de consulta con <code>allow-query</code>.</li> <li>Edita <code>/etc/bind/named.conf.options</code> para configurar redireccionamiento de consultas no resueltas (<code>forwarders</code>).</li> <li>Valida la configuraci\u00f3n con <code>named-checkconf</code>.</li> <li>Crea archivos de base de datos para:<ul> <li>Zona directa: Define registros SOA, NS, A y CNAME.</li> <li>Zona inversa: Define registros SOA, NS y PTR.</li> </ul> </li> <li>Valida los archivos con <code>named-checkzone</code>.</li> <li>Reinicia el servicio con <code>/etc/init.d/bind9 restart</code>.</li> </ol> </li> <li> <p>Configuraci\u00f3n del Servidor Secundario (<code>ns2</code>):</p> <ol> <li>Edita <code>/etc/bind/named.conf.local</code> para definir las zonas como <code>slave</code> e incluye la IP del maestro (<code>masters</code>).</li> <li>No es necesario crear archivos de zona; se sincronizan autom\u00e1ticamente.</li> </ol> </li> <li> <p>Configuraci\u00f3n de Clientes:</p> <ul> <li>Edita <code>/etc/resolv.conf</code> en cada m\u00e1quina para configurar los servidores DNS.</li> </ul> </li> <li> <p>Pruebas del Sistema:</p> <ul> <li>Realiza consultas con <code>nslookup</code>, <code>dig</code>, y <code>ping</code> desde los clientes.</li> <li>Simula fallos deteniendo <code>ns1</code> y verifica que <code>ns2</code> responde correctamente.</li> </ul> </li> <li> <p>A\u00f1adir Nueva M\u00e1quina (<code>pc03.2asir.edu</code>):</p> <ul> <li>Indica qu\u00e9 archivos, l\u00edneas y m\u00e1quinas deben modificarse para incluir esta nueva m\u00e1quina.</li> </ul> </li> </ol>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/05.-DNS%20con%20Ubuntu%20Server/#ejemplos-de-comandos","title":"Ejemplos de Comandos","text":"<ol> <li>Validaci\u00f3n de Configuraci\u00f3n:</li> </ol> <p><code>bash    named-checkconf    named-checkzone 2asir.edu /etc/bind/db.2asir.edu</code></p> <ol> <li>Reiniciar el Servicio:</li> </ol> <p><code>bash    sudo /etc/init.d/bind9 restart</code></p> <ol> <li>Consulta desde Clientes:</li> </ol> <p><code>bash    nslookup www.2asir.edu    nslookup pc03.2asir.edu    dig pc02.2asir.edu</code></p>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/05.-DNS%20con%20Ubuntu%20Server/#capturas-requeridas","title":"Capturas Requeridas","text":"<p>Incluye las siguientes capturas como evidencia de configuraci\u00f3n y pruebas:</p> <ol> <li>Instalaci\u00f3n de <code>bind9</code> exitosa.</li> <li>Configuraci\u00f3n de <code>/etc/bind/named.conf.local</code> y <code>/etc/bind/named.conf.options</code>.</li> <li>Archivos de base de datos para zonas directa e inversa.</li> <li>Comandos de validaci\u00f3n (<code>named-checkconf</code>, <code>named-checkzone</code>).</li> <li>Reinicio del servicio DNS.</li> <li>Consultas exitosas desde clientes (<code>nslookup</code>, <code>ping</code>).</li> <li>Pruebas de sincronizaci\u00f3n y respuesta del servidor secundario tras detener <code>ns1</code>.</li> </ol>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/01.-Archivos%20de%20Zona%20DNS%28Sol%29/","title":"An\u00e1lisis de Archivos de Zona DNS","text":""},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/01.-Archivos%20de%20Zona%20DNS%28Sol%29/#archivo-de-zona-directa","title":"Archivo de Zona Directa","text":"<pre><code>; Start of Authority (SOA) record\nfoo.com. IN SOA dns.foo.com. dnsowner.foo.com. ( ; \n</code></pre> <ul> <li><code>foo.com.</code>: El dominio ra\u00edz para el archivo de zona.</li> <li><code>IN SOA</code>: Especifica el registro SOA, que indica el servidor autoritativo principal para este dominio.</li> <li><code>dns.foo.com.</code>: Nombre del servidor DNS principal del dominio.</li> <li><code>dnsowner.foo.com.</code>: Direcci\u00f3n de correo del administrador del dominio, reemplazando el primer punto por <code>@</code> (<code>dnsowner@foo.com</code>).</li> </ul> <pre><code> 19960105 ; \n</code></pre> <ul> <li><code>19960105</code>: N\u00famero de serie del archivo de zona. Usado para identificar la versi\u00f3n del archivo; incrementa con cada actualizaci\u00f3n.</li> </ul> <pre><code> 10800 ; \n</code></pre> <ul> <li><code>10800</code>: Tiempo de actualizaci\u00f3n (refresh) en segundos. Indica cada cu\u00e1nto tiempo los servidores secundarios deben consultar por cambios.</li> </ul> <pre><code> 3600 ; \n</code></pre> <ul> <li><code>3600</code>: Tiempo de reintento (retry) en segundos. Especifica cu\u00e1nto esperar antes de intentar nuevamente si la actualizaci\u00f3n falla.</li> </ul> <pre><code> 604800 ; \n</code></pre> <ul> <li><code>604800</code>: Tiempo de expiraci\u00f3n (expire) en segundos. Define cu\u00e1nto tiempo los servidores secundarios deben considerar v\u00e1lidos los datos si no pueden actualizar.</li> </ul> <pre><code> 86400 ) ; \n</code></pre> <ul> <li><code>86400</code>: Tiempo de vida (TTL) predeterminado en segundos para los registros en esta zona.</li> </ul> <pre><code>; Name Server (NS) records.\nfoo.com.    IN  NS  dns.foo.com. ;\n</code></pre> <ul> <li><code>foo.com. IN NS dns.foo.com.</code>: Registro NS que especifica que <code>dns.foo.com.</code> es un servidor de nombres para <code>foo.com.</code>.</li> </ul> <pre><code> IN NS  dns2.foo.com. ;\n</code></pre> <ul> <li><code>dns2.foo.com.</code>: Segundo servidor de nombres para proporcionar redundancia.</li> </ul> <pre><code>; Mail Exchange (MX) records.\nfoo.com.    IN  MX  20  mail.foo.com. ;\n</code></pre> <ul> <li><code>IN MX 20 mail.foo.com.</code>: Define un servidor de correo con prioridad 20 (menor prioridad = mayor preferencia).</li> </ul> <pre><code> IN MX  40  mail2.foo.com. ;\n</code></pre> <ul> <li><code>IN MX 40 mail2.foo.com.</code>: Segundo servidor de correo con prioridad m\u00e1s baja.</li> </ul> <pre><code>; Address (A) records.\nlocalhost.foo.com.  IN  A   127.0.0.1 ;\n</code></pre> <ul> <li><code>localhost.foo.com.</code>: Direcci\u00f3n local del sistema para pruebas.</li> </ul> <pre><code>router.foo.com. IN  A   192.168.210.1 ;\n</code></pre> <ul> <li><code>router.foo.com.</code>: Direcci\u00f3n IP asignada al router.</li> </ul> <pre><code>dns.foo.com.    IN  A   192.168.210.2 ;\n</code></pre> <ul> <li><code>dns.foo.com.</code>: Direcci\u00f3n IP del servidor DNS principal.</li> </ul> <pre><code>mail2.foo.com.  IN  A   192.168.210.3 ;\ndns2.foo.com.   IN  A   192.168.210.3 ;\n</code></pre> <ul> <li><code>mail2.foo.com.</code> y <code>dns2.foo.com.</code> comparten la misma direcci\u00f3n IP (un solo servidor con ambas funciones).</li> </ul> <pre><code>mail.foo.com.   IN  A   192.168.210.4 ;\n</code></pre> <ul> <li><code>mail.foo.com.</code>: Direcci\u00f3n IP del servidor de correo con prioridad alta.</li> </ul> <pre><code>pc1.foo.com.    IN  A   192.168.210.5 ;\npc2.foo.com.    IN  A   192.168.210.6 ;\n</code></pre> <ul> <li><code>pc1.foo.com.</code> y <code>pc2.foo.com.</code>: Direcciones IP asignadas a computadoras espec\u00edficas en la red.</li> </ul> <pre><code>; Aliases in Canonical Name (CNAME) records.\nftp.foo.com.    IN  CNAME    mail2.foo.com. ;\n</code></pre> <ul> <li><code>ftp.foo.com.</code>: Alias para <code>mail2.foo.com.</code>. Todas las consultas dirigidas a <code>ftp.foo.com.</code> se redirigen a <code>mail2.foo.com.</code>.</li> </ul> <pre><code>www.foo.com.    IN  CNAME   mail2.foo.com. ;\nsysman.foo.com.     IN  CNAME   pc2.foo.com. ;\n</code></pre> <ul> <li><code>www.foo.com.</code>: Alias para <code>mail2.foo.com.</code>.</li> <li><code>sysman.foo.com.</code>: Alias para <code>pc2.foo.com.</code>.</li> </ul>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/01.-Archivos%20de%20Zona%20DNS%28Sol%29/#archivo-de-zona-inversa","title":"Archivo de Zona Inversa","text":"<pre><code>$ORIGIN 1.0.10.in-addr.arpa\n</code></pre> <ul> <li><code>$ORIGIN 1.0.10.in-addr.arpa</code>: Configura el dominio para la resoluci\u00f3n inversa de direcciones IP en este bloque (<code>10.0.1.x</code>).</li> </ul> <pre><code>$TTL 86400\n</code></pre> <ul> <li><code>$TTL 86400</code>: Tiempo de vida predeterminado para los registros (1 d\u00eda).</li> </ul> <pre><code>@ IN SOA dns1.example.com. hostmaster.example.com. (\n 2001062501 ;   \n</code></pre> <ul> <li><code>@ IN SOA</code>: Registro SOA para la zona inversa.</li> <li><code>dns1.example.com.</code>: Servidor DNS principal.</li> <li><code>hostmaster.example.com.</code>: Direcci\u00f3n de correo del administrador.</li> <li><code>2001062501</code>: N\u00famero de serie del archivo de zona.</li> </ul> <pre><code> 21600 ;    \n</code></pre> <ul> <li><code>21600</code>: Intervalo de actualizaci\u00f3n (6 horas).</li> </ul> <pre><code> 3600 ; \n</code></pre> <ul> <li><code>3600</code>: Intervalo de reintento (1 hora).</li> </ul> <pre><code> 604800 ; \n</code></pre> <ul> <li><code>604800</code>: Tiempo de expiraci\u00f3n (1 semana).</li> </ul> <pre><code> 86400 ) ; \n</code></pre> <ul> <li><code>86400</code>: TTL predeterminado (1 d\u00eda).</li> </ul> <pre><code> IN NS  dns1.example.com. ;\n IN NS  dns2.example.com. ;\n</code></pre> <ul> <li>Servidores de nombres autoritativos para esta zona inversa.</li> </ul> <pre><code>20  IN  PTR alice.example.com. ;\n</code></pre> <ul> <li><code>20 IN PTR alice.example.com.</code>: Direcci\u00f3n IP <code>10.0.1.20</code> se resuelve a <code>alice.example.com.</code>.</li> </ul> <pre><code>21  IN  PTR betty.example.com. ;\n22  IN  PTR charlie.example.com. ;\n23  IN  PTR doug.example.com. ;\n24  IN  PTR ernest.example.com. ;\n25  IN  PTR fanny.example.com.  ;\n</code></pre> <ul> <li>Mapas inversos para las direcciones IP <code>10.0.1.21</code> a <code>10.0.1.25</code>.</li> </ul>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/01.-Archivos%20de%20Zona%20DNS%28Sol%29/#conclusion","title":"Conclusi\u00f3n","text":"<ul> <li>El archivo de zona directa define c\u00f3mo resolver nombres de dominio en direcciones IP (DNS directo).</li> <li>El archivo de zona inversa resuelve direcciones IP a nombres de dominio (DNS inverso). </li> <li>Ambos archivos son esenciales para una configuraci\u00f3n DNS completa.</li> </ul>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/02.-Consultas%20DNS%20%28Sol%29/","title":"02.-Consultas DNS (Sol)","text":""},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/02.-Consultas%20DNS%20%28Sol%29/#1-preguntas-a-registros-del-tipo-a","title":"1. Preguntas a registros del tipo A:","text":"Dominio Comando Resultado www.iesromerovargas.com dig A www.iesromerovargas.com 213.186.33.5 www.us.es dig A www.us.es 193.147.175.38 es.wikipedia.org dig A es.wikipedia.org 185.15.58.224 www.ubuntu.com dig A www.ubuntu.com 185.125.190.20185.125.190.21185.125.190.29"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/02.-Consultas%20DNS%20%28Sol%29/#2-preguntas-a-registros-tipo-ns","title":"2. Preguntas a registros tipo NS:","text":"Dominio Comando Servidores DNS e IP IP Dominio ra\u00edz dig NS . a.root-servers.net b.root-servers.net c.root-servers.net d.root-servers.net e.root-servers.net f.root-servers.net g.root-servers.net h.root-servers.net i.root-servers.net j.root-servers.net k.root-servers.net l.root-servers.net m.root-servers.net  198.41.0.4199.9.14.201192.33.4.12199.7.91.13192.203.230.10192.5.5.241192.112.36.4198.97.190.53192.36.148.17192.58.128.30193.0.14.129199.7.83.42202.12.27.33 com dig NS com a.gtld-servers.netb.gtld-servers.netc.gtld-servers.netd.gtld-servers.nete.gtld-servers.netf.gtld-servers.netg.gtld-servers.neth.gtld-servers.neti.gtld-servers.netj.gtld-servers.netk.gtld-servers.netl.gtld-servers.netm.gtld-servers.net 192.5.6.30192.33.14.30192.26.92.30192.31.80.30192.12.94.30192.35.51.30192.42.93.30192.54.112.30192.43.172.30192.48.79.30192.52.178.30192.41.162.30192.55.83.30 org a0.org.afilias-nst.infoa2.org.afilias-nst.infob0.org.afilias-nst.orgb2.org.afilias-nst.orgc0.org.afilias-nst.infod0.org.afilias-nst.org 199.19.56.1199.249.112.1199.19.54.1199.249.120.1199.19.53.1199.249.116.1 es dig NS es ns1.nic.esns2.nic.esns3.nic.esns4.nic.esns5.nic.esns6.nic.esns7.nic.esns8.nic.es 194.69.254.1194.69.254.2194.69.254.3194.69.254.4194.69.254.5194.69.254.6194.69.254.7194.69.254.8 us.es dig NS us.es dns2.cica.eschico.rediris.essun.rediris.esjade.us.esonix.us.esdns1.cica.es 150.214.5.84162.219.54.2199.184.182.1150.214.5.84150.214.186.69150.214.5.83 wikipedia.org dig NS wikipedia.org ns0.wikimedia.orgns1.wikimedia.orgns2.wikimedia.org 208.80.154.238208.80.153.231198.35.27.27 ubuntu.com dig NS ubuntu.com ns1.canonical.comns2.canonical.comns3.canonical.com 185.125.190.65185.125.190.6691.189.91.139"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/02.-Consultas%20DNS%20%28Sol%29/#3-preguntas-a-registros-tipo-mx","title":"3. Preguntas a registros tipo MX:","text":"Dominio Comando Resultado: Prioridad, NS e IP iesromerovargas.com dig MX iesromerovargas.com 1 aspmx.l.google.com 173.194.76.265 alt1.aspmx.l.google.com 142.250.153.265 alt2.aspmx.l.google.com 142.251.9.2710 alt3.aspmx.l.google.com 142.250.150.2710 alt4.aspmx.l.google.com 74.125.200.26 us.es dig MX us.es 10 buzon.us.es 193.147.175.80 wikipedia.org dig MX wikipedia.org 10 buzon.us.es 193.147.175.80 ubuntu.com dig MX ubuntu.com 10 mx.ubuntu.com 185.125.188.72 - 73"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/02.-Consultas%20DNS%20%28Sol%29/#4-resolucion-de-registros-canonicos-cname","title":"4. Resoluci\u00f3n de registros can\u00f3nicos (CNAME):","text":"<p>En los casos mencionados, los dominios www.josedomingo.org e informatica.gonzalonazareno.org son registros CNAME (Canonical Name) es decir, est\u00e1n configurados como alias de otro dominio. Esto significa que, en lugar de apuntar directamente a una direcci\u00f3n IP (como lo har\u00eda un registro A), redirigen hacia otro dominio que tiene su propio registro A o configuraci\u00f3n.</p> Direcci\u00f3n Comando Resultado www.josedomingo.org dig CNAME www.josedomingo.org endor.josedomingo.org. informatica.gonzalonazareno.org dig CNAME informatica.gonzalonazareno.org satelite.gonzalonazareno.org."},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/03.-Archivo%20de%20Zona%20DNS%20%28Sol%29/","title":"DNS Zone Files","text":""},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/03.-Archivo%20de%20Zona%20DNS%20%28Sol%29/#primera-parte-sin-origin-ni-huecos-en-blanco","title":"Primera Parte: Sin <code>$ORIGIN</code>, <code>@</code> ni Huecos en Blanco","text":""},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/03.-Archivo%20de%20Zona%20DNS%20%28Sol%29/#archivo-de-zona-directa-pruebalocal","title":"Archivo de Zona Directa (<code>prueba.local</code>)","text":"<pre><code>; Archivo de zona directa para prueba.local\nprueba.local.       IN  SOA  ns1.prueba.local. admin.prueba.local. (\n                        2024112501 ; Serial\n                        86400      ; Refresh (1 d\u00eda)\n                        3600       ; Retry (1 hora)\n                        259200     ; Expire (3 d\u00edas)\n                        43200      ; Minimum TTL (12 horas)\n                    )\n\nprueba.local.       IN  NS  ns1.prueba.local.\nprueba.local.       IN  NS  ns2.prueba.local.\nprueba.local.       IN  MX  10 mail.prueba.local.\n\nns1.prueba.local.   IN  A   192.168.1.1\ndns1.prueba.local.  IN  CNAME ns1.prueba.local.\n\nns2.prueba.local.   IN  A   192.168.1.2\ndns2.prueba.local.  IN  CNAME ns2.prueba.local.\n\nserver.prueba.local. IN  A   192.168.1.1\nmail.prueba.local.   IN  CNAME server.prueba.local.\nwww.prueba.local.    IN  CNAME server.prueba.local.\nftp.prueba.local.    IN  CNAME server.prueba.local.\n\naux.prueba.local.    IN  A   192.168.1.2\nwww2.prueba.local.   IN  CNAME aux.prueba.local.\n\npc01.prueba.local.   IN  A   192.168.1.101\npc02.prueba.local.   IN  A   192.168.1.102\npc03.prueba.local.   IN  A   192.168.1.103\npc04.prueba.local.   IN  A   192.168.1.104\npc05.prueba.local.   IN  A   192.168.1.105\npc06.prueba.local.   IN  A   192.168.1.106\npc07.prueba.local.   IN  A   192.168.1.107\n</code></pre>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/03.-Archivo%20de%20Zona%20DNS%20%28Sol%29/#archivo-de-zona-inversa-1168192in-addrarpa","title":"Archivo de Zona Inversa (<code>1.168.192.in-addr.arpa</code>)","text":"<pre><code>; Archivo de zona inversa para 192.168.1.0/24\n1.168.192.in-addr.arpa.   IN  SOA  ns1.prueba.local. admin.prueba.local. (\n                               2024112501 ; Serial\n                               86400      ; Refresh (1 d\u00eda)\n                               3600       ; Retry (1 hora)\n                               259200     ; Expire (3 d\u00edas)\n                               43200      ; Minimum TTL (12 horas)\n                           )\n\n1.168.192.in-addr.arpa.   IN  NS  ns1.prueba.local.\n1.168.192.in-addr.arpa.   IN  NS  ns2.prueba.local.\n\n1.1.168.192.in-addr.arpa. IN  PTR server.prueba.local.\n1.1.168.192.in-addr.arpa. IN  PTR dns1.prueba.local.\n1.1.168.192.in-addr.arpa. IN  PTR mail.prueba.local.\n1.1.168.192.in-addr.arpa. IN  PTR www.prueba.local.\n1.1.168.192.in-addr.arpa. IN  PTR ftp.prueba.local.\n\n2.1.168.192.in-addr.arpa. IN  PTR aux.prueba.local.\n2.1.168.192.in-addr.arpa. IN  PTR dns2.prueba.local.\n2.1.168.192.in-addr.arpa. IN  PTR www2.prueba.local.\n\n101.1.168.192.in-addr.arpa. IN  PTR pc01.prueba.local.\n102.1.168.192.in-addr.arpa. IN  PTR pc02.prueba.local.\n103.1.168.192.in-addr.arpa. IN  PTR pc03.prueba.local.\n104.1.168.192.in-addr.arpa. IN  PTR pc04.prueba.local.\n105.1.168.192.in-addr.arpa. IN  PTR pc05.prueba.local.\n106.1.168.192.in-addr.arpa. IN  PTR pc06.prueba.local.\n107.1.168.192.in-addr.arpa. IN  PTR pc07.prueba.local.\n</code></pre>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/03.-Archivo%20de%20Zona%20DNS%20%28Sol%29/#segunda-parte-usando-origin-ttl-y-huecos-en-blanco","title":"Segunda Parte: Usando <code>$ORIGIN</code>, <code>$TTL</code>, <code>@</code> y Huecos en Blanco","text":""},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/03.-Archivo%20de%20Zona%20DNS%20%28Sol%29/#archivo-de-zona-directa-pruebalocal_1","title":"Archivo de Zona Directa (<code>prueba.local</code>)","text":"<pre><code>$TTL 12h\n$ORIGIN prueba.local.\n\n@   IN  SOA  ns1.prueba.local. admin.prueba.local. (\n            2024112501 ; Serial\n            1d         ; Refresh\n            1h         ; Retry\n            3d         ; Expire\n            12h        ; Minimum TTL\n        )\n\n    IN  NS  ns1\n    IN  NS  ns2\n    IN  MX  10 mail\n\nns1 IN  A   192.168.1.1\ndns1 IN  CNAME ns1\n\nns2 IN  A   192.168.1.2\ndns2 IN  CNAME ns2\n\nserver IN  A   192.168.1.1\nmail   IN  CNAME server\nwww    IN  CNAME server\nftp    IN  CNAME server\n\naux    IN  A   192.168.1.2\nwww2   IN  CNAME aux\n\npc01   IN  A   192.168.1.101\npc02   IN  A   192.168.1.102\npc03   IN  A   192.168.1.103\npc04   IN  A   192.168.1.104\npc05   IN  A   192.168.1.105\npc06   IN  A   192.168.1.106\npc07   IN  A   192.168.1.107\n</code></pre>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/03.-Archivo%20de%20Zona%20DNS%20%28Sol%29/#archivo-de-zona-inversa-1168192in-addrarpa_1","title":"Archivo de Zona Inversa (<code>1.168.192.in-addr.arpa</code>)","text":"<pre><code>$TTL 12h\n$ORIGIN 1.168.192.in-addr.arpa.\n\n@   IN  SOA  ns1.prueba.local. admin.prueba.local. (\n            2024112501 ; Serial\n            1d         ; Refresh\n            1h         ; Retry\n            3d         ; Expire\n            12h        ; Minimum TTL\n        )\n\n    IN  NS  ns1.prueba.local.\n    IN  NS  ns2.prueba.local.\n\n1   IN  PTR server.prueba.local.\n    IN  PTR dns1.prueba.local.\n    IN  PTR mail.prueba.local.\n    IN  PTR www.prueba.local.\n    IN  PTR ftp.prueba.local.\n\n2   IN  PTR aux.prueba.local.\n    IN  PTR dns2.prueba.local.\n    IN  PTR www2.prueba.local.\n\n101 IN  PTR pc01.prueba.local.\n102 IN  PTR pc02.prueba.local.\n103 IN  PTR pc03.prueba.local.\n104 IN  PTR pc04.prueba.local.\n105 IN  PTR pc05.prueba.local.\n106 IN  PTR pc06.prueba.local.\n107 IN  PTR pc07.prueba.local.\n</code></pre>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/04.-Uso%20de%20comandos%20DNS%20%28Sol%29/","title":"Uso de Comandos DNS","text":""},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/04.-Uso%20de%20comandos%20DNS%20%28Sol%29/#1-tutorial-de-comandos-dns","title":"1.- Tutorial de Comandos DNS","text":""},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/04.-Uso%20de%20comandos%20DNS%20%28Sol%29/#dig","title":"<code>dig</code>","text":"<p><code>dig</code> (Domain Information Groper) es una herramienta para consultar servidores DNS. Es muy vers\u00e1til y ampliamente utilizada para pruebas DNS.</p> <p>Comando B\u00e1sico:</p> <pre><code>dig dominio\n</code></pre> <p>Ejemplo:</p> <pre><code>dig www.mec.es\n</code></pre> <p>Este comando realiza una consulta al servidor DNS predeterminado para resolver el dominio proporcionado.</p> <p>Par\u00e1metros importantes: - <code>+short</code>: Muestra una salida reducida. - <code>+trace</code>: Realiza una consulta iterativa, comenzando desde los servidores ra\u00edz. - <code>+nocmd</code>: Oculta la cabecera del comando.</p>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/04.-Uso%20de%20comandos%20DNS%20%28Sol%29/#nslookup","title":"<code>nslookup</code>","text":"<p><code>nslookup</code> es una herramienta m\u00e1s simple para consultas DNS. Aunque est\u00e1 menos recomendada, sigue siendo \u00fatil.</p> <p>Comando B\u00e1sico:</p> <pre><code>nslookup dominio\n</code></pre> <p>Ejemplo:</p> <pre><code>nslookup www.mec.es\n</code></pre> <p>Par\u00e1metros importantes:</p> <ul> <li>Cambiar servidor DNS:   <code>bash   nslookup   server [IP del servidor DNS]</code></li> </ul>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/04.-Uso%20de%20comandos%20DNS%20%28Sol%29/#host","title":"<code>host</code>","text":"<p><code>host</code> es una herramienta compacta para resolver nombres DNS.</p> <p>Comando B\u00e1sico:</p> <pre><code>host dominio\n</code></pre> <p>Ejemplo:</p> <pre><code>host www.mec.es\n</code></pre> <p>Par\u00e1metros importantes:</p> <ul> <li><code>-t</code>: Especifica el tipo de registro (A, MX, NS, etc.).</li> </ul>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/04.-Uso%20de%20comandos%20DNS%20%28Sol%29/#2-determina-la-direccion-ip-de-la-maquina-wwwmeces","title":"2.- Determina la direcci\u00f3n IP de la m\u00e1quina www.mec.es","text":"<p>Comando:</p> <pre><code>dig +short www.mec.es\n</code></pre> <p>Resultado: <code>212.128.114.29</code></p>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/04.-Uso%20de%20comandos%20DNS%20%28Sol%29/#3-averigua-que-maquina-tiene-asignada-la-direccion-ip-193110128200","title":"3.- Averigua qu\u00e9 m\u00e1quina tiene asignada la direcci\u00f3n IP 193.110.128.200","text":"<p>Comando:</p> <pre><code>dig -x 193.110.128.200 +short\n</code></pre> <p>Resultado: <code>raw.elmundo.es</code></p>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/04.-Uso%20de%20comandos%20DNS%20%28Sol%29/#4-consultas-relacionadas-con-el-dominio-abces","title":"4.- Consultas relacionadas con el dominio abc.es","text":""},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/04.-Uso%20de%20comandos%20DNS%20%28Sol%29/#a-servidores-dns-del-dominio","title":"a. Servidores DNS del dominio","text":"<p>Comando:</p> <pre><code>for server in $(dig abc.es NS +short); do echo \"$server: $(dig +short $server)\"; done\n</code></pre> <p>Resultado: </p> <pre><code>a24-66.akam.net.: 2.16.130.66 \na1-229.akam.net.: 193.108.91.229 \na4-67.akam.net.: 72.246.46.67 \na18-65.akam.net.: 95.101.36.65 \na5-64.akam.net.: 95.100.168.64 \na11-64.akam.net.: 84.53.139.64\n</code></pre>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/04.-Uso%20de%20comandos%20DNS%20%28Sol%29/#b-servidor-primario-y-secundarios","title":"b. Servidor primario y secundarios","text":"<p>Comando:</p> <pre><code>dig abc.es SOA +short\n</code></pre> <p>Resultado: <code>a1-229.akam.net. dnsadmin.abc.es. 2019023111 86400 7200 2592000 300</code></p>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/04.-Uso%20de%20comandos%20DNS%20%28Sol%29/#identificar-servidores-secundarios","title":"Identificar servidores secundarios","text":"<p>Todos los servidores listados en la consulta NS (Name Server) son considerados servidores de nombres autorizados para el dominio. Sin embargo, en el registro SOA, solo el servidor primario aparece de manera expl\u00edcita. Los dem\u00e1s servidores (en este caso <code>a24-66.akam.net</code>, <code>a4-67.akam.net</code>, etc.) act\u00faan como secundarios.</p>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/04.-Uso%20de%20comandos%20DNS%20%28Sol%29/#5-registro-soa","title":"5.- Registro SOA","text":"<p>Consulta al DNS local:</p> <pre><code>dig abc.es SOA\n</code></pre> <p>Resultado:</p> <p><code>abc.es.         41    IN    SOA   a1-229.akam.net. dnsadmin.abc.es. 2019023111 86400 7200 2592000 300</code></p> <p>Para confirmar que esta informaci\u00f3n es autorizada, hay que hacer una consulta directamente al servidor primario <code>a1-229.akam.net</code>:</p> <p>Consulta al servidor primario:</p> <pre><code>dig @a1-229.akam.net. abc.es SOA\n</code></pre> <p>Resultado: <code>abc.es.         300   IN    SOA   a1-229.akam.net. dnsadmin.abc.es. 2019023111 86400 7200 2592000 300</code></p>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/04.-Uso%20de%20comandos%20DNS%20%28Sol%29/#comparacion-de-las-diferencias","title":"Comparaci\u00f3n de las diferencias:","text":"Campo DNS Local Servidor Primario Diferencia Servidor de consulta DNS local (<code>192.168.1.254</code>) Primario (<code>a1-229.akam.net</code>) El primario es autoritativo, el local puede ser una copia en cach\u00e9. Serial <code>2019023111</code> <code>2019023111</code> Coinciden: el local tiene datos actualizados. TTL <code>41</code> <code>300</code> El TTL m\u00e1s bajo en el local indica una copia en cach\u00e9. Autorizaci\u00f3n No autorizado (copia en cach\u00e9) Autorizado (directo del primario) El primario es la fuente confiable."},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/04.-Uso%20de%20comandos%20DNS%20%28Sol%29/#6-correo-del-administrador-del-dominio-abces","title":"6.-Correo del Administrador del dominio abc.es","text":"<pre><code>dig abc.es SOA\n</code></pre> <p>Resultado:</p> <p><code>abc.es.         41    IN    SOA   a1-229.akam.net. dnsadmin.abc.es. 2019023111 86400 7200 2592000 300</code></p> <p>Correo: <code>dnsadmin@abc.es</code></p>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/04.-Uso%20de%20comandos%20DNS%20%28Sol%29/#7-servidor-de-correo-de-abces","title":"7.- Servidor de correo de abc.es","text":"<p>Comando:</p> <pre><code>for server in $(dig MX abc.es +short | cut -d' ' -f2); do echo -n \"${server%.} \"; dig A ${server%.} +short | tr '\\n' ' '; echo; done\n</code></pre> <p>Resultado: </p> <pre><code>alt4.aspmx.l.google.com 74.125.200.27  \nalt3.aspmx.l.google.com 142.250.150.27\nalt1.aspmx.l.google.com 142.250.153.26  \nalt2.aspmx.l.google.com 142.251.9.26  \naspmx.l.google.com 142.250.110.27 \n</code></pre>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/04.-Uso%20de%20comandos%20DNS%20%28Sol%29/#8-ttl-de-wwwvanguardiaes","title":"8. TTL de www.vanguardia.es","text":"<p>Consulta repetida:</p> <pre><code>dig www.vanguardia.es | grep \"^www.vanguardia.es\"\n</code></pre> <p>Resultados:</p> <pre><code>www.vanguardia.es.    86310  IN    CNAME  www.lavanguardia.es. \nwww.vanguardia.es.    86302  IN    CNAME  www.lavanguardia.es. \nwww.vanguardia.es.    86298  IN    CNAME  www.lavanguardia.es.\n</code></pre> <p>El TTL disminuye en cada consulta hasta llegar a 0, momento en el cual el servidor DNS recarga el registro.</p>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/04.-Uso%20de%20comandos%20DNS%20%28Sol%29/#9-verifica-consultas-no-recursivas-en-un-servidor-especifico","title":"9. Verifica consultas no recursivas en un servidor espec\u00edfico","text":"<p>Comando:</p> <pre><code>dig @163.117.139.253 www.vanguardia.es +recurse\n</code></pre> <p>Resultado:</p> <pre><code>;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: REFUSED, id: 22228 \n;; flags: qr rd ad; QUERY: 1, ANSWER: 0, AUTHORITY: 0, ADDITIONAL: 1 \n;; WARNING: recursion requested but not available \n;; WARNING: Message has 11 extra bytes at end\n</code></pre>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/04.-Uso%20de%20comandos%20DNS%20%28Sol%29/#10-balanceo-de-carga-para-wwwelmundoes","title":"10. Balanceo de carga para www.elmundo.es","text":"<p>Comando:</p> <pre><code>dig +short www.elmundo.es\n</code></pre> <p>Resultados: </p> <pre><code>unidadeditorial.map.fastly.net.\n199.232.193.50\n199.232.197.50\n</code></pre> <p>Al realizar consultas DNS para www.elmundo.es, se obtienen dos direcciones IP diferentes:</p> <pre><code>199.232.193.50\n199.232.197.50\n</code></pre> <p>Ambas IPs pertenecen a un servicio de CDN (Content Delivery Network) de Fastly. Este tipo de infraestructura distribuye la carga de tr\u00e1fico entre varios servidores para mejorar la disponibilidad y el rendimiento. Las direcciones IP  corresponden a servidores que forman parte de este sistema de balanceo de carga.</p> <p>Respuesta a las preguntas:</p> <ul> <li> <p>\u00bfCu\u00e1ntas m\u00e1quinas est\u00e1n realizando balanceo de carga para el servidor web www.elmundo.es? En los resultados de tus consultas, ves dos direcciones IP diferentes (199.232.193.50 y 199.232.197.50). Esto indica que al menos dos m\u00e1quinas est\u00e1n participando en el balanceo de carga para www.elmundo.es.</p> </li> <li> <p>\u00bfObtienes siempre las mismas m\u00e1quinas? \u00bfEn el mismo orden? Llas IPs se mantienen constantes (199.232.193.50 y 199.232.197.50), pero el orden de las IPs puede variar. Esto es t\u00edpico de un sistema de balanceo de carga que distribuye las consultas entre servidores en funci\u00f3n de varios factores, como la carga o la latencia. El orden de las IPs puede cambiar entre consultas, pero las m\u00e1quinas que responden son las mismas.</p> </li> </ul>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/04.-Uso%20de%20comandos%20DNS%20%28Sol%29/#11-resolucion-iterativa-para-wwwtimesonlinecouk","title":"11. Resoluci\u00f3n iterativa para <code>www.timesonline.co.uk</code>","text":"<p>Comandos:</p> <p>Iterativa:</p> <pre><code>dig www.timesonline.co.uk\n</code></pre> <p>Resultados: <code>www.timesonline.co.uk. 300 IN CNAME alsop-n.uk.</code></p> <pre><code>dig alsop-n.uk\n</code></pre> <p>Resultados</p> <pre><code>lsop-n.uk.             60      IN      A       52.208.17.106\nalsop-n.uk.             60      IN      A       34.240.28.43\nalsop-n.uk.             60      IN      A       54.76.240.177\n</code></pre> <p>Explicaci\u00f3n del proceso - CNAME: <code>www.timesonline.co.uk. 300 IN CNAME alsop-n.uk.</code></p> <p>Esto significa que <code>www.timesonline.co.uk</code> es un alias para <code>alsop-n.uk</code>. El valor 300 indica que el registro tiene un TTL (Time to Live) de 300 segundos.</p> <ul> <li>Direcciones IP asociadas a alsop-n.uk:         alsop-n.uk. tiene varias direcciones IP asociadas:             52.208.17.106             54.76.240.177             34.240.28.43</li> </ul> <p>Cada una de estas direcciones IP corresponde a una m\u00e1quina que puede estar gestionando las solicitudes para <code>www.timesonline.co.uk</code> (a trav\u00e9s de su alias <code>alsop-n.uk</code>).</p>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/04.-Uso%20de%20comandos%20DNS%20%28Sol%29/#12-consulta-con-trace","title":"12.- Consulta con <code>+trace</code>","text":"<pre><code>dig +trace www.timesonline.co.uk\n\n; &lt;&lt;&gt;&gt; DiG 9.20.2-1-Debian &lt;&lt;&gt;&gt; +trace www.timesonline.co.uk\n;; global options: +cmd\n.                       86028   IN      NS      d.root-servers.net.\n.                       86028   IN      NS      e.root-servers.net.\n.                       86028   IN      NS      g.root-servers.net.\n.                       86028   IN      NS      h.root-servers.net.\n.                       86028   IN      NS      l.root-servers.net.\n.                       86028   IN      NS      f.root-servers.net.\n.                       86028   IN      NS      i.root-servers.net.\n.                       86028   IN      NS      j.root-servers.net.\n.                       86028   IN      NS      m.root-servers.net.\n.                       86028   IN      NS      c.root-servers.net.\n.                       86028   IN      NS      a.root-servers.net.\n.                       86028   IN      NS      b.root-servers.net.\n.                       86028   IN      NS      k.root-servers.net.\n.                       86028   IN      NS      e.root-servers.net.\n.                       86028   IN      NS      g.root-servers.net.\n.                       86028   IN      NS      h.root-servers.net.\n.                       86028   IN      NS      l.root-servers.net.\n.                       86028   IN      NS      f.root-servers.net.\n.                       86028   IN      NS      i.root-servers.net.\n.                       86028   IN      NS      j.root-servers.net.\n.                       86028   IN      NS      m.root-servers.net.\n.                       86028   IN      NS      c.root-servers.net.\n.                       86028   IN      NS      a.root-servers.net.\n.                       86028   IN      NS      b.root-servers.net.\n.                       86028   IN      NS      k.root-servers.net.\n.                       86028   IN      NS      d.root-servers.net.\n;; Received 813 bytes from 172.31.1.1#53(172.31.1.1) in 0 ms\n\nuk.                     172800  IN      NS      nsa.nic.uk.\nuk.                     172800  IN      NS      nsb.nic.uk.\nuk.                     172800  IN      NS      nsc.nic.uk.\nuk.                     172800  IN      NS      nsd.nic.uk.\nuk.                     172800  IN      NS      dns1.nic.uk.\nuk.                     172800  IN      NS      dns2.nic.uk.\nuk.                     172800  IN      NS      dns3.nic.uk.\nuk.                     172800  IN      NS      dns4.nic.uk.\nuk.                     86400   IN      DS      43876 8 2 A107ED2AC1BD14D924173BC7E827A1153582072394F9272BA37E2353 BC659603\nuk.                     86400   IN      RRSIG   DS 8 1 86400 20241209050000 20241126040000 61050 . JkLX5uy4iwctE9hSwLw/dCc/TS8Uc6Q27tUiCwNrACY/4f4U3gt9rEz9 iXfNcuYfU9v+dJTLNISjPt7Mun8j6h5ZcJov2U0N5EjlUbboe4tU//Rk GyUEyfji3MNLI+2wMIihVi1WZru0xygtjIvhsayk+fU5LQryY1R0ZRrP OoRAjZp26TXblcGVCu8LLaVsTTf5grsPGB0k4G+T6B0NLv6TGXVbEguP Whs48DIste648mgyzpybVSpRqpF6cIwJn5IMwtL4bB5yCfoT7Yz5QezR QgjsK3zh4nO6b5OLbooBFDv//dUC5SKH538sp6ElIhl6JDMDf9nFkqUW aFjGDQ==\n;; Received 889 bytes from 192.203.230.10#53(e.root-servers.net) in 11 ms\n\n;; UDP setup with 2401:fd80:400::1#53(2401:fd80:400::1) for www.timesonline.co.uk failed: network unreachable.\n;; no servers could be reached\n;; UDP setup with 2401:fd80:400::1#53(2401:fd80:400::1) for www.timesonline.co.uk failed: network unreachable.\n;; no servers could be reached\n;; UDP setup with 2401:fd80:400::1#53(2401:fd80:400::1) for www.timesonline.co.uk failed: network unreachable.\ntimesonline.co.uk.      172800  IN      NS      ns-1344.awsdns-40.org.\ntimesonline.co.uk.      172800  IN      NS      ns-1678.awsdns-17.co.uk.\ntimesonline.co.uk.      172800  IN      NS      ns-448.awsdns-56.com.\ntimesonline.co.uk.      172800  IN      NS      ns-949.awsdns-54.net.\nG9F1KIIHM8M9VHJK7LRVETBQCEOGJIQP.co.uk. 10800 IN NSEC3 1 1 0 - G9F25DVNV5F7H68TFHQLO4863NJHEARI NS SOA RRSIG DNSKEY NSEC3PARAM TYPE65534\nG9F1KIIHM8M9VHJK7LRVETBQCEOGJIQP.co.uk. 10800 IN RRSIG NSEC3 8 3 10800 20241227183405 20241122175640 33621 co.uk. LwV2q6CzjPsmMAd5WGd3SKr6DY2jnzWwdjMr623jiVBKLGMbe16xBcCY MO+0+fO6kJ2q1djXwIwH6bMXXUmrYMXnsezm2nOMs0wy5Lhf2xwCATdh LWzmvrYrSPKDfATEN4YEqbTHVQL+m9KZvFrtkrY95RE4yhsY67GhEmMa 7R8=\nQ17IDSIOJFAJ6IH1GJCQUJ5M6UFK1EOD.co.uk. 10800 IN NSEC3 1 1 0 - Q17NRVQHA6NCUIQ38O66LU1RIP3L65PP NS DS RRSIG\nQ17IDSIOJFAJ6IH1GJCQUJ5M6UFK1EOD.co.uk. 10800 IN RRSIG NSEC3 8 3 10800 20241225235828 20241120231829 33621 co.uk. gavu/4D+Rt8RCTg+KCBvZs5jl8+Kv3lOonfvMgDFw4Md4nccB9fSOZ53 zbAocvMcAfnPf56uAiZPmW/DRHZssykfRjnyHgbFHX6cyHw+WiZEDU51 6iv6fv1TTxJTLmhQvqQMF/zc5YyW+AKUkGgaiwCL55UOlUf9mENoMyaw lFw=\n;; Received 736 bytes from 156.154.101.3#53(nsb.nic.uk) in 35 ms\n\n;; UDP setup with 2600:9000:5305:4000::1#53(2600:9000:5305:4000::1) for www.timesonline.co.uk failed: network unreachable.\nwww.timesonline.co.uk.  300     IN      CNAME   alsop-n.uk.\ntimesonline.co.uk.      300     IN      NS      ns-1344.awsdns-40.org.\ntimesonline.co.uk.      300     IN      NS      ns-1678.awsdns-17.co.uk.\ntimesonline.co.uk.      300     IN      NS      ns-448.awsdns-56.com.\ntimesonline.co.uk.      300     IN      NS      ns-949.awsdns-54.net.\n;; Received 207 bytes from 205.251.197.64#53(ns-1344.awsdns-40.org) in 39 ms\n</code></pre> <p>La opci\u00f3n +trace de dig realiza una consulta recursiva desde el servidor ra\u00edz hasta llegar a la respuesta final, mostrando todos los pasos intermedios involucrados en la resoluci\u00f3n del dominio. Vamos a comparar los resultados que has obtenido con los pasos previos para alsop-n.uk y www.timesonline.co.uk.</p>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/04.-Uso%20de%20comandos%20DNS%20%28Sol%29/#resolucion-de-alsop-nuk-con-dig","title":"Resoluci\u00f3n de alsop-n.uk con dig:","text":"<p>El comando <code>dig A alsop-n.uk</code> te muestra directamente las direcciones IP asociadas con el dominio <code>alsop-n.uk</code>:</p> <pre><code>alsop-n.uk.             60      IN      A       52.208.17.106\nalsop-n.uk.             60      IN      A       34.240.28.43\nalsop-n.uk.             60      IN      A       54.76.240.177\n</code></pre> <p>Esta respuesta es clara y directa, proporcionando las direcciones IP sin ning\u00fan detalle adicional sobre c\u00f3mo se lleg\u00f3 a esta resoluci\u00f3n.</p>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/04.-Uso%20de%20comandos%20DNS%20%28Sol%29/#resolucion-de-wwwtimesonlinecouk-con-dig-trace","title":"Resoluci\u00f3n de <code>www.timesonline.co.uk</code> con <code>dig +trace</code>:","text":"<p>El comando dig +trace www.timesonline.co.uk sigue todos los pasos necesarios para resolver el dominio, mostrando las consultas a los servidores ra\u00edz y a los servidores DNS autoritativos. El flujo es el siguiente:</p>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/04.-Uso%20de%20comandos%20DNS%20%28Sol%29/#paso-1-consultas-a-los-servidores-raiz","title":"Paso 1: Consultas a los servidores ra\u00edz","text":"<p>La consulta comienza en los servidores ra\u00edz, los cuales te indican cu\u00e1l es el servidor responsable de la zona del dominio .uk:</p> <pre><code>.                       86028   IN      NS      d.root-servers.net.\n.                       86028   IN      NS      e.root-servers.net.\n...\n\n</code></pre>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/04.-Uso%20de%20comandos%20DNS%20%28Sol%29/#paso-2-resolucion-de-la-zona-uk","title":"Paso 2: Resoluci\u00f3n de la zona .uk","text":"<p>Luego, el servidor ra\u00edz devuelve los servidores DNS autoritativos para el dominio .uk. En este caso, los servidores de nombres para .uk son:</p> <pre><code>uk.                     172800  IN      NS      nsa.nic.uk.\nuk.                     172800  IN      NS      nsb.nic.uk.\n...\n</code></pre>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/04.-Uso%20de%20comandos%20DNS%20%28Sol%29/#paso-3-resolucion-del-dominio-timesonlinecouk","title":"Paso 3: Resoluci\u00f3n del dominio timesonline.co.uk","text":"<p>La siguiente consulta es a los servidores responsables del dominio timesonline.co.uk. Se obtiene informaci\u00f3n sobre los servidores de nombres para timesonline.co.uk:</p> <pre><code>timesonline.co.uk.      172800  IN      NS      ns-1344.awsdns-40.org.\ntimesonline.co.uk.      172800  IN      NS      ns-1678.awsdns-17.co.uk.\n...\n\n</code></pre>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/04.-Uso%20de%20comandos%20DNS%20%28Sol%29/#paso-4-resolucion-de-wwwtimesonlinecouk-como-cname","title":"Paso 4: Resoluci\u00f3n de www.timesonline.co.uk como CNAME","text":"<p>Finalmente, el servidor DNS de timesonline.co.uk responde con un registro CNAME para www.timesonline.co.uk:</p> <pre><code>www.timesonline.co.uk.  300     IN      CNAME   alsop-n.uk.\n</code></pre> <p>Esto confirma que www.timesonline.co.uk es un alias de alsop-n.uk, lo que coincide con lo que vimos en la consulta anterior. Comparaci\u00f3n de los resultados:</p>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/04.-Uso%20de%20comandos%20DNS%20%28Sol%29/#proceso-de-resolucion","title":"Proceso de resoluci\u00f3n:","text":"<p>Con dig simple: Directamente obtuviste las IPs de alsop-n.uk. Con dig +trace: El proceso es m\u00e1s largo, pasando por consultas a los servidores ra\u00edz, los servidores de zona .uk y finalmente obteniendo el registro CNAME para www.timesonline.co.uk, lo que te lleva a alsop-n.uk.</p>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/04.-Uso%20de%20comandos%20DNS%20%28Sol%29/#tipo-de-informacion","title":"Tipo de informaci\u00f3n:","text":"<p>Con dig simple: Solo obtuviste las direcciones IP asociadas con alsop-n.uk. Con dig +trace: Vimos todo el recorrido de la consulta, incluidos los servidores DNS autoritativos y la resoluci\u00f3n del alias CNAME.</p>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/04.-Uso%20de%20comandos%20DNS%20%28Sol%29/#resultado-final","title":"Resultado final:","text":"<p>Ambas consultas te conducen a las mismas direcciones IP de alsop-n.uk, pero el uso de +trace muestra c\u00f3mo la consulta va pasando por los distintos niveles del sistema de nombres de dominio (DNS).</p>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/04.-Uso%20de%20comandos%20DNS%20%28Sol%29/#conclusion","title":"Conclusi\u00f3n:","text":"<p>La opci\u00f3n +trace de dig es \u00fatil cuando deseas ver c\u00f3mo se resuelve un dominio paso a paso, mientras que un comando dig m\u00e1s simple solo te devuelve la informaci\u00f3n directamente sin mostrarte el proceso de resoluci\u00f3n completo. Ambos m\u00e9todos proporcionan el mismo resultado final (las direcciones IP de alsop-n.uk), pero +trace es m\u00e1s detallado y \u00fatil para depurar problemas o entender c\u00f3mo se realiza la resoluci\u00f3n de nombres en Internet.</p>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/04.-Uso%20de%20comandos%20DNS%20%28Sol%29/#13-informacion-de-servidores-de-correo-de-ituc3mes","title":"13. Informaci\u00f3n de servidores de correo de <code>it.uc3m.es</code>","text":"<p>Comando:</p> <pre><code>dig it.uc3m.es MX +short | cut -d' ' -f2 | while read server; do dig +short $server | while read ip; do echo \"$server $ip\"; done; done\n</code></pre> <p>Resultados: </p> <pre><code>aspmx2.googlemail.com. 142.250.153.26\naspmx3.googlemail.com. 142.251.9.27\naspmx.l.google.com. 74.125.71.27\nalt1.aspmx.l.google.com. 142.250.153.27\nalt2.aspmx.l.google.com. 142.251.9.27\n</code></pre>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/04.-Uso%20de%20comandos%20DNS%20%28Sol%29/#14-consulta-registro-de-zona-labituc3mes","title":"14. Consulta registro de zona <code>lab.it.uc3m.es</code>","text":"<p>Para obtener todos los registros de la zona <code>lab.it.uc3m.es</code>, puedes usar el siguiente comando con <code>dig</code> y la opci\u00f3n <code>AXFR</code> (que realiza una transferencia de zona DNS):</p> <pre><code>dig lab.it.uc3m.es AXFR @&lt;servidor_dns&gt;\n\n</code></pre> <p>Para obtener todos los registros de la zona lab.it.uc3m.es, puedes usar el siguiente comando con dig y la opci\u00f3n AXFR (que realiza una transferencia de zona DNS):</p> <pre><code>dig lab.it.uc3m.es AXFR @&lt;servidor_dns&gt;\n</code></pre> <p>Donde:</p> <ul> <li><code>lab.it.uc3m.es</code> es el dominio de la zona que quieres consultar.</li> <li><code>AXFR</code> es el tipo de consulta que solicita una transferencia de zona completa. = <code>@&lt;servidor_dns&gt;</code> es el servidor DNS que realizar\u00e1 la consulta. Este debe ser un servidor autorizado para la transferencia de zona de <code>lab.it.uc3m.es</code>. Se puede intentar usar un servidor DNS p\u00fablico como <code>8.8.8.8</code> (Google DNS), pero es probable que no permita transferencias de zona.</li> </ul> <pre><code>dig lab.it.uc3m.es AXFR @8.8.8.8\n</code></pre> <p>Si no se tiene acceso a los administradores del DNS para pedirles acceso a los registros de zona cabe obtenerlos mediante consultas individuales para obtener los diferentes registros.</p> <pre><code>dig lab.it.uc3m.es A\ndig lab.it.uc3m.es MX\ndig lab.it.uc3m.es NS\n</code></pre> <p>Resultado:</p> <pre><code>$ dig lab.it.uc3m.es A             \n\n; &lt;&lt;&gt;&gt; DiG 9.20.2-1-Debian &lt;&lt;&gt;&gt; lab.it.uc3m.es A\n;; global options: +cmd\n;; Got answer:\n;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 41146\n;; flags: qr rd ra; QUERY: 1, ANSWER: 2, AUTHORITY: 4, ADDITIONAL: 0\n\n;; QUESTION SECTION:\n;lab.it.uc3m.es.                        IN      A\n\n;; ANSWER SECTION:\nlab.it.uc3m.es.         60      IN      A       163.117.144.200\nlab.it.uc3m.es.         60      IN      A       163.117.144.129\n\n;; AUTHORITY SECTION:\nes.                     13980   IN      NS      c.nic.es.\nes.                     13980   IN      NS      a.nic.es.\nes.                     13980   IN      NS      g.nic.es.\nes.                     13980   IN      NS      h.nic.es.\n\n;; Query time: 19 msec\n;; SERVER: 172.30.1.1#53(172.30.1.1) (UDP)\n;; WHEN: Wed Nov 27 18:43:05 CET 2024\n;; MSG SIZE  rcvd: 132\n</code></pre> <pre><code>$ dig lab.it.uc3m.es MX\n\n; &lt;&lt;&gt;&gt; DiG 9.20.2-1-Debian &lt;&lt;&gt;&gt; lab.it.uc3m.es MX\n;; global options: +cmd\n;; Got answer:\n;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 2209\n;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 4, ADDITIONAL: 0\n\n;; QUESTION SECTION:\n;lab.it.uc3m.es.                        IN      MX\n\n;; ANSWER SECTION:\nlab.it.uc3m.es.         60      IN      MX      5 smtp.uc3m.es.\n\n;; AUTHORITY SECTION:\nes.                     13973   IN      NS      a.nic.es.\nes.                     13973   IN      NS      g.nic.es.\nes.                     13973   IN      NS      h.nic.es.\nes.                     13973   IN      NS      c.nic.es.\n\n;; Query time: 19 msec\n;; SERVER: 172.30.1.1#53(172.30.1.1) (UDP)\n;; WHEN: Wed Nov 27 18:43:12 CET 2024\n;; MSG SIZE  rcvd: 121\n</code></pre> <pre><code>$ dig lab.it.uc3m.es NS\n\n; &lt;&lt;&gt;&gt; DiG 9.20.2-1-Debian &lt;&lt;&gt;&gt; lab.it.uc3m.es NS\n;; global options: +cmd\n;; Got answer:\n;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 60641\n;; flags: qr rd ra; QUERY: 1, ANSWER: 4, AUTHORITY: 4, ADDITIONAL: 0\n\n;; QUESTION SECTION:\n;lab.it.uc3m.es.                        IN      NS\n\n;; ANSWER SECTION:\nlab.it.uc3m.es.         60      IN      NS      it000.lab.it.uc3m.es.\nlab.it.uc3m.es.         60      IN      NS      vortex.uc3m.es.\nlab.it.uc3m.es.         60      IN      NS      tamtam.it.uc3m.es.\nlab.it.uc3m.es.         60      IN      NS      lm000.lab.it.uc3m.es.\n\n;; AUTHORITY SECTION:\nlab.it.uc3m.es.         60      IN      NS      vortex.uc3m.es.\nlab.it.uc3m.es.         60      IN      NS      tamtam.it.uc3m.es.\nlab.it.uc3m.es.         60      IN      NS      lm000.lab.it.uc3m.es.\nlab.it.uc3m.es.         60      IN      NS      it000.lab.it.uc3m.es.\n\n;; Query time: 19 msec\n;; SERVER: 172.30.1.1#53(172.30.1.1) (UDP)\n;; WHEN: Wed Nov 27 18:43:17 CET 2024\n;; MSG SIZE  rcvd: 170\n</code></pre>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/04.-Uso%20de%20comandos%20DNS%20%28Sol%29/#15-lavadoragonzalonazarenoorg","title":"15. <code>lavadora.gonzalonazareno.org</code>","text":"<p>Comando:</p> <pre><code>dig lavadora.gonzalonazareno.org\n</code></pre> <p>Resultado: </p> <p>La direcci\u00f3n IP de <code>lavadora.gonzalonazareno.org</code> se encuentra a trav\u00e9s de su alias <code>satelite.gonzalonazareno.org</code>, y es: <code>5.39.73.79</code></p>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/04.-Uso%20de%20comandos%20DNS%20%28Sol%29/#16-redireccion-de-informaticagonzalonazarenoorg","title":"16. Redirecci\u00f3n de informatica.gonzalonazareno.org","text":"<p>Comando:</p> <pre><code>dig informatica.gonzalonazareno.org CNAME\n</code></pre> <p>Resultado: </p> <p>El dominio <code>informatica.gonzalonazareno.org</code> est\u00e1 redirigido a <code>satelite.gonzalonazareno.org</code>, cuya direcci\u00f3n IP es <code>5.39.73.79</code></p>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/04.-Uso%20de%20comandos%20DNS%20%28Sol%29/#17-servidores-dns-de-gonzalonazarenoorg","title":"17. Servidores DNS de gonzalonazareno.org","text":"<p>Comando:</p> <pre><code>dig gonzalonazareno.org NS\n</code></pre> <p>Resultado: <code>[Resultado del comando]</code></p>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/04.-Uso%20de%20comandos%20DNS%20%28Sol%29/#18-servidores-de-correo-de-gonzalonazarenoorg","title":"18. Servidores de correo de gonzalonazareno.org","text":"<p>Comando:</p> <pre><code>dig gonzalonazareno.org MX +short\n</code></pre> <p>Resultado: </p> <pre><code>5 satelite.gonzalonazareno.org.\n</code></pre>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/04.-Uso%20de%20comandos%20DNS%20%28Sol%29/#19-direccion-ip-80591152","title":"19. Direcci\u00f3n IP 80.59.1.152","text":"<p>Comando:</p> <pre><code>dig -x 80.59.1.152\n</code></pre> <p>Resultado: <code>152.red-80-59-1.staticip.rima-tde.net.</code></p>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/05.-DNS%20con%20Ubuntu%20Server%28Sol%29/","title":"05.-DNS con Ubuntu Server(Sol)","text":""},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/05.-DNS%20con%20Ubuntu%20Server%28Sol%29/#objetivo","title":"Objetivo","text":"<p>Configurar una red con servidores y clientes DNS utilizando Ubuntu Server en m\u00e1quinas virtuales. Se debe construir una red DNS funcional basada en las siguientes especificaciones.</p>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/05.-DNS%20con%20Ubuntu%20Server%28Sol%29/#especificaciones-de-la-red","title":"Especificaciones de la Red","text":"<pre><code>graph TD\n    %% Definici\u00f3n de las m\u00e1quinas virtuales con sus roles\n    M1(\"M1 - Servidor Principal &lt;br&gt; Nombre: ns1.2asir.edu &lt;br&gt; Alias: www, servidor &lt;br&gt; IP: 192.168.1.1 &lt;br&gt; Rol: Servidor DNS maestro &lt;br&gt; Conexi\u00f3n: Red Virtual y NAT (Acceso a Internet)\")\n    M2(\"M2 - Servidor DNS Esclavo &lt;br&gt; Nombre: ns2.2asir.edu &lt;br&gt; Alias: pcprof &lt;br&gt; IP: 192.168.1.2 &lt;br&gt; Rol: Servidor DNS esclavo (sincroniza con M1) &lt;br&gt; Conexi\u00f3n: Red Virtual\")\n    M3(\"M3 - Cliente/PC &lt;br&gt; Nombre: pc01.2asir.edu &lt;br&gt; IP: 192.168.1.3 &lt;br&gt; Rol: Cliente que consulta DNS en M1 y M2 &lt;br&gt; Conexi\u00f3n: Red Virtual\")\n    M4(\"M4 - Cliente/PC &lt;br&gt; Nombre: pc02.2asir.edu &lt;br&gt; IP: 192.168.1.4 &lt;br&gt; Rol: Cliente que consulta DNS en M1 y M2 &lt;br&gt; Conexi\u00f3n: Red Virtual\")\n    NAT(\"NAT - Acceso a Internet &lt;br&gt; IP: DHCP (Solo M1) &lt;br&gt; Rol: Redirige consultas DNS no resueltas a DNS externo\")\n    InternetDNS(\"Servidor DNS Externo &lt;br&gt; Rol: Responde consultas DNS no resueltas localmente\")\n    Concentrador(\"Red Virtual\")\n\n    %% Conexiones de red\n    M1 &lt;--&gt; Concentrador\n    M2 &lt;--&gt; Concentrador\n    M3 &lt;--&gt; Concentrador\n    M4 &lt;--&gt; Concentrador\n    M1 &lt;-- \"Acceso a Internet (NAT)\" --&gt; NAT\n\n\n    %% Redirecci\u00f3n de DNS Externos\n    NAT &lt;--&gt;|Consulta DNS Externa| InternetDNS\n\n    %% Marco para el entorno virtual\n    subgraph Entorno_Virtual[\"Entorno Virtual\"]\n        direction TB\n        M1\n        M2\n        M3\n        M4\n        Concentrador\n    end\n</code></pre> <ol> <li> <p>Estructura de la red:</p> <ul> <li>Cuatro m\u00e1quinas virtuales: M1, M2, M3 y M4 (todas con Ubuntu Server). <code>bash sudo virt-install \\    --name M&lt;x&gt; \\    --ram 1024 \\    --vcpus 1 \\    --disk path=/var/lib/libvirt/images/M&lt;x&gt;.qcow2,size=5 \\    --cdrom http://archive.ubuntu.com/ubuntu/dists/focal/main/installer-amd64/legacy-images/netboot/ubuntu-installer/amd64/boot.img \\    --os-variant ubuntu20.04 \\    --network bridge=virbr0,model=virtio \\    --graphics spice \\    --console pty,target_type=serial \\    --location http://archive.ubuntu.com/ubuntu/dists/focal/main/installer-amd64/</code> <p>Ojo:  <code>--name M&lt;x&gt;</code>: Define el nombre de la m\u00e1quina virtual. Cambia  por el nombre que desees. <p>Quiz\u00e1 arranque la m\u00e1quina en una consola sin login. Cambia con  a una consola con login. <p>Crear una y clonar el resto con las modificaciones pertinentes seg\u00fan los requisitos.</p> <li>Conexi\u00f3n de red:<ul> <li>M1: Dos tarjetas de red, una conectada a NAT para acceso a internet y otra al segmento de red virtual.</li> <li>M2, M3 y M4: Una tarjeta de red conectada al segmento de red virtual.</li> </ul> </li> <li>Direcciones IP:<ul> <li>Autom\u00e1tica para la conexi\u00f3n NAT de M1.</li> <li>Direcciones fijas para todas las dem\u00e1s conexiones.</li> </ul> </li> <li>Sistema DNS:</li> <li>Dominio: <code>2asir.edu</code></li> <li>Nombres can\u00f3nicos:<ul> <li>M1: <code>ns1.2asir.edu</code></li> <li>M2: <code>ns2.2asir.edu</code></li> <li>M3: <code>pc01.2asir.edu</code></li> <li>M4: <code>pc02.2asir.edu</code></li> </ul> </li> <li>Alias:<ul> <li><code>ns1</code> tambi\u00e9n ser\u00e1 <code>www</code> y <code>servidor</code>.</li> <li><code>ns2</code> tambi\u00e9n ser\u00e1 <code>pcprof</code>.</li> </ul> </li> <li>Servidores DNS:<ul> <li><code>ns1</code>: Servidor DNS maestro.</li> <li><code>ns2</code>: Servidor DNS esclavo, que sincronizar\u00e1 con <code>ns1</code>.</li> </ul> </li> <li> <p>Todas las m\u00e1quinas usar\u00e1n como servidores de nombres a <code>ns1</code> y <code>ns2</code>.</p> </li> <li>Las consultas a nombres no resueltos deben redirigirse a un servidor DNS de internet (configurable).</li> <li>Las consultas al sistema DNS montado deben ser posibles solo desde la red local.</li>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/05.-DNS%20con%20Ubuntu%20Server%28Sol%29/#resumen-de-pasos","title":"Resumen de Pasos","text":"<ol> <li> <p>Configuraci\u00f3n de Red:</p> <ul> <li>Asigna direcciones IP est\u00e1ticas para las conexiones virtuales.</li> <li>Establece los nombres (<code>/etc/hostname</code>) y actualiza <code>/etc/hosts</code>.</li> </ul> </li> <li> <p>Instalaci\u00f3n de <code>bind9</code>:</p> <ul> <li>Instala <code>bind9</code> en <code>ns1</code> y <code>ns2</code>.</li> <li>En M2, usa conexi\u00f3n NAT temporal para descargar e instalar <code>bind9</code>.</li> </ul> </li> <li> <p>Configuraci\u00f3n del Servidor Primario (<code>ns1</code>):</p> <ol> <li>Edita <code>/etc/bind/named.conf.local</code> para definir las zonas directa e inversa. Incluye restricciones de consulta con <code>allow-query</code>.</li> <li>Edita <code>/etc/bind/named.conf.options</code> para configurar redireccionamiento de consultas no resueltas (<code>forwarders</code>).</li> <li>Valida la configuraci\u00f3n con <code>named-checkconf</code>.</li> <li>Crea archivos de base de datos para:<ul> <li>Zona directa: Define registros SOA, NS, A y CNAME.</li> <li>Zona inversa: Define registros SOA, NS y PTR.</li> </ul> </li> <li>Valida los archivos con <code>named-checkzone</code>.</li> <li>Reinicia el servicio con <code>/etc/init.d/bind9 restart</code>.</li> </ol> </li> <li> <p>Configuraci\u00f3n del Servidor Secundario (<code>ns2</code>):</p> <ol> <li>Edita <code>/etc/bind/named.conf.local</code> para definir las zonas como <code>slave</code> e incluye la IP del maestro (<code>masters</code>).</li> <li>No es necesario crear archivos de zona; se sincronizan autom\u00e1ticamente.</li> </ol> </li> <li> <p>Configuraci\u00f3n de Clientes:</p> <ul> <li>Edita <code>/etc/resolv.conf</code> en cada m\u00e1quina para configurar los servidores DNS.</li> </ul> </li> <li> <p>Pruebas del Sistema:</p> <ul> <li>Realiza consultas con <code>nslookup</code>, <code>dig</code>, y <code>ping</code> desde los clientes.</li> <li>Simula fallos deteniendo <code>ns1</code> y verifica que <code>ns2</code> responde correctamente.</li> </ul> </li> <li> <p>A\u00f1adir Nueva M\u00e1quina (<code>pc03.2asir.edu</code>):</p> <ul> <li>Indica qu\u00e9 archivos, l\u00edneas y m\u00e1quinas deben modificarse para incluir esta nueva m\u00e1quina.</li> </ul> </li> </ol>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/05.-DNS%20con%20Ubuntu%20Server%28Sol%29/#ejemplos-de-comandos","title":"Ejemplos de Comandos","text":"<ol> <li>Validaci\u00f3n de Configuraci\u00f3n:</li> </ol> <pre><code>   named-checkconf\n   named-checkzone 2asir.edu /etc/bind/db.2asir.edu\n</code></pre> <ol> <li>Reiniciar el Servicio:</li> </ol> <pre><code>   sudo /etc/init.d/bind9 restart\n</code></pre> <ol> <li>Consulta desde Clientes:</li> </ol> <pre><code>   nslookup www.2asir.edu\n   nslookup pc03.2asir.edu\n   dig pc02.2asir.edu\n</code></pre>"},{"location":"04.-DNS/08.-Pr%C3%A1cticas/06.-Soluciones/05.-DNS%20con%20Ubuntu%20Server%28Sol%29/#capturas-requeridas","title":"Capturas Requeridas","text":"<p>Incluye las siguientes capturas como evidencia de configuraci\u00f3n y pruebas:</p> <ol> <li>Instalaci\u00f3n de <code>bind9</code> exitosa.</li> <li>Configuraci\u00f3n de <code>/etc/bind/named.conf.local</code> y <code>/etc/bind/named.conf.options</code>.</li> <li>Archivos de base de datos para zonas directa e inversa.</li> <li>Comandos de validaci\u00f3n (<code>named-checkconf</code>, <code>named-checkzone</code>).</li> <li>Reinicio del servicio DNS.</li> <li>Consultas exitosas desde clientes (<code>nslookup</code>, <code>ping</code>).</li> <li>Pruebas de sincronizaci\u00f3n y respuesta del servidor secundario tras detener <code>ns1</code>.</li> </ol>"},{"location":"05.-Docker/","title":"docker","text":"<ul> <li>01.-Introducci\u00f3n</li> <li>02.-Instalaci\u00f3n</li> <li>03.-Conceptos Clave</li> <li>04.-Manos a la obra</li> <li>05.-Gesti\u00f3n de im\u00e1genes</li> <li>06.-Vol\u00famenes</li> <li>07.-Redes</li> <li>08.-Escenarios multicontenedor </li> <li>09.-Ejercicios</li> <li> <p>10.-Cheatsheet</p> </li> <li> <p>Anexo: Docker en python y django</p> </li> </ul>"},{"location":"05.-Docker/#documentacion-oficial-y-enlaces-de-interes","title":"Documentaci\u00f3n oficial y enlaces de inter\u00e9s","text":"<ul> <li>P\u00e1gina oficial</li> <li>Documentaci\u00f3n oficial</li> <li>Docker Hub</li> <li>Introducci\u00f3n a Docker - CPR de Zafra (Abril de 2021)</li> <li>Comandos b\u00e1sicos de Docker CLI para la gesti\u00f3n de im\u00e1genes y contenedores</li> <li>Creaci\u00f3n de im\u00e1genes personalizadas y registro en Docker Hub</li> <li>Implementaci\u00f3n de una aplicaci\u00f3n en un contenedor de Docker</li> <li>Integraci\u00f3n de Docker con herramientas de orquestaci\u00f3n como Kubernetes o Docker Compose</li> <li>Buenas pr\u00e1cticas y consideraciones de seguridad para el uso de Docker</li> </ul>"},{"location":"05.-Docker/01.-Introducci%C3%B3n/","title":"01.-Introducci\u00f3n","text":"<p>La configuraci\u00f3n adecuada de un entorno de desarrollo local sigue siendo un gran reto a pesar de todos los otros avances de la programaci\u00f3n moderna. Simplemente hay demasiadas variables: diferentes ordenadores, sistemas operativos, versiones de lenguajes y frameworks, opciones de entornos virtuales,  y as\u00ed sucesivamente. Cuando se a\u00f1ade el reto de trabajar en equipo en un entorno en el que todos necesitan tener la misma configuraci\u00f3n, el problema se magnifica.</p> <p>En los \u00faltimos a\u00f1os ha surgido una soluci\u00f3n: Docker. Aunque s\u00f3lo tiene unos pocos a\u00f1os, Docker se ha convertido r\u00e1pidamente en la opci\u00f3n por defecto para muchos desarrolladores que trabajan en proyectos a nivel de producci\u00f3n.</p> <p>Docker es un proyecto open source que ha revolucionado la manera de desarrollar software gracias a la sencillez con la que permite gestionar contenedores. Los contenedores LXC (LinuX Containers) son un concepto relativamente antiguo y utilizado desde hace tiempo por grandes empresas como Amazon o Google, pero cuyo gesti\u00f3n era complicada. Sin embargo, Docker define APIs y herramientas de l\u00ednea de comandos que hacen casi trivial la creaci\u00f3n, distribuci\u00f3n y ejecuci\u00f3n de contenedores. De ah\u00ed que el lema de Docker sea: \u201cBuild, Ship and Run. Any application, Anywhere\u201d y se haya convertido en una herramienta fundamental tanto para desarrolladores como para administradores de sistemas.</p> <p>Con Docker finalmente es posible reproducir un entorno de producci\u00f3n de forma fiel y fiable localmente, desde la versi\u00f3n adecuada del lenguaje hasta la instalaci\u00f3n de las librer\u00edas necesarias, a la par de ejecutar servicios adicionales como una base de datos a nivel de producci\u00f3n. Esto significa que ya no es importante si se desarrolla en un equipo Linux, Mac o Windows. Todo funciona dentro del mismo Docker.</p> <p>Docker tambi\u00e9n facilita exponencialmente la colaboraci\u00f3n en equipo. Atr\u00e1s quedaron los d\u00edas de compartir archivos README largos y obsoletos para a\u00f1adir un nuevo desarrollador a un proyecto de grupo.</p> <p>En lugar de eso, con Docker s\u00f3lo se tienen que compartir dos archivos: <code>Dockerfile</code> y  <code>docker-compose.yml</code> y el desarrollador puede tener la confianza de que su entorno de desarrollo local es exactamente igual que el del resto del equipo.</p> <p>Docker no es una tecnolog\u00eda perfecta. Todav\u00eda es relativamente nueva y compleja en sus entra\u00f1as; a\u00fan est\u00e1 en desarrollo activo. Pero aspira a la promesa de una pol\u00edtica coherente y a un entorno de desarrollo compartible, que pueda ejecutarse localmente en cualquier ordenador o desplegado en cualquier servidor, lo que lo convierte en una opci\u00f3n s\u00f3lida.</p>"},{"location":"05.-Docker/01.-Introducci%C3%B3n/#que-es-docker","title":"\u00bfQu\u00e9 es Docker?","text":"<p>Docker es una forma de aislar todo un sistema operativo a trav\u00e9s de contenedores Linux que son un tipo de virtualizaci\u00f3n.</p> <p>La virtualizaci\u00f3n tiene sus ra\u00edces en los inicios de la inform\u00e1tica cuando las computadoras grandes y caras eran la norma. \u00bfC\u00f3mo podr\u00edan varios programadores utilizar la misma m\u00e1quina?. La respuesta fue la virtualizaci\u00f3n y espec\u00edficamente las m\u00e1quinas virtuales que son copias completas de un sistema inform\u00e1tico desde el sistema operativo en adelante. </p> <p>Cuando se alquila un espacio en un proveedor de cloud computing como Amazon Web Services (AWS) normalmente no se proporciona una pieza de hardware dedicada. En lugar de eso, se comparte un servidor f\u00edsico con otros clientes. Pero como cada cliente tiene su propio sistema virtual que se ejecuta en el servidor, le parece que tiene el suyo propio.</p> <p>Esta tecnolog\u00eda es la que hace posible a\u00f1adir o eliminar servidores de un servicio de cloud de forma r\u00e1pida y sencilla. Se trata en gran medida de software entre bastidores, no de hardware real.</p> <p>\u00bfCu\u00e1l es el inconveniente de una m\u00e1quina virtual? Tama\u00f1o y velocidad. Un sistema operativo hu\u00e9sped t\u00edpico (guest) puede ocupar f\u00e1cilmente hasta 700MB de tama\u00f1o. As\u00ed que si un servidor f\u00edsico soporta tres m\u00e1quinas virtuales, eso es al menos 2,1 GB de espacio en disco ocupado junto con el resto de necesidades para otros recursos como CPU y memoria.</p> <p>Al entrar en Docker, la idea clave es que la mayor\u00eda de los ordenadores dependen del mismo sistema operativo Linux. \u00bfY si virtualizamos desde la capa de Linux hacia arriba? \u00bfNo proporcionar\u00eda eso una forma m\u00e1s r\u00e1pida y ligera de duplicar gran parte de la misma funcionalidad? La respuesta es s\u00ed. Y en los \u00faltimos a\u00f1os los contenedores Linux se han vuelto muy populares. Para la mayor\u00eda de las aplicaciones, especialmente las aplicaciones web, una m\u00e1quina virtual proporciona mucho m\u00e1s recursos de los que se necesitan y un contenedor es m\u00e1s que suficiente.</p> <p>Esto, fundamentalmente, es Docker: \u00a1una forma de implementar contenedores Linux!</p> <p>Una analog\u00eda que podemos usar es la de los edificios y los apartamentos. Las m\u00e1quinas virtuales son como viviendas: edificios independientes con su propia infraestructura, incluida la fontaner\u00eda y calefacci\u00f3n, as\u00ed como cocina, ba\u00f1os, dormitorios, etc. Los contenedores Docker son como los apartamentos: comparten una infraestructura com\u00fan como la fontaner\u00eda y la calefacci\u00f3n, pero vienen en varios tama\u00f1os que se ajustan a las necesidades exactas de un propietario.</p>"},{"location":"05.-Docker/01.-Introducci%C3%B3n/#contenedores-vs-entornos-virtuales","title":"Contenedores vs. Entornos Virtuales","text":"<p>Como programador de Python, por ejemplo, se debe estar familiarizado con el concepto de entornos virtuales que son una forma de aislar los paquetes Python. Gracias al entorno virtual, una computadora puede ejecutar m\u00faltiples proyectos localmente. Por ejemplo, el Proyecto A podr\u00eda usar Python 3.10 y Django 4.1 entre otras dependencias; mientras que el Proyecto B usa Python 3.8 y Django 2.2. Configurando un entorno virtual dedicado en cada proyecto se puede gestionar estos diferentes paquetes de software sin contaminar nuestro entorno global.</p> <p>Hay una peque\u00f1a confusi\u00f3n derivada de que hay m\u00faltiples herramientas en este momento para implementar un entorno virtual: desde <code>virtualenv</code>, <code>venv</code> a <code>pipenv</code> o <code>poetry</code>, pero fundamentalmente todas hacen lo mismo.</p> <p>La mayor distinci\u00f3n entre los entornos virtuales y Docker es que los entornos virtuales s\u00f3lo pueden aislar paquetes Python. No pueden aislar a los no-Python como una base de datos PostgreSQL o MySQL. Y siguen dependiendo del sistema global; de la instalaci\u00f3n de Python a nivel de sistema (en otras palabras, de su ordenador). Los entornos virtuales apuntan a una instalaci\u00f3n Python existente; no contienen Python en s\u00ed mismos.</p> <p>Los contenedores Linux van un paso m\u00e1s all\u00e1 y a\u00edslan todo el sistema operativo, no s\u00f3lo las partes de Python. En otras palabras, instalaremos el propio Python dentro de Docker, as\u00ed como se instalar\u00e1 y ejecutar\u00e1 en \u00e9l la base de datos a nivel de producci\u00f3n.</p>"},{"location":"05.-Docker/02.-Instalaci%C3%B3n/","title":"02.-Instalaci\u00f3n","text":"<p>La documentaci\u00f3n oficial incluye instrucciones de instalaci\u00f3n de Docker Community para\u00a0MacOS,\u00a0Windows,\u00a0Linux\u00a0o servicios en la\u00a0nube.</p> <ul> <li>Instalaci\u00f3n en Ubuntu</li> <li>Instalaci\u00f3n en Arch</li> <li>Instalaci\u00f3n del plugin de ZSH</li> </ul> <p>Sin embargo existen modos m\u00e1s pr\u00e1cticos apoy\u00e1ndonos en el trabajo desarrollado por la comunidad en cada una de las distribuciones.</p> <ul> <li>01.-Instalaci\u00f3n r\u00e1pida en Arch Linux</li> <li>02.-Instalaci\u00f3n r\u00e1pida en Fedora by H\u00e9ctor Del Real L\u00f3pez</li> <li>03.-Instalaci\u00f3n r\u00e1pida en Ubuntu by Yana Zhu</li> <li>04.-Instalaci\u00f3n r\u00e1pida en Ubuntu by Jorge Naranjo Jim\u00e9nez</li> <li>05.-Instalaci\u00f3n r\u00e1pida en Ubuntu por Alberto Romero Rubiales</li> <li> <p>06.-Instalaci\u00f3n r\u00e1pida en Ubuntu por Estefany LIzeth Silva Robles</p> </li> <li> <p>Enlaces:</p> </li> </ul> <p>Conocimiento Libre en la Universidad de Costa Rica (UCR): Docker, aplicaciones en cualquier parte</p>"},{"location":"05.-Docker/02.-Instalaci%C3%B3n/01.-Instalaci%C3%B3n%20r%C3%A1pida%20en%20Arch%20Linux/","title":"01.-Instalaci\u00f3n r\u00e1pida en Arch Linux","text":""},{"location":"05.-Docker/02.-Instalaci%C3%B3n/01.-Instalaci%C3%B3n%20r%C3%A1pida%20en%20Arch%20Linux/#instalacion","title":"Instalaci\u00f3n","text":""},{"location":"05.-Docker/02.-Instalaci%C3%B3n/01.-Instalaci%C3%B3n%20r%C3%A1pida%20en%20Arch%20Linux/#actualizamos-repositorios","title":"Actualizamos repositorios","text":"<pre><code>sudo pacman -Syy\n</code></pre>"},{"location":"05.-Docker/02.-Instalaci%C3%B3n/01.-Instalaci%C3%B3n%20r%C3%A1pida%20en%20Arch%20Linux/#instalamos-docker-y-docker-compose","title":"Instalamos <code>docker</code> y <code>docker-compose</code>","text":"<pre><code>sudo pacman -S docker docker-compose\n</code></pre>"},{"location":"05.-Docker/02.-Instalaci%C3%B3n/01.-Instalaci%C3%B3n%20r%C3%A1pida%20en%20Arch%20Linux/#iniciamos-docker-y-lo-habilitamos-para-que-se-inicie-al-reiniciar","title":"Iniciamos Docker y lo habilitamos para que se inicie al reiniciar","text":"<pre><code>sudo systemctl enable docker\nsudo systemctl start docker\n</code></pre>"},{"location":"05.-Docker/02.-Instalaci%C3%B3n/01.-Instalaci%C3%B3n%20r%C3%A1pida%20en%20Arch%20Linux/#comprobamos-la-version-de-docker-y-si-esta-instalado","title":"Comprobamos la versi\u00f3n de docker y si est\u00e1 instalado","text":"<p><code>docker -v</code></p>"},{"location":"05.-Docker/02.-Instalaci%C3%B3n/01.-Instalaci%C3%B3n%20r%C3%A1pida%20en%20Arch%20Linux/#anadimos-a-nuestro-usuario-para-controlar-docker","title":"A\u00f1adimos a nuestro usuario para controlar Docker","text":"<p>Creamos el grupo <code>docker</code>:</p> <pre><code>sudo groupadd docker\n</code></pre> <p>A\u00f1adimos al usuario:</p> <pre><code>sudo usermod -aG docker $USER\n</code></pre> <p>ATENCI\u00d3N: Para que los cambios surtan efecto habr\u00e1 que reiniciar la m\u00e1quina completamente, no basta con cerrar el terminal.</p>"},{"location":"05.-Docker/02.-Instalaci%C3%B3n/01.-Instalaci%C3%B3n%20r%C3%A1pida%20en%20Arch%20Linux/#comprobar-la-instalacion","title":"Comprobar la instalaci\u00f3n","text":"<p>Para comprobar si Docker est\u00e1 instalado correctamente en tu sistema, puedes ejecutar el siguiente comando:</p> <pre><code>docker run hello-world\n</code></pre> <p>Este comando descargar\u00e1 la imagen <code>hello-world</code> de Docker Hub y la ejecutar\u00e1 en un contenedor. Si todo funciona correctamente, deber\u00edas ver un mensaje que indica que Docker est\u00e1 instalado y funcionando correctamente.</p> <pre><code>Unable to find image 'hello-world:latest' locally\nlatest: Pulling from library/hello-world\n2db29710123e: Pull complete \nDigest: sha256:4e83453afed1b4fa1a3500525091dbfca6ce1e66903fd4c01ff015dbcb1ba33e\nStatus: Downloaded newer image for hello-world:latest\n\nHello from Docker!\nThis message shows that your installation appears to be working correctly.\n\nTo generate this message, Docker took the following steps:\n 1. The Docker client contacted the Docker daemon.\n 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub.\n    (amd64)\n 3. The Docker daemon created a new container from that image which runs the\n    executable that produces the output you are currently reading.\n 4. The Docker daemon streamed that output to the Docker client, which sent it\n    to your terminal.\n\nTo try something more ambitious, you can run an Ubuntu container with:\n $ docker run -it ubuntu bash\n\nShare images, automate workflows, and more with a free Docker ID:\n https://hub.docker.com/\n\nFor more examples and ideas, visit:\n https://docs.docker.com/get-started/\n</code></pre>"},{"location":"05.-Docker/02.-Instalaci%C3%B3n/01.-Instalaci%C3%B3n%20r%C3%A1pida%20en%20Arch%20Linux/#docker-compose-en-arch-con-python","title":"Docker-Compose en Arch con Python","text":"<p>En principio ya se ha realizado la instalaci\u00f3n de <code>docker-compose</code>. Otra forma de hacer lo propio es mediante la herramienta de instalaci\u00f3n de paquetes de python <code>pip</code>.</p>"},{"location":"05.-Docker/02.-Instalaci%C3%B3n/01.-Instalaci%C3%B3n%20r%C3%A1pida%20en%20Arch%20Linux/#instalando","title":"Instalando","text":"<p>Si no tienes instalado <code>pip</code>, deber\u00e1s instalarlo</p> <pre><code>sudo pacman -S  python-pip\n</code></pre> <p>Ahora vamos a instalar docker-compose</p> <pre><code>sudo pip3 install docker-compose\n</code></pre>"},{"location":"05.-Docker/02.-Instalaci%C3%B3n/01.-Instalaci%C3%B3n%20r%C3%A1pida%20en%20Arch%20Linux/#version","title":"Versi\u00f3n","text":"<p>Vamos a verificar la versi\u00f3n de docker-compose</p> <pre><code>docker-compose -v\n</code></pre>"},{"location":"05.-Docker/02.-Instalaci%C3%B3n/01.-Instalaci%C3%B3n%20r%C3%A1pida%20en%20Arch%20Linux/#levantar-un-docker-con-docker-compose","title":"Levantar un docker con docker-compose","text":"<p>Ahora cuando tenga un archivo\u00a0docker-compose.yml, lo levantar\u00e9 con:</p> <pre><code>docker-compose up -d\n</code></pre>"},{"location":"05.-Docker/02.-Instalaci%C3%B3n/01.-Instalaci%C3%B3n%20r%C3%A1pida%20en%20Arch%20Linux/#instalando-portainer","title":"Instalando Portainer","text":"<p>Portainer gestiona los contenedores de un modo gr\u00e1fico:</p> <pre><code>portainer:\n  image: portainer/portainer-ce:latest\n  container_name: portainer\n  restart: unless-stopped\n  security_opt:\n    - no-new-privileges:true\n  volumes:\n    - /etc/localtime:/etc/localtime:ro\n    - /var/run/docker.sock:/var/run/docker.sock:ro\n    - ./portainer-data:/data\n  ports:\n    - 9000:9000\n</code></pre> <p>Publicado por Angel el 07/12/2022</p>"},{"location":"05.-Docker/02.-Instalaci%C3%B3n/02.-Instalaci%C3%B3n%20r%C3%A1pida%20en%20Fedora/","title":"Instalaci\u00f3n de Docker Desktop en Fedora 37","text":"<p>La versi\u00f3n de Docker Desktop nos permite lanzar contenedores tanto en modo gr\u00e1fico como desde la terminal.</p>"},{"location":"05.-Docker/02.-Instalaci%C3%B3n/02.-Instalaci%C3%B3n%20r%C3%A1pida%20en%20Fedora/#requisitos-previos","title":"Requisitos previos","text":"<p>Para instalar Docker necesitamos la terminal de Gnome, como uso KDE, voy a instalar la terminal con el siguiente comando</p> <p><code>sudo dnf install gnome-terminal-3.46.8-1.fc37.x86_64</code></p>"},{"location":"05.-Docker/02.-Instalaci%C3%B3n/02.-Instalaci%C3%B3n%20r%C3%A1pida%20en%20Fedora/#instalacion","title":"Instalaci\u00f3n","text":"<p>Una vez instalada vamos a a\u00f1adir los repositorios de Docker</p> <pre><code>sudo dnf -y install dnf-plugins-core\n\nsudo dnf config-manager \\\n    --add-repo \\\n    https://download.docker.com/linux/fedora/docker-ce.repo\n</code></pre> <p>Despu\u00e9s descargamos el archivo rpm de docker y abrimos la carpeta de descarga en la terminal. He descargado la versi\u00f3n 4.18.0 as\u00ed que la instalo con el siguiente comando</p> <pre><code>sudo dnf install ./docker-desktop-4.18.0-x86_64.rpm\n</code></pre> <p>El instalador nos pedir\u00e1 que importemos la clave gpg de Docker, le damos a Y para aceptar.</p>"},{"location":"05.-Docker/02.-Instalaci%C3%B3n/02.-Instalaci%C3%B3n%20r%C3%A1pida%20en%20Fedora/#comprobaciones","title":"Comprobaciones","text":"<p>Una vez instalado lo iniciaremos con el siguiente comando</p> <pre><code>systemctl --user enable docker-desktop\n</code></pre> <p>Si queremos que Docker se inicialice cada vez que se reinicie el ordenador ejecutamos lo siguiente</p> <pre><code>systemctl --user enable docker-desktop\n</code></pre> <p>Podemos comprobar si se ha instalado correctamente viendo la version de Docker y tambi\u00e9n ejecutando un contenedor de prueba.</p> <pre><code>docker -v\ndocker run hello-world\n</code></pre> <p>Docker descargar\u00e1 el contenedor y lo ejecutar\u00e1. Si lo ejecuta correctamente mostrar\u00e1 este mensaje</p> <pre><code>Hello from Docker!  \nThis message shows that your installation appears to be working correctly.  \n\nTo generate this message, Docker took the following steps:  \n1. The Docker client contacted the Docker daemon.  \n2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub.  \n\u00a0\u00a0\u00a0(amd64)  \n3. The Docker daemon created a new container from that image which runs the  \n\u00a0\u00a0\u00a0executable that produces the output you are currently reading.  \n4. The Docker daemon streamed that output to the Docker client, which sent it  \n\u00a0\u00a0\u00a0to your terminal.  \n\nTo try something more ambitious, you can run an Ubuntu container with:  \n$ docker run -it ubuntu bash  \n\nShare images, automate workflows, and more with a free Docker ID:  \nhttps://hub.docker.com/  \n\nFor more examples and ideas, visit:  \nhttps://docs.docker.com/get-started/\n</code></pre> <p>Hecho esto, ya est\u00e1 instalado docker desktop y podremos iniciar contenedores en modo gr\u00e1fico.</p> <p>por H\u00e9ctor Del Real L\u00f3pez</p>"},{"location":"05.-Docker/02.-Instalaci%C3%B3n/03.-Instalaci%C3%B3n%20r%C3%A1pida%20en%20Ubuntu/","title":"03.-Instalaci\u00f3n r\u00e1pida en Ubuntu","text":"<p>Para instalar Docker Desktop, se sigue los siguientes pasos:</p> <p>1). Configurar el repositorio del paquete de Docker.</p> <p>\u200b       1.- Configuraci\u00f3n del paquete.</p> <ul> <li>Para configurar el repositorio con <code>apt</code> , se necesita instalar lo siguiente paquetes:</li> </ul> <p><code>bash   $ sudo apt-get update   $ sudo apt-get install ca-certificates                 install curl                 install gnupg</code></p> <ul> <li>A\u00f1adir la clave GPG oficial de Docker:</li> </ul> <p><code>bash   $ sudo install -m 0755 -d /etc/apt/keyrings   $ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg   $ sudo chmod a+r /etc/apt/keyrings/docker.gpg</code></p> <ul> <li>Configurar el repositorio con el siguiente comando:</li> </ul> <p><code>bash   $ echo \\     \"deb [arch=\"$(dpkg --print-architecture)\" signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\     \"$(. /etc/os-release &amp;&amp; echo \"$VERSION_CODENAME\")\" stable\" | \\     sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null</code></p> <p>\u200b       2.- Instalaci\u00f3n del Docker Engine.</p> <ul> <li>Actualizar el paquete <code>apt</code> :</li> </ul> <p><code>bash   $ sudo apt-get update</code></p> <ul> <li>Instalar Docker Engine y Docker Compose:</li> </ul> <p><code>bash   $ sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin</code></p> <ul> <li>Verificar que la instalaci\u00f3n es completada, con una imagen de hello-world:</li> </ul> <p><code>bash   $ sudo docker run hello-world</code></p> <p>2). Descargar el paquete de DEB correspondiente.</p> <p>Lo puede descargar autom\u00e1ticamente en el siguiente enlace:</p> <p>https://desktop.docker.com/linux/main/amd64/docker-desktop-4.18.0-amd64.deb?utm_source=docker&amp;utm_medium=webreferral&amp;utm_campaign=docs-driven-download-linux-amd64</p> <p>3). Instalar el paquete con <code>apt</code> como indica a continuaci\u00f3n (con la versi\u00f3n 4.18.0):</p> <pre><code>$ sudo apt-get update\n$ sudo apt-get install ./docker-desktop-4.18.0-amd64.deb\n</code></pre>"},{"location":"05.-Docker/02.-Instalaci%C3%B3n/03.-Instalaci%C3%B3n%20r%C3%A1pida%20en%20Ubuntu/#version-que-utiliza-mi-ubuntu","title":"Versi\u00f3n que utiliza (mi) Ubuntu:","text":"<pre><code>$ docker compose version\nDocker Compose version v2.17.2\n\n$ docker --version \nDocker version 23.0.4, build f480fb1\n\n$ docker version \nClient: Docker Engine - Community\n Cloud integration: v1.0.31\n Version:           23.0.4\n API version:       1.41 (downgraded from 1.42)\n Go version:        go1.19.8\n Git commit:        f480fb1\n Built:             Fri Apr 14 10:32:03 2023\n OS/Arch:           linux/amd64\n Context:           desktop-linux\n\nServer: Docker Desktop 4.18.0 (104112)\n Engine:\n  Version:          20.10.24\n  API version:      1.41 (minimum version 1.12)\n  Go version:       go1.19.7\n  Git commit:       5d6db84\n  Built:            Tue Apr  4 18:18:42 2023\n  OS/Arch:          linux/amd64\n  Experimental:     false\n containerd:\n  Version:          1.6.18\n  GitCommit:        2456e983eb9e37e47538f59ea18f2043c9a73640\n runc:\n  Version:          1.1.4\n  GitCommit:        v1.1.4-0-g5fd4c4d\n docker-init:\n  Version:          0.19.0\n  GitCommit:        de40ad0\n</code></pre>"},{"location":"05.-Docker/02.-Instalaci%C3%B3n/03.-Instalaci%C3%B3n%20r%C3%A1pida%20en%20Ubuntu/#instalacion-de-docker-en-arch","title":"Instalaci\u00f3n de Docker en Arch.","text":"<p>Para instalar Docker en Arch sigue los siguientes pasos:</p> <p>1). Instalar el paquete de Docker Desktop manualmente porque Docker no tiene un repositorio de paquetes Arch.</p> <p>2). Instalar Docker client binary en Linux.</p> <ul> <li> <p>Descargar el archivo binario est\u00e1tico en https://download.docker.com/linux/static/stable/, elige la correspondiente y descarga el archivo <code>.tgz</code>.</p> </li> <li> <p>Extraer el archivo usando el comando <code>tar</code>:</p> </li> </ul> <p><code>bash   $ tar xzvf /path/to/&lt;FILE&gt;.tar.gz</code></p> <ul> <li>OPCIONAL. Mover el archivo binario a un directorio de path.</li> </ul> <p><code>bash   $ sudo cp docker/* /usr/bin/</code></p> <ul> <li>Empezar el Docker daemon:</li> </ul> <p><code>bash   $ sudo dockerd &amp;</code></p> <ul> <li>Verificar que Docker esta instalado correctamente, con una imagen de hello-world:</li> </ul> <p><code>bash    $ sudo docker run hello-world</code></p> <p>3). Descargar el paquete Arch en la siguiente pagina:</p> <p>https://docs.docker.com/desktop/release-notes/</p> <p>4). Instalar el paquete: </p> <pre><code>$ sudo pacman -U ./docker-desktop-&lt;version&gt;-&lt;arch&gt;.pkg.tar.zst\n</code></pre>"},{"location":"05.-Docker/02.-Instalaci%C3%B3n/03.-Instalaci%C3%B3n%20r%C3%A1pida%20en%20Ubuntu/#version","title":"Versi\u00f3n:","text":"<pre><code>$ docker compose version\nDocker Compose version v2.5.0\n\n$ docker --version\nDocker version 20.10.14, build a224086349\n\n$ docker version\nClient: Docker Engine - Community\nCloud integration: 1.0.24\nVersion:           20.10.14\nAPI version:       1.41\n...\n</code></pre> <p>by Yana Zhu</p>"},{"location":"05.-Docker/02.-Instalaci%C3%B3n/04.-Instalaci%C3%B3n%20r%C3%A1pida%20en%20Ubuntu/","title":"Instalar Docker en Ubuntu","text":"<p>Vamos a seguir los pasos que hay que realizar para instalar Docker versi\u00f3n 20.04 en Ubuntu.</p> <p>Primero debemos de actualizar nuestra lista de paquetes:</p> <pre><code>$ sudo apt update\n</code></pre> <p>Luego, debemos instalar algunos paquetes de requisitos previos que permitan a <code>apt</code> usar paquetes a trav\u00e9s de HTTPS:</p> <pre><code>$ sudo apt install apt-transport-https ca-certificates curl software-properties-common\n</code></pre> <p>A continuaci\u00f3n, a\u00f1adimos la clave de GPG para el repositorio oficial de Docker en nuestro sistema:</p> <pre><code>$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -\n</code></pre> <p>Agregamos el repositorio de Docker a las fuentes de APT:</p> <pre><code> $ sudo add-apt-repository \"deb [arch=amd64] https://download.docker.com/linux/ubuntu focal stable\"\n</code></pre> <p>Actualizamos el paquete de base de datos con los paquetes de Docker del repositorio reci\u00e9n agregado:</p> <pre><code>$ sudo apt update\n</code></pre> <p>Ahora nos aseguramos de estar en el repositorio de Docker en lugar del repositorio predeterminado de Ubuntu para realizar la instalaci\u00f3n:</p> <pre><code>$ apt-cache policy docker-ce\n</code></pre> <p>Por \u00faltimo, instalamos Docker:</p> <pre><code>$ sudo apt install docker-ce\n</code></pre> <p>Ya est\u00e1 Docker instalado, para comprobarlo usamos:</p> <pre><code>$ sudo systemctl status docker\n</code></pre>"},{"location":"05.-Docker/02.-Instalaci%C3%B3n/05.-Instalaci%C3%B3n%20r%C3%A1pida%20en%20Ubuntu/","title":"Instalaci\u00f3n de Docker en Ubuntu","text":"<p>Instalaremos la \u00faltima versi\u00f3n 23.0.4 de Docker en las versiones de Ubuntu 18.04, 20.04, 21.10 y 22.04.</p>"},{"location":"05.-Docker/02.-Instalaci%C3%B3n/05.-Instalaci%C3%B3n%20r%C3%A1pida%20en%20Ubuntu/#instalar-docker-con-el-repositorio-apt","title":"Instalar Docker con el Repositorio apt","text":"<p>Para instalar Docker desde el repositorio apt lo primero que deberemos de realizar es utilizar el siguiente comando:</p> <pre><code>sudo apt update\n</code></pre> <p>Este comando ser\u00e1 utilizado para ver si tenemos todos nuestros paquetes del sistema actualizados.</p> <p>Una vez finalizado ese paso deberemos instalar los certificados necesarios:</p> <pre><code>sudo apt install ca-certificates curl gnupg lsb-release\n</code></pre> <p>A continuaci\u00f3n, registra el llavero GPG de Docker con apt. Esto permitir\u00e1 a apt validar los paquetes Docker que instales.</p> <pre><code>sudo mkdir -p /etc/apt/keyrings\n</code></pre> <pre><code>$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg\n</code></pre> <pre><code>$ sudo chmod a+r /etc/apt/keyrings/docker.gpg\n</code></pre> <p>Con el comando <code>curl</code> nos descargaremos la clave GPG de Docker para Ubuntu, la cual se guarda en el directorio de llaveros de apt. </p> <p>Para a\u00f1adir la fuente del paquete Docker al sistema debemos ejecutar el comando <code>echo</code> de la siguiente forma:</p> <pre><code>echo \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null\n</code></pre> <p>Esto utiliza la sustituci\u00f3n del shell para detectar autom\u00e1ticamente la arquitectura de tu sistema y descargar la lista de paquetes adecuada.</p> <p>Actualizamos de nuevo la lista de paquetes para que apt sepa que los paquetes Docker existen:</p> <pre><code>sudo apt update\n</code></pre> <p>Ahora podemos utilizar el comando apt install para a\u00f1adir los componentes de Docker al sistema.</p> <pre><code>sudo apt install docker-ce docker-ce-cli containerd.io\n</code></pre> <p>Por ultimo para comprobar que tenemos bien instalado Docker realizaremos el comando siguiente para su funcionamiento:</p> <pre><code>docker run hello-world\n</code></pre>"},{"location":"05.-Docker/02.-Instalaci%C3%B3n/06.-Instalaci%C3%B3n%20r%C3%A1pida%20en%20Ubuntu/","title":"06.-Instalaci\u00f3n r\u00e1pida en Ubuntu","text":""},{"location":"05.-Docker/02.-Instalaci%C3%B3n/06.-Instalaci%C3%B3n%20r%C3%A1pida%20en%20Ubuntu/#pasos-para-instalar-docker","title":"Pasos para instalar Docker","text":"<p>Instalaci\u00f3n de Docker en Ubuntu 20.04 de Ubuntu.</p> <p>Primero, actualice su lista de paquetes existente:</p> <pre><code>sudo apt update\n</code></pre> <p>A continuaci\u00f3n, instale algunos paquetes de requisitos previos que permitan a <code>apt</code> usar paquetes a trav\u00e9s de HTTPS:</p> <pre><code>sudo apt install apt-transport-https ca-certificates curl software-properties-common\n</code></pre> <p>Luego, a\u00f1ada la clave de GPG para el repositorio oficial de Docker en su sistema:</p> <pre><code>curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -\n</code></pre> <p>Agregue el repositorio de Docker a las fuentes de APT:</p> <pre><code>sudo add-apt-repository \"deb [arch=amd64] https://download.docker.com/linux/ubuntu focal stable\"\n</code></pre> <p>A continuaci\u00f3n, actualice el paquete de base de datos con los paquetes de Docker del repositorio reci\u00e9n agregado:</p> <pre><code>sudo apt update\n</code></pre> <p>Aseg\u00farese de estar a punto de realizar la instalaci\u00f3n desde el  repositorio de Docker en lugar del repositorio predeterminado de Ubuntu:</p> <pre><code>apt-cache policy docker-ce\n</code></pre> <p>Si bien el n\u00famero de versi\u00f3n de Docker puede ser distinto, ver\u00e1 un resultado como el siguiente:</p> <p>Output of apt-cache policy docker-ce</p> <p></p> <p>Observe que <code>docker-ce</code> no est\u00e1 instalado, pero la opci\u00f3n m\u00e1s viable para la instalaci\u00f3n es del repositorio de Docker para Ubuntu 20.04 (<code>focal</code>).</p> <p>Por \u00faltimo, instale Docker:</p> <pre><code>sudo apt install docker-ce\n</code></pre> <p>Con esto, Docker quedar\u00e1 instalado, el demonio se iniciar\u00e1 y el  proceso se habilitar\u00e1 para ejecutarse en el inicio. Compruebe que  funcione:</p> <pre><code>sudo systemctl status docker\n</code></pre> <p>El resultado debe ser similar al siguiente, y mostrar que el servicio est\u00e1 activo y en ejecuci\u00f3n:</p> <p></p> <p>La instalaci\u00f3n de Docker ahora le proporcionar\u00e1 no solo el servicio  de Docker (demonio) sino tambi\u00e9n la utilidad de l\u00ednea de comandos <code>docker</code> o el cliente de Docker. </p>"},{"location":"05.-Docker/02.-Instalaci%C3%B3n/06.-Instalaci%C3%B3n%20r%C3%A1pida%20en%20Ubuntu/#como-asegurarte-de-que-el-motor-docker-funciona-en-ubuntu","title":"C\u00f3mo Asegurarte de que el Motor Docker Funciona en Ubuntu.","text":"<p>Utilizar esta linea de comando, para asegurarte de que todo funciona iniciando un contenedor:</p> <pre><code>$ sudo docker run hello-world\n</code></pre> <p>Ver\u00e1s que el cliente Docker extrae el <code>hello-world:latest</code> a tu m\u00e1quina, desde el repositorio Docker Hub:</p> <p>A continuaci\u00f3n, se iniciar\u00e1 autom\u00e1ticamente un nuevo contenedor. La  imagen de inicio \u00abhola-mundo\u00bb est\u00e1 configurada para ejecutar un simple  comando que emite alguna informaci\u00f3n b\u00e1sica sobre Docker y luego sale  inmediatamente:</p> <p></p> <p>Al ver la salida mostrada arriba, significa que Docker est\u00e1 listo para ser utilizado.</p>"},{"location":"05.-Docker/03.-Conceptos%20Clave/","title":"03.-Conceptos Clave","text":"<p>01.-Im\u00e1genes</p> <p>02.-Contenedores</p> <p>03.-Vol\u00famenes</p> <p>04.-Capas</p> <p>05.-Redes</p> <p>06.-Estructura de docker</p>"},{"location":"05.-Docker/03.-Conceptos%20Clave/02.-Contenedores/","title":"02.-Contenedores","text":"<p>En pocas palabras, un contenedor es un proceso de espacio aislado en su m\u00e1quina que est\u00e1 al margen de todos los dem\u00e1s procesos en la m\u00e1quina host. Ese aislamiento aprovecha los\u00a0espacios de nombres del kernel y cgroups, caracter\u00edsticas que han estado en Linux durante mucho tiempo. Docker ha trabajado para que estas capacidades sean accesibles y f\u00e1ciles de usar. Para resumir, un contenedor:</p> <ul> <li>Un contenedor es una imagen instanciada (en ejecuci\u00f3n). Se puede crear, iniciar, detener, mover o eliminar un contenedor mediante DockerAPI o CLI.</li> <li>No albergan un sistema operativo sino que a\u00edslan el espacio de usuario.</li> <li>Son muy ligeros porque corren como un proceso sobre el SO del host.</li> <li>Puede ejecutarse en m\u00e1quinas locales, m\u00e1quinas virtuales o implementarse en la nube.</li> <li>Escalan en funci\u00f3n de la demanda, mientras que las M\u00e1quinas Virtuales (MV) tienen que ser aprovisionadas de recursos previamente.</li> <li>Est\u00e1 aislado de otros contenedores y ejecuta su propio software, binarios y configuraciones.</li> </ul> <p>Una imagen de Docker es un archivo compuesto por m\u00faltiples capas que se utiliza para ejecutar c\u00f3digo en un contenedor de Docker. Estas im\u00e1genes son las plantillas base desde la que partimos ya sea para crear una nueva imagen o crear nuevos contenedores para ejecutar las aplicaciones.</p>"},{"location":"05.-Docker/03.-Conceptos%20Clave/02.-Contenedores/#contenedores-windows-y-contenedores-linux","title":"Contenedores Windows y contenedores Linux","text":"<p>Los contenedores Windows corren sobre Windows y los contenedores Linux sobre Linux Se diferencian en los tipos de aislamiento que tienen ambos</p> <p>Los contenedores Linux:</p> <ul> <li>Se ejecutan sobre el host de modo que son visibles a ellos</li> <li>Se ejecutan sobre el kernel como un proceso visible desde el host</li> </ul> <p>Los contenedores Windows:</p> <ul> <li>Se ejecutan sobre una m\u00e1quina virtual l\u00ednux controlada por el hipervisor de windows (Hyper-V)</li> <li>En Hyper-V Windows lanza una MV super fina que tiene su propio kernel y por tanto los contenedores no son visibles desde el propio SO.</li> </ul>"},{"location":"05.-Docker/03.-Conceptos%20Clave/02.-Contenedores/#portabilidad","title":"Portabilidad","text":"<p>Un contenedor es ejecutado por lo que se denomina el Docker Engine, un demonio que es f\u00e1cilmente instalable en todas las distribuciones Linux y tambi\u00e9n en Windows. Un contenedor ejecuta una imagen de docker, que es una representaci\u00f3n del sistema de ficheros y otros metadatos que el contenedor va a utilizar para su ejecuci\u00f3n. Una vez que hemos generado una imagen de Docker, ya sea en nuestro ordenador o v\u00eda una herramienta externa, esta imagen podr\u00e1 ser ejecutada por cualquier Docker Engine, independientemente del sistema operativo y la infraestructura que haya por debajo.</p>"},{"location":"05.-Docker/03.-Conceptos%20Clave/02.-Contenedores/#inmutabilidad","title":"Inmutabilidad","text":"<p>Una aplicaci\u00f3n la componen tanto el c\u00f3digo fuente como las librer\u00edas del sistema operativo y del lenguaje de programaci\u00f3n necesarias para la ejecuci\u00f3n de dicho c\u00f3digo. Estas dependencias van en funci\u00f3n, a su vez, del sistema operativo donde nuestro c\u00f3digo va a ser ejecutado, y por esto mismo ocurre muchas veces aquello de que \u201cno s\u00e9, en mi m\u00e1quina funciona\u201d. Sin embargo, el proceso de instalaci\u00f3n de dependencias en Docker no depende del sistema operativo, sino que este proceso se realiza cuando se genera una imagen de docker. Es decir, una imagen de docker (tambi\u00e9n llamada repositorio por su parecido con los repositorios de git) contiene tanto el c\u00f3digo de la aplicaci\u00f3n como las dependencias que necesita para su ejecuci\u00f3n. Una imagen se genera una vez y puede ser ejecutada las veces que sean necesarias, y siempre ejecutar\u00e1 con las misma versi\u00f3n del c\u00f3digo fuente y sus dependencias, por lo que se dice que es inmutable. Si unimos inmutabilidad con el hecho de que Docker es portable, decimos que Docker es una herramienta fiable, ya que una vez generada una imagen, \u00e9sta se comporta de la misma manera independientemente del sistema operativo y de la infraestructura donde se est\u00e9 ejecutando.</p>"},{"location":"05.-Docker/03.-Conceptos%20Clave/02.-Contenedores/#ligereza","title":"Ligereza","text":"<p>Los contenedores corriendo en la misma m\u00e1quina comparten entre ellos el sistema operativo, pero cada contenedor es un proceso independiente con su propio sistema de ficheros y su propio espacio de procesos y usuarios (para este fin Docker utiliza cgroups y namespaces, recursos de aislamiento basados en el kernel de Linux). Esto hace que la ejecuci\u00f3n de contenedores sea mucho m\u00e1s ligera que otros mecanismos de virtualizaci\u00f3n. Comparemos por ejemplo con otra tecnolog\u00eda muy utilizada como es Virtualbox. Virtualbox permite del orden de 4 \u00f3 5 m\u00e1quinas virtuales en un ordenador convencional, mientras que en el mismo ordenador podremos correr cientos de containers sin mayor problema, adem\u00e1s de que su gesti\u00f3n es mucho m\u00e1s sencilla.</p>"},{"location":"05.-Docker/03.-Conceptos%20Clave/03.-Vol%C3%BAmenes/","title":"03.-Vol\u00famenes","text":"<p>En Docker, un volumen es un mecanismo para persistir los datos que se generan dentro de un contenedor de Docker, de manera que puedan ser compartidos y reutilizados por otros contenedores.</p> <p>Un volumen de Docker es un \u00e1rea de almacenamiento de datos que se encuentra fuera del sistema de archivos del contenedor y que se mantiene separada del ciclo de vida del contenedor. Esto significa que los datos almacenados en un volumen persistir\u00e1n incluso despu\u00e9s de que se elimine el contenedor.</p> <p>Los vol\u00famenes de Docker se pueden utilizar para diferentes fines, como por ejemplo:</p> <ul> <li>Compartir datos entre varios contenedores: Los vol\u00famenes permiten compartir datos entre varios contenedores de Docker, lo que facilita el intercambio de informaci\u00f3n entre diferentes aplicaciones y servicios.</li> <li>Almacenar datos persistentes: Los vol\u00famenes se pueden utilizar para almacenar datos que deben persistir m\u00e1s all\u00e1 del ciclo de vida de un contenedor, como por ejemplo datos de una base de datos.</li> <li>Hacer copias de seguridad de datos: Los vol\u00famenes permiten hacer copias de seguridad de los datos almacenados en un contenedor, lo que ayuda a proteger la informaci\u00f3n importante en caso de fallos en el sistema o errores humanos.</li> </ul>"},{"location":"05.-Docker/03.-Conceptos%20Clave/04.-Capas/","title":"04.-Capas","text":"<p>Las im\u00e1genes se construyen sobre una tecnolog\u00eda de sistema de ficheros por capas:</p> <ul> <li> <p>Para crear una imagen, generalmente se crea el archivo de texto <code>Dockerfile</code> formado por diferentes instrucciones. Cada l\u00ednea representa una instrucci\u00f3n, y cada vez que se ejecuta el Dockerfile se ejecutan dichas instrucciones de arriba a abajo.</p> </li> <li> <p>Estos <code>Dockerfile</code>-s se almacenan como texto y se pueden compartir con facilidad, as\u00ed como almacenarse en sistemas de control de versiones.</p> </li> <li> <p>Cada instrucci\u00f3n que se ejecuta cambia ligeramente el estado del sistema de archivos respecto a la instrucci\u00f3n anterior.</p> </li> <li> <p>La diferencia entre el estado del sistema de ficheros antes y despu\u00e9s de cada instrucci\u00f3n se guarda en disco como un archivo, que conforma una capa.</p> </li> <li> <p>Cada imagen es un conjunto de capas que contienen los diferentes cambios que se van realizando sobre el sistema de archivos empaquetados.</p> </li> <li> <p>Al final del <code>Dockerfile</code>, la \u00faltima instrucci\u00f3n define el comando que se ejecutar\u00e1 cuando arranquemos el contenedor.</p> </li> <li> <p>Al ejecutar un comando a partir de la imagen creada, se ejecuta el comando especificado y se convierte en el proceso con PID 1 dentro del \u00e1rbol virtual de procesos.</p> </li> <li> <p>Cada vez que se ejecuta una instrucci\u00f3n, se crea un contenedor y se etiqueta con un hash creado para obtener un nombre \u00fanico. De este modo, podemos reutilizar estas capas intermedias y solo tener que construirlas una vez.</p> </li> </ul> <p>El contenedor seguir\u00e1 en marcha mientras el proceso creado siga en ejecuci\u00f3n.</p>"},{"location":"05.-Docker/03.-Conceptos%20Clave/05.-Redes/","title":"05.-Redes","text":"<p>En Docker, las redes son una forma de conectar contenedores y permitir que se comuniquen entre s\u00ed y con otros servicios en la red. Las redes de Docker se utilizan para facilitar la comunicaci\u00f3n entre contenedores y para aislar los contenedores de otras redes. Docker proporciona varios tipos de redes, que se utilizan para diferentes prop\u00f3sitos:</p> <ul> <li> <p>Bridge network (red puente): Es la red predeterminada en Docker. Cada contenedor se conecta a una red puente virtual, que se encuentra en el host. Los contenedores en la misma red puente pueden comunicarse entre s\u00ed mediante sus nombres de host.</p> </li> <li> <p>Host network (red de host): En esta red, los contenedores se conectan directamente a la red del host, en lugar de a una red virtual. Esto permite que los contenedores tengan acceso directo a los recursos de red del host, pero tambi\u00e9n puede presentar problemas de seguridad.</p> </li> <li> <p>Overlay network (red de superposici\u00f3n): Esta red se utiliza para conectar contenedores que se ejecutan en diferentes hosts. Los contenedores en la misma red de superposici\u00f3n pueden comunicarse entre s\u00ed como si estuvieran en la misma red local.</p> </li> <li> <p>Macvlan network (red de Macvlan): Esta red se utiliza para conectar contenedores directamente a una interfaz de red f\u00edsica del host. Esto permite que los contenedores tengan direcciones IP \u00fanicas y se comuniquen directamente con otros dispositivos en la red.</p> </li> </ul> <p>Adem\u00e1s de estos tipos de redes, Docker tambi\u00e9n permite crear redes personalizadas para satisfacer las necesidades espec\u00edficas de una aplicaci\u00f3n o servicio.</p>"},{"location":"05.-Docker/03.-Conceptos%20Clave/06.-Estructura%20de%20docker/","title":"06.-Estructura de docker","text":"<p>Docker est\u00e1 formado fundamentalmente por tres componentes:</p> <ul> <li>Docker Engine</li> <li>Docker Client</li> <li>Docker Registry</li> </ul> <p></p>"},{"location":"05.-Docker/03.-Conceptos%20Clave/06.-Estructura%20de%20docker/#docker-engine-o-demonio-docker","title":"Docker Engine o Demonio Docker:","text":"<p>Es un demonio que corre sobre cualquier distribuci\u00f3n de Linux (y ahora tambi\u00e9n en Windows) y que expone una API externa para la gesti\u00f3n de im\u00e1genes y contenedores (y otras entidades que se van a\u00f1adiendo en sucesivas distribuciones de docker como vol\u00famenes o redes virtuales). Podemos destacar entre sus funciones principales:</p> <ul> <li>Creaci\u00f3n de im\u00e1genes docker.</li> <li>Publicaci\u00f3n de im\u00e1genes en un Docker Registry o Registro de Docker (otro componente  Docker que se explicar\u00e1 a continuaci\u00f3n).</li> <li>Descarga de im\u00e1genes desde un Registro de Docker</li> <li>Ejecuci\u00f3n de contenedores usando im\u00e1genes locales.</li> </ul> <p>Otra funci\u00f3n fundamental del Docker Engine es la gesti\u00f3n de los contenedores en ejecuci\u00f3n, permitiendo parar su ejecuci\u00f3n, rearrancarla, ver sus logs o sus estad\u00edsticas de uso de recursos.</p>"},{"location":"05.-Docker/03.-Conceptos%20Clave/06.-Estructura%20de%20docker/#docker-registry-o-registro-docker","title":"Docker Registry o Registro Docker","text":"<p>El Registro es otro componente de Docker que suele correr en un servidor independiente y donde se publican las im\u00e1genes que generan los Docker Engine de tal manera que est\u00e9n disponibles para su utilizaci\u00f3n por cualquier otra m\u00e1quina. Es un componente fundamental dentro de la arquitectura de Docker ya que permite distribuir nuestras aplicaciones. El Registro de Docker es un proyecto open source que puede ser instalado gratuitamente en cualquier servidor, pero Docker ofrece Docker Hub, un sistema SaaS de pago donde puedes subir tus propias im\u00e1genes, acceder a im\u00e1genes p\u00fablicas de otros usuarios, e incluso a im\u00e1genes oficiales de las principales aplicaciones como son: MySQL, MongoDB, RabbitMQ, Redis, etc.</p> <p>El registro de Docker funciona de una manera muy parecida a git (de la misma manera que Dockerhub y us m\u00e9todos de pago funcionan de una manera muy parecida a Github). Cada imagen, tambi\u00e9n conocida como repositorio, es una sucesi\u00f3n de capas. Es decir, cada vez que hacemos un build en local de nuestra imagen, el Registro de Docker s\u00f3lo almacena el diff respecto de la versi\u00f3n anterior, haciendo mucho m\u00e1s eficiente el proceso de creaci\u00f3n y distribuci\u00f3n de im\u00e1genes.</p>"},{"location":"05.-Docker/03.-Conceptos%20Clave/06.-Estructura%20de%20docker/#docker-client-o-cliente-docker","title":"Docker Client o Cliente Docker","text":"<p>Es cualquier herramienta que hace uso de la api remota del Docker Engine, pero suele hacer referencia al comando <code>docker</code> que hace las veces de herramienta de l\u00ednea de comandos (cli) para gestionar un Docker Engine. La cli de docker se puede configurar para hablar con un Docker Engine local o remoto, permitiendo gestionar tanto nuestro entorno de desarrollo local, como nuestros servidores de producci\u00f3n.</p>"},{"location":"05.-Docker/03.-Conceptos%20Clave/01.-Im%C3%A1genes/01.-Im%C3%A1genes/","title":"01.-Im\u00e1genes","text":"<p>Una imagen de Docker es un paquete de software que contiene todo lo necesario para ejecutar una aplicaci\u00f3n, incluyendo el c\u00f3digo, las dependencias, el sistema operativo, las bibliotecas y las configuraciones.</p> <p>Las im\u00e1genes se construyen sobre una tecnolog\u00eda de sistema de ficheros por capas.</p> <p>Las im\u00e1genes de Docker se utilizan como plantillas para crear contenedores de Docker, que son instancias en tiempo de ejecuci\u00f3n de una imagen.</p> <p>Las im\u00e1genes se crean a partir de un archivo de configuraci\u00f3n llamado <code>Dockerfile</code>, que especifica los componentes y configuraciones necesarios para la aplicaci\u00f3n. Cada instrucci\u00f3n que se ejecuta cambia ligeramente el estado del sistema de archivos respecto a la instrucci\u00f3n anterior.</p> <p>La diferencia entre el estado del sistema de ficheros antes y despu\u00e9s de cada instrucci\u00f3n se guarda en disco como un archivo, que conforma una capa, por tanto, una imagen es un conjunto de capas que contienen los diferentes cambios que se van realizando sobre el sistema de archivos empaquetados.</p> <p>Una vez que se ha creado una imagen de Docker, se puede almacenar en un registro de im\u00e1genes de Docker, como Docker Hub o un registro privado, para que otros usuarios puedan descargarla y utilizarla en la creaci\u00f3n de contenedores.</p> <p>Las im\u00e1genes de Docker son portables y se pueden ejecutar en cualquier sistema que admita la plataforma Docker. Adem\u00e1s, como las im\u00e1genes est\u00e1n aisladas del sistema operativo del host, se pueden ejecutar varias instancias de la misma imagen en diferentes contenedores sin interferir entre s\u00ed.</p>"},{"location":"05.-Docker/03.-Conceptos%20Clave/01.-Im%C3%A1genes/02.-Docker%20Hub/","title":"02.-Docker Hub","text":"<p>Docker Hub es el mayor repositorio del mundo de im\u00e1genes de contenedores con una gran variedad de fuentes de contenido, incluidos desarrolladores, proyectos de c\u00f3digo abierto y proveedores de software independientes (ISV Independent Software Vendor) que construyen y distribuyen su c\u00f3digo en contenedores. Los usuarios tienen acceso a repositorios p\u00fablicos gratuitos para almacenar y compartir im\u00e1genes o pueden elegir un plan de suscripci\u00f3n para repositorios privados.</p>"},{"location":"05.-Docker/04.-Manos%20a%20la%20obra/","title":"04.-Manos a la obra","text":"<p>Una vez instalado <code>docker</code> en nuestro sistema o en una m\u00e1quina virtual, empezamos con la parte pr\u00e1ctica y divertida del uso de esta tecnolog\u00eda. Para empezar vamos a familiarizarnos con la gesti\u00f3n de im\u00e1genes y contenedores desde nuestra querida l\u00ednea de comandos:</p> <p>01.-Versi\u00f3n y Gesti\u00f3n del Servicio</p> <p>02.-Usar el comando docker</p> <p>03.-Trabajar con im\u00e1genes de docker</p> <p>04.-Ejecutar un contenedor de Docker</p> <p>05.-Administrar contenedores de docker</p> <p>06.-Creaci\u00f3n de una imagen personalizada a partir de un contenedor</p> <p>07.-Guardar im\u00e1genes de docker en un repositorio de docker</p> <p>08.-Variables de entorno</p> <p>09.-Practica con Docker Playground</p> <p>10.-Limpi\u00e1ndolo todo</p>"},{"location":"05.-Docker/04.-Manos%20a%20la%20obra/01.-Versi%C3%B3n%20y%20Gesti%C3%B3n%20del%20Servicio/","title":"01.-Versi\u00f3n y Gesti\u00f3n del Servicio","text":""},{"location":"05.-Docker/04.-Manos%20a%20la%20obra/01.-Versi%C3%B3n%20y%20Gesti%C3%B3n%20del%20Servicio/#version","title":"Versi\u00f3n","text":"<pre><code>$ docker --version\n$ docker -v\n</code></pre> <pre><code>Docker version 23.0.3, build 3e7cbfdee1\n</code></pre>"},{"location":"05.-Docker/04.-Manos%20a%20la%20obra/01.-Versi%C3%B3n%20y%20Gesti%C3%B3n%20del%20Servicio/#estado-del-servicio","title":"Estado del servicio","text":"<pre><code>$ sudo systemctl status docker\n</code></pre> <pre><code>\u25cf docker.service - Docker Application Container Engine\n     Loaded: loaded (/usr/lib/systemd/system/docker.service; enabled; preset: disabled)\n     Active: active (running) since Fri 2023-04-21 10:10:47 CEST; 13min ago\nTriggeredBy: \u25cf docker.socket\n       Docs: https://docs.docker.com\n   Main PID: 685 (dockerd)\n      Tasks: 17\n     Memory: 123.2M\n        CPU: 438ms\n     CGroup: /system.slice/docker.service\n             \u2514\u2500685 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock\n\nabr 21 10:10:46 SDD dockerd[685]: time=\"2023-04-21T10:10:46.219884270+02:00\" level=info msg=\"Firewalld: i&gt;\nabr 21 10:10:46 SDD dockerd[685]: time=\"2023-04-21T10:10:46.744731604+02:00\" level=info msg=\"Default brid&gt;\nabr 21 10:10:47 SDD dockerd[685]: time=\"2023-04-21T10:10:47.019068520+02:00\" level=info msg=\"Firewalld: i&gt;\nabr 21 10:10:47 SDD dockerd[685]: time=\"2023-04-21T10:10:47.290530069+02:00\" level=info msg=\"Loading cont&gt;\nabr 21 10:10:47 SDD dockerd[685]: time=\"2023-04-21T10:10:47.415183339+02:00\" level=warning msg=\"Not using&gt;\nabr 21 10:10:47 SDD dockerd[685]: time=\"2023-04-21T10:10:47.415390693+02:00\" level=info msg=\"Docker daemo&gt;\nabr 21 10:10:47 SDD dockerd[685]: time=\"2023-04-21T10:10:47.415694639+02:00\" level=info msg=\"Daemon has c&gt;\nabr 21 10:10:47 SDD dockerd[685]: time=\"2023-04-21T10:10:47.470857994+02:00\" level=info msg=\"[core] [Serv&gt;\nabr 21 10:10:47 SDD systemd[1]: Started Docker Application Container Engine.\nabr 21 10:10:47 SDD dockerd[685]: time=\"2023-04-21T10:10:47.494255040+02:00\" level=info msg=\"API listen o&gt;\nlines 1-22/22 (END)\n</code></pre>"},{"location":"05.-Docker/04.-Manos%20a%20la%20obra/01.-Versi%C3%B3n%20y%20Gesti%C3%B3n%20del%20Servicio/#arranque-del-servicio","title":"Arranque del servicio","text":"<pre><code>$ sudo sytemctl start docker\n</code></pre>"},{"location":"05.-Docker/04.-Manos%20a%20la%20obra/01.-Versi%C3%B3n%20y%20Gesti%C3%B3n%20del%20Servicio/#parada-del-servicio","title":"Parada del servicio","text":"<pre><code>$ sudo sytemctl stop docker.socket\n</code></pre>"},{"location":"05.-Docker/04.-Manos%20a%20la%20obra/01.-Versi%C3%B3n%20y%20Gesti%C3%B3n%20del%20Servicio/#habilitacion-del-servicio","title":"Habilitaci\u00f3n del servicio","text":"<p>Podemos hacer que el servicio arranque con el sistema con el siguiente comando:</p> <pre><code>$ sudo systemctl enable docker\n</code></pre>"},{"location":"05.-Docker/04.-Manos%20a%20la%20obra/01.-Versi%C3%B3n%20y%20Gesti%C3%B3n%20del%20Servicio/#deshabilitacion-del-servicio","title":"Deshabilitaci\u00f3n del servicio","text":"<p>Podemos hacer que el servicio NO arranque con el sistema con el siguiente comando:</p> <pre><code>$ sudo systemctl disable docker\n</code></pre>"},{"location":"05.-Docker/04.-Manos%20a%20la%20obra/02.-Usar%20el%20comando%20docker/","title":"02.-Usar el comando docker","text":"<p>El uso de docker consiste en pasar a este una cadena de opciones y comandos seguida de argumentos. La sintaxis adopta esta forma:</p> <pre><code>$ docker [opciones] [comando] [argumento]\n</code></pre> <p>Para ver todos los subcomandos disponibles, escribimos lo siguiente:</p> <pre><code>$ docker\n</code></pre> <p>Si deseamos ver las opciones disponibles para un comando espec\u00edfico, escribimos lo siguiente:</p> <pre><code>$ docker &lt;subcomando-docker&gt; --help\n</code></pre> <p>Para ver informaci\u00f3n sobre <code>docker</code> relacionada con todo el sistema, utilizamos el siguiente comando:</p> <pre><code>$ docker info\n</code></pre>"},{"location":"05.-Docker/04.-Manos%20a%20la%20obra/03.-Trabajar%20con%20im%C3%A1genes%20de%20docker/","title":"03.-Trabajar con im\u00e1genes de docker","text":"<p>Los contenedores de Docker se construyen con im\u00e1genes de Docker. Por defecto, Docker obtiene estas im\u00e1genes de Docker Hub, un registro de Docker gestionado por Docker, la empresa responsable del proyecto Docker. Cualquiera puede alojar sus im\u00e1genes en Docker Hub, de modo que la mayor\u00eda de las aplicaciones y las distribuciones de Linux que necesitaremos tendr\u00e1n im\u00e1genes alojadas all\u00ed.</p> <p>Podemos buscar im\u00e1genes disponibles en Docker Hub usando el comando <code>docker</code> con el subcomando <code>search</code>. Por ejemplo, para buscar la imagen de Ubuntu, escribimos lo siguiente:</p> <pre><code>$ docker search ubuntu\n</code></pre> <pre><code>NAME                             DESCRIPTION                                     STARS     OFFICIAL   AUTOMATED\nubuntu                           Ubuntu is a Debian-based Linux operating sys\u2026   15864     [OK]       \nwebsphere-liberty                WebSphere Liberty multi-architecture images \u2026   293       [OK]       \nopen-liberty                     Open Liberty multi-architecture images based\u2026   59        [OK]       \nneurodebian                      NeuroDebian provides neuroscience research s\u2026   100       [OK]       \nubuntu-debootstrap               DEPRECATED; use \"ubuntu\" instead                50        [OK]       \nubuntu-upstart                   DEPRECATED, as is Upstart (find other proces\u2026   113       [OK]       \nubuntu/nginx                     Nginx, a high-performance reverse proxy &amp; we\u2026   84                   \nubuntu/cortex                    Cortex provides storage for Prometheus. Long\u2026   3                    \nubuntu/squid                     Squid is a caching proxy for the Web. Long-t\u2026   54                   \nubuntu/apache2                   Apache, a secure &amp; extensible open-source HT\u2026   57                   \nubuntu/mysql                     MySQL open source fast, stable, multi-thread\u2026   45                   \nubuntu/kafka                     Apache Kafka, a distributed event streaming \u2026   29                   \nubuntu/bind9                     BIND 9 is a very flexible, full-featured DNS\u2026   51                   \nubuntu/redis                     Redis, an open source key-value store. Long-\u2026   17                   \nubuntu/prometheus                Prometheus is a systems and service monitori\u2026   40                   \nubuntu/postgres                  PostgreSQL is an open source object-relation\u2026   27                   \nubuntu/zookeeper                 ZooKeeper maintains configuration informatio\u2026   5                    \nubuntu/grafana                   Grafana, a feature rich metrics dashboard &amp; \u2026   9                    \nubuntu/memcached                 Memcached, in-memory keyvalue store for smal\u2026   5                    \nubuntu/prometheus-alertmanager   Alertmanager handles client alerts from Prom\u2026   8                    \nubuntu/dotnet-deps               Chiselled Ubuntu for self-contained .NET &amp; A\u2026   7                    \nubuntu/dotnet-runtime            Chiselled Ubuntu runtime image for .NET apps\u2026   5                    \nubuntu/cassandra                 Cassandra, an open source NoSQL distributed \u2026   2                    \nubuntu/dotnet-aspnet             Chiselled Ubuntu runtime image for ASP.NET a\u2026   4                    \nubuntu/telegraf                  Telegraf collects, processes, aggregates &amp; w\u2026   4   \n</code></pre> <p>El comando que acabamos de ejecutar buscar\u00e1 en los repositorios de Docker Hub en busca de im\u00e1genes que coincidan con el criterio de b\u00fasqueda y devuelve los posibles candidatos.</p> <p>En la columna de OFFICIAL, OK indica que la imagen creada est\u00e1 avalada por la empresa responsable del proyecto. Una vez que identifique la imagen que desear\u00eda usar, podemos descargarla utilizando el subcomando docker pull.</p> <pre><code>$ docker pull ubuntu\n</code></pre> <p>Para ver las im\u00e1genes que tenemos disponibles localmente utilizamos el comando:</p> <pre><code>$ docker images\n</code></pre>"},{"location":"05.-Docker/04.-Manos%20a%20la%20obra/04.-Ejecutar%20un%20contenedor%20de%20Docker/","title":"04.-Ejecutar un contenedor de Docker","text":"<p>El contenedor <code>hello-world</code> que creamos en la instalaci\u00f3n es un ejemplo de un contenedor que se ejecuta y se cierra tras emitir un mensaje de prueba. Los contenedores pueden ofrecer una utilidad mucho mayor y ser interactivos</p> <p>Como ejemplo, ejecutemos un contenedor usando la imagen m\u00e1s reciente de Ubuntu. La combinaci\u00f3n de los conmutadores <code>-i</code> y <code>-t</code> le proporcionan un acceso interactivo del shell al contenedor:</p> <pre><code>$ docker run -it ubuntu\n</code></pre> <p>Nuestros s\u00edmbolos del sistema deben cambiar para reflejar el hecho de que ahora estamos trabajando dentro del contenedor.</p> <p>Ahora podemos ejecutar cualquier comando dentro del contenedor. Por ejemplo, actualizar los repositorios. No es necesario prefijar ning\u00fan comando con sudo, ya que todas las operaciones dentro del contenedor se ejecutan por defecto con el usuario root:</p> <pre><code>$ apt update\n</code></pre> <p>Importante: Cuando trabajamos con contenedores debemos tener en cuenta un detalle y es que las im\u00e1genes que implementamos en muchas ocasiones pueden no tener instaladas algunas aplicaciones que por defecto s\u00ed vienen instaladas en otras im\u00e1genes. Un claro ejemplo es que el contenedor de Ubuntu que estamos utilizando no tiene el editor de texto <code>nano</code>.</p> <p>El motivo por el que no est\u00e1 instalado por defecto este editor es simple, las im\u00e1genes de Docker buscan ser lo m\u00e1s ligeras y modulares posibles para ofrecer servicios de una manera sencilla y r\u00e1pida. Por lo que instalar programas innecesarios que har\u00edan que el tama\u00f1o de la m\u00e1quina fuese mayor va en contra del prop\u00f3sito por el que fue creada esta tecnolog\u00eda.</p> <p>Para instalar nano ejecutamos el comando apt seguido del programa que deseamos instalar.</p> <pre><code>$ apt install nano\n</code></pre>"},{"location":"05.-Docker/04.-Manos%20a%20la%20obra/05.-Administrar%20contenedores%20de%20docker/","title":"05.-Administrar contenedores de docker","text":"<p>Para mostrar los contenedores activos utilizamos el\u00a0 comando:</p> <pre><code>$\u00a0 docker ps\n</code></pre> <p>Si el comando no ha devuelto ning\u00fan contenedor es porque si no a\u00f1adimos la opci\u00f3n\u00a0<code>-d</code>\u00a0 al comando <code>docker run</code>, cuando salimos del contenedor \u00e9ste se para.</p> <p>Para comprobar los contenedores activos e inactivos utilizamos el comando:</p> <pre><code>$ docker ps -a\n</code></pre> <p>Para ver el \u00faltimo contenedor que ha sido creado utilizamos la opci\u00f3n <code>-l</code>:</p> <pre><code>$ docker ps -l\n</code></pre> <p>Para iniciar un contenedor detenido, utilizamos docker start, seguido del nombre del contenedor\u00a0o el ID. Vamos a iniciar el contenedor basado en Ubuntu con el ID cf9cc8313e87:</p> <pre><code>$ docker start cf9cc8313e87\n</code></pre> <p>Para detener un contenedor, utilizamos <code>docker stop</code>, seguido del ID o nombre del contenedor. Esta vez usaremos el nombre que Docker asign\u00f3 al contenedor, que es <code>nostalgic_grothendieck</code>:</p> <pre><code>$ docker stop nostalgic_grothendieck\n</code></pre> <p>Del mismo modo que hemos borrado el contenedor una vez detenido, tambi\u00e9n podemos eliminarlo mientras est\u00e1 a\u00fan corriendo con la opci\u00f3n -f.</p> <pre><code>$ docker rm -f nombre_contenedor\n</code></pre> <p>Podemos iniciar un nuevo contenedor y darle un nombre usando el conmutador <code>\u2013name</code>. Tambi\u00e9n podemos usar el conmutador \u2013rm para crear un contenedor que se elimine de forma autom\u00e1tica cuando se detenga. Consulte el comando docker run help para obtener m\u00e1s informaci\u00f3n sobre estas y otras opciones.</p>"},{"location":"05.-Docker/04.-Manos%20a%20la%20obra/06.-Creaci%C3%B3n%20de%20una%20imagen%20personalizada%20a%20partir%20de%20un%20contenedor/","title":"06.-Creaci\u00f3n de una imagen personalizada a partir de un contenedor","text":"<p>Los contenedores pueden convertirse en im\u00e1genes que podremos usar para crear contenedores nuevos. Veamos c\u00f3mo funciona.</p> <p>Despu\u00e9s de instalar el editor de texto <code>nano</code> dentro del contenedor de Ubuntu, dispondremos de un contenedor que se ejecuta a partir de una imagen, pero este es diferente de la imagen que utilizamos para crearlo. Sin embargo, quiz\u00e1s deseemos reutilizar este contenedor que ya tiene instalado <code>nano</code> como base de nuevas im\u00e1genes posteriormente.</p> <pre><code>$ docker commit -m \u00abEscribimos una breve descripci\u00f3n del contenedor\u00bb -a \u00abNombre del autor\u00bb id_contenedor repositorio/nombre_nueva_imagen\n</code></pre> <p>El conmutador <code>-m</code> es el mensaje que permite a otros saber qu\u00e9 cambios realizamos, mientras que <code>-a</code> se utiliza para especificar el autor. El <code>container_id</code> es el que observamos anteriormente cuando iniciamos la sesi\u00f3n interactiva de Docker. A menos que hayamos creado repositorios adicionales en Docker Hub, el campo repositorio generalmente corresponde a nuestro nombre de usuario de Docker Hub.</p> <p>Partiendo del siguiente caso vamos a crear una imagen personalizada de ubuntu con el editor de texto preinstalado por nosotros.</p> <p>Copiamos el ID del contenedor.</p> <p>Con el comando exit salimos del contenedor y adaptamos el comando anterior a nuestro propio caso.</p> <pre><code>$ docker commit -m \"Ubuntu con editor de texto\" -a Mentecato bea6a695cbc3 ubuntu_con_nano\n</code></pre> <p>Comprobamos que se ha guardado la imagen localmente con el nombre <code>ubuntu_con_nano</code></p> <pre><code>$ docker images\n</code></pre>"},{"location":"05.-Docker/04.-Manos%20a%20la%20obra/07.-Guardar%20im%C3%A1genes%20de%20docker%20en%20un%20repositorio%20de%20docker/","title":"07.-Guardar im\u00e1genes de docker en un repositorio de docker","text":"<p>En primer lugar, nos registramos en Docker Hub accediendo a su p\u00e1gina https://hub.docker.com/.</p> <p>A continuaci\u00f3n iniciamos sesi\u00f3n en Docker Hub con el siguiente comando. </p> <p>Importante: Se le solicitar\u00e1 autenticarse usando su contrase\u00f1a de Docker Hub. </p> <pre><code>$ docker login -u nombre_de_usuario\n</code></pre> <p>Para el ejemplo que se muestra en el \u00faltimo paso, deberemos escribir lo siguiente:</p> <pre><code>$ docker tag pjvdockerhub/ubuntu_con_nano pjvdockerhub/ubuntu_con_nano\n</code></pre> <p>Para guardar la imagen de nuestro contenedor en nuestro repositorio de Docker Hub utilizamos el comando.</p> <pre><code>$ docker push nombre_de_usuario/nombre_imagen\n</code></pre> <p>Siguiendo el esquema anterior comando quedar\u00eda as\u00ed.</p> <pre><code>$ docker push pjvdockerhub/ubuntu_con_nano\n</code></pre> <p>Iniciamos sesi\u00f3n en nuestro repositorio de docker y comprobamos que ya tenemos disponible nuestra imagen.</p> <p>Para utilizar esta imagen en cualquier equipo primero iniciamos sesi\u00f3n en docker con el comando <code>docker login -u nombre_usuario</code>y luego escribimos el siguiente comando:</p> <pre><code>$ docker pull nombre_de_usuario/imagen\n</code></pre> <p>En mi caso el comando queda del siguiente modo:</p> <pre><code>$ docker pull pjvdockerhub/ubuntu_con_nano\n</code></pre>"},{"location":"05.-Docker/04.-Manos%20a%20la%20obra/08.-Variables%20de%20entorno/","title":"08.-Variables de entorno","text":"<p>Las variables de entorno en Docker son una forma de proporcionar configuraci\u00f3n din\u00e1mica a los contenedores. Podemos establecer variables de entorno en las instancias de contenedor para proporcionar configuraci\u00f3n din\u00e1mica a la aplicaci\u00f3n o el script que se ejecuta en el contenedor.</p> <p>Para establecer una variable de entorno en un contenedor, puede utilizar el argumento <code>--env</code> o <code>-e</code> con el comando <code>docker run</code>. Por ejemplo, para establecer la variable de entorno <code>MI_VAR</code> en el valor <code>mi_valor</code>, puede ejecutar lo siguiente:</p> <pre><code>docker run --env MY_VAR=my_value my_image\n</code></pre> <p>Tambi\u00e9n podemos establecer variables de entorno en un archivo <code>.env</code> y utilizar el comando <code>docker-compose</code> para ejecutar los contenedores.</p>"},{"location":"05.-Docker/04.-Manos%20a%20la%20obra/09.-Practica%20con%20Docker%20Playground/","title":"09.-Practica con Docker Playground","text":"<p>Podemos practicar gratuitamente Docker desde la siguiente p\u00e1gina https://labs.play-with-docker.com/</p> <p>Hacemos clic sobre A\u00f1adir nueva instancia y ya podemos comenzar a practicar con Docker.</p> <p>Comprobamos la versi\u00f3n de Docker que viene instalada.</p> <p>Ejercicio: Utiliza Docker Playground para instalar un servidor web Apache.</p> <p>Soluci\u00f3n:</p> <p>En primer lugar, buscamos una imagen de apache en los repositorios de Docker Hub.</p> <pre><code>$ docker search apache\n</code></pre> <p>Descargamos la imagen oficial de apache httpd.</p> <pre><code>$ docker pull httpd\n</code></pre> <p>Creamos el contenedor de apache.</p> <pre><code>$ docker run -dit --name servidor_web -p 80:80 httpd\n</code></pre> <p>Par\u00e1metros docker run:</p> <p><code>-d</code> = permite ejecutar el contenedor en segundo plano</p> <p><code>-i</code> = permite que el contenedor sea interactivo</p> <p><code>\u2013t</code> = proporciona al contenedor una terminal</p> <p><code>--name</code> = nombre del contenedor</p> <p><code>-p</code> = permite mapear puertos desde el interior del contenedor 80:80 al exterior del contenedor 80:80. El puerto que utilizamos ha sido el 80 porque es el puerto por defecto que utiliza apache para conexiones no seguras.</p>"},{"location":"05.-Docker/04.-Manos%20a%20la%20obra/10.-Limpi%C3%A1ndolo%20todo/","title":"10.-Limpi\u00e1ndolo todo","text":"<ul> <li>Para ver en qu\u00e9 y de cu\u00e1nto espacio estamos utilizando en nuestro sistema de contenedores docker:</li> </ul> <pre><code>$ docker system df\n</code></pre> <ul> <li>Para borrar todos los contenedores:</li> </ul> <pre><code>$ docker container prune\n</code></pre> <ul> <li>Para listar los vol\u00famenes locales existentes  <code>$ docker volume ls</code></li> <li>Para borrar todos los vol\u00famenes locales no asociados a un contenedor:</li> </ul> <pre><code>$ docker volume prune\n</code></pre> <ul> <li>Para borrar vol\u00famenes locales individualmente:</li> </ul> <pre><code>$ docker volume rm \u00abvolumen_local\u00bb\n</code></pre> <ul> <li>Para borrar todas las im\u00e1genes:</li> </ul> <pre><code>$ docker rmi $(docker images -a -q)\n</code></pre> <ul> <li>Para limpiar todos los contenedores detenidos, las im\u00e1genes no utilizadas y los vol\u00famenes no utilizados:</li> </ul> <pre><code>$ docker system prune\n</code></pre>"},{"location":"05.-Docker/04.-Manos%20a%20la%20obra/11.-Ejercicios%20creaci%C3%B3n%20de%20contenedores%20b%C3%A1sicos%20I/","title":"11.-Ejercicios creaci\u00f3n de contenedores b\u00e1sicos I","text":""},{"location":"05.-Docker/04.-Manos%20a%20la%20obra/11.-Ejercicios%20creaci%C3%B3n%20de%20contenedores%20b%C3%A1sicos%20I/#ejercicios-para-repasar","title":"Ejercicios para repasar","text":"<ul> <li>Instala docker en una m\u00e1quina y config\u00faralo para que se pueda usar con un usuario sin privilegios.</li> </ul> <pre><code>$ sudo pacman -Syy\n$ sudo pacman -S docker docker-compose\n$ sudo systemctl enable docker\n$ sudo systemctl start docker\n$ sudo usermod -aG docker $USER\n$ reboot\n</code></pre> <ul> <li>Ejecuta un contenedor a partir de la imagen <code>hello-word</code>. Comprueba que nos devuelve la salida adecuada. Comprueba que no se est\u00e1 ejecutando. Lista los contenedores que est\u00e1n parados. Borra el contenedor.</li> </ul> <pre><code>$ docker run --name mi_contenedor hello-world\n</code></pre> <pre><code>$ docker ps\n</code></pre> <pre><code>$ docker ps -a\n</code></pre> <pre><code>$ docker rm mi_contenedor\n</code></pre> <pre><code>$ docker image rm hello-world\n</code></pre> <ul> <li>Crea un contenedor interactivo desde una imagen <code>debian</code>. Instala un paquete (por ejemplo <code>nano</code>).  Vuelve a iniciar el contenedor y accede de nuevo a \u00e9l de forma interactiva. \u00bfSigue instalado el <code>nano</code>?. Sal del contenedor, y b\u00f3rralo. Crea un nuevo contenedor interactivo desde la misma imagen. \u00bfTiene el <code>nano</code> instalado?</li> </ul> <pre><code>$ docker search debian\n$ docker run -it --name mi_contenedor debian\n$ apt update\n$ apt upgrade\n$ apt install nano\n</code></pre> <p>Sal de la terminal, \u00bfsigue el contenedor corriendo?</p> <pre><code>$ docker ps\n\u00abNo\u00bb\n</code></pre> <p>\u00bfPor qu\u00e9?</p> <pre><code>\u00abEl contenedor se detiene porque el proceso principal que se ejecuta en el contenedor, bash en este caso, termina su ejecuci\u00f3n\u00bb\n</code></pre> <p>Vuelve a iniciar el contenedor y accede de nuevo a \u00e9l de forma interactiva. </p> <pre><code>$ docker start -i mi_contenedor\n</code></pre> <p>\u00bfSigue instalado  <code>nano</code>?.</p> <pre><code>\u00abS\u00ed\u00bb\n</code></pre> <p>Sal del contenedor, y b\u00f3rralo. Crea un nuevo contenedor interactivo desde la misma imagen.</p> <pre><code>$ docker rm debian\n$ docker ps -a\n$ docker run -it --name mi_nuevo_contenedor debian\n</code></pre> <p>\u00bfTiene <code>nano</code> instalado?</p> <pre><code>\u00abNo\u00bb\n</code></pre> <ul> <li>Crea un contenedor demonio con un servidor <code>nginx</code> usando la imagen oficial de nginx.</li> </ul> <pre><code>$ docker run -d -p 8080:80 --name servidor_nginx nginx\n</code></pre> <p>Al crear el contenedor, \u00bfhas tenido que indicar alg\u00fan comando para que lo ejecute?</p> <pre><code>\u00abNo\u00bb\n</code></pre> <p>Accede al navegador web y comprueba que el servidor est\u00e1 funcionando.   <code>$ firefox localhost</code>  Muestra los logs del contenedor.  <code>shell  $ docker logs servidor_nginx</code></p> <ul> <li>Crea un contenedor con la aplicaci\u00f3n Nextcloud, mirando la documentaci\u00f3n en docker Hub, para personalizar el nombre de la base de datos sqlite que va a utilizar.</li> </ul> <pre><code>$ docker run -d -p 8080:80 -v nextcloud:/var/www/html --name nextcloud-db -e SQLITE_DATABASE=BD nextcloud\n</code></pre> <p>Este comando crear\u00e1 un contenedor de Nextcloud con una base de datos SQLite llamada <code>BD</code>. El contenedor se ejecutar\u00e1 en segundo plano (<code>-d</code>), expondr\u00e1 el puerto <code>8080</code> (<code>-p</code>) y se vincular\u00e1 a un volumen llamado <code>nextcloud</code> (<code>-v</code>). Tambi\u00e9n se asignar\u00e1 un nombre al contenedor (<code>--name</code>) para facilitar su referencia y se especificar\u00e1 la variable de entorno <code>SQLITE_DATABASE</code> para nombrar la base de datos.</p>"},{"location":"05.-Docker/04.-Manos%20a%20la%20obra/11.-Ejercicios%20creaci%C3%B3n%20de%20contenedores%20b%C3%A1sicos%20I/#ejercicio-para-entregar","title":"Ejercicio para entregar","text":"<p>Crearemos un contenedor demonio a partir de la imagen <code>nginx</code>, el contenedor se debe llamar <code>servidor_web</code> y se debe acceder a \u00e9l utilizando el puerto 8181 del ordenador donde tengas instalado docker.</p> <p>Entrega un fichero comprimido o un documento markdown con los siguientes pantallazos:</p> <ol> <li>Pantallazo donde se vea la creaci\u00f3n del contenedor y podamos comprobar que el contenedor est\u00e1 funcionando.</li> <li>Pantallazo donde se vea el acceso al servidor web utilizando un navegador web (recuerda que tienes que acceder a la ip del ordenador donde tengas instalado docker)</li> <li>Pantallazo donde se vean las im\u00e1genes que tienes en tu registro local.</li> <li>Pantallazo donde se vea como se elimina el contenedor (recuerda que antes debe estar parado el contenedor).</li> </ol>"},{"location":"05.-Docker/05.-Gesti%C3%B3n%20de%20im%C3%A1genes/","title":"05.- Gesti\u00f3n de im\u00e1genes","text":"<p>Hasta ahora hemos creado contenedores a partir de las im\u00e1genes que encontramos en Docker Hub. Estas im\u00e1genes las han creado otras personas.</p> <p>Para crear un contenedor que sirva nuestra aplicaci\u00f3n, tendremos que crear una imagen personaliza, es lo que llamamos \u201cdockerizar\u201d una aplicaci\u00f3n.</p> <p></p> <p>Una imagen docker es un paquete autocontenido que contiene todo lo necesario para ejecutar una aplicaci\u00f3n o servicio en un contenedor docker. Hay dos formas principales de crear una imagen docker:</p> <ul> <li> <p>A partir de un contenedor: Consiste en crear un contenedor a partir de una imagen base, modificarlo seg\u00fan las necesidades y luego guardar los cambios como una nueva imagen. Esta forma es \u00fatil para hacer pruebas r\u00e1pidas o personalizar una imagen existente.</p> </li> <li> <p>A partir de un <code>Dockerfile</code>: La segunda forma consiste en escribir un Dockerfile con las instrucciones para construir la imagen desde cero. Esta forma es m\u00e1s recomendable para automatizar el proceso de creaci\u00f3n de im\u00e1genes, documentar los pasos y facilitar la reproducci\u00f3n y el mantenimiento de la imagen.</p> </li> </ul>"},{"location":"05.-Docker/05.-Gesti%C3%B3n%20de%20im%C3%A1genes/01.-Imagen%20a%20partir%20de%20un%20contenedor/","title":"01.-Imagen a partir de un contenedor","text":"<p>La primera forma para personalizar im\u00e1genes es partiendo de un contenedor que hayamos modificado.</p> <ul> <li>Arranca un contenedor a partir de una imagen base.</li> </ul> <pre><code>$ docker run -it --name mi_apache debian bash\n</code></pre> <ul> <li>Realiza las modificaciones pertinentes en el contenedor (instalaciones, modificaci\u00f3n de archivos,\u2026).</li> </ul> <pre><code>root@\u00abcontenedor\u00bb:/# apt update &amp;&amp; apt install apache2 -y\nroot@\u00abcontenedor\u00bb:/# echo \"&lt;h1&gt;Dockerizando Apache&lt;/h1&gt;\" &gt; /var/www/html/index.html\nroot@\u00abcontenedor\u00bb:/# exit\n</code></pre> <p>El primer comando actualiza la lista de paquetes disponibles e instala el servidor web <code>apache2</code> en el contenedor. El operador <code>&amp;&amp;</code> indica que el segundo comando solo se ejecuta si el primero tiene \u00e9xito. El indicador <code>-y</code> permite instalar el paquete sin confirmaci\u00f3n.</p> <p>El segundo comando crea un fichero llamado <code>index.html</code> en el directorio <code>/var/www/html</code> del contenedor, que es el directorio ra\u00edz por defecto del servidor web <code>apache1</code>. El fichero contiene una etiqueta HTML que muestra el texto <code>Curso Docker</code> como un encabezado de nivel 1. El operador <code>&gt;</code> redirige la salida del comando <code>echo</code> al fichero indicado.</p> <ul> <li>Crear una nueva imagen partiendo de ese contenedor usando <code>docker commit</code>. Con esta instrucci\u00f3n se crear\u00e1 una nueva imagen con las capas de la  imagen base m\u00e1s la capa propia del contenedor. Si no indicamos etiqueta en el nombre, se pondr\u00e1 la etiqueta <code>latest</code>.</li> </ul> <pre><code>$ docker commit mi_apache mi_nuevo_apache:v1\nsha256:017a4489735f91f68366f505e4976c111129699785e1ef609aefb51615f98fc4\n\n$ docker images\nREPOSITORY       TAG       IMAGE ID       CREATED         SIZE\nmi_nuevo_apache   v1        4a5b320915d6   3 seconds ago   253MB\ndebian           latest    34b4fa67dc04   8 hours ago     124MB\n...\n</code></pre> <ul> <li>Podr\u00edamos crear un nuevo contenedor a partir de esta nueva imagen, pero al crear una imagen con este m\u00e9todo no podemos configurar el proceso que se va a ejecutar por defecto al crear el contenedor (el proceso por defecto que se ejecuta ser\u00eda el de la imagen base). Por lo tanto en la creaci\u00f3n del nuevo contenedor tendr\u00edamos que indicar el  proceso que queremos ejecutar. En este caso para ejecutar el servidor web <code>apache2</code> tendremos que ejecutar el comando <code>apache2ctl -D FOREGROUND</code>:</li> </ul> <pre><code>$ docker run -d -p 8080:80 \\\n             --name servidor_web \\\n             mi_nuevo_apache:v1 \\\n             bash -c \"apache2ctl -D FOREGROUND\"\n</code></pre> <p>Una vez lanzado podemos acceder a nuestro nuevo apache2 mediante la url http://localhost:8080/</p>"},{"location":"05.-Docker/05.-Gesti%C3%B3n%20de%20im%C3%A1genes/02.-Imagen%20a%20partir%20de%20un%20fichero%20Dockerfile/","title":"02.-Imagen a partir de un fichero Dockerfile","text":"<p>El m\u00e9todo anterior tiene algunos inconvenientes:</p> <ul> <li> <p>No se puede reproducir la imagen. Si la perdemos tenemos que recordar toda la secuencia de \u00f3rdenes que hab\u00edamos ejecutado desde que arrancamos el contenedor hasta que ten\u00edamos una versi\u00f3n definitiva e hicimos <code>docker commit</code>.</p> </li> <li> <p>No podemos configurar el proceso que se ejecutar\u00e1 en el contenedor que hemos creado desde la imagen. Los contenedores creados a partir de la nueva imagen ejecutaran por defecto el proceso que estaba configurado en la imagen base.</p> </li> <li> <p>No podemos cambiar la imagen de base. Si ha habido alguna actualizaci\u00f3n, problemas de seguridad, etc. con la imagen de base tenemos que descargar la nueva versi\u00f3n, volver a crear un nuevo contenedor basado en ella y ejecutar de nuevo toda la secuencia de \u00f3rdenes.</p> </li> </ul> <p>Por todas estas razones, el m\u00e9todo preferido para la creaci\u00f3n de im\u00e1genes es el uso de ficheros <code>Dockerfile</code> y el comando <code>docker build</code>. Con este m\u00e9todo vamos a tener las siguientes ventajas:</p> <ul> <li> <p>Podremos reproducir la imagen f\u00e1cilmente ya que en el fichero <code>Dockerfile</code> tenemos todas y cada una de las \u00f3rdenes necesarias para la construcci\u00f3n de la imagen. Si adem\u00e1s ese Dockerfile est\u00e1 guardado en un sistema de control de versiones como git podremos, no s\u00f3lo reproducir la imagen sino asociar los cambios en el <code>Dockerfile</code> a los cambios en las versiones de las im\u00e1genes creadas.</p> </li> <li> <p>Podremos configurar el proceso que se ejecutar\u00e1 por defecto en los contenedores creados a partir de la nueva imagen.</p> </li> <li> <p>Si queremos cambiar la imagen de base esto es extremadamente sencillo con un <code>Dockerfile</code>; \u00fanicamente tendremos que modificar la primera l\u00ednea de ese fichero tal y como explicaremos m\u00e1s adelante.</p> </li> </ul>"},{"location":"05.-Docker/05.-Gesti%C3%B3n%20de%20im%C3%A1genes/02.-Imagen%20a%20partir%20de%20un%20fichero%20Dockerfile/#gestion-de-imagenes","title":"Gesti\u00f3n de im\u00e1genes","text":"<p>Para crear una imagen de docker, se sigue el siguiente proceso b\u00e1sico:</p> <ol> <li>Crear un archivo <code>Dockerfile</code></li> <li>Escribir las instrucciones del <code>Dockerfile</code></li> <li>Construir la imagen</li> <li>Etiquetar la imagen</li> <li>Subir la imagen a un repositorio de im\u00e1genes</li> </ol>"},{"location":"05.-Docker/05.-Gesti%C3%B3n%20de%20im%C3%A1genes/02.-Imagen%20a%20partir%20de%20un%20fichero%20Dockerfile/#ejemplo-de-dockerfile-servidor-apache","title":"Ejemplo de <code>Dockerfile</code>: Servidor Apache","text":"<p>Para simplificar el proceso de crear una imagen a partir de un contenedor podemos utilizar un <code>Dockerfile</code> y un volumen local con nuestra p\u00e1gina web en este ejemplo particular para obtener una idea de nuestros objetivos.</p> <ul> <li>Creamos un directorio en el sistema local que contendr\u00e1 el archivo <code>index.html</code>. Por ejemplo, podemos crear un directorio llamado <code>html</code> y dentro de \u00e9l colocar el archivo <code>index.html</code> con el contenido deseado.</li> </ul> <pre><code>$ mkdir html\n$ cd html\n$ echo \"&lt;h1&gt;Dockerizando Apache&lt;/h1&gt;\" &gt; index.html\n</code></pre> <ul> <li>Creamos un archivo llamado <code>Dockerfile</code> en el mismo directorio donde est\u00e1 el directorio <code>html</code> (no dentro de \u00e9l) en el que colocaremos el siguiente contenido:</li> </ul> <pre><code>FROM debian\n\nRUN apt-get update &amp;&amp; apt-get install -y apache2\n\nCOPY ./html /var/www/html\n\nEXPOSE 80\n\nCMD [\"apache2ctl\", \"-D\", \"FOREGROUND\"]\n</code></pre> <p>Este <code>Dockerfile</code> utiliza la imagen base <code>debian</code>, actualiza los repositorios, instala el servidor Apache y copia el contenido del directorio <code>html</code> local al directorio <code>/var/www/html</code> dentro del contenedor. Luego expone el puerto 80 y ejecuta el comando <code>apache2ctl -D FOREGROUND</code> para iniciar el servidor Apache.</p> <ul> <li>Ahora podemos construir la imagen de Docker ejecutando el siguiente comando en el directorio donde se encuentra el <code>Dockerfile</code>:</li> </ul> <pre><code>docker build -t mi_nuevo_apache:v1 .\n</code></pre> <p>Este comando construir\u00e1 la imagen de Docker utilizando el <code>Dockerfile</code> y la etiquetar\u00e1 como <code>mi_nuevo_apache:v1</code>.</p> <ul> <li>Una vez que la imagen se haya construido correctamente, podemos ejecutar el siguiente comando para iniciar un contenedor basado en esa imagen y utilizar un volumen local para el archivo <code>index.html</code>:</li> </ul> <pre><code>docker run -d -p 8080:80 --name servidor_web -v ./html:/var/www/html mi_nuevo_apache:v1\n</code></pre> <p>Con estos pasos, tendremos un contenedor en ejecuci\u00f3n que utiliza el archivo <code>index.html</code> desde el volumen local y expone el puerto 8080 en nuestra m\u00e1quina host.</p> <p>Finalmente accederemos con nuestro navegador a la direcci\u00f3n: http://localhost:8080</p> <p>Nota Aclaratoria sobre sincronizaci\u00f3n de directorios:</p> <p>\u00bfSe sincronizan los directorios <code>./hml</code> y <code>/var/www/html</code> autom\u00e1ticamente?</p> <pre><code>  En principio, **no**. En el fichero `dockerfile` proporcionado no se establece una sincronizaci\u00f3n en tiempo real entre el directorio `./html` de nuestro sistema local y el directorio `/var/www/html` del contenedor. La instrucci\u00f3n `COPY` en el `Dockerfile` simplemente **copia** el contenido del directorio local `html` al directorio `/var/www/html` dentro del contenedor durante el proceso de construcci\u00f3n de la imagen.\n</code></pre> <p>Una vez que se ha construido y se est\u00e1 ejecutando un contenedor a partir de la imagen, los cambios realizados en el directorio local <code>html</code> no se reflejar\u00e1n autom\u00e1ticamente en el directorio <code>/var/www/html</code> del contenedor. Esto significa que si realizamos modificaciones en los archivos en el directorio <code>html</code> de nuestro sistema local despu\u00e9s de iniciar el contenedor, los cambios no se sincronizar\u00e1n autom\u00e1ticamente en el contenedor.</p> <p>Sin embargo, hay formas de lograr la sincronizaci\u00f3n en tiempo real entre el sistema local y el contenedor. Una de las formas m\u00e1s comunes es utilizando vol\u00famenes de Docker.</p> <p>Al ejecutar el contenedor, podemos usar la opci\u00f3n <code>-v</code> o <code>--volume</code> para montar un volumen y establecer una sincronizaci\u00f3n bidireccional entre un directorio en tu sistema local y un directorio dentro del contenedor. Por ejemplo:</p> <p><code>docker run -d -p 8080:80 --name servidor_web -v /ruta/al/directorio/html:/var/www/html mi_nuevo_apache:v1</code></p> <p>En este caso, <code>/ruta/al/directorio/html</code> representa la ruta al directorio <code>html</code> en nuestro sistema local, y <code>/var/www/html</code> es el directorio dentro del contenedor. Con esta configuraci\u00f3n, cualquier cambio realizado en el directorio <code>html</code> de nuestro sistema local se sincronizar\u00e1 autom\u00e1ticamente con el directorio <code>/var/www/html</code> dentro del contenedor.</p> <p>Esta sincronizaci\u00f3n en tiempo real nos permite realizar cambios en los archivos del directorio <code>html</code> en nuestro sistema local y ver los resultados reflejados inmediatamente en el contenedor sin necesidad de reconstruir la imagen o reiniciar el contenedor.</p> <p>Es importante tener en cuenta que la sincronizaci\u00f3n de directorios utilizando vol\u00famenes solo se produce mientras el contenedor est\u00e1 en ejecuci\u00f3n. Si se elimina el contenedor, los datos del volumen no persistir\u00e1n a menos que se utilicen vol\u00famenes de Docker persistentes o se realice una configuraci\u00f3n adicional.</p>"},{"location":"05.-Docker/05.-Gesti%C3%B3n%20de%20im%C3%A1genes/02.-Imagen%20a%20partir%20de%20un%20fichero%20Dockerfile/#el-fichero-dockerfile","title":"El fichero <code>Dockerfile</code>","text":"<p>El archivo\u00a0<code>Dockerfile</code>\u00a0es un archivo de texto que contiene las instrucciones para construir una imagen de Docker. En \u00e9l se especifican el sistema operativo base, las dependencias, las bibliotecas y las configuraciones necesarias para la aplicaci\u00f3n. Contiene un conjunto de instrucciones que ser\u00e1n ejecutadas de forma secuencial para construir una nueva imagen docker. Cada una de estas instrucciones crea una nueva capa en la imagen que estamos creando y debe empezar por una palabra clave en may\u00fasculas, como FROM, RUN, COPY, etc. <code>Dockerfile</code> tambi\u00e9n puede especificar variables de entorno, puertos expuestos, comandos de entrada y salida y otros metadatos</p> <p>En definitiva, <code>Dockerfile</code> es un fichero de texto que contiene una serie de instrucciones para construir una imagen docker. Cada instrucci\u00f3n a\u00f1ade una capa a la imagen.</p>"},{"location":"05.-Docker/05.-Gesti%C3%B3n%20de%20im%C3%A1genes/02.-Imagen%20a%20partir%20de%20un%20fichero%20Dockerfile/#formato-de-un-dockerfile","title":"Formato de un <code>Dockerfile</code>","text":"<p>El fichero <code>Dockerfile</code> se crear\u00e1 dentro de la carpeta donde tengamos el proyecto</p> <pre><code>FROM ubuntu:14.04\nENTRYPOINT [\"/bin/echo\"]\n</code></pre>"},{"location":"05.-Docker/05.-Gesti%C3%B3n%20de%20im%C3%A1genes/02.-Imagen%20a%20partir%20de%20un%20fichero%20Dockerfile/#ejecutar-un-comando","title":"Ejecutar un comando","text":"<p>Si en lugar de utilizar entrypoints queremos pasar par\u00e1metros, podemos utilizar CMD</p> <pre><code>CMD [\"/bin/echo\" , \"Hi Docker !\"]\n</code></pre> <p>Hay varias instrucciones que podemos usar en la construcci\u00f3n de un Dockerfile, pero la estructura fundamental del fichero es:</p> <ul> <li>Indicamos imagen base: <code>FROM</code></li> <li>Metadatos: <code>LABEL</code></li> <li>Instrucciones de construcci\u00f3n: <code>RUN, COPY, ADD, WORKDIR</code></li> <li>Configuraci\u00f3n: Variable de entornos, usuarios, puertos: <code>USER, EXPOSE, ENV</code></li> <li>Instrucciones de arranque: <code>CMD, ENTRYPOINT</code></li> </ul>"},{"location":"05.-Docker/05.-Gesti%C3%B3n%20de%20im%C3%A1genes/02.-Imagen%20a%20partir%20de%20un%20fichero%20Dockerfile/#instrucciones-en-un-dockerfile","title":"Instrucciones en un <code>Dockerfile</code>","text":"<p>\u00c9stas son las principales instrucciones que podemos usar:</p> <ul> <li> <p><code>FROM</code>: Sirve para especificar la imagen sobre la que voy a construir la m\u00eda. Ejemplo: <code>FROM php:7.4-apache</code></p> </li> <li> <p><code>LABEL</code> : Sirve para a\u00f1adir metadatos a la imagen mediante <code>\u00abclave\u00bb=\u00abvalor\u00bb</code>. Ejemplo: <code>LABEL company=iesromerovargas</code> </p> </li> <li> <p><code>COPY</code>: Para copiar ficheros desde mi equipo a la imagen. Esos ficheros deben estar en el mismo contexto (carpeta o repositorio). Su sintaxis es <code>COPY [--chown=&lt;usuario&gt;:&lt;grupo&gt;] src dest</code>. Por ejemplo: <code>COPY --chown=www-data:www-data myapp /var/www/html</code></p> </li> <li> <p><code>ADD</code>: Es similar a <code>COPY</code> pero tiene funcionalidades adicionales como especificar URLs y tratar archivos comprimidos.</p> </li> <li> <p><code>RUN</code>: Ejecuta una orden creando una nueva capa. El comando <code>RUN</code> puede escribirse en formato SHELL (<code>RUN \u00aborden\u00bb</code>) o bajo la opci\u00f3n de escritura EXEC(<code>RUN [\u00aborden\u00bb,\u00abpar\u00e1metro1\u00bb,\u00abpar\u00e1metro2\u00bb]</code>):</p> <ul> <li>Ejemplo:      <code>RUN apt update &amp;&amp; apt install -y git</code>     En este caso es muy importante que pongamos la opci\u00f3n -y porque en el proceso de construcci\u00f3n no puede haber interacci\u00f3n con el usuario.</li> </ul> </li> <li> <p><code>WORKDIR</code>: Establece el directorio de trabajo dentro de la imagen que estamos creando para posteriormente usar las \u00f3rdenes <code>RUN</code>,<code>COPY</code>,<code>ADD</code>,<code>CMD</code> o <code>ENTRYPOINT</code>.</p> <ul> <li>Ejemplo:     `WORKDIR /usr/local/apache/htdocs</li> </ul> </li> <li> <p><code>EXPOSE</code>: Nos da informaci\u00f3n acerca de qu\u00e9 puertos tendr\u00e1 abiertos el contenedor cuando se cree uno en base a la imagen que estamos creando. Es meramente informativo.</p> <ul> <li>Ejemplo:     <code>EXPOSE 80</code></li> </ul> </li> <li> <p><code>USER</code>: Para especificar (por nombre o <code>UID/GID</code>) el usuario de trabajo para todas las \u00f3rdenes <code>RUN</code>, <code>CMD</code> y <code>ENTRYPOINT</code> posteriores.</p> <ul> <li>Ejemplos:     <code>USER gatsby / USER 1001:10001</code></li> </ul> </li> <li> <p><code>ARG</code>: Para definir variables para las cuales los usuarios pueden especificar valores a la hora de hacer el proceso de <code>build</code> mediante el <code>flag --build-arg</code>. Su sintaxis es <code>ARG \u00abnombre_variable\u00bb</code> o <code>ARG nombre_variable=valor_por_defecto</code>. Posteriormente esa variable se puede usar en el resto de la \u00f3rdenes de la siguiente manera <code>$nombre_variable</code>.</p> <ul> <li>Ejemplo:      <code>ARG usuario=www-data</code>. No se puede usar con <code>ENTRYPOINT</code> y <code>CMD</code>.</li> </ul> </li> <li><code>ENV</code>: Para establecer variables de entorno dentro del contenedor. Puede ser usado posteriormente en las \u00f3rdenes <code>RUN</code> a\u00f1adiendo <code>$</code> delante de el nombre de la variable de entorno.<ul> <li>Ejemplo:      <code>ENV WEB_DOCUMENT_ROOT=/var/www/html</code> No se puede usar con <code>ENTRYPOINT</code> y <code>CMD</code>.</li> </ul> </li> <li><code>ENTRYPOINT</code>: Para establecer el ejecutable que se lanza siempre cuando se crea el contenedor con <code>docker run</code>, salvo que se especifique expresamente algo diferente con el flag <code>--entrypoint</code>. Su sintaxis es la siguiente: <code>ENTRYPOINT \u00abcommand\u00bb</code> \u00f3 <code>ENTRYPOINT [\"executable\",\"param1\",\"param2\"]</code>.<ul> <li>Ejemplo:     <code>ENTRYPOINT [\"/usr/sbin/apache2ctl\",\"-D\",\"FOREGROUND\"]</code></li> </ul> </li> <li><code>CMD</code>: Para establecer el ejecutable por defecto (salvo que se sobreescriba desde la orden <code>docker run</code>) o para especificar par\u00e1metros para un <code>ENTRYPOINT</code>. Si tenemos varios s\u00f3lo se ejecuta el \u00faltimo. Su sintaxis es: <code>CMD param1 param2</code> \u00f3 <code>CMD [\"param1\",\"param2\"]</code> \u00f3 <code>CMD[\"command\",\"param1\"]</code>.<ul> <li>Ejemplo:     <code>CMD [\u201c-c\u201d \u201c/etc/nginx.conf\u201d] / ENTRYPOINT [\u201cnginx\u201d]</code></li> </ul> </li> </ul> <p>Para una descripci\u00f3n completa sobre el fichero Dockerfile, puedes acceder a la documentaci\u00f3n oficial.</p>"},{"location":"05.-Docker/05.-Gesti%C3%B3n%20de%20im%C3%A1genes/02.-Imagen%20a%20partir%20de%20un%20fichero%20Dockerfile/#ejemplo-de-dockerfile-aplicacion-python","title":"Ejemplo de <code>Dockerfile</code>: Aplicaci\u00f3n Python","text":"<pre><code># Usar una imagen base de python\nFROM python:3.10\n\n# Instalar poetry con pip\nENV POETRY_VERSION=1.4.2\nRUN pip install \"poetry==$POETRY_VERSION\"\n\n# Copiar los archivos de configuraci\u00f3n de poetry\nWORKDIR /app\nCOPY pyproject.toml poetry.lock ./\n\n# Desactivar la creaci\u00f3n de virtualenvs\nRUN poetry config virtualenvs.create false\n\n# Instalar las dependencias con poetry\nRUN poetry install\n\n# Copiar el archivo python\nCOPY hola_mundo.py ./\n\n# Ejecutar el archivo con poetry run python\nCMD [\"poetry\", \"run\", \"python\", \"hola_mundo.py\"]\n</code></pre> <p>En este caso, el fichero <code>Dockerfile</code> se utiliza para construir una imagen de Docker que ejecuta un script de Python llamado <code>hola_mundo.py</code> utilizando Poetry como gestor de dependencias y empaquetado.</p> <p><code>Poetry</code> es una herramienta de gesti\u00f3n de dependencias y empaquetado para aplicaciones y proyectos de Python. Est\u00e1 dise\u00f1ada para simplificar y agilizar el manejo de las dependencias de Python, as\u00ed como la gesti\u00f3n del entorno virtual y la construcci\u00f3n de paquetes.</p> <p>Aqu\u00ed se explica el contenido y las acciones realizadas en cada instrucci\u00f3n de nuestro <code>Dockerfile</code>:</p> <ul> <li> <p><code>FROM python:3.10</code>: Esta l\u00ednea establece la imagen base para el contenedor, en este caso, se utiliza la imagen oficial de Python versi\u00f3n 3.10.</p> </li> <li> <p><code>ENV POETRY_VERSION=1.4.2</code>: Se establece la variable de entorno <code>POETRY_VERSION</code> con el valor \"1.4.2\", que indica la versi\u00f3n espec\u00edfica de Poetry a instalar.</p> </li> <li> <p><code>RUN pip install \"poetry==$POETRY_VERSION\"</code>: Se utiliza el comando <code>pip</code> para instalar Poetry en el contenedor, utilizando la versi\u00f3n especificada en la variable de entorno.</p> </li> <li> <p><code>WORKDIR /app</code>: Establece el directorio de trabajo dentro del contenedor como \"/app\". Los comandos posteriores se ejecutar\u00e1n en este directorio.</p> </li> <li> <p><code>COPY pyproject.toml poetry.lock ./</code>: Copia los archivos de configuraci\u00f3n de Poetry (<code>pyproject.toml</code> y <code>poetry.lock</code>) desde el directorio local al directorio de trabajo dentro del contenedor. Poetry crea por defecto un entorno virtual para cada proyecto que gestiona, pero en el caso de docker, esto no es necesario ni deseable, ya que la imagen de docker ya es un entorno aislado. Por eso, se usa ese comando para indicarle a poetry que instale las dependencias directamente en el int\u00e9rprete de python de la imagen, sin crear un entorno virtual adicional.</p> </li> <li> <p><code>RUN poetry config virtualenvs.create false</code>: Configura Poetry para que no cree entornos virtuales. Esto significa que las dependencias se instalar\u00e1n a nivel de sistema en lugar de en un entorno virtual separado.</p> </li> <li> <p><code>RUN poetry install</code>: Instala las dependencias del proyecto utilizando Poetry. Las dependencias se obtienen del archivo <code>pyproject.toml</code> y se instalan en el contenedor.</p> </li> <li> <p><code>COPY hola_mundo.py ./</code>: Copia el archivo <code>hola_mundo.py</code> desde el directorio local al directorio de trabajo dentro del contenedor.</p> </li> <li> <p><code>CMD [\"poetry\", \"run\", \"python\", \"hola_mundo.py\"]</code>: Define el comando predeterminado que se ejecutar\u00e1 cuando se inicie el contenedor. En este caso, se utiliza Poetry para ejecutar el script Python <code>hola_mundo.py</code>.</p> </li> </ul> <p>Para construir la imagen, se debe ejecutar el siguiente comando en la terminal, asegur\u00e1ndonos de estar en la misma ubicaci\u00f3n que el archivo <code>Dockerfile</code>:</p> <pre><code>docker build -t \u00abnombre-de-la-imagen:version\u00bb .\n</code></pre> <p>Despu\u00e9s de construir y etiquetar la imagen, se puede subir a un registro de im\u00e1genes de Docker utilizando el comando <code>docker push</code>. Por ejemplo:</p> <pre><code>docker push \u00abnombre-de-la-imagen:version\u00bb\n</code></pre> <p>Una vez subida la imagen, se puede descargar y ejecutar en cualquier sistema que admita Docker utilizando el comando <code>docker run</code>.</p>"},{"location":"05.-Docker/05.-Gesti%C3%B3n%20de%20im%C3%A1genes/03.-Construyendo%20im%C3%A1genes%20con%20docker%20build/","title":"03.-Construyendo im\u00e1genes con <code>docker build</code>","text":"<p>El comando <code>docker build</code> construye la nueva imagen leyendo las instrucciones del fichero <code>Dockerfile</code> y la informaci\u00f3n de un entorno, que para nosotros va a ser un directorio (aunque tambi\u00e9n podemos guardar informaci\u00f3n, por ejemplo, en un repositorio git).</p> <p>La creaci\u00f3n de la imagen es ejecutada por el docker engine, que recibe toda la informaci\u00f3n del entorno, por lo tanto es recomendable guardar el <code>Dockerfile</code> en un directorio vac\u00edo y a\u00f1adir los ficheros necesarios para la creaci\u00f3n de la imagen. El comando <code>docker build</code> ejecuta las instrucciones de un <code>Dockerfile</code> l\u00ednea por l\u00ednea y va mostrando los resultados en pantalla.</p> <p>Tenemos que tener en cuenta que cada instrucci\u00f3n ejecutada crea una imagen intermedia. Una vez finalizada la construcci\u00f3n de la imagen nos devuelve su id. Algunas im\u00e1genes intermedias se guardan en cach\u00e9, otras se borran. Por lo tanto, si por ejemplo, en un comando ejecutamos <code>cd /scripts/</code> y en otra l\u00ednea le mandamos a ejecutar un script <code>./install.sh</code> no va a funcionar, ya que ha lanzado otra imagen intermedia. Teniendo esto en cuenta, la manera correcta de hacerlo ser\u00eda:</p> <p><code>cd /scripts/;./install.sh</code></p> <p>Para terminar indicar que la creaci\u00f3n de im\u00e1genes intermedias generadas por la ejecuci\u00f3n de cada instrucci\u00f3n del <code>Dockerfile</code>, es un mecanismo de cach\u00e9, es decir, si en alg\u00fan momento falla la creaci\u00f3n de la imagen, al corregir el <code>Dockerfile</code> y volver a construir la imagen, los pasos que hab\u00edan funcionado anteriormente no se repiten ya que tenemos a nuestra disposici\u00f3n las im\u00e1genes intermedias, y el proceso contin\u00faa por la instrucci\u00f3n que caus\u00f3 el fallo.</p>"},{"location":"05.-Docker/05.-Gesti%C3%B3n%20de%20im%C3%A1genes/03.-Construyendo%20im%C3%A1genes%20con%20docker%20build/#ejemplo-de-dockerfile","title":"Ejemplo de <code>Dockerfile</code>","text":"<p>Vamos a crear un directorio (nuestro entorno) donde vamos a crear un <code>Dockerfile</code> y un fichero <code>index.html</code>:</p> <pre><code>$ cd build\n$ ls\nDockerfile  index.html\n</code></pre> <p>El contenido de Dockerfile es:</p> <pre><code>FROM debian:buster-slim\nMAINTAINER Paco \u00c1vila \"favila@iesromerovargas.com\"\nRUN apt-get update &amp;&amp; apt-get install -y apache2 \nCOPY index.html /var/www/html/\nCMD [\"/usr/sbin/apache2ctl\", \"-D\", \"FOREGROUND\"]\n</code></pre> <p>Para crear la imagen usaremos el comando <code>docker build</code>, indicando el nombre de la nueva imagen (opci\u00f3n -t) e indicando el directorio contexto.</p> <pre><code>$ docker build -t iesromerovargas/myapache2:v2 .\n</code></pre> <p>Nota: Ponemos como directorio el <code>.</code> porque estamos ejecutando esta instrucci\u00f3n desde el directorio donde est\u00e1 el <code>Dockerfile</code>.</p> <p>Una vez terminado, podr\u00edamos ver que hemos generado una nueva imagen:</p> <pre><code>$ docker images\n    REPOSITORY                TAG                 IMAGE ID            CREATED             SIZE\n    iesromerovargas/myapache2 v2                  3bd28de7ae88        43 seconds ago      195MB\n...\n</code></pre> <p>Si usamos el par\u00e1metro <code>--no-cache</code> en <code>docker build</code> har\u00edamos la construcci\u00f3n de una imagen sin usar las capas cacheadas por haber realizado anteriormente im\u00e1genes con capas similares.</p> <p>En este caso al crear el contenedor a partir de esta imagen no hay que indicar el proceso que se va a ejecutar, porque ya se ha indicando en el fichero <code>Dockerfile</code>:</p> <pre><code>$ docker run -d -p 8080:80 --name servidor_web iesromerovargas/myapache2:v2\n</code></pre>"},{"location":"05.-Docker/05.-Gesti%C3%B3n%20de%20im%C3%A1genes/04.-Organizaci%C3%B3n%20de%20las%20im%C3%A1genes/","title":"04.-Organizaci\u00f3n de las im\u00e1genes","text":"<p>Las im\u00e1genes est\u00e1n hechas de capas ordenadas. Puedes pensar en una capa como un conjunto de cambios en el sistema de archivos. Cuando tomas todas las capas y las apilas, obtienes una nueva imagen que contiene todos los cambios acumulados.</p> <p>Si tienes muchas im\u00e1genes basadas en capas similares, como Sistema Operativo base o paquetes comunes, entonces todas \u00e9stas capas comunes ser\u00e1 almacenadas solo una vez.</p> <p></p> <p>Cuando un nuevo contenedor es creado desde una imagen, todas las capas de la imagen son \u00fanicamente de lectura y una delgada capa lectura-escritura es agregada arriba. Todos los cambios efectuados al contenedor espec\u00edfico son almacenados en esa capa.</p> <p>El contenedor no puede modificar los archivos desde su capa de imagen (que es s\u00f3lo lectura). Crear\u00e1 una copia del fichero en su capa superior, y desde ese punto en adelante, cualquiera que trate de acceder al archivo obtendr\u00e1 la copia de la capa superior.</p> <p></p> <p>Por lo tanto cuando creamos un contenedor ocupa muy poco de disco duro, porque las capas de la imagen desde la que se ha creado se comparten con el contenedor:</p> <p>Veamos el tama\u00f1o de nuestra imagen <code>ubuntu</code>:</p> <pre><code>$ docker images\nREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\nubuntu              latest              f63181f19b2f        7 days ago          72.9MB\n</code></pre> <p>Si creamos un contenedor interactivo:</p> <pre><code>$ docker run -it --name contenedor1 ubuntu /bin/bash \n</code></pre> <p>Nos salimos, y a continuaci\u00f3n visualizamos los contenedores con la opci\u00f3n <code>-s</code> (size):</p> <pre><code>$ docker ps -a -s\nCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS                       PORTS               NAMES               SIZE\na2d1ce6990d8        ubuntu              \"/bin/bash\"              8 seconds ago       Exited (130) 5 seconds ago                       contenedor1         0B (virtual 72.9MB)\n</code></pre> <p>Nos damos cuenta que el tama\u00f1o real del contenedor es 0B y el virtual, el que comparte con la imagen son los 72,9MB que es el tama\u00f1o de la imagen ubuntu.</p> <p>Si a continuaci\u00f3n volvemos a acceder al contenedor y creamos un fichero:</p> <pre><code>$ docker start contenedor1\ncontenedor1\n$ docker attach contenedor1\nroot@a2d1ce6990d8:/# echo \"00000000000000000\"&gt;file.txt\n</code></pre> <p>Y volvemos a ver el tama\u00f1o, vemos que ha crecido con la creaci\u00f3n del fichero:</p> <pre><code>$ docker ps -a -s\nCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS                      PORTS               NAMES               SIZE\na2d1ce6990d8        ubuntu              \"/bin/bash\"              56 seconds ago      Exited (0) 2 seconds ago                        contenedor1         52B (virtual 72.9MB)\n</code></pre> <p>Por todo lo que hemos explicado, ahora se entiende que no podemos eliminar una imagen cuando tenemos contenedores creados a a partir de ella.</p> <p>Por \u00faltimo al solicitar informaci\u00f3n de la imagen, podemos ver informaci\u00f3n sobre sus capas:</p> <pre><code>$ docker inspect ubuntu:latest\n...\n\"RootFS\": {\n        \"Type\": \"layers\",\n        \"Layers\": [\n            \"sha256:9f32931c9d28f10104a8eb1330954ba90e76d92b02c5256521ba864feec14009\",\n            \"sha256:dbf2c0f42a39b60301f6d3936f7f8adb59bb97d31ec11cc4a049ce81155fef89\",\n            \"sha256:02473afd360bd5391fa51b6e7849ce88732ae29f50f3630c3551f528eba66d1e\"\n        ]\n...\n</code></pre>"},{"location":"05.-Docker/05.-Gesti%C3%B3n%20de%20im%C3%A1genes/05.-Registro%20de%20im%C3%A1genes%20y%20Docker%20Hub/","title":"05.-Registro de im\u00e1genes y Docker Hub","text":"<p>El Registro docker es un componente donde se almacena las im\u00e1genes generadas por el Docker Engine. Puede estar instalada en un servidor independiente y es un componente fundamental, ya que nos permite distribuir nuestras  aplicaciones. Es un proyecto open source que puede ser instalado  gratuitamente en cualquier servidor, pero, como hemos comentado, el proyecto nos ofrece Docker Hub</p> <p></p> <p>El nombre de una imagen suele estar formado por tres partes:</p> <pre><code>usuario/nombre:etiqueta\n</code></pre> <ul> <li><code>usuario</code>: El nombre del usuario que la ha generado. Si la subimos a Docker Hub  debe ser el mismo usuario que tenemos dado de alta en nuestra cuenta.  Las im\u00e1ges oficiales en Docker Hub no tienen nombre de usuario.</li> <li><code>nombre</code>: Nombre significativo de la imagen.</li> <li><code>etiqueta</code>: Nos permite versionar las im\u00e1genes. De esta manera controlamos los cambios que se van produciendo en ella. Si no indicamos etiqueta, por defecto se usa la etiqueta <code>latest</code>, por lo que la mayor\u00eda de las im\u00e1genes tienen una versi\u00f3n con este nombre.</li> </ul>"},{"location":"05.-Docker/05.-Gesti%C3%B3n%20de%20im%C3%A1genes/06.-Buenas%20pr%C3%A1cticas%20en%20creaci%C3%B3n%20de%20Dockerfile/","title":"06.-Buenas pr\u00e1cticas en creaci\u00f3n de Dockerfile","text":"<ul> <li>Los contenedores deber ser \u201cef\u00edmeros\u201d: Cuando decimos \u201cef\u00edmeros\u201d queremos decir que la creaci\u00f3n, parada, despliegue de los contenedores creados a partir de la imagen que vamos a generar con nuestro <code>Dockerfile</code> debe tener una m\u00ednima configuraci\u00f3n.</li> <li>Uso de ficheros <code>.dockerignore</code>: Como hemos indicado anteriormente, todos los ficheros del contexto se env\u00edan al docker engine, es recomendable usar un directorio vac\u00edo donde vamos creando los ficheros que vamos a enviar. Adem\u00e1s, para aumentar el rendimiento, y no enviar al daemon ficheros innecesarios podemos hacer uso de un fichero <code>.dockerignore</code>, para excluir ficheros y directorios.</li> <li>No instalar paquetes innecesarios: Para reducir la complejidad, dependencias, tiempo de creaci\u00f3n y tama\u00f1o de la imagen resultante, se debe evitar instalar paquetes extras o innecesarios. Si alg\u00fan paquete no es necesario durante la creaci\u00f3n de la imagen, lo mejor es desinstalarlo durante el proceso.</li> <li>Minimizar el n\u00famero de capas: Debemos encontrar el balance entre la legibilidad del <code>Dockerfile</code> y minimizar el n\u00famero de capas que utiliza.</li> <li>Indicar las instrucciones a ejecutar en m\u00faltiples l\u00edneas: Cada vez que sea posible y para hacer m\u00e1s f\u00e1cil futuros cambios, hay que organizar los argumentos de las instrucciones que contengan m\u00faltiples l\u00edneas, esto evitar\u00e1 la duplicaci\u00f3n de paquetes y har\u00e1 que el archivo sea m\u00e1s f\u00e1cil de leer. Por ejemplo:</li> </ul> <pre><code>   RUN apt-get update &amp;&amp; apt-get install -y \\\n   git \\\n   wget \\\n   apache2 \\\n   php5\n</code></pre>"},{"location":"05.-Docker/05.-Gesti%C3%B3n%20de%20im%C3%A1genes/07.-Ejercicios%20de%20creaci%C3%B3n%20de%20contenedores%20b%C3%A1sicos%20II/","title":"07.-Ejercicios de creaci\u00f3n de contenedores b\u00e1sicos II","text":""},{"location":"05.-Docker/05.-Gesti%C3%B3n%20de%20im%C3%A1genes/07.-Ejercicios%20de%20creaci%C3%B3n%20de%20contenedores%20b%C3%A1sicos%20II/#ejercicios-para-repasar","title":"Ejercicios para repasar","text":"<ul> <li>Descarga las siguientes im\u00e1genes: <code>ubuntu:18.04</code>, <code>httpd</code>, <code>tomcat:9.0.74-jdk17-temurin-jammy</code> , <code>jenkins/jenkins:lts</code>, <code>php:7.4-apache</code>.</li> </ul> <pre><code>$ docker pull ubuntu:18.04\n$ docker pull httpd\n$ docker pull tomcat:9.0.74-jdk17-temurin-jammy\n$ docker pull jenkins/jenkins:lts\n$ docker pull php:7.4-apache\n</code></pre> <ul> <li>Muestra las im\u00e1genes que tienes descargadas.</li> </ul> <pre><code>$ docker images\nREPOSITORY        TAG                          IMAGE ID       CREATED        SIZE\ntomcat            9.0.74-jdk17-temurin-jammy   3f55087df9b4   18 hours ago   476MB\nhttpd             latest                       28505717e3ae   37 hours ago   145MB\njenkins/jenkins   lts                          976459dc87b0   45 hours ago   472MB\nubuntu            18.04                        3941d3b032a8   8 weeks ago    63.1MB\nphp               7.4-apache                   20a3732f422b   5 months ago   453MB\n</code></pre> <ul> <li>Crea un contenedor demonio con la imagen <code>php:7.4-apache</code>.</li> </ul> <pre><code>docker run -d --name -p 8080:80 php php:7.4-apache\n</code></pre> <ul> <li>Comprueba el tama\u00f1o del contenedor en el disco duro.</li> </ul> <pre><code>docker ps --sa\n</code></pre> <ul> <li> <p>Con la instrucci\u00f3n <code>docker cp</code> podemos copiar ficheros a o desde un contenedor. Puedes encontrar informaci\u00f3n es esta p\u00e1gina. Crea un fichero en tu ordenador, con el siguiente contenido:</p> <p><code>&lt;?php  echo phpinfo();  ?&gt;</code></p> </li> <li> <p>Copia un fichero <code>info.php</code> al directorio <code>/var/www/html</code> del contenedor con <code>docker cp</code>.</p> </li> </ul> <pre><code>$ docker cp ./info.php php:/var/www/html\n</code></pre> <ul> <li>Vuelve a comprobar el espacio ocupado por el contenedor.</li> </ul> <pre><code>docker ps --sa\n</code></pre> <ul> <li>Accede al fichero <code>info.php</code> desde un navegador web.</li> </ul> <pre><code>firefox http://localhost:8080/info.php/\n</code></pre>"},{"location":"05.-Docker/05.-Gesti%C3%B3n%20de%20im%C3%A1genes/07.-Ejercicios%20de%20creaci%C3%B3n%20de%20contenedores%20b%C3%A1sicos%20II/#ejercicio-para-entregar","title":"Ejercicio para entregar","text":""},{"location":"05.-Docker/05.-Gesti%C3%B3n%20de%20im%C3%A1genes/07.-Ejercicios%20de%20creaci%C3%B3n%20de%20contenedores%20b%C3%A1sicos%20II/#servidor-web","title":"Servidor web","text":"<ul> <li>Arranca un contenedor que ejecute una instancia de la imagen <code>php:7.4-apache</code>, que se llame <code>web</code> y que sea accesible desde tu equipo en el puerto 8000.</li> <li>Colocar en el directorio ra\u00edz del servicio web (<code>/var/www/html</code>) de dicho contenedor un fichero llamado <code>index.html</code> con el siguiente contenido:</li> </ul> <pre><code>&lt;h1&gt;HOLA SOY XXXXXXXXXXXXXXX&lt;/h1&gt;\n</code></pre> <p>Deber\u00e1s sustituir XXXXXXXXXXX por tu nombre y tus apellidos.</p> <ul> <li>Colocar en ese mismo directorio ra\u00edz un archivo llamado <code>index.php</code> con el siguiente contenido: <code>&lt;?php     echo phpinfo();     ?&gt;</code></li> <li>Para crear los ficheros tienes tres alternativas:<ul> <li>Ejecutando bash de forma interactiva en el contenedor y creando los ficheros.</li> <li>Ejecutando un comando <code>echo</code> en el contenedor con <code>docker exec</code>.</li> <li>Usando <code>docker cp</code> como hemos visto en el ejercicio 5.</li> </ul> </li> </ul>"},{"location":"05.-Docker/05.-Gesti%C3%B3n%20de%20im%C3%A1genes/07.-Ejercicios%20de%20creaci%C3%B3n%20de%20contenedores%20b%C3%A1sicos%20II/#servidor-de-base-de-datos","title":"Servidor de base de datos","text":"<ul> <li>Arrancar un contenedor que se llame <code>bbdd</code> y que ejecute una instancia de la imagen <code>mariadb</code> para que sea accesible desde el puerto 3336.</li> <li>Antes de arrancarlo visitar la p\u00e1gina del contenedor en Docker Hub y establecer las variables de entorno necesarias para que:<ul> <li>La contrase\u00f1a de root sea <code>root</code>.</li> <li>Crear una base de datos autom\u00e1ticamente al arrancar que se llame <code>prueba</code>.</li> <li>Crear el usuario <code>invitado</code> con las contrase\u00f1a <code>invitado</code>.</li> </ul> </li> </ul> <p>Deber\u00e1s entregar los siguientes pantallazos comprimidos en un zip o en un documento pdf:</p> <ul> <li>Pantallazo que desde el navegador muestre el fichero <code>index.html</code>.</li> <li>Pantallazo que desde el navegador muestre el fichero <code>index.php</code>.</li> <li>Pantallazo donde se vea el tama\u00f1o del contenedor <code>web</code> despu\u00e9s de crear los dos ficheros.</li> <li>Pantallazo donde desde un cliente de base de datos (instalado en tu ordenador) se pueda observar que hemos podido conectarnos al servidor de base de datos con el usuario creado y que se ha creado la base de datos prueba (<code>show databases</code>). El acceso se debe realizar desde el ordenador que ten\u00e9is instalado docker, no hay que acceder desde dentro del contenedor, es decir, no usar <code>docker exec</code>.</li> <li>Pantallazo donde se comprueba que no se puede borrar la imagen <code>mariadb</code> mientras el contenedor <code>bbdd</code> est\u00e1 creado.</li> </ul>"},{"location":"05.-Docker/06.-Vol%C3%BAmenes/","title":"06.- Vol\u00famenes","text":"<p>Los contenedores son ef\u00edmeros, es decir, los ficheros, datos y configuraciones que creamos en los contenedores sobreviven a las paradas de los mismos pero, sin embargo, son destruidos si el contenedor es destruido.</p>"},{"location":"05.-Docker/06.-Vol%C3%BAmenes/#los-datos-en-los-contenedores","title":"Los datos en los contenedores","text":"<p>Ante la situaci\u00f3n anteriormente descrita Docker nos proporciona varias soluciones para persistir los datos de los contenedores. En este curso nos vamos a centrar en las dos que considero que son m\u00e1s importantes:</p> <ul> <li>Los vol\u00famenes docker.</li> <li>Los bind mount</li> <li>Los tmpfs mounts: Almacenan en memoria la informaci\u00f3n. (No lo vamos a ver en este curso)</li> </ul>"},{"location":"05.-Docker/06.-Vol%C3%BAmenes/01.-Vol%C3%BAmenes%20docker%20y%20bind%20mount/","title":"01.-Vol\u00famenes docker y bind mount","text":""},{"location":"05.-Docker/06.-Vol%C3%BAmenes/01.-Vol%C3%BAmenes%20docker%20y%20bind%20mount/#volumenes-docker","title":"Vol\u00famenes docker","text":"<p>Si elegimos conseguir la persistencia usando vol\u00famenes estamos haciendo que los datos de los contenedores que nosotros decidamos se almacenen en una parte del sistema de ficheros que es gestionada por docker y a la que, debido a sus permisos, s\u00f3lo docker tendr\u00e1 acceso. En linux se guardan en <code>/var/lib/docker/volumes</code>. Este tipo de vol\u00famenes se suele usar en los siguientes casos:</p> <ul> <li>Para compartir datos entre contenedores. Simplemente tendr\u00e1n que usar el mismo volumen.</li> <li>Para copias de seguridad ya sea para que sean usadas posteriormente por otros contenedores o para mover esos vol\u00famenes a otros hosts.</li> <li>Cuando queremos almacenar los datos de nuestro contenedor no localmente sino en un proveedor cloud.</li> </ul>"},{"location":"05.-Docker/06.-Vol%C3%BAmenes/01.-Vol%C3%BAmenes%20docker%20y%20bind%20mount/#gestionando-volumenes","title":"Gestionando vol\u00famenes","text":"<p>Algunos comando \u00fatiles para trabajar con vol\u00famenes docker:</p> <ul> <li>docker volume create: Crea un volumen con el nombre indicado.</li> <li>docker volume rm: Elimina el volumen indicado.</li> <li>docker volume prune: Para eliminar los vol\u00famenes que no est\u00e1n siendo usados por ning\u00fan contenedor.</li> <li>docker volume ls: Nos proporciona una lista de los vol\u00famenes creados y algo de informaci\u00f3n adicional.</li> <li>docker volume inspect: Nos dar\u00e1 una informaci\u00f3n mucho m\u00e1s detallada de el volumen que hayamos elegido.</li> </ul>"},{"location":"05.-Docker/06.-Vol%C3%BAmenes/01.-Vol%C3%BAmenes%20docker%20y%20bind%20mount/#bind-mounts","title":"Bind mounts","text":"<p>Si elegimos conseguir la persistencia de los datos de los contenedores usando bind mount lo que estamos haciendo es \u201cmapear\u201d (montar) una parte de mi sistema de ficheros, de la que yo normalmente tengo el control, con una parte del sistema de ficheros del contenedor. Por lo tanto podemos montar tanto directorios como ficheros. De esta manera conseguimos:</p> <ul> <li>Compartir ficheros entre el host y los containers.</li> <li>Que otras aplicaciones que no sean docker tengan acceso a esos ficheros, ya sean c\u00f3digo, ficheros etc\u2026</li> </ul>"},{"location":"05.-Docker/06.-Vol%C3%BAmenes/02.-Asociando%20almacenamiento%20a%20los%20contenedores%20I/","title":"02.-Asociando almacenamiento a los contenedores I","text":"<p>Veamos como puedo usar los vol\u00famenes y los bind mounts en los contenedores. Aunque hay dos formas de asociar el almacenamiento al contenedor nosotros vamos a usar el flag <code>--volume</code> o <code>-v</code>.</p> <p>Si usamos im\u00e1genes de DockerHub, debemos leer la informaci\u00f3n que cada imagen nos proporciona en su p\u00e1gina ya que esa informaci\u00f3n suele indicar c\u00f3mo persistir los datos de esa imagen, ya sea con vol\u00famenes o bind mounts, y cu\u00e1les son las carpetas importantes en caso de ser im\u00e1genes que contengan ciertos servicios (web, base de datos etc\u2026)</p>"},{"location":"05.-Docker/06.-Vol%C3%BAmenes/02.-Asociando%20almacenamiento%20a%20los%20contenedores%20I/#ejemplo-usando-volumenes-docker","title":"Ejemplo usando vol\u00famenes docker","text":"<p>Lo primero que vamos a hacer es crear un volumen docker:</p> <pre><code>$ docker volume create miweb\nmiweb\n</code></pre> <p>A continuaci\u00f3n creamos un contenedor con el volumen asociado, usando <code>--mount</code>, y creamos un fichero <code>index.html</code>:</p> <pre><code>$ docker run -d --name my-apache-app -v miweb:/usr/local/apache2/htdocs -p 8080:80 httpd:2.4\nb51f89eb21701362279489c5b52a06b1a44c10194c00291de895b404ab347b80\n</code></pre> <p>-d: Ejecuta el contenedor en segundo plano y muestra el ID del contenedor. --name my-apache-app: Asigna el nombre my-apache-app al contenedor. -v miweb:/usr/local/apache2/htdocs: Monta el volumen <code>miweb</code> en el directorio <code>/usr/local/apache2/htdocs</code> del contenedor, donde se almacenan los archivos web del servidor Apache. -p 8080:80: Publica el puerto <code>80</code> del contenedor en el puerto <code>8080</code> del host, permitiendo acceder al servidor web desde el host. httpd:2.4: Es la imagen base del contenedor, que contiene el servidor web Apache versi\u00f3n 2.4.</p> <pre><code>$ docker exec my-apache-app bash -c 'echo \"&lt;h1&gt;Hola&lt;/h1&gt;\" &gt; /usr/local/apache2/htdocs/index.html'\n\n$ curl http://localhost:8080\n&lt;h1&gt;Hola&lt;/h1&gt;\n\n$ docker rm -f my-apache-app \nmy-apache-app\n</code></pre> <p>Despu\u00e9s de borrar el contenedor, volvemos a crear otro contenedor con el mismo volumen asociado:</p> <pre><code>$ docker run -d --name my-apache-app -v miweb:/usr/local/apache2/htdocs -p 8080:80 httpd:2.4\nbaa3511ca2227e30d90fa2b4b225e209889be4badff583ce58ac1feaa73d5d77\n</code></pre> <p>Y podemos comprobar que no no se ha perdido la informaci\u00f3n (el fichero <code>index.html</code>):</p> <pre><code>$ curl http://localhost:8080\n&lt;h1&gt;Hola&lt;/h1&gt;\n</code></pre> <p>Algunas aclaraciones:</p> <ul> <li>Al no indicar el volumen, se crear\u00e1 un nuevo volumen.</li> <li>Si usamos el flag <code>-v</code> e indicamos un nombre, se crear\u00e1 un volumen docker nuevo.</li> <li>Cuando usamos vol\u00famenes o bind mount, el contenido de lo que tenemos sobreescribir\u00e1 la carpeta destino en el sistema de ficheros del contenedor en caso de que exista.</li> </ul>"},{"location":"05.-Docker/06.-Vol%C3%BAmenes/03.-Asociando%20almacenamiento%20a%20los%20contenedores%20II/","title":"03.-Asociando almacenamiento a los contenedores II","text":""},{"location":"05.-Docker/06.-Vol%C3%BAmenes/03.-Asociando%20almacenamiento%20a%20los%20contenedores%20II/#ejemplo-montando-directorios-usando-bind-mount","title":"Ejemplo: montando directorios usando bind mount","text":"<p>En este caso vamos a crear un directorio en el sistema de archivo del host, donde vamos a crear un fichero <code>index.html</code>:</p> <pre><code>$ mkdir web\n$ cd web\n/web$ echo \"&lt;h1&gt;Hola&lt;/h1&gt;\" &gt; index.html\n</code></pre> <p>Y podemos montar ese directorio en un contenedor, en este caso usamos la opci\u00f3n <code>-v</code>:</p> <pre><code>$ docker run -d --name my-apache-app -v /home/\u00abusuario\u00bb/web:/usr/local/apache2/htdocs -p 8080:80 httpd:2.4\n8de025f6ff4d4b8a5a57d10a9cbb283b103209f358c43148a4716a33a404e208\n</code></pre> <p>Y comprobamos que realmente estamos sirviendo el fichero que tenemos en el directorio que hemos creado.</p> <pre><code>$ curl http://localhost:8080\n&lt;h1&gt;Hola&lt;/h1&gt;\n</code></pre> <p>Eliminamos el contenedor y volvemos a crear otro con el directorio montado:</p> <pre><code>$ docker rm -f my-apache-app \nmy-apache-app\n\n$ docker run -d --name my-apache-app -v /home/usuario/web:/usr/local/apache2/htdocs -p 8080:80 httpd:2.4\n1751b04b0548217d7faa628fd69c10e84c695b0e5cc33b482df2c04a6af83292\n\n$ curl http://localhost:8080\n&lt;h1&gt;Hola&lt;/h1&gt;\n</code></pre> <p>Adem\u00e1s podemos comprobar que podemos modificar el contenido del fichero aunque est\u00e9 montado en el contenedor:</p> <pre><code>$ echo \"&lt;h1&gt;Adi\u00f3s&lt;/h1&gt;\" &gt; web/index.html \n$ curl http://localhost:8080\n&lt;h1&gt;Adi\u00f3s&lt;/h1&gt;\n</code></pre> <p>Por \u00faltimo, indicar que si nuestra carpeta origen no existe y hacemos un bind mount con <code>-v</code>, esa carpeta se crear\u00e1 pero lo que tendremos en el contenedor es una carpeta vac\u00eda.</p>"},{"location":"05.-Docker/06.-Vol%C3%BAmenes/04.-Redes%20en%20docker/","title":"04.-Redes en docker","text":""},{"location":"05.-Docker/06.-Vol%C3%BAmenes/04.-Redes%20en%20docker/#tipos-de-redes-en-docker","title":"Tipos de redes en docker","text":"<p>Cuando instalamos docker tenemos las siguientes redes predefinidas:</p> <pre><code>$ docker network ls\nNETWORK ID          NAME                DRIVER              SCOPE\nec77cfd20583        bridge              bridge              local\n69bb21378df5        host                host                local\n089cc966eaeb        none                null                local\n</code></pre> <ul> <li>Por defecto los contenedores que creamos se conectan a la red de tipo bridge llamada <code>bridge</code> (por defecto el direccionamiento de esta red es 172.17.0.0/16). Los contenedores conectados a esta red que quieren exponer alg\u00fan puerto al exterior tienen que usar la opci\u00f3n <code>-p</code> para mapear puertos.</li> </ul> <p>Este tipo de red nos va a permitir:</p> <ul> <li>Aislar los distintos contenedores que tengamos en distintas subredes docker, de tal manera que desde cada una de las subredes solo podremos acceder a los equipos de esa misma subred.</li> <li>Aislar los contenedores del acceso exterior.</li> <li> <p>Publicar servicios que tengamos en los contenedores mediante redirecciones que docker implementar\u00e1 con las pertinentes reglas de iptables (firewall).</p> <p></p> </li> </ul> <p>Veamos un ejemplo:</p> <p>Vamos a crear un contenedor interactivo con la imagen <code>debian</code>:</p> <pre><code>$ docker run -it --name contenedor1 --rm debian bash\n</code></pre> <p>Nota: Hemos usado la opci\u00f3n <code>--rm</code> para al finalizar de ejecutar el proceso, el contenedor se elimina.</p> <p>En otra pesta\u00f1a, podemos ejecutar esta instrucci\u00f3n para obtener la ip que se le ha asignado:</p> <pre><code>$ docker inspect -f '{{range.NetworkSettings.Networks}}{{.IPAddress}}{{end}}' contenedor1\n172.17.0.2\n</code></pre> <p>Obtenemos informaci\u00f3n del contenedor filtrando el json de salida para obtener la IPv4 que se le ha asignado.</p> <p>Observamos que el contenedor tiene una ip en la red <code>172.17.0.0/16</code>. Adem\u00e1s podemos comprobar que se ha creado un <code>bridge</code> en el host, al que se conectan los contenedores:</p> <pre><code>$ ip a\n...\n5: docker0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default \n    link/ether 02:42:be:71:11:9e brd ff:ff:ff:ff:ff:ff\n    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0\n       valid_lft forever preferred_lft forever\n    inet6 fe80::42:beff:fe71:119e/64 scope link \n       valid_lft forever preferred_lft forever\n...\n</code></pre> <p>Adem\u00e1s podemos comprobar que se han creado distintas cadenas en el cortafuegos para gestionar la comunicaci\u00f3n de los contenedores. Podemos ejecutar como administrador: <code>iptables -L -n</code> y <code>iptables -L -n -t nat</code> y comprobarlo.</p> <ul> <li>Si conecto un contenedor a la red host, el contenedor ofrece el servicio que tiene configurado en el puerto de la red del anfitri\u00f3n. No tiene ip propia, sino es c\u00f3mo si tuviera la ip del anfitri\u00f3n. Por lo tanto, los puertos son accesibles directamente desde el host. Por ejemplo:</li> </ul> <pre><code>$ docker run -d --name mi_servidor --network host josedom24/aplicacionweb:v1\n\n$ docker ps\nCONTAINER ID        IMAGE                        COMMAND                  CREATED             STATUS              PORTS               NAMES\n135c742af1ff        josedom24/aplicacionweb:v1   \"/usr/sbin/apache2ct\u2026\"   3 seconds ago       Up 2 seconds                                  mi_servidor\n</code></pre> <p>Probamos acceder directamente al puerto 80 del servidor para ver la p\u00e1gina web.</p> <ul> <li>La red none no configurar\u00e1 ninguna IP para el contenedor y no tiene acceso a la red externa ni a otros contenedores. Tiene la direcci\u00f3n loopback y se puede usar para ejecutar trabajos por lotes.</li> </ul>"},{"location":"05.-Docker/06.-Vol%C3%BAmenes/05.-Ejemplos/","title":"Ejemplo 1: Contenedor nextcloud con almacenamiento persistente","text":"<p>Vamos a desplegar un contenedor con nextcloud, para simplificar la instalaci\u00f3n vamos a realizar la instalaci\u00f3n con una base de dato SQLite. Si estudiamos la documentaci\u00f3n de la imagen <code>nextcloud</code> en Docker Hub, la forma m\u00e1s sencilla de no perder la informaci\u00f3n es crear un volumen para guardar el directorio <code>/var/www/html</code> del contenedor. Vamos a realizar el ejercicio usando vol\u00famenes docker y bind mount.</p>"},{"location":"05.-Docker/06.-Vol%C3%BAmenes/05.-Ejemplos/#ejemplo-con-volumenes","title":"Ejemplo con vol\u00famenes","text":"<p>Creamos un volumen:</p> <pre><code>$ docker volume create nextcloud\nnextcloud\n</code></pre> <p>Y creamos el contenedor, guardando el directorio <code>/var/www/html</code> del contenedor en el volumen creado:</p> <pre><code>$ docker run -d -p 80:80  -v nextcloud:/var/www/html --name contenedor_nextcloud nextcloud\n</code></pre> <p>Comprobamos que podemos acceder, terminamos de configurar la aplicaci\u00f3n y una vez operativa subimos los ficheros a la aplicaci\u00f3n:</p> <p></p> <p>A continuaci\u00f3n eliminamos el contenedor y creamos uno nuevo con el mismo volumen:</p> <pre><code>$ docker rm -f contenedor_nextcloud\n\n$ docker run -d -p 80:80  -v nextcloud:/var/www/html --name contenedor_nextcloud nextcloud\n</code></pre> <p>Accede de nuevo a la aplicaci\u00f3n comprueba que la aplicaci\u00f3n sigue configurada y que los ficheros subidos no se han perdido.</p>"},{"location":"05.-Docker/06.-Vol%C3%BAmenes/05.-Ejemplos/#ejemplo-con-bind-mount","title":"Ejemplo con bind mount","text":"<p>En este caso, vamos a crear un directorio en nuestro ordenador, que es el que vamos a montar en el contenedor:</p> <pre><code>mkdir datos_nextcloud\n</code></pre> <p>Y creamos el contenedor con la siguiente instrucci\u00f3n:</p> <pre><code>docker run -d -p 80:80 -v /home/vagrant/datos_nextcloud:/var/www/html --name contenedor_nextcloud nextcloud\n</code></pre> <p>Volvemos a acceder, configuramos la aplicaci\u00f3n y subimos alg\u00fan fichero. Usando bind mount tenemos acceso al directorio:</p> <pre><code>$ cd datos_nextcloud/\n~/datos_nextcloud$ ls\n3rdparty  COPYING  config       core      custom_apps  index.html  lib  ocm-provider  ocs-provider  remote.php  robots.txt  themes\nAUTHORS   apps     console.php  cron.php  data         index.php   occ  ocs           public.php    resources   status.php  version.php\n</code></pre> <p>Podemos comprobar que al eliminar el contenedor y crearlo de nuevo usando el mismo directorio bind mount, toda la configuraci\u00f3n y los ficheros subidos no se han perdido.</p>"},{"location":"05.-Docker/06.-Vol%C3%BAmenes/05.-Ejemplos/#ejemplo2-contenedor-mariadb-con-almacenamiento-persistente","title":"Ejemplo2: Contenedor mariadb con almacenamiento persistente","text":"<p>Si estudiamos la documentaci\u00f3n de la imagen mariadb en Docker Hub, nos indica que podemos crear un contenedor con informaci\u00f3n persistente de mariadb, de la siguiente forma:</p> <pre><code>$ docker run --name some-mariadb -v /home/\u00abusuario\u00bb/datadir:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mariadb\n</code></pre> <p>Es decir se va a crear un directorio <code>/home/\u00abusuario\u00bb/datadir</code> en el host, donde se va a guardar la informaci\u00f3n de la base de datos. Si tenemos que crear de nuevo el contenedor indicaremos ese directorio como bind mount y volveremos a tener accesible la informaci\u00f3n.</p> <pre><code>$ cd datadir/\n~/datadir$ ls\naria_log.00000001  aria_log_control  ib_buffer_pool  ib_logfile0  ibdata1  ibtmp1  multi-master.info  mysql  performance_schema\n\n$ docker exec -it some-mariadb bash -c 'mysql -uroot -p$MYSQL_ROOT_PASSWORD'\n...\nMariaDB [(none)]&gt; create database prueba;\nMariaDB [(none)]&gt; quit\n\n$ docker rm -f some-mariadb \nsome-mariadb\n\n$ docker run --name some-mariadb -v /home/vagrant/datadir:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mariadb\nf36589090dd33b116da87e599850b1f25c9ae40e4b28c036c23e602d7bde4cc5\n\n$ docker exec -it some-mariadb bash -c 'mysql -uroot -p $MYSQL_ROOT_PASSWORD'\n...\nMariaDB [(none)]&gt; show databases;\n+--------------------+\n| Database           |\n+--------------------+\n| information_schema |\n| mysql              |\n| performance_schema |\n| prueba             |\n+--------------------+\n4 rows in set (0.003 sec)\n</code></pre>"},{"location":"05.-Docker/06.-Vol%C3%BAmenes/05.-Ejemplos/#que-informacion-tenemos-que-guardar","title":"\u00bfQu\u00e9 informaci\u00f3n tenemos que guardar?","text":"<p>Para terminar: \u00bfQu\u00e9 debemos guardar de forma persistente en un contenedor?</p> <ul> <li>Los datos de la aplicaci\u00f3n</li> <li>Los logs del servicio</li> <li>La configuraci\u00f3n del servicio: En este caso podemos a\u00f1adirla a la imagen, pero ser\u00e1 necesaria la creaci\u00f3n de una nueva imagen si cambiamos la configuraci\u00f3n. Si la guardamos en un volumen hay que tener en cuanta que ese fichero lo tenemos que tener en el entorno de producci\u00f3n (puede ser bueno, porque las configuraciones de los distintos entornos puede variar).</li> </ul>"},{"location":"05.-Docker/06.-Vol%C3%BAmenes/06.-Otros%20usos%20del%20almacenamiento/","title":"06.-Otros usos del almacenamiento","text":"<p>En los ejemplos anteriores hemos usado los vol\u00famenes como copia de seguridad de la informaci\u00f3n, para hacer persistente los contenedores. En este apartado vamos a ver dos ejemplos explicando otros dos usos que le podemos dar al almacenamiento en docker:</p>"},{"location":"05.-Docker/06.-Vol%C3%BAmenes/06.-Otros%20usos%20del%20almacenamiento/#compartir-informacion-entre-contenedores","title":"Compartir informaci\u00f3n entre contenedores","text":"<p>En este caso vamos a usar un volumen o bind mount para compartir informaci\u00f3n entre dos contenedores. Si seguimos el principio que un contenedor tiene que ejecutar un s\u00f3lo proceso, en ocasiones nos puede hacer falta que otro contenedor haga una operaci\u00f3n auxiliar y genere una informaci\u00f3n que compartir\u00e1 con el primero por medio de almacenamiento que estar\u00e1 montado en los dos contenedores.</p> <p>Un ejemplo podr\u00eda ser un servicio web que est\u00e1 ofreciendo informaci\u00f3n que tiene que ir leyendo de un repositorio Git. en este caso podr\u00edamos poner un contenedor secundario que cada cierto tiempo leyera el repositorio y le pasara la informaci\u00f3n al primer contenedor por medio de almacenamiento compartido.</p> <p>En nuestro ejemplo vamos a hacer algo mucho m\u00e1s sencillo: el contenedor principal es un servidor web que ofrece un fichero <code>index.html</code> y este fichero se va actualizando por el segundo contenedor, que en el ejemplo lo \u00fanico que va a hacer es escribir la fecha y la hora cada un segundo. Vemos el ejemplo usando vol\u00famenes docker:</p> <p>Lo primero creamos el volumen:</p> <pre><code>$ docker volume create datos_compartidos\n</code></pre> <p>Creamos el primer contenedor con el volumen montado en el DocumentRoot y el tipo de acceso solo lectura, opci\u00f3n <code>ro</code>:</p> <pre><code>$ docker run -d -p 8181:80 --name contenedor1 -v datos_compartidos:/var/www/html:ro php:7.4-apache\n</code></pre> <p>A continuaci\u00f3n creamos el segundo contenedor con un proceso que va a modificar el fichero <code>index.html</code> que guarda en el volumen cada un segundo:</p> <pre><code>$ docker run -d  --name contenedor2 -v datos_compartidos:/srv debian bash -c \"while true; do date &gt;&gt; /srv/index.html;sleep 1;done\"\n</code></pre> <p>Accedemos al puerto 8181 del anfitri\u00f3n y comprueba c\u00f3mo se va actualizando el fichero <code>index.html</code> que estamos viendo.</p> <p>Lo podr\u00edamos hacer tambi\u00e9n con bind mount:</p> <pre><code>$ docker run -d -p 8181:80 --name contenedor1 -v /home/vagrant/compartido:/var/www/html:ro php:7.4-apache\n$ docker run -d  --name contenedor2 -v /home/vagrant/compartido:/srv debian bash -c \"while true; do date &gt;&gt; /srv/index.html;sleep 1;done\"\n</code></pre> <p>Y podr\u00edamos ver el contenido del fichero <code>~/compartido/index.html</code>.</p>"},{"location":"05.-Docker/06.-Vol%C3%BAmenes/06.-Otros%20usos%20del%20almacenamiento/#comprobar-compatibilidad-de-codigo-entre-distintas-versiones-de-un-lenguaje-de-programacion","title":"Comprobar compatibilidad de c\u00f3digo entre distintas versiones de un lenguaje de programaci\u00f3n","text":"<p>Otro utilidad que le podemos dar al almacenamiento, en este caso a los bind mount, es la posibilidad de comprobar la compatibilidad de un c\u00f3digo en diferentes versiones del lenguaje de programaci\u00f3n.</p> <p>Veamos un ejemplo en PHP: imaginemos que tenemos un c\u00f3digo que es compatible y funciona bien en PHP 5 y queremos comprobar como se comporta en la versi\u00f3n PHP 7.</p> <p>Siguiendo la documentaci\u00f3n Migraci\u00f3n de PHP 5.6.x a PHP 7.0.x, se ha escogido la funci\u00f3n list que se comporta de manera distinta en PHP5 que en PHP7.</p> <p>Imaginemos que tenemos un directorio <code>codigo</code> con nuestra aplicaci\u00f3n <code>index.php</code>:</p> <pre><code>&lt;?php\n// Funciona bien en php5 ya que list hace la asignaci\u00f3n desde el \u00faltimo al primero\n$info = array('cafe\u00edna','marr\u00f3n', 'caf\u00e9');\n\n// Enumerar todas las variables\nlist($datos[], $datos[], $datos[]) = $info;\necho \"El $datos[0] es $datos[1] y la $datos[2] lo hace especial.\\n\";\n?&gt;\n</code></pre> <p>A continuaci\u00f3n vamos a crear dos contenedores que sirva este c\u00f3digo usando im\u00e1genes distintas , para cada versi\u00f3n de PHP y usando puertos distintos para acceder a cada versi\u00f3n de la aplicaci\u00f3n:</p> <pre><code>$ docker run -d -p 8081:80 --name php56 -v /home/vagrant/codigo:/var/www/html:ro php:5.6-apache\n$ docker run -d -p 8082:80 --name php74 -v /home/vagrant/codigo:/var/www/html:ro php:7.4-apache\n</code></pre> <p>Y ya podemos acceder a los dos puertos de nuestro anfitri\u00f3n y comprobar c\u00f3mo se comporta en PHP5 y en PHP7.</p>"},{"location":"05.-Docker/06.-Vol%C3%BAmenes/Ejercicios%20de%20Vol%C3%BAmenes/","title":"Ejercicios para repasar","text":"<p>Vamos a trabajar con vol\u00famenes docker:</p> <ol> <li>Crea un volumen docker que se llame <code>miweb</code>.</li> <li>Crea un contenedor desde la imagen <code>php:7.4-apache</code> donde montes en el directorio <code>/var/www/html</code> (que sabemos que es el DocuemntRoot del servidor que nos ofrece esa imagen) el volumen docker que has creado.</li> <li>Utiliza el comando <code>docker cp</code> para copiar un fichero <code>index.html</code> en el directorio <code>/var/www/html</code>.</li> <li>Accede al contenedor desde el navegador para ver la informaci\u00f3n ofrecida por el fichero <code>index.html</code>.</li> <li>Borra el contenedor</li> <li>Crea un nuevo contenedor y monta el mismo volumen como en el ejercicio anterior.</li> <li>Accede al contenedor desde el navegador para ver la informaci\u00f3n ofrecida por el fichero <code>index.html</code>. \u00bfSegu\u00eda existiendo ese fichero?</li> </ol> <p>Vamos a trabajar con bind mount:</p> <ol> <li>Crea un directorio en tu host y dentro crea un fichero <code>index.html</code>.</li> <li>Crea un contenedor desde la imagen <code>php:7.4-apache</code> donde montes en el directorio <code>/var/www/html</code> el directorio que has creado por medio de <code>bind mount</code>.</li> <li>Accede al contenedor desde el navegador para ver la informaci\u00f3n ofrecida por el fichero <code>index.html</code>.</li> <li>Modifica el contenido del fichero <code>index.html</code> en tu host y comprueba que al refrescar la p\u00e1gina ofrecida por el contenedor, el contenido ha cambiado.</li> <li>Borra el contenedor</li> <li>Crea un nuevo contenedor y monta el mismo directorio como en el ejercicio anterior.</li> <li>Accede al contenedor desde el navegador para ver la informaci\u00f3n ofrecida por el fichero <code>index.html</code>. \u00bfSe sigue viendo el mismo contenido?</li> </ol>"},{"location":"05.-Docker/06.-Vol%C3%BAmenes/Ejercicios%20de%20Vol%C3%BAmenes/#ejercicios-para-entregar","title":"Ejercicios para entregar","text":"<p>Entrega uno de estos dos ejercicios (si est\u00e1s muy aburrido puedes entregar los dos):</p>"},{"location":"05.-Docker/06.-Vol%C3%BAmenes/Ejercicios%20de%20Vol%C3%BAmenes/#creacion-y-uso-de-volumenes","title":"Creaci\u00f3n y uso de vol\u00famenes","text":"<ol> <li>Crear los siguientes vol\u00famenes con la orden <code>docker volume</code>: volumen_datos y volumen_web.</li> <li>Una vez creados:<ul> <li>Arrancar un contenedor llamado <code>c1</code> sobre la imagen <code>php:7.4-apache</code> que monte el volumen_web en la ruta <code>/var/www/html</code> y que sea accesible en el puerto 8080.</li> <li>Arrancar un contenedor llamado <code>c2</code> sobre la imagen <code>mariadb</code> que monte el volumen_datos en la ruta <code>/var/lib/mysql</code> y cuya contrase\u00f1a de <code>root</code> sea <code>admin</code>.</li> </ul> </li> <li>Intenta borrar el volumen volumen_datos, para ello tendr\u00e1s que parar y borrar el contenedor <code>c2</code> y tras ello borrar el volumen.</li> <li>Copia o crea un fichero <code>index.html</code> al contenedor <code>c1</code>, accede al contenedor y comprueba que se est\u00e1 visualizando.</li> <li>Borra el contenedor <code>c1</code> y crea un contenedor <code>c3</code> con las mismas caracter\u00edsticas que <code>c1</code> pero sirviendo en el puerto 8081.</li> </ol> <p>Deber\u00e1s entregar los siguientes pantallazos comprimidos en un zip o en un documento pdf:</p> <ul> <li>Pantallazo donde se puedan ver los dos vol\u00famenes creados.</li> <li>Pantallazo con la orden correspondiente para arrancar el contenedor c1 usando el volumen_web.</li> <li>Pantallazo con la orden correspondiente para arrancar el contenedor c2 usando el volumen_datos.</li> <li>Pantallazo donde se vea el proceso para poder borrar el volumen_datos.</li> <li>Pantallazo donde se vea el borrado de <code>c1</code> y la creaci\u00f3n de <code>c3</code>.</li> <li>Pantallazo donde se vea el acceso al contenedor <code>c3</code>.</li> </ul>"},{"location":"05.-Docker/06.-Vol%C3%BAmenes/Ejercicios%20de%20Vol%C3%BAmenes/#bind-mount-para-compartir-datos","title":"Bind mount para compartir datos","text":"<ol> <li> <p>Crea una carpeta llamada <code>saludo</code> y dentro de ella crea un fichero llamado <code>index.html</code> con el siguiente contenido (Deber\u00e1s sustituir ese XXXXXx por tu nombre.):</p> <p><code>&lt;h1&gt;HOLA SOY XXXXXX&lt;/h1&gt;</code></p> </li> <li> <p>Una vez hecho esto arrancar dos contenedores basados en la imagen php:7.4-apache que hagan un bind mount de la carpeta <code>saludo</code> en la carpeta <code>/var/www/html</code> del contenedor. Uno de ellos vamos a acceder con el puerto 8181 y el otro con el 8282. Y su nombres ser\u00e1n <code>c1</code> y <code>c2</code>.</p> </li> <li>Modifica el contenido del fichero <code>~/saludo/index.html</code>.</li> <li>Comprueba que puedes seguir accediendo a los contenedores, sin necesidad de reiniciarlos.</li> </ol> <p>Deber\u00e1s entregar los siguientes pantallazos comprimidos en un zip o en un documento pdf:</p> <ul> <li>Pantallazo con la orden correspondiente para arrancar el contenedor c1 (puerto 8181) realizando el bind mount solicitado.</li> <li>Pantallazo con la orden correspondiente para arrancar el contenedor c2 (puerto 8282) realizando el bind mount solicitado.</li> <li>Pantallazo donde se pueda apreciar que accediendo a <code>c1</code> se puede ver el contenido de <code>index.html</code>.</li> <li>Pantallazo donde se pueda apreciar que accediendo a <code>c2</code> se puede ver el contenido de <code>index.html</code>.</li> <li>Otro dos pantallazos (o uno) donde se vea accediendo a los contenedores despu\u00e9s de modificar el fichero <code>index.html</code>.</li> </ul>"},{"location":"05.-Docker/07.-Redes/","title":"07.- Redes","text":"<p>Aunque hasta ahora no lo hemos tenido en cuenta, cada vez que creamos un contenedor, \u00e9ste se conecta a una red virtual y docker hace una configuraci\u00f3n del sistema (usando bridges e iptables) para que la m\u00e1quina tenga una ip interna, tenga acceso al exterior, podamos mapear (DNAT) puertos,\u2026</p>"},{"location":"05.-Docker/07.-Redes/01.-Introducci%C3%B3n%20a%20las%20redes%20en%20docker/","title":"Introducci\u00f3n a las redes en docker","text":"<p>Vamos a crear un contenedor interactivo con la imagen <code>debian</code>:</p> <pre><code>$ docker run -it --name contenedor1 --rm debian bash\n</code></pre> <p>Nota: Hemos usado la opci\u00f3n <code>--rm</code> para, al finalizar de ejecutar el proceso, el contenedor se elimine.</p> <p>En otra pesta\u00f1a, podemos ejecutar esta instrucci\u00f3n para obtener la ip que se le ha asignado:</p> <pre><code>$ docker inspect -f '{{range.NetworkSettings.Networks}}{{.IPAddress}}{{end}}' contenedor1\n172.17.0.2\n</code></pre> <p>Obtenemos informaci\u00f3n del contenedor filtrando el fichero json de salida para obtener la IPv4 que se le ha asignado.</p> <p>Observamos que el contenedor tiene una ip en la red <code>172.17.0.0/16</code>. Adem\u00e1s podemos comprobar que se ha creado un <code>bridge</code> en el host, al que se conectan los contenedores:</p> <pre><code>$ ip a\n...\n5: docker0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default \n    link/ether 02:42:be:71:11:9e brd ff:ff:ff:ff:ff:ff\n    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0\n       valid_lft forever preferred_lft forever\n    inet6 fe80::42:beff:fe71:119e/64 scope link \n       valid_lft forever preferred_lft forever\n...\n</code></pre> <p>Podemos comprobar tambi\u00e9n que se han creado distintas cadenas en el cortafuegos para gestionar la comunicaci\u00f3n de los contenedores. Podemos ejecutar como administrador: <code>iptables -L -n</code> e <code>iptables -L -n - t nat</code> para comprobarlo.</p>"},{"location":"05.-Docker/07.-Redes/02.-Tipos%20de%20redes%20en%20docker/","title":"02.-Tipos de redes en docker","text":"<p>Cuando instalamos docker tenemos las siguientes redes predefinidas:</p> <pre><code>$ docker network ls\nNETWORK ID          NAME                DRIVER              SCOPE\nec77cfd20583        bridge              bridge              local\n69bb21378df5        host                host                local\n089cc966eaeb        none                null                local\n</code></pre> <ul> <li> <p>Por defecto los contenedores que creamos se conectan a la red de tipo bridge llamada <code>bridge</code> (por defecto el direccionamiento de esta red es 172.17.0.0/16). Los contenedores conectados a esta red que quieren exponer alg\u00fan puerto al exterior tienen que usar la opci\u00f3n <code>-p</code> para mapear puertos.</p> <p>Este tipo de red nos van a permitir:</p> <ul> <li>Aislar los distintos contenedores que tenemos en distintas subredes docker, de tal manera que desde cada una de las subredes solo podremos acceder a los equipos de esa misma subred.</li> <li>Aislar los contenedores del acceso exterior.</li> <li>Publicar servicios que tengamos en los contenedores mediante redirecciones que docker implementar\u00e1 con las pertinentes reglas de iptables.</li> </ul> <p></p> </li> <li> <p>Si conecto un contenedor a la red host, el contenedor ofrece el servicio que tiene configurado en el puerto de la red del anfitri\u00f3n. No tiene ip propia, sino es como si tuviera la ip del anfitri\u00f3n. Por lo tanto, los puertos son accesibles directamente desde el host. Por ejemplo:</p> </li> </ul> <pre><code>      $ docker run -d --name mi_servidor --network host josedom24/aplicacionweb:v1\n\n      $ docker ps\n      CONTAINER ID        IMAGE                        COMMAND                  CREATED             STATUS              PORTS               NAMES\n      135c742af1ff        josedom24/aplicacionweb:v1   \"/usr/sbin/apache2ct\u2026\"   3 seconds ago       Up 2 seconds                                  mi_servidor\n</code></pre> <p>Probemos a acceder directamente al puerto 80 del servidor para ver la p\u00e1gina web.</p> <ul> <li>La red none no configurar\u00e1 ninguna IP para el contenedor y no tiene acceso a la red externa ni a otros contenedores. Tiene la direcci\u00f3n loopback y se puede usar para ejecutar trabajos por lotes.</li> </ul>"},{"location":"05.-Docker/07.-Redes/03.-Gestionando%20redes%20en%20docker/","title":"03.-Gestionando redes en docker","text":"<p>Tenemos que hacer una diferenciaci\u00f3n entre dos tipos de redes bridge:</p> <ul> <li>La red creada por defecto por docker para que funcionen todos los contenedores.</li> <li>Y las redes \u201cbridge\u201d definidas por el usuario.</li> </ul> <p>La red \u201cbridge\u201d usada por defecto por los contenedores, se diferencia en varios aspectos de las redes \u201cbridge\u201d que creamos nosotros. Estos aspectos son los siguientes:</p> <ul> <li>Las redes que nosotros definamos proporcionan resoluci\u00f3n DNS entre los contenedores, cosa que la red por defecto no hace a no ser que usemos opciones que ya se consideran obsoletas (\u201cdeprectated\u201d) (<code>--link</code>).</li> <li>Puedo conectar en caliente a los contenedores redes \u201cbridge\u201d definidas por el usuario. Si uso la red por defecto tengo que parar previamente el contenedor.</li> <li>Me permite gestionar de manera m\u00e1s segura el aislamiento de los contenedores, ya que si no indico una red al arrancar un contenedor \u00e9ste se incluye en la red por defecto donde pueden convivir servicios que no tengan nada que ver.</li> <li>Tengo m\u00e1s control sobre la configuraci\u00f3n de las redes si las defino yo. Los contenedores de la red por defecto comparten todos la misma configuraci\u00f3n de red (MTU, reglas ip tables etc\u2026).</li> <li>Los contenedores dentro de la red \u201cbridge\u201d por defecto comparten todos ciertas variables de entorno lo que puede provocar ciertos conflictos.</li> </ul> <p>En definitiva: Es importante que nuestro contenedores en producci\u00f3n se est\u00e9n ejecutando sobre una red definida por el usuario.</p> <p>Para gestionar las redes creadas por el usuario:</p> <ul> <li>docker network ls: Listado de las redes.</li> <li>docker network create: Creaci\u00f3n de redes. Ejemplos:<ul> <li><code>docker network create red1</code></li> <li><code>docker network create -d bridge --subnet 172.24.0.0/16 --gateway 172.24.0.1 red2</code></li> </ul> </li> <li>docker network rm/prune: Borrar redes. Teniendo en cuenta que no puedo borrar una red que tenga contenedores que la est\u00e9n usando. deber\u00e9 primero borrar los contenedores o desconectar la red.</li> <li>docker network inspect: Nos da informaci\u00f3n de la red.</li> </ul> <p>Nota: Cada red docker que creemos establece un puente de red espec\u00edfico para cada red que podemos ver con <code>ip a</code>:</p> <p></p>"},{"location":"05.-Docker/07.-Redes/04.-Uso%20de%20la%20red%20bridge%20por%20defecto/","title":"04.-Uso de la red bridge por defecto","text":"<p>Esta manera en enlazar contenedores no est\u00e1 recomendada y es obsoleta. Adem\u00e1s, el uso de contenedores conectados a la red por defecto no est\u00e1 recomendado en entornos de producci\u00f3n. Para realizar este tipo de enlace vamos a usar el flag <code>--link</code>. </p> <p>\u00bfPor qu\u00e9 tratamos sobre ella si ya hemos determinado que no se suelen usar?: La raz\u00f3n es que en la documentaci\u00f3n de las im\u00e1genes en DockerHub se suele explicar el enlazado de contenedores usando esta opci\u00f3n.</p> <p>Veamos un ejemplo, primero creamos un contenedor de mariadb:</p> <pre><code>$ docker run -d --name servidor_mariadb \\\n                -e MYSQL_DATABASE=mi_basededatos \\\n                -e MYSQL_USER=usuario \\\n                -e MYSQL_PASSWORD=asdasd \\\n                -e MYSQL_ROOT_PASSWORD=asdasd \\\n                mariadb\n</code></pre> <p>A continuaci\u00f3n vamos a crear un nuevo contenedor, enlazado con el contenedor anterior:</p> <pre><code>$ docker run -d --name servidor_web --link servidor_mariadb:mariadb nginx\n</code></pre> <p>Para realizar la asociaci\u00f3n entre contenedores (realmente estamos enlazando el contenedor <code>servidor_web</code> al <code>servidor_mariadb</code>) hemos utilizado el par\u00e1metro <code>--link</code>, donde se indica el nombre del contenedor enlazado y un alias por el que nos podemos referir a \u00e9l. Normalmente las aplicaciones utilizan el nombre del alias que hemos indicado para conectarse al otro contenedor. En este tipo de enlace tenemos dos caracter\u00edsticas:</p> <ul> <li>El contenedor al que hemos enlazado es conocido por resoluci\u00f3n est\u00e1tica</li> </ul> <p>El contenedor modifica el fichero <code>/etc/hosts</code> para que tengamos resoluci\u00f3n est\u00e1tica del contenedor enlazado. Podemos comprobarlo:</p> <pre><code>$ docker exec servidor_web cat /etc/hosts\n...\n172.17.0.2  mariadb c76089892798 servidor_mariadb\n</code></pre> <p>Podemos comprobar que el servidor DNS del contenedor, es el mismo que tiene nuestro host, por lo tanto la resoluci\u00f3n no se hace desde un servidor DNS:</p> <pre><code>$ docker exec servidor_web cat /etc/resolv.conf\n...\nnameserver 192.168.121.1\n</code></pre> <p>El servidor DNS <code>192.168.121.1</code> es el que tiene configurado el equipo local donde hemos instalado docker.</p> <ul> <li>Se comparten las variables de entorno</li> </ul> <p>Las variables de entorno del contenedor enlazado son accesibles desde el contenedor. Por cada asociaci\u00f3n de contenedores, docker crea una serie de variables de entorno, en este caso, en el contenedor servidor, se crear\u00e1n las siguientes variables, donde se utiliza el nombre del alias indicada en el par\u00e1metro <code>--link</code>:</p> <pre><code>$ docker exec servidor_web env\n...\nMARIADB_PORT=tcp://172.17.0.2:3306\nMARIADB_PORT_3306_TCP=tcp://172.17.0.2:3306\nMARIADB_PORT_3306_TCP_ADDR=172.17.0.2\nMARIADB_PORT_3306_TCP_PORT=3306\nMARIADB_PORT_3306_TCP_PROTO=tcp\nMARIADB_NAME=/servidor/mariadb\nMARIADB_ENV_MYSQL_USER=usuario\nMARIADB_ENV_MYSQL_PASSWORD=asdasd\nMARIADB_ENV_MYSQL_ROOT_PASSWORD=asdasd\nMARIADB_ENV_MYSQL_DATABASE=mi_basededatos\nMARIADB_ENV_GOSU_VERSION=1.10\nMARIADB_ENV_GPG_KEYS=177F4010FE56CA3336300305F1656F24C74CD1D8\nMARIADB_ENV_MARIADB_MAJOR=10.4\nMARIADB_ENV_MARIADB_VERSION=1:10.4.11+maria~bionic\n</code></pre>"},{"location":"05.-Docker/07.-Redes/05.-Uso%20de%20las%20redes%20bridge%20definidas%20por%20el%20usuario/","title":"05.-Uso de las redes bridge definidas por el usuario","text":"<p>Vamos a crear una red tipo bridge definida por el usuario con la instrucci\u00f3n <code>docker network create</code>:</p> <pre><code>$ docker network create red1\n\n</code></pre> <p>Como no hemos indicado ninguna configuraci\u00f3n en la red que hemos creado, docker asigna un direccionamiento a la red:</p> <pre><code>$ docker network inspect red1\n[\n    {\n        \"Name\": \"red1\",\n        ...\n            \"Config\": [\n                {\n                    \"Subnet\": \"172.18.0.0/16\",\n                    \"Gateway\": \"172.18.0.1\"\n                }\n            ]\n        },\n        ...\n]\n</code></pre> <p>Vamos a crear dos contenedores conectados a dicha red:</p> <pre><code>$ docker run -d --name my-apache-app --network red1 -p 8080:80 httpd:2.4\n</code></pre> <p>Lo primero que vamos a comprobar es la resoluci\u00f3n DNS:</p> <pre><code>$ docker run -it --name contenedor1 --network red1 debian bash\nroot@98ab5a0c2f0c:/# apt update &amp;&amp; apt install dnsutils -y\n...\nroot@98ab5a0c2f0c:/# dig my-apache-app\n...\n;; ANSWER SECTION:\nmy-apache-app.      600 IN  A   172.18.0.2\n...\n;; SERVER: 127.0.0.11#53(127.0.0.11)\n...\n</code></pre> <p>Podemos comprobar la configuraci\u00f3n DNS del contenedor:</p> <pre><code>root@98ab5a0c2f0c:/# cat /etc/resolv.conf \nnameserver 127.0.0.11\n...\n</code></pre> <p>Evidentemente desde los dos contenedores se pueden resolver los dos nombres:</p> <pre><code>root@98ab5a0c2f0c:/# dig contenedor1\n...\n;; ANSWER SECTION:\ncontenedor1.        600 IN  A   172.18.0.3\n...\n;; SERVER: 127.0.0.11#53(127.0.0.11)\n...\n</code></pre>"},{"location":"05.-Docker/07.-Redes/05.-Uso%20de%20las%20redes%20bridge%20definidas%20por%20el%20usuario/#conectando-los-contenedores-a-otras-redes","title":"Conectando los contenedores a otras redes","text":"<p>A continuaci\u00f3n vamos a crear otra red bridge, pero vamos a indicar el direccionamiento:</p> <pre><code>$ docker network create red2 --subnet 192.168.100.0/24 --gateway 192.168.100.1\n</code></pre> <p>Creamos un contenedor conectado a esta nueva red y comprobamos que no hay conectividad con los dos anteriores:</p> <pre><code>$ docker run -it --name contenedor2 --network red2 debian bash\nroot@f9c7ac830a18:/# ip a\n...\n    inet 192.168.100.2/24 brd 192.168.100.255 scope global eth0\n...\nroot@f9c7ac830a18:/# ping contenedor1\nping: contenedor1: Name or service not known\n</code></pre> <p>Ahora podemos probar como podemos conectar un contenedor a una red. Para conectar usaremos <code>docker network connect</code> y para desconectarla usaremos <code>docker network disconnect</code>.</p> <pre><code>$ docker network connect red2 contenedor1 \n\n$ docker start contenedor1\ncontenedor1\n\n$ docker start contenedor2\ncontenedor2\n\n$ docker attach contenedor1\nroot@98ab5a0c2f0c:/# ip a\n...\n46: eth0@if47: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default\n    ...\n    inet 172.18.0.3/16 brd 172.18.255.255 scope global eth0\n...\n48: eth1@if49: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default \n...    \n    inet 192.168.100.2/24 brd 192.168.100.255 scope global eth1\n...\nroot@98ab5a0c2f0c:/# ping contenedor2\nPING contenedor2 (192.168.100.3) 56(84) bytes of data.\n64 bytes from contenedor2.red2 (192.168.100.3): icmp_seq=1 ttl=64 time=0.082 ms\n...\n</code></pre> <p>Evidentemente desde el <code>contenedor2</code> tambi\u00e9n tenemos conectividad a contenedor1, pero evidentemente no al contenedor <code>my-apache-app</code>:</p> <pre><code>$ docker attach contenedor2\nroot@f9c7ac830a18:/# ping contenedor1\nPING contenedor1 (192.168.100.2) 56(84) bytes of data.\n64 bytes from contenedor1.red2 (192.168.100.2): icmp_seq=1 ttl=64 time=0.072 ms\n...\nroot@f9c7ac830a18:/# ping my-apache-app\nping: my-apache-app: Name or service not known\n</code></pre>"},{"location":"05.-Docker/07.-Redes/05.-Uso%20de%20las%20redes%20bridge%20definidas%20por%20el%20usuario/#mas-opciones-al-trabajar-con-redes-en-docker","title":"M\u00e1s opciones al trabajar con redes en docker","text":"<p>Tanto al crear un contenedor con el flag <code>--network</code>, como con la instrucci\u00f3n <code>docker network connect</code>, podemos usar algunos otros flags:</p> <ul> <li><code>--dns</code>: para establecer unos servidores DNS predeterminados.</li> <li><code>--ip</code>: Para establecer una ip fija en el contenedor.</li> <li><code>--ip6</code>: para establecer la direcci\u00f3n de red ipv6</li> <li><code>--hostname</code> o <code>-h</code>: para establecer el nombre de host del contenedor. Si no lo establezco ser\u00e1 el ID del mismo.</li> <li><code>--add-host</code>: a\u00f1ade entradas de nuevos hosts en el fichero <code>/etc/hosts</code></li> </ul> <p>Veamos un ejemplo:</p> <p>Primero creamos una red:</p> <pre><code>$ docker network create --subnet 192.168.100.0/24 red3\n</code></pre> <p>Y creamos un contenedor conectado a esta red con algunos par\u00e1metros extras:</p> <pre><code>$ docker run -it --name contenedor --network red3 \\\n                                   --ip 192.168.100.10 \\\n                                   --add-host=testing.example.com:192.168.100.20 \\\n                                   --dns 8.8.8.8 \\\n                                   --hostname servidor1 \\\n                                   debian\n</code></pre> <p>Como hemos comentado anteriormente estos par\u00e1metros tambi\u00e9n lo podemos usar al conectar un contenedor a una red con <code>docker network connect</code>. Veamos con detenimiento cada uno de los par\u00e1metros:</p> <ul> <li><code>--hostname servidor1</code>: Indicamos el nombre de la m\u00e1quina. Lo comprobamos:</li> </ul> <pre><code>root@servidor1:/# cat /etc/hostname \nservidor1\n</code></pre> <ul> <li><code>--ip 192.168.100.10</code>: Nos permite poner una ip fija en el contenedor. Vamos a comprobarlo:</li> </ul> <pre><code>root@servidor1:/# ip a\n...\n25: eth0@if26: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default \n    ...\n    inet 192.168.100.10/24 brd 192.168.100.255 scope global eth0\n    ...\n</code></pre> <ul> <li><code>--add-host=testing.example.com:192.168.100.20</code>: A\u00f1adimos un nuevos host como resoluci\u00f3n est\u00e1tica. Lo comprobamos:</li> </ul> <pre><code>root@servidor1:/# cat /etc/hosts\n...\n192.168.100.20  testing.example.com\n192.168.100.10  servidor1\n\nroot@servidor1:/# ping testing.example.com\nPING testing.example.com (192.168.100.20) 56(84) bytes of data.\n...\n</code></pre> <ul> <li><code>--dns 8.8.8.8</code>: Hemos configurado como DNS el servidor <code>8.8.8.8</code>. Veamos esto con detenimiento, como hemos visto anteriormente al conectar el contenedor a una red bridge definida por el usuario se crea un servidor DNS que nos permite la resoluci\u00f3n por el nombre del contenedor (par\u00e1metro <code>--name</code>, no se resuelve el nombre que hayamos indicado con el par\u00e1metro <code>--hostname</code>), veamos el servidor DNS:</li> </ul> <pre><code>root@servidor1:/# cat /etc/resolv.conf \nnameserver 127.0.0.11\n...\n</code></pre> <p>Por defecto este servidor hace forward con el servidor DNS que tenga configurado el anfitri\u00f3n (es decir usa el DNS del anfitri\u00f3n para resolver los nombre que no conoce). Con la opci\u00f3n <code>--dns 8.8.8.8</code>, estamos cambiando el DNS al que hacemos forwarding, por lo tanto ese cambio no se visualizar en el fichero <code>/etc/resolv.conf</code>.</p>"},{"location":"05.-Docker/07.-Redes/06.-Convertir%20el%20uso%20de%20la%20red%20bridge%20por%20defecto%20por%20una%20definida%20por%20el%20usuario/","title":"06.-Convertir el uso de la red bridge por defecto por una definida por el usuario","text":"<p>Hemos comentado que en muchos de las descripciones de las im\u00e1genes que encontramos en Docker Hub se sigue utilizando el par\u00e1metro <code>--link</code> para enlazar los contenedores que se conectan en la red bridge por defecto.</p> <p>Por ejemplo, vamos a estudiar la imagen <code>sdelements/lets-chat</code> que nos permite ejecutar una aplicaci\u00f3n desarrollado con node.js y que implementa un chat. Esta aplicaci\u00f3n usa una base de datos mongodb para guardar los datos.</p> <p>Si nos fijamos en la documentaci\u00f3n de la imagen, nos pone la siguiente instrucci\u00f3n para crear el contenedor a partir de la imagen:</p> <pre><code>$ docker run  --name some-letschat --link some-mongo:mongo -p 8080:8080 -d sdelements/lets-chat\n</code></pre> <p>Estamos suponiendo que tenemos un contenedor llamado <code>some-mongo</code> creada a partir de la imagen <code>mongo</code> que esta sirviendo la base de datos:</p> <pre><code>$ docker run -d --name some-mongo mongo\n</code></pre> <p>El contenedor <code>some-letschat</code> se enlaza con el contenedor <code>some-mongo</code> con el par\u00e1metro <code>--link some-mongo:mongo</code>, es decir el contenedor de la aplicaci\u00f3n podr\u00e1 hacer referencia (por resoluci\u00f3n est\u00e1tica) al servidor de base de datos por los dos nombres: el nombre del contenedor <code>some-mongo</code> y el alias que hemos creado <code>mongo</code>. C\u00f3mo coment\u00e1bamos anteriormente el nombre de alias es el que se usa internamente por la aplicaci\u00f3n para conectar con la base de datos.</p>"},{"location":"05.-Docker/07.-Redes/06.-Convertir%20el%20uso%20de%20la%20red%20bridge%20por%20defecto%20por%20una%20definida%20por%20el%20usuario/#usando-una-red-bridge-por-defecto","title":"Usando una red bridge por defecto","text":"<p>Vamos a estudiar c\u00f3mo podemos realizar este despliegue usando una red bridge definida por el usuario. En este caso, los contenedores que conectaremos a esa nueva red tendr\u00e1n resoluci\u00f3n DNs usando los nombres de los contenedores. Por lo tanto, como sabemos que la aplicaci\u00f3n usa el nombre del alias (<code>mongo</code>) para conectarse al otro contenedor, lo \u00fanico que tenemos que hacer es poner ese mismo nombre al contenedor de la base de datos.</p> <p>Creamos una red bridge definida por el usuario:</p> <pre><code>$ docker network create red_letschat\n</code></pre> <p>Creamos el contenedor de la base de datos conectado a la nueva red, haciendo coincidir el nombre con el alias que pon\u00edamos anteriormente con el par\u00e1metro <code>--link</code>:</p> <pre><code>$ docker run -d --network red_letschat --name mongo mongo\n</code></pre> <p>Y el contenedor de la aplicaci\u00f3n conectado a la nueva red:</p> <pre><code>$ docker run --name some-letschat --network red_letschat -p 8080:8080 -d sdelements/lets-chat\n</code></pre> <p></p>"},{"location":"05.-Docker/07.-Redes/07.-Ejemplos/","title":"Ejemplo 1: Despliegue de la aplicaci\u00f3n Guestbook","text":"<p>En este ejemplo vamos a desplegar una aplicaci\u00f3n web que requiere de dos servicios (servicio web y servicio de base de datos) para su ejecuci\u00f3n. La aplicaci\u00f3n se llama GuestBook y necesita los dos siguientes servicios:</p> <ul> <li>La aplicaci\u00f3n guestbook es una aplicaci\u00f3n web desarrollada en python que es servida por el puerto 5000/tcp. Utilizaremos la imagen <code>iesgn/guestbook</code>.</li> <li>Esta aplicaci\u00f3n guarda la informaci\u00f3n en una base de datos no relacional redis, que utiliza el puerto 6379/tcp para conectarnos. Usaremos la imagen <code>redis</code>.</li> </ul> <p>La aplicaci\u00f3n guestbook por defecto utiliza el nombre <code>redis</code> para conectarse a la base de datos, por lo tanto debemos nombrar al contenedor redis con ese nombre para que tengamos una resoluci\u00f3n de nombres adecuada.</p> <p>Los dos contenedores tienen que estar en la misma red y deben tener acceso por nombres (resoluci\u00f3n DNS) ya que de principio no sabemos que ip va a coger cada contenedor. Por lo tanto vamos a crear los contenedores en la misma red:</p> <pre><code>$ docker network create red_guestbook\n</code></pre> <p>Para ejecutar los contenedores:</p> <pre><code>$ docker run -d --name redis --network red_guestbook redis\n\n$ docker run -d -p 80:5000 --name guestbook --network red_guestbook iesgn/guestbook\n</code></pre> <p>Algunas observaciones:</p> <ul> <li>No es necesario mapear el puerto de <code>redis</code>, ya que no vamos a acceder desde el exterior. Sin embargo la aplicaci\u00f3n <code>guestbook</code> va a poder acceder a la base de datos porque est\u00e1n conectado a la misma red.</li> <li>Al nombrar al contenedor de la base de datos con <code>redis</code> se crea una entrada en el DNS que resuelve ese nombre con la ip del contenedor. Como hemos indicado, por defecto, la aplicaci\u00f3n guestbook usa ese nombre para acceder.</li> </ul> <p></p>"},{"location":"05.-Docker/07.-Redes/07.-Ejemplos/#ejemplo-2-despliegue-de-la-aplicacion-temperaturas","title":"Ejemplo 2: Despliegue de la aplicaci\u00f3n Temperaturas","text":"<p>Vamos a hacer un despliegue completo de una aplicaci\u00f3n llamada Temperaturas. Esta aplicaci\u00f3n nos permite consultar la temperatura m\u00ednima y m\u00e1xima de todos los municipios de Espa\u00f1a. Esta aplicaci\u00f3n est\u00e1 formada por dos microservicios:</p> <ul> <li><code>frontend</code>: Es una aplicaci\u00f3n escrita en Python que nos ofrece una p\u00e1gina web para hacer las b\u00fasquedas y visualizar los resultados. Este microservicio har\u00e1 peticiones HTTP al segundo microservicio para obtener la informaci\u00f3n. Este microservicio ofrece el servicio en el puerto 3000/tcp. Usaremos la imagen <code>iesgn/temperaturas_frontend</code>.</li> <li><code>backend</code>: Es el segundo microservicio que nos ofrece un servicio web de tipo API Restful. A esta API Web podemos hacerles consultas sobre los municipios y sobre las temperaturas. En este caso, se utiliza el puerto 5000/tcp para ofrecer el servicio. Usaremos la imagen <code>iesgn/temperaturas_backend</code>.</li> </ul> <p>El microservicio <code>frontend</code> se conecta a <code>backend</code> usando el nombre <code>temperaturas-backend</code>. Por lo tanto el contenedor con el micorservicio <code>backend</code> tendr\u00e1 ese nombre para disponer de una resoluci\u00f3n de nombres adecuada en el dns.</p> <p>Vamos a crear una red para conectar los dos contenedores:</p> <pre><code>$ docker network create red_temperaturas\n</code></pre> <p>Para ejecutar los contenedores:</p> <pre><code>$ docker run -d --name temperaturas-backend --network red_temperaturas iesgn/temperaturas_backend\n\n$ docker run -d -p 80:3000 --name temperaturas-frontend --network red_temperaturas iesgn/temperaturas_frontend\n</code></pre> <p>Algunas observaciones:</p> <ul> <li>Este es un tipo de aplicaci\u00f3n, que se caracteriza por no necesitar guardar informaci\u00f3n para su funcionamiento. Son las denominadas aplicaciones sin estado, por lo tanto no necesitamos almacenamiento adicional para la aplicaci\u00f3n.</li> <li>No es necesario mapear el puerto de <code>backend</code>, ya que no vamos a acceder desde el exterior. Sin embargo el microservicio <code>frontend</code> va a poder acceder a <code>backend</code> al puerto 5000 porque est\u00e1n conectado a la misma red.</li> <li>Al nombrar al contenedor de la base de datos con <code>temperaturas-backend</code> se crea una entrada en el DNS que resuelve ese nombre con la ip del contenedor. Como hemos indicado, por defecto, el microservicio <code>frontend</code> usa ese nombre para acceder.</li> </ul> <p></p>"},{"location":"05.-Docker/07.-Redes/07.-Ejemplos/#ejemplo-3-despliegue-de-wordpress-mariadb","title":"Ejemplo 3: Despliegue de Wordpress + mariadb","text":"<p>Para la instalaci\u00f3n de WordPress necesitamos dos contenedores: la base de datos (imagen <code>mariadb</code>) y el servidor web con la aplicaci\u00f3n (imagen <code>wordpress</code>). Los dos contenedores tienen que estar en la misma red y deben tener acceso por nombres (resoluci\u00f3n DNS) ya que de principio no sabemos que ip va a coger cada contenedor. Por lo tanto vamos a crear los contenedores en la misma red:</p> <pre><code>$ docker network create red_wp\n</code></pre> <p>Siguiendo la documentaci\u00f3n de la imagen mariadb y la imagen wordpress podemos ejecutar los siguientes comandos para crear los dos contenedores:</p> <pre><code>$ docker run -d --name servidor_mysql \\\n                --network red_wp \\\n                -v /opt/mysql_wp:/var/lib/mysql \\\n                -e MYSQL_DATABASE=bd_wp \\\n                -e MYSQL_USER=user_wp \\\n                -e MYSQL_PASSWORD=asdasd \\\n                -e MYSQL_ROOT_PASSWORD=asdasd \\\n                mariadb\n\n$ docker run -d --name servidor_wp \\\n                --network red_wp \\\n                -v /opt/wordpress:/var/www/html/wp-content \\\n                -e WORDPRESS_DB_HOST=servidor_mysql \\\n                -e WORDPRESS_DB_USER=user_wp \\\n                -e WORDPRESS_DB_PASSWORD=asdasd \\\n                -e WORDPRESS_DB_NAME=bd_wp \\\n                -p 80:80 \\\n                wordpress\n\n$ docker ps\nCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                NAMES\n5b2c5a82a524        wordpress           \"docker-entrypoint.s\u2026\"   9 minutes ago       Up 9 minutes        0.0.0.0:80-&gt;80/tcp   servidor_wp\nf70f22aed3d1        mariadb             \"docker-entrypoint.s\u2026\"   9 minutes ago       Up 9 minutes        3306/tcp             servidor_mysql\n</code></pre> <p>Algunas observaciones:</p> <ul> <li>El contenedor <code>servidor_mysql</code> ejecuta un script <code>docker-entrypoint.sh</code> que es el encargado, a partir de las variables de entorno, configurar la base de datos: crea usuario, crea base de datos, cambia la contrase\u00f1a del usuario root,\u2026 y termina ejecutando el servidor mariadb.</li> <li>Al crear la imagen <code>mariadb</code> han tenido en cuenta de que tiene que permitir la conexi\u00f3n desde otra m\u00e1quina, por lo que en la configuraci\u00f3n tenemos comentado el par\u00e1metro <code>bind-address</code>.</li> <li>Del mismo modo el contenedor <code>servidor_wp</code> ejecuta un script <code>docker-entrypoint.sh</code>, que entre otras cosas, a partir de las variables de entorno, ha creado el fichero <code>wp-config.php</code> de wordpress, por lo que durante la instalaci\u00f3n no te ha pedido las credenciales de la base de datos.</li> <li>Si te das cuenta la variable de entorno <code>WORDPRESS_DB_HOST</code> la hemos inicializado al nombre del servidor de base de datos. Como est\u00e1n conectada a la misma red definida por el usuario, el contenedor wordpress al intentar acceder al nombre <code>servidor_mysql</code> estar\u00e1 accediendo al contenedor de la base de datos.</li> <li>Al servicio al que vamos a acceder desde el exterior es al servidor web, es por lo que hemos mapeado los puertos con la opci\u00f3n <code>-p</code>. Sin embargo en el contenedor de la base de datos no es necesario mapear los puertos porque no vamos a acceder a ella desde el exterior. Sin embargo, el contenedor <code>servidor_wp</code> puede acceder al puerto 3306 del <code>servidor_mysql</code> sin problemas ya que est\u00e1n conectados a la misma red.</li> </ul> <p></p>"},{"location":"05.-Docker/07.-Redes/07.-Ejemplos/#ejemplo-4-despliegue-de-tomcat-nginx","title":"Ejemplo 4: Despliegue de tomcat + nginx","text":"<p>En este ejemplo vamos a desplegar una aplicaci\u00f3n muy sencilla en un servidor de aplicaci\u00f3n Tomcat, a la que accederemos utilizando un proxy inverso nginx. En este ejercicio, adem\u00e1s de seguir trabajando con las redes de tipo bridge definida por el usuario, vamos a usar bind mount para montar los ficheros de configuraci\u00f3n y de despliegue en los contenedores.</p>"},{"location":"05.-Docker/07.-Redes/07.-Ejemplos/#desplegando-tomcat","title":"Desplegando tomcat","text":"<p>Antes de hacer el despliegue del primer contenedor, vamos a crear una red bridge para conectar los contenedores:</p> <pre><code>$ docker network create red_tomcat\n</code></pre> <p>A continuaci\u00f3n vamos a crear un contenedor a partir de la imagen <code>tomcat</code>. En la documentaci\u00f3n podemos ver que el directorio <code>/usr/local/tomcat/webapps/</code> es donde tenemos que poner el fichero de despliegue <code>war</code> (vamos a usar bind mount para montar el fichero war en el directorio). No vamos a mapear puerto porque no vamos a acceder a este contenedor desde el exterior.</p> <p>Tenemos un directorio donde tenemos el fichero war (puedes encontrar estos ficheros en el repositorio github):</p> <pre><code>$ cd tomcat\n~/tomcat$ ls\ndefault.conf  sample.war\n</code></pre> <p>Y creamos el contenedor conectada a nuestra nueva red:</p> <pre><code>$ docker run -d --name aplicacionjava \\\n                --network red_tomcat \\\n                -v /home/vagrant/tomcat/sample.war:/usr/local/tomcat/webapps/sample.war:ro \\\n                tomcat:9.0\n</code></pre>"},{"location":"05.-Docker/07.-Redes/07.-Ejemplos/#desplegando-nginx-como-proxy-inverso","title":"Desplegando nginx como proxy inverso","text":"<p>Como vimos anteriormente en el directorio de trabajo tenemos tambi\u00e9n la configuraci\u00f3n de nginx para que funcione como proxy inverso:</p> <pre><code>server {\n    listen       80;\n    listen  [::]:80;\n    server_name  localhost;\n\n    location / {\n        root   /usr/share/nginx/html;\n    proxy_pass http://aplicacionjava:8080/sample/;\n    }\n    error_page   500 502 503 504  /50x.html;\n    location = /50x.html {\n        root   /usr/share/nginx/html;\n    }\n}\n</code></pre> <p>Como vemos para realizar el proxy inverso usamos la directiva <code>proxy_pass</code>indicando la direcci\u00f3n que nos ofrece tomcat, en este caso usamos el nombre del contenedor anterior (<code>aplicacionjava</code>) que ser\u00e1 resuelto por el servidor DNS interno, usando el puerto est\u00e1ndar de tomcat el 8080 y el directorio <code>sample</code> donde se ha desplegado la aplicaci\u00f3n. Para la creaci\u00f3n del contenedor de nginx:</p> <pre><code>$ docker run -d --name proxy \\\n                -p 80:80 \\\n                --network red_tomcat \\\n                -v /home/vagrant/tomcat/default.conf:/etc/nginx/conf.d/default.conf:ro \\\n                nginx\n</code></pre> <p>Y al acceder la ip de nuestro host:</p> <p></p>"},{"location":"05.-Docker/08.-Escenarios%20multicontenedor/","title":"08.- Escenarios multicontenedor","text":"<p>Compose es una herramienta para definir y ejecutar aplicaciones Docker multicontenedor. Con Compose, utilizamos un archivo YAML para configurar los servicios de nuestra aplicaci\u00f3n. Luego, con un solo comando, creamos e iniciamos todos los servicios a partir de nuestra configuraci\u00f3n.</p> <p>Compose funciona en todos los entornos: producci\u00f3n, staging, desarrollo, pruebas, as\u00ed como flujos de trabajo CI (Continuous Integration). Tambi\u00e9n dispone de comandos para gestionar todo el ciclo de vida de su aplicaci\u00f3n:</p> <ul> <li>Iniciar, detener y reconstruir servicios</li> <li>Ver el estado de los servicios en ejecuci\u00f3n</li> <li>Transmitir la salida de registro de los servicios en ejecuci\u00f3n</li> <li>Ejecutar un comando puntual en un servicio</li> </ul> <p>Las caracter\u00edsticas clave de Compose que lo hacen eficaz son:</p> <ul> <li>Disponer de m\u00faltiples entornos aislados en un \u00fanico host</li> <li>Preserva los datos de volumen cuando se crean contenedores</li> <li>S\u00f3lo recrea los contenedores que han cambiado</li> <li>Soporta variables y el movimiento de las composiciones entre entornos</li> </ul>"},{"location":"05.-Docker/08.-Escenarios%20multicontenedor/01.-Instalaci%C3%B3n%20de%20docker-compose/","title":"01.-Instalaci\u00f3n de docker-compose","text":"<p>La manera m\u00e1s sencilla de realizar la instalaci\u00f3n de esta herramienta es utilizar el paquete de nuestra distribuci\u00f3n:</p> <pre><code>apt install docker-compose\n</code></pre> <p>Tambi\u00e9n se puede con <code>pip</code> en un entorno virtual:</p> <pre><code>python3 -m venv docker-compose\nsource docker-compose/bin/activate\n(docker-compose) ~# pip install docker-compose\n</code></pre> <p>Puedes acceder a la documentaci\u00f3n oficial para ver otras posibilidades de instalaci\u00f3n.</p>"},{"location":"05.-Docker/08.-Escenarios%20multicontenedor/02.-El%20fichero%20docker-compose.yml/","title":"02.-El fichero docker-compose.yml","text":"<p>En el fichero <code>docker-compose.yml</code> vamos a definir el escenario. El programa docker-compose se debe ejecutar en el directorio donde este ese fichero. Por lo tanto tenderemos un directorio con un fichero <code>docker-compose.yml</code> para cada una las aplicaciones que queremos desplegar. Por ejemplo para la ejecuci\u00f3n de la aplicaci\u00f3n Let\u2019s Chat podr\u00edamos tener un fichero <code>docker-compose.yml</code>, dentro de una carpeta, con el siguiente contenido:</p> <pre><code>version: '3.1'\nservices:\n  app:\n    container_name: letschat\n    image: sdelements/lets-chat\n    restart: always\n    environment:\n      LCB_DATABASE_URI: mongodb://mongo/letschat\n    ports:\n      - 80:8080\n    depends_on:\n      - db\n  db:\n    container_name: mongo\n    image: mongo\n    restart: always\n    volumes:\n      - /opt/mongo:/data/db\n</code></pre> <p>Puedes encontrar todos los par\u00e1metros que podemos definir en la documentaci\u00f3n oficial.</p> <p>Algunos par\u00e1metros interesantes:</p> <ul> <li>Es escenario est\u00e1 formado por <code>services</code>. Cada uno ello va a crear un contenedor.</li> <li><code>restart: always</code>: Indicamos la pol\u00edtica de reinicio del contenedor si por cualquier condici\u00f3n se para. M\u00e1s informaci\u00f3n.</li> <li><code>depend on</code>: Indica la dependencia entre contenedores. No se va a iniciar un contenedor hasta que otro este funcionando. M\u00e1s informaci\u00f3n.</li> </ul> <p>Cuando creamos un escenario con <code>docker-compose</code> se crea una nueva red definida por el usuario donde se conectan los contenedores, por lo tanto, obtenemos resoluci\u00f3n por dns que resuelve tanto el nombre del contenedor (por ejemplo, <code>mongo</code>) como el nombre del servicio (por ejemplo, <code>db</code>).</p>"},{"location":"05.-Docker/08.-Escenarios%20multicontenedor/03.-El%20comando%20docker-compose/","title":"03.-El comando docker-compose","text":"<p>Una vez hemos creado el archivo <code>docker-compose.yml</code> tenemos que empezar a trabajar con \u00e9l, es decir a crear los contenedores que describe su contenido.</p> <p>Esto lo haremos mediante el ejecutable <code>docker-compose</code>. Es importante destacar que debemos invocarla desde el directorio en el que se encuentra el fichero <code>docker-compose.yml</code>.</p> <p>Los subcomandos m\u00e1s usados son:</p> <ul> <li><code>docker-compose up</code>: Crear los contenedores (servicios) que est\u00e1n descritos en el <code>docker-compose.yml</code>.</li> <li><code>docker-compose up -d</code>: Crear en modo detach los contenedores (servicios) que est\u00e1n descritos en el <code>docker-compose.yml</code>. Eso significa que no muestran mensajes de log en el terminal y que se nos vuelve a mostrar un prompt.</li> <li><code>docker-compose stop</code>: Detiene los contenedores que previamente se han lanzado con <code>docker-compose up</code>.</li> <li><code>docker-compose run</code>: Inicia los contenedores descritos en el <code>docker-compose.yml</code> que est\u00e9n parados.</li> <li><code>docker-compose rm</code>: Borra los contenedores parados del escenario. Con las opci\u00f3n <code>-f</code> elimina tambi\u00e9n los contenedores en ejecuci\u00f3n.</li> <li><code>docker-compose pause</code>: Pausa los contenedores que previamente se han lanzado con <code>docker-compose up</code>.</li> <li><code>docker-compose unpause</code>: Reanuda los contenedores que previamente se han pausado.</li> <li><code>docker-compose restart</code>: Reinicia los contenedores. Orden ideal para reiniciar servicios con nuevas configuraciones.</li> <li><code>docker-compose down</code>: Para los contenedores, los borra y tambi\u00e9n borra las redes que se han creado con <code>docker-compose up</code> (en caso de haberse creado).</li> <li><code>docker-compose down -v</code>: Para los contenedores y borra contenedores, redes y vol\u00famenes.</li> <li><code>docker-compose logs</code>: Muestra los logs de todos los servicios del escenario. Con el par\u00e1metro <code>-f</code>podremos ir viendo los logs en \u201cvivo\u201d.</li> <li><code>docker-compose logs servicio1</code>: Muestra los logs del servicio llamado <code>servicio1</code> que estaba descrito en el <code>docker-compose.yml</code>.</li> <li><code>docker-compose exec servicio1 /bin/bash</code>: Ejecuta una orden, en este caso <code>/bin/bash</code> en un contenedor llamado <code>servicio1</code> que estaba descrito en el <code>docker-compose.yml</code></li> <li><code>docker-compose build</code>: Ejecuta, si est\u00e1 indicado, el proceso de construcci\u00f3n de una imagen que va a ser usado en el <code>docker-compose.yml</code> a partir de los ficheros <code>Dockerfile</code> que se indican.</li> <li><code>docker-compose top</code>: Muestra los procesos que est\u00e1n ejecut\u00e1ndose en cada uno de los contenedores de los servicios.</li> </ul>"},{"location":"05.-Docker/08.-Escenarios%20multicontenedor/03.-El%20comando%20docker-compose/#despliegue-de-lets-chat","title":"Despliegue de Let\u2019s Chat","text":"<p>Para desplegar la aplicaci\u00f3n Let\u2019s Chat que vimos en el punto anterior, ejecutamos la siguiente instrucci\u00f3n en el directorio donde tengamos el fichero <code>docker-compose.yml</code>:</p> <pre><code>$ docker-compose up -d\nCreating network \"letschat_default\" with the default driver\nCreating mongo ... done\nCreating letschat ... done\n</code></pre> <p>Podemos ver los contenedores que se est\u00e1n ejecutando:</p> <pre><code>$ docker-compose ps\n  Name               Command             State               Ports             \n-------------------------------------------------------------------------------\nletschat   npm start                     Up      5222/tcp, 0.0.0.0:80-&gt;8080/tcp\nmongo      docker-entrypoint.sh mongod   Up      27017/tcp                   \n</code></pre> <p>Podemos acceder desde el navegador a la aplicaci\u00f3n:</p> <p></p> <p>Finalmente podemos destruir el escenario:</p> <pre><code>$ docker-compose down \nStopping letschat ... done\nStopping mongo   ... done\nRemoving letschat ... done\nRemoving mongo   ... done\nRemoving network letschat_default\n</code></pre>"},{"location":"05.-Docker/08.-Escenarios%20multicontenedor/04.-Almacenamiento%20con%20docker-compose/","title":"04.-Almacenamiento con docker-compose","text":""},{"location":"05.-Docker/08.-Escenarios%20multicontenedor/04.-Almacenamiento%20con%20docker-compose/#definiendo-volumenes-docker-con-docker-compose","title":"Definiendo vol\u00famenes docker con docker-compose","text":"<p>Adem\u00e1s de definir los <code>services</code>, con docker-compose podemos definir los vol\u00famenes que vamos a necesitar en nuestra infraestructura. Adem\u00e1s, como hemos visto, podremos indicar que vol\u00famen va a utilizar cada contenedor.</p> <p>Veamos un ejemplo:</p> <pre><code>version: '3.1'\nservices:\n  db:\n    container_name: contenedor_mariadb\n    image: mariadb\n    restart: always\n    environment:\n      MYSQL_ROOT_PASSWORD: asdasd\n    volumes:\n      - mariadb_data:/var/lib/mysql\nvolumes:\n    mariadb_data:\n</code></pre> <p>Y podemos iniciar el escenario:</p> <pre><code>$ docker-compose up -d\nCreating network \"docker-compose_default\" with the default driver\nCreating volume \"docker-compose_mariadb_data\" with default driver\nCreating contenedor_mariadb ... done\n\n$ docker-compose ps\n       Name                    Command             State    Ports  \n-------------------------------------------------------------------\ncontenedor_mariadb   docker-entrypoint.sh mysqld   Up      3306/tcp\n</code></pre> <p>Y comprobamos que se ha creado un nuevo volumen:</p> <pre><code>$ docker volume ls\nDRIVER    VOLUME NAME\nlocal     docker-compose_mariadb_data\n...\n</code></pre> <p>En la definici\u00f3n del servicio <code>db</code> hemos indicado que el contenedor montar\u00e1 el volumen en un directorio determinado con el par\u00e1metro <code>volumes</code>. Podemos comprobar que efectivamente se ha realizado el montaje:</p> <pre><code>$ docker inspect contenedor_mariadb\n...\n\"Mounts\": [\n    {\n        \"Type\": \"volume\",\n        \"Name\": \"docker-compose_mariadb_data\",\n        \"Source\": \"/var/lib/docker/volumes/docker-compose_mariadb_data/_data\",\n        \"Destination\": \"/var/lib/mysql\",\n        \"Driver\": \"local\",\n        \"Mode\": \"rw\",\n        \"RW\": true,\n        \"Propagation\": \"\"\n    }\n],\n...\n</code></pre> <p>Recuerda que si necesitas iniciar el escenario desde 0, debes eliminar el volumen:</p> <pre><code>$ docker-compose down -v\nStopping contenedor_mariadb ... done\nRemoving contenedor_mariadb ... done\nRemoving network docker-compose_default\nRemoving volume docker-compose_mariadb_data\n</code></pre>"},{"location":"05.-Docker/08.-Escenarios%20multicontenedor/04.-Almacenamiento%20con%20docker-compose/#utilizacion-de-bind-mount-con-docker-compose","title":"Utilizaci\u00f3n de bind mount con docker-compose","text":"<p>De forma similar podemos indicar que un contenedor va a utilizar bind mount como almacenamiento. En este caso ser\u00eda:</p> <pre><code>version: '3.1'\nservices:\n  db:\n    container_name: contenedor_mariadb\n    image: mariadb\n    restart: always\n    environment:\n      MYSQL_ROOT_PASSWORD: asdasd\n    volumes:\n      - ./data:/var/lib/mysql\n</code></pre> <p>Y despu\u00e9s de iniciar el escenario podemos ver c\u00f3mo se ha creado el directorio <code>data</code>:</p> <pre><code>$ cd data/\n/data$ ls\naria_log.00000001  aria_log_control  ibdata1  ib_logfile0  ibtmp1  mysql\n</code></pre>"},{"location":"05.-Docker/08.-Escenarios%20multicontenedor/05.-Redes%20con%20docker-compose/","title":"05.-Redes con docker-compose","text":"<p>Como hemos indicado anteriormente, cuando creamos un escenario con <code>docker-compose</code> se crea una nueva red definida por el usuario donde se conectan los contenedores, por lo tanto, obtenemos resoluci\u00f3n por dns que resuelve tanto el nombre del contenedor, como el nombre del servicio.</p> <p>Sin embargo en el fichero <code>docker-compose.yaml</code> podemos definir y configurar las redes que necesitemos en nuestro escenario, as\u00ed como la conexi\u00f3n de los distintos contenedores a dichas redes.</p> <p>Veamos un ejemplo:</p> <pre><code>version: '3.1'\nservices:\n  app:\n    container_name: servidor_web\n    image: httpd:2.4\n    restart: always\n    ports:\n      - 8080:80\n    networks:\n      red_web:\n        ipv4_address: 192.168.10.10\n      red_interna:\n        ipv4_address: 192.168.20.10\n    hostname: servidor_web\n\n  db:\n    container_name: servidor_mariadb\n    image: mariadb\n    environment:\n      MYSQL_ROOT_PASSWORD: asdasd\n    restart: always\n    networks:\n      red_interna:\n        ipv4_address: 192.168.20.20\n    hostname: servidor_mariadb\nnetworks:\n    red_web:\n        ipam:\n            config:\n              - subnet: 192.168.10.0/24\n    red_interna:\n        ipam:\n            config:\n              - subnet: 192.168.20.0/24\n</code></pre> <p>Iniciamos el escenario:</p> <pre><code>$ docker-compose up -d\nCreating network \"docker-compose_red_web\" with the default driver\nCreating network \"docker-compose_red_interna\" with the default driver\nCreating servidor_mariadb ... done\nCreating servidor_web     ... done\n</code></pre> <p>Comprobamos que los dos contenedores se est\u00e1n ejecutando:</p> <pre><code>$ docker-compose ps\n      Name                   Command             State                  Ports                \n---------------------------------------------------------------------------------------------\nservidor_mariadb   docker-entrypoint.sh mysqld   Up      3306/tcp                            \nservidor_web       httpd-foreground              Up      0.0.0.0:8080-&gt;80/tcp,:::8080-&gt;80/tcp\n</code></pre> <p>Accedemos al servidor web e instalamos los paquetes necesarios para hacer las comprobaciones de configuraci\u00f3n de la red:</p> <pre><code>$ docker-compose exec app bash\nroot@servidor_web::/usr/local/apache2# apt-get update &amp;&amp; apt-get install -y inetutils-ping \\\n   iproute2 \\\n   dnsutils\n</code></pre> <p>Comprobamos que el hostname se ha configurado de manera adecuada:</p> <pre><code>root@servidor_web:/usr/local/apache2# cat /etc/hostname\nservidor_web\n</code></pre> <p>Comprobamos que el contenedor est\u00e1 conectado a las dos redes y tiene las direcciones que hemos indicado:</p> <pre><code>root@servidor_web:/usr/local/apache2# ip a\n...\n401: eth0@if402: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc \n...\n    inet 192.168.20.10/24 brd 192.168.20.255 scope global eth0\n...\n403: eth1@if404: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc \n...\n    inet 192.168.10.10/24 brd 192.168.10.255 scope global eth1\n</code></pre> <p>Comprobamos que tenemos resoluci\u00f3n DNS tanto con el nombre del servicio como con el nombre del contenedor:</p> <pre><code>root@servidor_web:/usr/local/apache2# dig servidor_mariadb\n\n...\n;; ANSWER SECTION:\nservidor_mariadb.   600 IN  A   192.168.20.20\n...\n\nroot@servidor_web:/usr/local/apache2# dig db\n\n...\n;; ANSWER SECTION:\ndb.         600 IN  A   192.168.20.20\n...\n</code></pre> <p>Y por \u00faltimos comprobamos que hay conectividad:</p> <pre><code>root@servidor_web:/usr/local/apache2# ping servidor_mariadb\nPING servidor_mariadb (192.168.20.20): 56 data bytes\n64 bytes from 192.168.20.20: icmp_seq=0 ttl=64 time=0.195 ms\n...\n</code></pre>"},{"location":"05.-Docker/08.-Escenarios%20multicontenedor/06.-Ejemplos/","title":"Ejemplo 1: Despliegue de la aplicaci\u00f3n guestbook","text":"<p>En este ejemplo vamos a desplegar con docker-compose la aplicaci\u00f3n guestbook, que estudiamos en el m\u00f3dulo de redes: Ejemplo 1: Despliegue de la aplicaci\u00f3n Guestbook.</p> <p>Puedes encontrar el fichero <code>docker-compose.yml</code> en en este directorio del repositorio.</p> <p>En el fichero <code>docker-compose.yml</code> vamos a definir el escenario. El programa <code>docker-compose</code> se debe ejecutar en el directorio donde este ese fichero.</p> <pre><code>version: '3.1'\nservices:\n  app:\n    container_name: guestbook\n    image: iesgn/guestbook\n    restart: always\n    ports:\n      - 80:5000\n  db:\n    container_name: redis\n    image: redis\n    restart: always\n</code></pre> <p>Para crear el escenario:</p> <pre><code>$ docker-compose up -d\nCreating network \"guestbook_default\" with the default driver\nCreating guestbook ... done\nCreating redis     ... done\n</code></pre> <p>Para listar los contenedores:</p> <pre><code>$ docker-compose ps\n  Name                 Command               State          Ports        \n-------------------------------------------------------------------------\nguestbook   python3 app.py                   Up      0.0.0.0:80-&gt;5000/tcp\nredis       docker-entrypoint.sh redis ...   Up      6379/tcp            \n</code></pre> <p>Para parar los contenedores:</p> <pre><code>$ docker-compose stop \nStopping guestbook    ... done\nStopping redis ... done\n</code></pre> <p>Para eliminar el escenario:</p> <pre><code>docker-compose down\nStopping guestbook ... done\nStopping redis     ... done\nRemoving guestbook ... done\nRemoving redis     ... done\nRemoving network guestbook_default\n</code></pre>"},{"location":"05.-Docker/08.-Escenarios%20multicontenedor/06.-Ejemplos/#ejemplo-2-despliegue-de-la-aplicacion-temperaturas","title":"Ejemplo 2: Despliegue de la aplicaci\u00f3n Temperaturas","text":"<p>En este ejemplo vamos a desplegar con docker-compose la aplicaci\u00f3n Temperaturas, que estudiamos en el m\u00f3dulo de redes: Ejemplo 2: Despliegue de la aplicaci\u00f3n Temperaturas.</p> <p>Puedes encontrar el fichero <code>docker-compose.yml</code> en en este directorio del repositorio.</p> <p>En este caso el fichero <code>docker-compose.yml</code> puede tener esta forma:</p> <pre><code>version: '3.1'\nservices:\n  frontend:\n    container_name: temperaturas-frontend\n    image: iesgn/temperaturas_frontend\n    restart: always\n    ports:\n      - 80:3000\n    depends_on:\n      - backend\n  backend:\n    container_name: temperaturas-backend\n    image: iesgn/temperaturas_backend\n    restart: always\n</code></pre> <p>Para crear el escenario:</p> <pre><code>$ docker-compose up -d\nCreating network \"temperaturas_default\" with the default driver\nCreating temperaturas-backend ... done\nCreating temperaturas-frontend ... done\n\n</code></pre> <p>Para listar los contenedores:</p> <pre><code>$ docker-compose ps\n---------------------------------------------------------------------\ntemperaturas-backend    python3 app.py   Up      5000/tcp            \ntemperaturas-frontend   python3 app.py   Up      0.0.0.0:80-&gt;3000/tcp\n</code></pre>"},{"location":"05.-Docker/08.-Escenarios%20multicontenedor/06.-Ejemplos/#ejemplo-3-despliegue-de-wordpress-mariadb","title":"Ejemplo 3: Despliegue de WordPress + Mariadb","text":"<p>En este ejemplo vamos a desplegar con docker-compose la aplicaci\u00f3n WordPress + MariaDB, que estudiamos en el m\u00f3dulo de redes: Ejemplo 3: Despliegue de Wordpress + mariadb .</p> <p>Puedes encontrar los ficheros <code>docker-compose.yml</code> en este directorio del repositorio.</p>"},{"location":"05.-Docker/08.-Escenarios%20multicontenedor/06.-Ejemplos/#utilizando-volumenes-docker","title":"Utilizando vol\u00famenes docker","text":"<p>Por ejemplo para la ejecuci\u00f3n de wordpress persistente con vol\u00famenes docker podr\u00edamos tener un fichero <code>docker-compose.yml</code> con el siguiente contenido:</p> <pre><code>version: '3.1'\nservices:\n  wordpress:\n    container_name: servidor_wp\n    image: wordpress\n    restart: always\n    environment:\n      WORDPRESS_DB_HOST: db\n      WORDPRESS_DB_USER: user_wp\n      WORDPRESS_DB_PASSWORD: asdasd\n      WORDPRESS_DB_NAME: bd_wp\n    ports:\n      - 80:80\n    volumes:\n      - wordpress_data:/var/www/html/wp-content\n  db:\n    container_name: servidor_mysql\n    image: mariadb\n    restart: always\n    environment:\n      MYSQL_DATABASE: bd_wp\n      MYSQL_USER: user_wp\n      MYSQL_PASSWORD: asdasd\n      MYSQL_ROOT_PASSWORD: asdasd\n    volumes:\n      - mariadb_data:/var/lib/mysql\nvolumes:\n    wordpress_data:\n    mariadb_data:\n</code></pre> <p>Para crear el escenario:</p> <pre><code>$ docker-compose up -d\nCreating network \"wp_default\" with the default driver\nCreating servidor_wp    ... done\nCreating servidor_mysql ... done\n</code></pre> <p>Para listar los contenedores:</p> <pre><code>$ docker-compose ps\n     Name                   Command               tate         Ports       \n---------------------------------------------------------------------------\nservidor_mysql   docker-entrypoint.sh mysqld      Up      306/tcp          \nservidor_wp      docker-entrypoint.sh apach ...   Up      0.0.0.0:80-&gt;80/tcp\n</code></pre> <p>Para parar los contenedores:</p> <pre><code>$ docker-compose stop \nStopping servidor_wp    ... done\nStopping servidor_mysql ... done\n</code></pre> <p>Para borrar los contenedores:</p> <pre><code>$ docker-compose rm\nGoing to remove servidor_wp, servidor_mysql\nAre you sure? [yN] y\nRemoving servidor_wp    ... done\nRemoving servidor_mysql ... done\n</code></pre> <p>Para eliminar el escenario (contenedores, red y vol\u00famenes):</p> <pre><code>$ docker-compose down -v\nStopping servidor_mysql ... done\nStopping servidor_wp    ... done\nRemoving servidor_mysql ... done\nRemoving servidor_wp    ... done\nRemoving network volumen_default\nRemoving volume volumen_wordpress_data\nRemoving volume volumen_mariadb_data\n</code></pre>"},{"location":"05.-Docker/08.-Escenarios%20multicontenedor/06.-Ejemplos/#utilizando-bind-mount","title":"Utilizando bind-mount","text":"<p>Por ejemplo para la ejecuci\u00f3n de wordpress persistente con bind mount podr\u00edamos tener un fichero <code>docker-compose.yml</code> con el siguiente contenido:</p> <pre><code>version: '3.1'\nservices:\n  wordpress:\n    container_name: servidor_wp\n    image: wordpress\n    restart: always\n    environment:\n      WORDPRESS_DB_HOST: db\n      WORDPRESS_DB_USER: user_wp\n      WORDPRESS_DB_PASSWORD: asdasd\n      WORDPRESS_DB_NAME: bd_wp\n    ports:\n      - 80:80\n    volumes:\n      - ./wordpress:/var/www/html/wp-content\n  db:\n    container_name: servidor_mysql\n    image: mariadb\n    restart: always\n    environment:\n      MYSQL_DATABASE: bd_wp\n      MYSQL_USER: user_wp\n      MYSQL_PASSWORD: asdasd\n      MYSQL_ROOT_PASSWORD: asdasd\n    volumes:\n      - ./mysql:/var/lib/mysql\n</code></pre>"},{"location":"05.-Docker/08.-Escenarios%20multicontenedor/06.-Ejemplos/#ejemplo-4-despliegue-de-tomcat-nginx","title":"Ejemplo 4: Despliegue de tomcat + nginx","text":"<p>En este ejemplo vamos a desplegar con docker-compose la aplicaci\u00f3n Java con Tomcat y nginx como proxy inverso que vimos en la sesi\u00f3n anterior en el Ejemplo 4: Despliegue de tomcat + nginx .</p> <p>Puedes encontrar el fichero <code>docker-compose.yml</code> en en este directorio del repositorio.</p> <p>El fichero <code>docker-compose.yaml</code> ser\u00eda:</p> <pre><code>version: '3.1'\nservices:\n  aplicacionjava:\n    container_name: tomcat\n    image: tomcat:9.0\n    restart: always\n    volumes:\n      - ./sample.war:/usr/local/tomcat/webapps/sample.war:ro\n  proxy:\n    container_name: nginx\n    image: nginx\n    ports:\n      - 80:80\n    volumes:\n      - ./default.conf:/etc/nginx/conf.d/default.conf:ro\n</code></pre> <p>Como podemos ver en el directorio donde tenemos guardado el <code>docker-compose.yaml</code>, tenemos los dos ficheros necesarios para la configuraci\u00f3n: <code>sample.war</code> y <code>default.conf</code>.</p> <p>Creamos el escenario:</p> <pre><code>$ docker-compose up -d\nCreating network \"ejemplo4_default\" with the default driver\nCreating nginx  ... done\nCreating tomcat ... done\n</code></pre> <p>Comprobar que los contenedores est\u00e1n funcionando:</p> <pre><code>$ docker-compose ps\n Name               Command               State         Ports       \n--------------------------------------------------------------------\nnginx    /docker-entrypoint.sh ngin ...   Up      0.0.0.0:80-&gt;80/tcp\ntomcat   catalina.sh run                  Up      8080/tcp          \n</code></pre> <p>Y acceder al puerto 80 de nuestra IP para ver la aplicaci\u00f3n.</p>"},{"location":"05.-Docker/08.-Escenarios%20multicontenedor/06.-Ejemplos/#ejemplos-reales-de-despliegues-usando-docker-compose","title":"Ejemplos reales de despliegues usando docker-compose","text":"<p>En la actualidad la mayor\u00eda de los despliegues reales que se hacen con docker, se realizan usando la herramienta docker-compose, veamos algunos ejemplos:</p> <ul> <li>Despliegue de jitsi: Jitsi es una aplicaci\u00f3n de videoconferencia, VoIP, y mensajer\u00eda instant\u00e1nea con aplicaciones nativas para iOS y Android, y con soporte para Windows, Linux y Mac OS X a trav\u00e9s de la web.\u200b Es compatible con varios protocolos populares de mensajer\u00eda instant\u00e1nea y de telefon\u00eda, y se distribuye bajo los t\u00e9rminos de la licencia Apache, por lo que es software libre y de c\u00f3digo abierto. Podemos encontar las instrucciones para desplegarlo con docker en esta p\u00e1gina y podemos acceder al fichero docker-compose.yml.</li> <li>Despliegue de las aplicaciones de Bitnami: Bitnami es una empresa que nos proporciona distintas formas de despliegues de aplicaciones web en la nube. Una de estas formas es la utilizaci\u00f3n de docker, y podemos ver que todas las aplicaciones que nos ofrece Bitnami tienen el fichero <code>docker-compose.yml</code> para realizar el despliegue, por ejemplo podemos ver el fichero de la aplicaci\u00f3n PrestaShop de Bitnami.</li> <li>Despliegue de Guacamole: Apache Guacamole es un cliente (aplicaci\u00f3n web HTML5) capaz de ofrecerte funcionalidades para acceso remoto a servidores y otros equipos remotos desde cualquier parte solo con la ayuda de una conexi\u00f3n y un navegador web. Podemos instalar Guacamole con docker y aunque en esa p\u00e1gina no tenemos el fichero <code>docker-compse-yml</code> podemos encontrar ejemplos de muchos usuarios en GitHub.</li> </ul>"},{"location":"05.-Docker/09.-Ejercicios/","title":"Ejercicios","text":"<p>Ejercicios creaci\u00f3n de contenedores b\u00e1sicos I</p> <p>Ejercicios de creaci\u00f3n de contenedores b\u00e1sicos II</p> <p>Ejercicios de Vol\u00famenes</p>"},{"location":"05.-Docker/10.-Cheatsheet/","title":"07.-Cheatsheet","text":""},{"location":"05.-Docker/10.-Cheatsheet/#docker-run","title":"Docker Run","text":"<pre><code>docker run -it --name=cont1 ubuntu /bin/bash\n</code></pre> <ul> <li>Crea un contenedor con la imagen \u201cubuntu\u201d (al no especificar, toma versi\u00f3n \u201clatest\u201d), le establece un nombre \u201ccont1\u201d y lanza en modo interactivo una shell \u201cbash\u201d.</li> </ul> <pre><code>docker run -d -p 1200:80 nginx\n</code></pre> <ul> <li>Crea un contenedor con la versi\u00f3n \u201clatest\u201d de la imagen \u201cnginx\u201d y lo lanza en \u201cbackground\u201d, exponiendo el puerto 80 del contenedor en el puerto 1200 de la m\u00e1quina anfitri\u00f3n.</li> </ul> <pre><code>docker run -it -e MENSAJE=HOLA ubuntu:14.04 bash\n</code></pre> <ul> <li>Crea un contenedor con la imagen \u201cubuntu\u201d, versi\u00f3n \u201c14.04\u201d y establece la variable de entorno \u201cMENSAJE\u201d.</li> </ul>"},{"location":"05.-Docker/10.-Cheatsheet/#docker-ps","title":"Docker ps","text":"<pre><code>docker ps\n</code></pre> <ul> <li>Muestra informaci\u00f3n de los contenedores en ejecuci\u00f3n.</li> </ul> <pre><code>docker ps -a\n</code></pre> <ul> <li>Muestra informaci\u00f3n de todos los contenedores, tanto parados como en ejecuci\u00f3n.</li> </ul>"},{"location":"05.-Docker/10.-Cheatsheet/#docker-startstoprestart","title":"Docker Start/Stop/Restart","text":"<pre><code>docker start micontenedor\n</code></pre> <ul> <li>Arranca el contenedor con nombre \u201cmi contenedor\u201d.</li> </ul> <pre><code>docker start -ai micontenedor\n</code></pre> <ul> <li>Arranca el contenedor con nombre \u201cmi contenedor\u201d, enlazando el comando ejecutado al arranque a la entrada y salida est\u00e1ndar de la terminal del anfitri\u00f3n.</li> </ul>"},{"location":"05.-Docker/10.-Cheatsheet/#docker-exec","title":"Docker Exec","text":"<pre><code>docker exec -it -e FICHERO=prueba cont bash\n</code></pre> <ul> <li>Lanza en el contenedor \u201ccont\u201d (que debe estar arrancado) el comando \u201cbash\u201d, estableciendo la variable de entorno \u201cFICHERO\u201d y enlazando la ejecuci\u00f3n de forma interactiva a la entrada y salida est\u00e1ndar del anfitri\u00f3n.</li> </ul> <pre><code>docker exec -d cont touch /tmp/prueba\n</code></pre> <ul> <li>Lanza en el contenedor \u201ccont\u201d (que debe estar arrancado) el comando \u201ctouch /tmp/prueba\u201d. Este comando se ejecuta en segundo plano, generando el fichero \u201c/tmp/prueba\u201d.</li> </ul>"},{"location":"05.-Docker/10.-Cheatsheet/#docker-attach","title":"Docker attach","text":"<pre><code>docker attach idcontainer\n</code></pre> <ul> <li>Enlaza nuestra terminal la entrada/salida de nuestra al proceso en segundo plano del contenedor \u201cidcontainer\u201d.</li> </ul>"},{"location":"05.-Docker/10.-Cheatsheet/#docker-logs","title":"Docker logs","text":"<pre><code>docker logs -n 10 idcontainer\n</code></pre> <ul> <li>Muestra las 10 \u00faltimas l\u00edneas de la salida estandar producida por el proceso en ejecuci\u00f3n en el contendor.</li> </ul>"},{"location":"05.-Docker/10.-Cheatsheet/#docker-cp","title":"Docker cp","text":"<pre><code>docker cp idcontainer:/tmp/prueba ./\n</code></pre> <ul> <li>Copia el fichero \u201c/tmp/prueba\u201d del contenedor \u201cidcontainer\u201d al directorio actual del anfitri\u00f3n.</li> </ul> <pre><code>docker cp ./miFichero idcontainer:/tmp\n</code></pre> <ul> <li>Copia el fichero \u201cmiFichero\u201d del directorio actual del anfitri\u00f3n a la carpeta \u201c/tmp\u201d del contenedor.</li> </ul>"},{"location":"05.-Docker/10.-Cheatsheet/#gestion-de-imagenes","title":"Gesti\u00f3n de im\u00e1genes","text":"<pre><code>docker images\n</code></pre> <ul> <li>Informaci\u00f3n de im\u00e1genes locales disponibles.</li> </ul> <pre><code>docker search ubuntu\n</code></pre> <ul> <li>Busca la imagen \u201cubuntu\u201d en el repositorio remoto (por defecto Docker Hub).</li> </ul> <pre><code>docker pull alpine\n</code></pre> <ul> <li>Descarga localmente imagen \u201calpine\u201d.</li> </ul> <pre><code>docker history alpine\n</code></pre> <ul> <li>Muestra la historia de creaci\u00f3n de la imagen \u201calpine\u201d.</li> </ul> <pre><code>docker rmi ubuntu:14.04\n</code></pre> <ul> <li>Elimina localmente la imagen \u201cubuntu\u201d con tag \u201c14.04\u201d.</li> </ul> <pre><code>docker rmi $(docker images -q)\n</code></pre> <ul> <li>Borra toda imagen local que no est\u00e9 siendo usada por un contenedor.</li> </ul> <pre><code>docker rm IDCONTENEDOR\n</code></pre> <ul> <li>Borra un contenedor con IDCONTENEDOR.</li> </ul> <pre><code>docker stop $(docker ps -a -q)\n</code></pre> <ul> <li>Para todos los contenedores del sistema.</li> </ul> <pre><code>docker rm $(docker ps -a -q)\n</code></pre> <ul> <li>Borra todos los contenedores parados del sistema.</li> </ul> <pre><code>docker system prune -a\n</code></pre> <ul> <li>Borra todas las im\u00e1genes y contenedores parados del sistema.</li> </ul>"},{"location":"05.-Docker/10.-Cheatsheet/#creacion-de-imagenes-a-partir-de-contenedores","title":"Creaci\u00f3n de im\u00e1genes a partir de contenedores","text":"<pre><code>docker commit -m \u201ccomentario\u201d IDCONTENEDOR usuario/imagen:version\n</code></pre> <ul> <li>Hace commit de un contenedor existente a una imagen local.</li> </ul> <pre><code>docker save -o copiaSeguridad.tar imagenA\n</code></pre> <ul> <li>Guarda una copia de seguridad de una imagen en fichero \u201c.tar\u201d.</li> </ul> <pre><code>docker load -i copiaSeguridad.tar\n</code></pre> <ul> <li>Restaura una copia de seguridad de una imagen en fichero \u201c.tar\u201d.</li> </ul>"},{"location":"05.-Docker/10.-Cheatsheet/#docker-hub","title":"Docker Hub","text":"<pre><code>docker login\n</code></pre> <ul> <li>Permite introducir credenciales del registro (por defecto \u201cDocker Hub\u201d).</li> </ul> <pre><code>docker push usuario/imagen:version\n</code></pre> <ul> <li>Permite subir al repositorio una imagen mediante \u201cpush\u201d.</li> </ul>"},{"location":"05.-Docker/10.-Cheatsheet/#ejemplo-de-dockerfile","title":"Ejemplo de Dockerfile","text":"<pre><code>FROM alpine\nLABEL maintainer=\"email@gmail.com\"\n\n#Actualizamos e instalamos paquetes con APK para Alpine\nRUN apk update &amp;&amp; apk add apache2 php php-apache2 openrc tar\n\n#Copiamos script para lanzar Apache 2\nADD ./start.sh /start.sh\n\n#Descargamos un ejemplo de &lt;?php phpinfo(); ?&gt; por ense\u00f1ar como bajar algo de Internet\n#Podr\u00eda haber sido simplemente\n#RUN echo \"&lt;?php phpinfo(); ?&gt;\" &gt; /var/www/localhost/htdocs/index.php\nADD https://gist.githubusercontent.com/SyntaxC4/5648247/raw/94277156638f9c309f2e36e19bff378ba7364907/info.php\n/var/www/localhost/htdocs/index.php\n\n# Si quisi\u00e9ramos algo como Wordpress har\u00edamos\n#ADD http://wordpress.org/latest.tar.gz /var/www/localhost/htdocs/wordpress.tar.gz\n#RUN tar xvzf /var/www/localhost/htdocs/wordpress.tar.gz &amp;&amp; rm -rf /var/www/localhost/htdocs/wordpress.tar.gz\n\n# Usamos usuario y grupo www-data. El grupo lo crea Apache, pero si quisi\u00e9ramos crear grupo\n# Grupo www-data RUN set -x &amp;&amp; addgroup -g 82 -S www-data\n# Creamos usuario www-data y lo a\u00f1adimos a ese grupo\nRUN adduser -u 82 -D -S -G www-data www-data\n\n# Hacemos todos los ficheros de /var/www propiedad de www-data\n# Y damos permisos a esos ficheros y a start.sh\nRUN chown -R www-data:www-data /var/www/ &amp;&amp; chmod -R 775 /var/www/ &amp;&amp; chmod 755 /start.sh\n\n#Indicamos puerto a exponer (para otros contenedores) 80\nEXPOSE 80\n\n#Comando lanzado por defecto al instalar el contendor\nCMD /start.sh\n</code></pre> <ul> <li>Ejemplo de fichero \u201cDockerfile\u201d.</li> </ul>"},{"location":"05.-Docker/10.-Cheatsheet/#gestion-de-redes","title":"Gesti\u00f3n de redes","text":"<pre><code>docker network create redtest\n</code></pre> <ul> <li>Creamos la red \u201credtest\u201d</li> </ul> <pre><code>docker network ls\n</code></pre> <ul> <li>Nos permite ver el listado de redes existentes.</li> </ul> <pre><code>docker network rm redtest\n</code></pre> <ul> <li>Borramos la red \u201credtest\u201d.</li> </ul> <pre><code>docker run -it --network redtest ubuntu /bin/bash\n</code></pre> <ul> <li>Conectamos el contenedor que creamos a la red \u201credtest\u201d.</li> </ul> <pre><code>docker network connect IDRED IDCONTENEDOR\n</code></pre> <ul> <li>Conectamos un contenedor a una red.</li> </ul> <pre><code>docker network disconnect IDRED IDCONTENEDOR\n</code></pre> <ul> <li>Desconectamos un contenedor de una red</li> </ul>"},{"location":"05.-Docker/10.-Cheatsheet/#volumenes","title":"Vol\u00famenes","text":"<pre><code>docker run -d -it --name appcontainer -v /home/sergi/target:/app nginx:latest\n</code></pre> <ul> <li>Creamos un contenedor y asignamos un volumen con \u201cbinding mount\u201d.</li> </ul> <pre><code>docker run -d -it --name appcontainer -v micontenedor:/app nginx:latest\n</code></pre> <ul> <li>Creamos un contenedor y asignamos un volumen Docker llamado \u201cmicontenedor\u201d.</li> </ul> <pre><code>docker volume create/ls/rm mivolumen\n</code></pre> <ul> <li>Permite crear, listar o eliminar vol\u00famenes Docker.</li> </ul> <pre><code>docker run -d -it --tmpfs /app nginx\n</code></pre> <ul> <li>Permite crear un contenedor y asociar un volumen \u201ctmpfs\u201d.</li> </ul> <pre><code>docker run --rm --volumes-from contenedor1 -v /home/sergi/backup:/backup ubuntu bash -c \"cd\n/datos &amp;&amp; tar cvf /backup/copiaseguridad.tar .\"\n</code></pre> <ul> <li>Permite realizar una copia de seguridad de un volumen asociado a \u201ccontenedor1\u201d y que se monta en \u201c/datos\u201d. Dicha copia finalmente acabar\u00e1 en \u201c/home/sergi/backup\u201d de la m\u00e1quina anfitri\u00f3n.</li> </ul> <pre><code>docker volume rm $(docker volume ls -q)\n</code></pre> <ul> <li>Permite eliminar todos los l\u00famenes de tu m\u00e1quina.</li> </ul>"},{"location":"05.-Docker/10.-Cheatsheet/#ejemplo-basico-de-fichero-docker-composeyml","title":"Ejemplo b\u00e1sico de fichero \u201cdocker-compose.yml\u201d","text":"<pre><code>version: \"3.9\"\nservices:\n    db:\n        image: mariadb:10.11.2\n        volumes:\n        - db_data:/var/lib/mysql\n        environment:\n            MARIADB_ROOT_PASSWORD: somewordpress\n            MARIADB_DATABASE: wordpress\n            MARIADB_USER: wordpress\n            MARIADB_PASSWORD: wordpress\n    wordpress:\n            image: wordpress:latest\n            ports:\n            - \"8000:80\"\n            environment:\n                WORDPRESS_DB_HOST: db:3306\n                WORDPRESS_DB_USER: wordpress\n                WORDPRESS_DB_PASSWORD: wordpress\n                WORDPRESS_DB_NAME: wordpress\nvolumes:\n    db_data:\n</code></pre>"},{"location":"05.-Docker/10.-Cheatsheet/#principales-comandos-de-docker-compose","title":"Principales comandos de \u201cDocker Compose\u201d","text":"<pre><code>docker compose up -d\n</code></pre> <ul> <li>Inicia el sistema definido en \u201cdocker-compose.yml\u201d en segundo plano. Genera y descarga im\u00e1genes requeridas.</li> </ul> <pre><code>docker compose down\n</code></pre> <ul> <li>Detiene y elimina los contenedores seg\u00fan la configuraci\u00f3n de \u201cdocker-compose.yml\u201d.</li> </ul> <pre><code>docker compose build/pull\n</code></pre> <ul> <li>Construye/descarga las im\u00e1genes de contenedores seg\u00fan la configuraci\u00f3n de \u201cdocker-compose.yml\u201d.</li> </ul> <pre><code>docker compose ps\n</code></pre> <ul> <li>Muestra informaci\u00f3n de los contenedores seg\u00fan la configuraci\u00f3n de \u201cdocker-compose.yml\u201d.</li> </ul> <pre><code>docker compose up -d --scale web=3\n</code></pre> <ul> <li>Similar a \u201cdocker compose up -d\u201d solo que adem\u00e1s, el servicio definido como \u201cweb\u201d en el fichero \u201cdocker-compose.yml\u201d lo escala creando 3 copias y realizando balanceo autom\u00e1tico si se realiza una petici\u00f3n al host llamado como el servicio \u201cweb\u201d.</li> </ul>"},{"location":"05.-Docker/10.-Cheatsheet/#principales-comandos-de-kubernetes","title":"Principales comandos de \u201cKubernetes\u201d","text":"<pre><code>kubectl apply -f \u201cfichero.yaml\u201d\n</code></pre> <ul> <li>Aplica en Kubernetes la configuraci\u00f3n especificada en \u201cfichero.yaml\u201d.</li> </ul> <pre><code>kubectl create deployment midespliegue --image=sergarb1/flaskparakubernetes --port=5000\n</code></pre> <ul> <li>Crea un despliegue basado en una imagen dada y en el puerto 5000.</li> </ul> <pre><code>kubectl expose deployment midespliegue --type=LoadBalancer --name=midespliegue-http\n</code></pre> <ul> <li>Crea un servicio de tipo \u201cLoadBalancer\u201d exponeniendo \u201cmidespliegue\u201d.</li> </ul> <pre><code>kubectl get pods; kubectl get services; kubectl get deployments\n</code></pre> <ul> <li>Muestra informaci\u00f3n de pods, servicios o despliegues.</li> </ul> <pre><code>kubectl scale deployment midespliegue --replicas=3\n</code></pre> <ul> <li>Escala horizontalmente un despliegue a 3 r\u00e9plicas.</li> </ul> <pre><code>kubectl autoscale deployment midespliegue --min=5 --max=10\n</code></pre> <ul> <li>Configura autoescalado horizontal, aceptando entre 5 y 10 r\u00e9plicas.</li> </ul> <pre><code>kubectl delete pod/deployment/service/autoscale nombre\n</code></pre> <ul> <li>Permite eliminar un pod, despliegue, servicio o autoescalado.</li> </ul>"},{"location":"05.-Docker/10.-Cheatsheet/#principales-comandos-de-mnikube","title":"Principales comandos de \u201cMniKube\u201d","text":"<pre><code>minikube start\n</code></pre> <ul> <li>Inicia la m\u00e1quina virtual que contiene MiniKube y pone el cluster Kubernetes en marcha</li> </ul> <pre><code>minikube service miservicio\n</code></pre> <ul> <li>Nos permite acceder a un servicio dentro de MiniKube desde la m\u00e1quina local.</li> </ul> <pre><code>minikube tunnel\n</code></pre> <ul> <li>Mientras est\u00e9 en ejecuci\u00f3n, expone un servicio dentro de MiniKube a la m\u00e1quina local</li> </ul>"},{"location":"05.-Docker/10.-Cheatsheet/#ejemplo-de-fichero-yaml-despliegueserviciopersistencia-con-kubernetes","title":"Ejemplo de fichero YAML despliegue/servicio/persistencia con Kubernetes","text":"<pre><code>#Definimos la informaci\u00f3n del servicio\napiVersion: v1\nkind: Service\nmetadata:\n  name: wordpress\n  labels:\n    app: wordpress\nspec:\n  ports:\n    #El servicio se expone en el puerto 80\n    - port: 80\n  selector:\n    app: wordpress\n    tier: frontend\n  #Aplicamos balanceo de carga para facilitar su escalado horizontal\n  type: LoadBalancer\n\n---\n#Definimos un volumen persistente\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: wp-pv-claim\n  labels:\n    app: wordpress\nspec:\n  #Indica que solo puede ser montado para lectura/escritura por un nodo. Para el resto lectura.\n  #En este caso, se usa para modificar un fichero de configuraci\u00f3n.\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n    storage: 20Gi\n\n---\n#definimos el despliegue\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: wordpress\n  labels:\n    app: wordpress\nspec:\n  selector:\n    matchLabels:\n    app: wordpress\n    tier: frontend\n  strategy:\n    type: Recreate\n  template:\n    metadata:\n    labels:\n    app: wordpress\n    tier: frontend\n    spec:\n      #Imagen\n    containers:\n      - image: wordpress:4.8-apache\n    name: wordpress\n\n    #Indicamos variables de entorno\n    env:\n    - name: WORDPRESS_DB_HOST\n    value: wordpress-mysql\n    - name: WORDPRESS_DB_PASSWORD\n    value: CEFIREdocker\n    ports:\n    - containerPort: 80\n    name: wordpress\n    volumeMounts:\n    - name: wordpress-persistent-storage\n    mountPath: /var/www/html\n    volumes:\n    - name: wordpress-persistent-storage\n    persistentVolumeClaim:\n    claimName: wp-pv-claim\n\n</code></pre>"},{"location":"05.-Docker/intermezzo/Docker%20Compose/","title":"Docker Compose","text":"<p>Docker Compose es una herramienta que se utiliza para definir y ejecutar aplicaciones Docker de m\u00faltiples contenedores. Con Docker Compose, se puede definir una aplicaci\u00f3n en un archivo YAML y luego ejecutarla con un solo comando. Docker Compose tambi\u00e9n permite la creaci\u00f3n de redes personalizadas y vol\u00famenes de datos para los contenedores.</p> <p>Docker Compose es \u00fatil para simplificar la gesti\u00f3n de aplicaciones Docker complejas. Por ejemplo, si una aplicaci\u00f3n consta de varios contenedores que deben comunicarse entre s\u00ed, Docker Compose puede definir f\u00e1cilmente las relaciones entre los contenedores y las redes que los conectan. Tambi\u00e9n puede definir vol\u00famenes de datos para los contenedores, lo que permite el almacenamiento persistente de datos.</p> <p>Presentamos a continuaci\u00f3n un ejemplo de un archivo YAML de Docker Compose para una aplicaci\u00f3n Django:</p> <pre><code>version: '3'\n\nservices:\n    db:\n        image: postgres\n    environment:\n        POSTGRES_DB: django_db\n        POSTGRES_USER: django_user\n        POSTGRES_PASSWORD: django_password\n\n    web:\n        build: .\n            command: python manage.py runserver 0.0.0.0:8000\n        volumes:\n        -  .:/code\n\nports:\n    - \"8000:8000\"\n\ndepends_on:\n    - db\n</code></pre> <p>En este ejemplo, se definen dos servicios: <code>db</code> y <code>web</code>. El servicio <code>db</code> utiliza la imagen de <code>postgres</code> y se definen las variables de entorno para la base de datos. El servicio <code>web</code> se construye a partir del directorio actual y se ejecuta el comando para iniciar el servidor Django. Tambi\u00e9n se define un volumen para el c\u00f3digo fuente y se expone en el puerto 8000. El servicio <code>web</code> depende del servicio <code>db</code>.</p>"},{"location":"05.-Docker/intermezzo/Docker%20en%20python%20y%20django/","title":"Docker en python y django","text":"<p>Ok, suficiente teor\u00eda. Empecemos a usar Docker y Django juntos. El primer paso es registrarse en Docker Hub para obtener una cuenta gratuita y luego instalar la aplicaci\u00f3n de escritorio Docker en nuestra m\u00e1quina local:</p> <ul> <li>Docker para Linux</li> <li>Para distribuciones basadas en Arch ser\u00e1 algo tan f\u00e1cil como ejecutar <code>pacman -S docker</code></li> <li>Docker para Mac</li> <li>Docker para Windows</li> </ul> <p>Esta descarga puede tomarse alg\u00fan tiempo ya que es un archivo grande.</p> <p>Una vez que Docker se haya terminado de instalar, podemos confirmar que se est\u00e1 ejecutando la versi\u00f3n correcta escribiendo <code>docker --version</code> en la l\u00ednea de comandos. Debe ser al menos la versi\u00f3n 18.</p> <pre><code>$ docker --version\nDocker versi\u00f3n 19.03.5-ce, build 633a0ea838\n</code></pre> <p>Docker se utiliza a menudo con una herramienta adicional, Docker Compose, para ayudar a automatizar los comandos. Docker Compose se incluye con las descargas de Mac y Windows, pero si se est\u00e1 en Linux, tendr\u00e1 que a\u00f1adirse manualmente. Puede hacerse ejecutando el comando <code>sudo pip install docker-compose</code> despu\u00e9s de que la instalaci\u00f3n de Docker haya finalizado.</p> <ul> <li>Para distribuciones basadas en Arch ser\u00e1 algo tan f\u00e1cil como ejecutar <code>pacman -S docker-compose</code>. (Si surgen problemas con alg\u00fan fichero ya instalado en el sistema, borrar todos aquellos ficheros que est\u00e9n involucrados y proceder con la instalaci\u00f3n como se indica)</li> </ul>"},{"location":"05.-Docker/intermezzo/Docker%20en%20python%20y%20django/#docker-hola-mundo","title":"Docker, Hola Mundo","text":"<p>Docker se env\u00eda con su propia imagen de \"Hello, World\" que es un primer paso \u00fatil para comprobar la instalaci\u00f3n. Introducir en la l\u00ednea de comandos el comando <code>docker run hello-world</code>. Esto descargar\u00e1 una imagen Docker oficial y luego se ejecutar\u00e1 dentro de un contenedor. Se discutir\u00e1 sobre las im\u00e1genes y los contenedores en breve.</p> <pre><code>$ docker run hello-world\nUnable to find image 'hello-world:latest' locally\nlatest: Pulling from library/hello-world\n1b930d010525: Pull complete\nDigest: sha256:b8ba256769a0ac28dd126d584e0a2011cd2877f3f76e093a7ae560f2a5301c00\nStatus: Downloaded newer image for hello-world:latest\nHello from Docker!\nThis message shows that your installation appears to be working correctly.\nTo generate this message, Docker took the following steps:\n 1. The Docker client contacted the Docker daemon.\n 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub.\n(amd64)\n 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading.\n 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal.\nTo try something more ambitious, you can run an Ubuntu container with:\n$ docker run -it ubuntu bash\nShare images, automate workflows, and more with a free Docker ID:\nhttps://hub.docker.com/\nFor more examples and ideas, visit:\nhttps://docs.docker.com/get-started/\n</code></pre> <p>El comando <code>docker info</code> nos permite inspeccionar Docker. Contendr\u00e1 una gran cantidad de informaci\u00f3n, pero si nos centramos en las l\u00edneas superiores tenemos 1 contenedor que se detenido y 1 imagen.</p> <pre><code>$ docker info\nClient:\n Debug Mode: false\n\nServer:\n Containers: 1\n  Running: 0\n  Paused: 0\n  Stopped: 1\n Images: 1\n...\n</code></pre>"},{"location":"05.-Docker/intermezzo/Docker%20en%20python%20y%20django/#django-hola-mundo","title":"Django, Hola mundo","text":"<p>Ahora vamos a crear un proyecto de Django \"Hello, World\" que se ejecuta localmente en nuestro ordenador y luego lo moveremos por completo dentro de Docker para que se pueda ver c\u00f3mo encajan todas las piezas.</p> <p>El primer paso es elegir una ubicaci\u00f3n para nuestro c\u00f3digo. Esto puede ser en cualquier parte del ordenador pero si est\u00e1s en Linux, una ubicaci\u00f3n f\u00e1cil de encontrar es el Escritorio . Desde la l\u00ednea de comandos navegamos hasta el <code>Escritorio</code> y creamos un directorio <code>code</code> para todos los ejemplos:</p> <pre><code>$ cd ~/Desktop\n$ mkdir code &amp;&amp; cd code\n</code></pre> <p>Luego creeamos un directorio <code>hello</code> donde  instalaremos Django usando Pipenv que crea un archivo Pipfile y un archivo Pipfile.lock.  Activamos el entorno virtual con el comando <code>shell</code>.</p> <pre><code>$ mkdir hello &amp;&amp; cd hello\npipenv install django==2.2.7\n$ pipenv shell\n(hello) $\n</code></pre> <p>Si se necesita ayuda para instalar Pipenv o Python 3, se pueden encontrar m\u00e1s detalles aqu\u00ed. Ahora podemos usar el comando <code>startproject</code> para crear un nuevo proyecto de Django llamado <code>hello_project</code>. A\u00f1adir un punto, <code>.</code>, al final del comando es un paso opcional pero muchos desarrolladores de Django lo hacen. Sin el punto, Django a\u00f1ade un directorio adicional al proyecto; con el <code>.</code>, esto no ocurre. Por \u00faltimo, utilice el comando <code>migrate</code> para inicializar la base de datos e iniciar la web local con el comando <code>runserver</code>.</p> <pre><code>(hola) $ django-admin startproject hello_project .\n(hola) $ python manage.py migrate\n(hola) $ python manage.py runserver\n</code></pre> <p>Suponiendo que todo ha funcionado correctamente, ahora deber\u00edamos poder navegar para ver el la p\u00e1gica de bienvenida de Django en http://127.0.0.1:8000/ en su navegador web.</p> <p></p>"},{"location":"05.-Docker/intermezzo/Docker%20en%20python%20y%20django/#pages-app","title":"Pages App","text":"<p>Ahora haremos una p\u00e1gina de inicio simple creando una <code>pages</code> app espec\u00edfica  para ello. Parar el servidor local escribiendo Control+c y luego usar el comando <code>startapp</code> a\u00f1adiendo el nombre de la <code>pages</code> que se desee.</p> <pre><code>(hola) $ python manage.py startapp pages\n</code></pre> <p>Django instala autom\u00e1ticamente un nuevo directorio de p\u00e1ginas y varios archivos para nosotros. Pero incluso aunque la app ha sido creada, nuestro <code>hello_project</code> no la reconocer\u00e1 hasta que la a\u00f1adamos a la configuraci\u00f3n de <code>INSTALLED_APPS</code> de archivo <code>hello_project/settings.py</code>.</p> <p>Django carga las apps de arriba a abajo, por lo que, en general, es una buena pr\u00e1ctica a\u00f1adir las nuevas aplicaciones debajo de las aplicaciones incorporadas en las que pueden confiar, tales como <code>admin</code>, <code>auth</code>, y todas las aplicaciones restantes.</p> <p>T\u00e9ngase en cuenta que si bien es posible simplemente escribir el nombre de la app, <code>pages</code>,  es mejor escribir la <code>pages.apps.apps.PagesConfig</code> completa lo que abre m\u00e1s posibilidades en la configuraci\u00f3n de las apps.</p> <pre><code># hello_project/settings.py\nINSTALLED_APPS = [\n    'django.contrib.admin',\n    'django.contrib.auth',\n    'django.contrib.contenttypes',\n    'django.contrib.sessions',\n    'django.contrib.messages',\n    'django.contrib.staticfiles',\n    'pages.apps.apps.PagesConfig', # nuevo\n]\n</code></pre> <p>Ahora podemos establecer la ruta URL para la app <code>pages</code>. Ya que queremos que nuestro mensaje aparezca en la p\u00e1gina de inicio usaremos la cadena vac\u00eda <code>''</code> . No olvidar a\u00f1adir la importaci\u00f3n de <code>include</code> en la segunda l\u00ednea tambi\u00e9n.</p> <pre><code># hello_project/urls.py\nfrom django.contrib import admin\nfrom django.urls import path, include # nuevo\n\nurlpatterns = [\n    path('admin/', admin.site.urls),\n    path('', include('pages.urls')), # nuevo\n]\n</code></pre> <p>En lugar de crear una plantilla en este punto, podemos simplemente codificar un mensaje en nuestra capa de la vista <code>pages/views.py</code> que producir\u00e1 la cadena <code>Hello, World!</code>.</p> <pre><code># pages/views.py\nfrom django.http import HttpResponse\n\ndef home_page_view(request):\n    return HttpResponse('Hello, World!')\n</code></pre> <p>\u00bfQu\u00e9 es lo siguiente? El \u00faltimo paso es crear un archivo <code>urls.py</code> dentro de la app <code>pages</code>y enlazarlo to <code>home_page_view</code>. Si se encuentra en un ordenador Mac o Linux, el comando <code>touch</code> se puede usar desde la l\u00ednea de comandos para crear nuevos archivos. En Windows habr\u00e1 que crear el nuevo archivo con un editor de texto.</p> <pre><code>(hola) $ touch pages/urls.py\n</code></pre> <p>En el editor de texto importar <code>path</code> en la primera l\u00ednea, a\u00f1adir la <code>home_page_view</code>, y colocar su ruta para otra vez ser la cadena vac\u00eda ''. N\u00f3tese que tambi\u00e9n provee un nombre opcional, <code>home</code>, para esta ruta lo cual es una buena pr\u00e1ctica.</p> <pre><code># pages/urls.py\nfrom django.urls import path\n\nfrom .views import home_page_view\n\n\nurlpatterns = [\npath('', home_page_view, name='home')\n]\n\n</code></pre> <p>El flujo completo de nuestra p\u00e1gina web Django es el siguiente:</p> <ul> <li>cuando un usuario va a su homepage ser\u00e1 primero encaminado a <code>hello_project/urls.py</code></li> <li>luego a <code>pages/urls.py</code></li> <li>y finalmente dirigido a la <code>home_page_view</code> que devuelve la cadena <code>Hello, World!</code></li> </ul> <p>El trabajo para una p\u00e1gina de inicio b\u00e1sica ha terminado. Iniciemos de nuevo el servidor local.</p> <pre><code>(hola) $ python manage.py runserver\n</code></pre> <p>Si se actualiza el navegador web en http://127.0.0.1:8000/, ahora saldr\u00e1 nuestro deseado mensaje.</p> <p></p> <p>Ahora es el momento de cambiar a Docker. Detengamos de nuevo el servidor local con Ctrl+C y salgamos de nuestro entorno virtual, que ya no necesitamos, escribiendo <code>exit</code>.</p> <pre><code>(hello) $ exit\n$\n</code></pre> <p>\u00bfC\u00f3mo sabemos que nuestro entorno virtual ya no est\u00e1 activo? No habr\u00e1 un par\u00e9ntesis alrededor del nombre de directorio en el prompt. Cualquier comando Django normal que se intente ejecutar en este punto fallar\u00e1. Por ejemplo, probar <code>python manage.py runserver</code> para ver lo que ocurre.</p> <pre><code>$ python manage.py runserver\nFile \"./manage.py\", line 14\n  ) from exc\n       ^\nSyntaxError: invalid syntax\n</code></pre> <p>Esto significa que estamos totalmente fuera del entorno virtual y preparados para Docker.</p>"},{"location":"05.-Docker/intermezzo/Docker%20en%20python%20y%20django/#imagenes-contenedores-y-el-docker-host","title":"Im\u00e1genes, Contenedores y el \"Docker Host\"","text":"<p>Una imagen Docker es una instant\u00e1nea en el tiempo de lo que contiene un proyecto. Est\u00e1 representado por un <code>Dockerfile</code> y es literalmente una lista de instrucciones que deben ser construidas/ejecutadas. Un contenedor Docker es una instancia en ejecuci\u00f3n de una imagen. Para continuar con la analog\u00eda de nuestro apartamento de antes, la imagen es el plano o conjunto de planos del apartamento; el contenedor es el edificio real totalmente construido.</p> <p>El tercer concepto central es el Docker host, que es el sistema operativo subyacente. Es posible tener varios contenedores ejecut\u00e1ndose dentro de un mismo Docker host. Cuando nos referimos a c\u00f3digo o procesos que se ejecutan en el Docker, significa que se ejecutan en el Docker host.</p> <p>Creemos nuestro primer <code>Dockerfile</code> para ver toda esta teor\u00eda en acci\u00f3n.</p> <pre><code>$ touch Dockerfile\n</code></pre> <p>Dentro del <code>Dockerfile</code> agregamos el siguiente c\u00f3digo que recorreremos l\u00ednea por l\u00ednea m\u00e1s abajo.</p> <pre><code># Pull base image\nFROM python:3.8\n\n\n# Set environment variables\nENV PYTHONDONTWRITEBYTECODE 1\nENV PYTHONUNBUFFERED 1\n\n\n# Set work directory\nWORKDIR /code\n\n\n# Install dependencies\nCOPY Pipfile Pipfile.lock /code/\nRUN pip install pipenv &amp;&amp; pipenv install --system\n\n\n# Copy project\nCOPY . /code/\n</code></pre> <p>Los <code>Dockerfiles</code> se leen de arriba hacia abajo cuando se crea una imagen. La primera instrucci\u00f3n debe ser el comando <code>FROM</code> que nos permite importar una imagen base que usar, en nuestro caso Python 3.8.</p> <p>Luego usamos el comando <code>ENV</code> para establecer dos variables de entorno:</p> <ul> <li><code>PYTHONUNBUFFERED</code> asegura que la salida de nuestra consola se vea familiar y que no est\u00e9 almacenada en un b\u00fafer de Docker, lo cual no queremos</li> <li><code>PYTHONDONTWRITEBYTECODE</code> significa que Python no intentar\u00e1 escribir archivos <code>.pyc</code>, que tampoco deseamos</li> </ul> <p>A continuaci\u00f3n usamos <code>WORKDIR</code> para establecer una ruta de directorio de trabajo por defecto dentro de nuestra imagen llamada <code>code</code>que es donde guardaremos nuestro c\u00f3digo. Si no lo hicimos, entonces cada vez que queramos ejecutar comandos dentro de nuestro contenedor tendr\u00edamos que escribir una ruta muy larga. En su lugar, Docker asumir\u00e1 que queremos ejecutar todos los comandos desde este directorio.</p> <p>Para nuestras dependencias estamos usando <code>pipenv</code>, as\u00ed que copiamos tanto el archivo <code>Pipfile</code> como el archivo <code>Pipfile.lock</code> en el directorio <code>/code/</code> en Docker.</p> <p>Vale la pena tomarse un momento para explicar por qu\u00e9 <code>pipenv</code> crea un <code>Pipfile.lock</code>. El concepto de bloqueo de archivos no es exclusivo de Python o Pipenv; de hecho ya est\u00e1 presente en los gestores de paquetes de los lenguajes de programaci\u00f3n m\u00e1s modernos: <code>Gemfile.lock</code> en Ruby, <code>yarn.lock</code> en JavaScript, <code>composer.lock</code> en PHP, etc. Pipenv fue el primer proyecto popular en incorporarlos en la paqueter\u00eda de Python.</p> <p>La ventaja de un archivo de bloqueo es que esto conduce a una construcci\u00f3n determinista: no importa cu\u00e1ntas veces se instalen los paquetes de software, se obtendr\u00e1 el mismo resultado. Sin un fichero lock que \"bloquee\" las dependencias y su orden, no se cumplir\u00eda necesariamente. Lo que significa que dos miembros del equipo que instalan la misma lista de software pueden tener instalaciones de construcci\u00f3n ligeramente diferentes.</p> <p>Cuando estamos trabajando con Docker donde hay c\u00f3digo tanto local en nuestro ordenador como tambi\u00e9n dentro de Docker, el potencial de conflictos de <code>Pipfile.lock</code> surge cuando se actualizan paquetes de software.</p> <p>Siguiendo adelante usamos el comando <code>RUN</code> para instalar primero <code>pipenv</code> y luego <code>pipenv install</code> para instalar los paquetes de software listados en nuestro Pipfile.lock, actualmente s\u00f3lo Django. Es un es importante a\u00f1adir tambi\u00e9n el indicador <code>--system</code>, ya que por defecto Pipenv buscar\u00e1 el par\u00e1metro en el que instalar cualquier paquete, pero como estamos dentro de Docker ahora, t\u00e9cnicamente no hay ning\u00fan entorno virtual. En cierto modo, el contenedor Docker es nuestro entorno virtual y mucho m\u00e1s. As\u00ed que debemos usar la bandera <code>--system</code> para asegurarnos de que nuestros paquestes est\u00e1n disponibles en todo el Docker para nosotros.</p> <p>Como paso final copiamos el resto de nuestro c\u00f3digo local en el directorio <code>/code/</code> dentro de Docker. \u00bfPor qu\u00e9 copiamos el c\u00f3digo local dos veces, primero el Pipfile y Pipfile.lock y luego el resto? La raz\u00f3n es que las im\u00e1genes se crean en base a instrucciones de arriba hacia abajo por lo que queremos que las cosas que cambian a menudo -como nuestro c\u00f3digo local- sea el \u00faltimo. De esta manera s\u00f3lo tenemos que regenerar esa parte de la imagen ante un cambio y no se reinstala todo cada vez que lo haya. Como el software de los paquetes contenidos en nuestros <code>Pipfile</code> y <code>Pipfile.lock</code> cambian con poca frecuencia, implica que no tiene sentido copiarlos e instalarlos antes.</p> <p>Nuestras instrucciones de imagen ya est\u00e1n hechas, as\u00ed que vamos a construir la imagen usando el comando <code>docker build .</code>. El punto <code>.</code> indica que el directorio actual es donde se debe ejecutar el comando comando. Se genera una gran cantidad de texto en pantalla; s\u00f3lo se incluye las dos primeras l\u00edneas y las tres \u00faltimas.</p> <pre><code>$ docker build .\nSending build context to Docker daemon 154.1kB\nStep 1/7 : FROM python:3.8\n...\nStep 7/7 : COPY . /code/\n---&gt; a48b2acb1fcc\nSuccessfully built a48b2acb1fcc\n</code></pre> <p>Pasando a lo siguiente, ahora necesitamos crear un archivo <code>docker-composition.yml</code> para controlar c\u00f3mo ejecutar el comando que ser\u00e1 construido en base a nuestra imagen de <code>Dockerfile</code>.</p> <pre><code>$ touch docker-compose.yml\n</code></pre> <p>Contendr\u00e1 el siguiente c\u00f3digo</p> <pre><code>version: '3.7'\n\nservices:\n  web:\n    build: .\n    command: python /code/manage.py runserver 0.0.0.0:8000\n    volumes:\n      - .:/code\n    ports:\n      - 8000:8000\n</code></pre> <p>En la l\u00ednea superior se especifica la versi\u00f3n m\u00e1s reciente de Docker Compose que es actualmente 3.7  (no confundir con la versi\u00f3n de Python que puede ser bien parecida) A continuaci\u00f3n, especificamos qu\u00e9 <code>services</code> (o contenedores) queremos que funcionen en nuestro \"Docker host\". Es posible tener varios <code>services</code> funcionando, pero por ahora s\u00f3lo tenemos uno para el servidor <code>web</code>. Especificaremos c\u00f3mo construir el contenedor diciendo, \"Busca el directorio en curso <code>.</code> el <code>Dockerfile</code>\" . Luego, dentro del contenedor, ejecute el comando para arrancar el servidor local. El montaje de los vol\u00famenes sincroniza autom\u00e1ticamente el sistema de archivos Docker con nuestro sistema de archivos local. \u00a1Esto significa que no tenemos que reconstruir la imagen cada vez que cambiamos un solo fichero!.</p> <p>Por \u00faltimo especificamos los puertos (<code>ports</code>) a exponer dentro de Docker que solo ser\u00e1 el 8000, que es el puerto Django por defecto.</p> <p>Si es la primera vez que utiliza Docker, es muy probable que se est\u00e9 muy confundido en este momento. No hay motivo de preocupaci\u00f3n. Crearemos m\u00faltiples im\u00e1genes y contenedores Docker y, con la pr\u00e1ctica, el flujo comenzar\u00e1 a tener m\u00e1s sentido. Se ver\u00e1 como se usan archivos <code>Dockerfile</code> y <code>docker-composition.yml</code> muy similares en cada uno de los proyectos.</p> <p>El paso final es ejecutar nuestro contenedor Docker usando el comando <code>docker-compose up</code>. Este comando resultar\u00e1 en otro largo flujo de texto de salida en la l\u00ednea de comandos.</p> <pre><code>$ docker-compose up\nCreating network \"hello_default\" with the default driver\nBuilding web\nStep 1/7 : FROM python:3.8\n...\nCreating hello_web_1 ... done\nAttaching to hello_web_1\nweb_1 | Performing system checks...\nweb_1 |\nweb_1 | System check identified no issues (0 silenced).\nweb_1 | September 20, 2019 - 17:21:57\nweb_1 | Django version 2.2.5, using settings 'hello_project.settings'\nweb_1 | Starting development server at http://0.0.0.0:8000/\nweb_1 | Quit the server with CONTROL-C.\n</code></pre> <p>Para confirmar que realmente funcion\u00f3, volveremos a poner http://127.0.0.1:8000/ en el navegador web. Actualizaremos la p\u00e1gina y aparecer\u00e1 la p\u00e1gina \"Hello, World\".</p> <p>Django se est\u00e1 ejecutando ahora puramente dentro de un contenedor Docker. No estamos trabajando dentro de un entorno virtual local. No ejecutamos el comando <code>runserver</code>. Todo nuestro c\u00f3digo y nuestro servidor Django se est\u00e1 ejecutando desde dentro de un Docker aut\u00f3nomo. !Todo un \u00e9xito!</p> <p>Detendremos el contenedor con Ctrl+C y adem\u00e1s escribiremos <code>docker-compose down</code>. Los contenedores absorben una gran cantidad de memoria, as\u00ed que es una buena idea detenerlos de esta manera cuando hayamos terminado de usarlos.</p> <p>Los contenedores se han concebido para ser est\u00e1ticos (no pueden cambiar), por lo que utilizamos <code>volumes</code> para copiar nuestro c\u00f3digo en sitios donde si que pueda guardarse.</p> <pre><code>$ docker-compose down\nRemoving hello_web_1 ... done\nRemoving network hello_default\n</code></pre>"},{"location":"05.-Docker/intermezzo/Instalaci%C3%B3n%20de%20zsh%20en%20ubuntu/","title":"Instalaci\u00f3n de zsh en ubuntu","text":"<p>Para instalar Zsh en Ubuntu, sigue los siguientes pasos:</p> <ul> <li>Abre una terminal en tu sistema Ubuntu.</li> <li>Actualiza la lista de paquetes de Ubuntu con el siguiente comando:</li> </ul> <pre><code>$ sudo apt update\n</code></pre> <ul> <li>Ahora, instala Zsh con el siguiente comando:</li> </ul> <pre><code> sudo apt install zsh\n</code></pre> <ul> <li>Despu\u00e9s de la instalaci\u00f3n, verifica que la versi\u00f3n de Zsh instalada es la \u00faltima disponible con:</li> </ul> <pre><code>zsh --version\n</code></pre> <ul> <li>Para configurar Zsh como tu shell predeterminada, utiliza el siguiente comando:</li> </ul> <pre><code>sudo chsh -s $(which zsh)\n</code></pre> <ul> <li>Cierra la sesi\u00f3n actual (saliendo del modo gr\u00e1fico) e inicia sesi\u00f3n nuevamente para que los cambios surtan efecto.</li> <li>Instalar Oh-my-zsh seg\u00fan las instrucciones de su p\u00e1gina web es decir, ejecutar el comando:</li> </ul> <pre><code>sh -c \"$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\"\n</code></pre> <ul> <li>Abre tu terminal y ejecuta el siguiente comando para abrir el archivo de configuraci\u00f3n de Oh My Zsh:</li> </ul> <pre><code>vi ~/.zshrc\n</code></pre> <ul> <li>Busca la l\u00ednea que comienza con <code>ZSH_THEME</code> y cambia el valor despu\u00e9s del signo igual por el nombre del te   ma que quieres utilizar. Por ejemplo, si quieres utilizar el tema agnoster, la l\u00ednea deber\u00eda verse as\u00ed:</li> </ul> <pre><code>ZSH_THEME=\"agnoster\"\n</code></pre> <ul> <li> <p>Guarda los cambios y cierra el archivo de configuraci\u00f3n.</p> </li> <li> <p>Sal de tu sesi\u00f3n de terminal actual y vuelve a iniciarla para que los cambios tengan efecto.</p> </li> </ul> <p>instalacion_del_plugin_en_ZSH</p>"},{"location":"05.-Docker/intermezzo/ejercicios/","title":"Ejercicios","text":"<p>https://osl.ugr.es/2021/03/24/tutorial-basico-de-docker/</p> <p>https://iesgn.github.io/curso_docker_2021/sesion1/ejercicios.html</p>"},{"location":"05.-Docker/intermezzo/instalacion_del_plugin_en_ZSH/","title":"Instalaci\u00f3n del plugin de ZSH","text":"<p>La instalaci\u00f3n del plugin de Docker en Zsh puede variar dependiendo del m\u00e9todo que se utilice para instalar Zsh en tu sistema operativo. A continuaci\u00f3n, se describe el proceso de instalaci\u00f3n en sistemas operativos basados en Linux:</p> <ol> <li>Abre una terminal y aseg\u00farate de tener instalado Zsh en tu sistema y el gestor de paquetes Oh My Zsh. </li> <li>Ahora, abre el archivo de configuraci\u00f3n de Zsh en un editor de texto. Puedes hacerlo ejecutando el siguiente comando en la terminal:</li> </ol> <p><code>vim ~/.zshrc</code></p> <ol> <li>Busca la l\u00ednea que comienza con <code>plugins=</code> y agrega <code>docker</code> al final de la lista de plugins separados por espacios. Debe quedar algo como esto:</li> </ol> <p><code>plugins=(git docker)</code></p> <ol> <li> <p>Guarda los cambios y cierra el archivo.</p> </li> <li> <p>Ahora, reinicia Zsh para que los cambios tengan efecto:</p> </li> </ol> <p><code>source ~/.zshrc</code></p> <p>Una vez completados estos pasos, el plugin de Docker deber\u00eda estar instalado y listo para usarse en Zsh. Puedes probarlo ejecutando un comando de Docker en la terminal.</p>"},{"location":"05.-Docker/intermezzo/instalacion_del_plugin_en_ZSH/#otros-plugins","title":"Otros plugins","text":"<p>Aparte del plugin oficial de Docker, hay varios otros plugins que puedes instalar en Zsh para trabajar con Docker. Algunos de los plugins m\u00e1s populares son:</p> <ul> <li>zsh-autosuggestions-docker: Este plugin agrega sugerencias autom\u00e1ticas para comandos de Docker en Zsh. Puedes instalarlo utilizando el siguiente comando:</li> </ul> <p><code>git clone https://github.com/hlissner/zsh-autosuggestions ~/.oh-my-zsh/custom/plugins/zsh-autosuggestions</code></p> <ul> <li>zsh-completion-docker: Este plugin agrega completado de tabulaci\u00f3n para comandos de Docker en Zsh. Puedes instalarlo utilizando el siguiente comando:</li> </ul> <p><code>git clone https://github.com/docker/cli.git ~/.oh-my-zsh/custom/plugins/zsh-completion-docker</code></p> <ul> <li>zsh-syntax-highlighting-docker: Este plugin agrega resaltado de sintaxis para comandos de Docker en Zsh. Puedes instalarlo utilizando el siguiente comando:</li> </ul> <p><code>git clone https://github.com/zsh-users/zsh-syntax-highlighting.git ~/.oh-my-zsh/custom/plugins/zsh-syntax-highlighting-docker</code></p> <p>Para utilizar estos plugins, debes agregarlos a la lista de plugins en el archivo de configuraci\u00f3n de Zsh (<code>~/.zshrc</code>) de la misma manera que se agreg\u00f3 el plugin de Docker. Por ejemplo:</p> <pre><code>plugins=(git docker zsh-autosuggestions zsh-completion-docker zsh-syntax-highlighting-docker)\n</code></pre> <p>Igual que antes y una vez que hayas agregado estos plugins, reinicia <code>zsh</code> para que los cambios tengan efecto. Luego, podr\u00e1s utilizar las funciones adicionales que ofrecen estos plugins para trabajar con <code>docker</code> en <code>zsh</code>.</p>"},{"location":"99.-Anexos/","title":"Index","text":"<p>01.-Recorrido hist\u00f3rico de la gesti\u00f3n de redes en Linux</p> <p>02.-C\u00f3mo instalar NetworkManager</p> <p>03.-C\u00f3mo cambiar el nombre del host en linux</p> <p>04.-Por qu\u00e9 tengo un fichero50-cloud-init en la configuraci\u00f3n de netplan</p> <p>05.-Esperas en el arranque de linux por la red</p> <p>06.-FAQ Clonaci\u00f3n de M\u00e1quinas Virtuales en KVM-QEMU</p> <p>07.-Manual B\u00e1sico de NAT e IPTABLES</p>"},{"location":"99.-Anexos/00.-Mi%20clave%20p%C3%BAblica/","title":"00.-Mi clave p\u00fablica","text":"<p>ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBPUpV/dynhwON9bAgywtp/LBxcv4C6RBxLnFalUVqULJGTgwgT8vnGeYFGblzJ/7ZG5uzPdRqVxesvi15xQSvcE=</p>"},{"location":"99.-Anexos/01.-Recorrido%20hist%C3%B3rico%20de%20la%20gesti%C3%B3n%20de%20redes%20en%20Linux/","title":"01.-Recorrido hist\u00f3rico de la gesti\u00f3n de redes en Linux","text":""},{"location":"99.-Anexos/01.-Recorrido%20hist%C3%B3rico%20de%20la%20gesti%C3%B3n%20de%20redes%20en%20Linux/#los-primeros-tiempos-etcnetworkinterfaces","title":"Los primeros tiempos: <code>/etc/network/interfaces</code>","text":"<p>En los primeros d\u00edas de Linux, la configuraci\u00f3n de red era algo manual y directo. Si quer\u00edas configurar una direcci\u00f3n IP fija o activar el DHCP, ten\u00edas que hacerlo a trav\u00e9s de un archivo llamado <code>/etc/network/interfaces</code>. Este archivo era bastante simple: all\u00ed se defin\u00edan las interfaces de red y c\u00f3mo deber\u00edan comportarse. Por ejemplo, si quer\u00edas que una tarjeta de red (<code>eth0</code>, como se llamaba en su momento) tuviera una IP fija, lo configurabas directamente en ese archivo. Era un sistema muy b\u00e1sico pero efectivo para configurar redes en entornos peque\u00f1os.</p> <p>Aqu\u00ed tienes un ejemplo t\u00edpico de c\u00f3mo se configuraba:</p> <pre><code>auto eth0\niface eth0 inet static\n    address 192.168.1.100\n    netmask 255.255.255.0\n    gateway 192.168.1.1\n</code></pre> <p>Sin embargo, este m\u00e9todo era bastante est\u00e1tico. Si cambiabas de red o necesitabas configuraciones m\u00e1s din\u00e1micas, se volv\u00eda tedioso. Y en servidores m\u00e1s grandes o en la nube, donde las redes pueden cambiar a menudo, esto se hac\u00eda dif\u00edcil de gestionar.</p>"},{"location":"99.-Anexos/01.-Recorrido%20hist%C3%B3rico%20de%20la%20gesti%C3%B3n%20de%20redes%20en%20Linux/#la-llegada-de-networkmanager","title":"La llegada de NetworkManager","text":"<p>A medida que los ordenadores port\u00e1tiles y el uso de redes inal\u00e1mbricas se hicieron m\u00e1s comunes, la necesidad de un sistema que pudiera gestionar redes de manera m\u00e1s din\u00e1mica se hizo evidente. As\u00ed naci\u00f3 NetworkManager.</p> <p>NetworkManager es una herramienta que se encarga de gestionar las conexiones de red de forma autom\u00e1tica. Esto significa que si conectas tu equipo a una nueva red, NetworkManager lo detecta y ajusta la configuraci\u00f3n autom\u00e1ticamente, algo que era dif\u00edcil con el viejo sistema basado en <code>/etc/network/interfaces</code>. Adem\u00e1s, tambi\u00e9n puede gestionar conexiones VPN, WiFi y Ethernet de manera mucho m\u00e1s flexible. Este sistema se empez\u00f3 a usar mucho en los escritorios Linux porque facilita la movilidad: te conectas a una red en casa, otra en el trabajo, y NetworkManager se encarga de todo.</p> <p>La gesti\u00f3n se puede hacer desde la l\u00ednea de comandos con <code>nmcli</code>, una interfaz gr\u00e1fica en entornos de escritorio o incluso a trav\u00e9s de un men\u00fa en la barra de tareas. Todo es mucho m\u00e1s amigable y autom\u00e1tico, especialmente para usuarios que no quieren estar editando archivos de texto cada vez que se mueven de red a otra.</p>"},{"location":"99.-Anexos/01.-Recorrido%20hist%C3%B3rico%20de%20la%20gesti%C3%B3n%20de%20redes%20en%20Linux/#la-evolucion-hacia-la-nube-cloud-init","title":"La evoluci\u00f3n hacia la nube: Cloud-Init","text":"<p>Con el crecimiento de los servidores en la nube (como en AWS, Azure o Google Cloud), surgi\u00f3 la necesidad de automatizar muchas configuraciones al inicio de las m\u00e1quinas virtuales. Aqu\u00ed es donde aparece Cloud-Init, una herramienta pensada para entornos cloud.</p> <p>Cuando lanzas una m\u00e1quina virtual en la nube, Cloud-Init es el que se encarga de configurarla al arrancar. Puede asignar direcciones IP, configurar nombres de host, a\u00f1adir claves SSH y m\u00e1s, sin que el administrador tenga que intervenir manualmente. Es perfecto para esos entornos donde tienes que desplegar cientos de servidores y quieres que se configuren solos seg\u00fan el entorno en el que est\u00e9n.</p> <p>Cloud-Init es un paso adelante en automatizaci\u00f3n, pero a veces interfiere si quieres hacer configuraciones manuales, porque est\u00e1 dise\u00f1ado para trabajar solo al inicio.</p>"},{"location":"99.-Anexos/01.-Recorrido%20hist%C3%B3rico%20de%20la%20gesti%C3%B3n%20de%20redes%20en%20Linux/#la-simplificacion-moderna-netplan","title":"La simplificaci\u00f3n moderna: Netplan","text":"<p>En 2017, Ubuntu introdujo Netplan como una forma de simplificar y unificar la configuraci\u00f3n de red. Netplan es como una capa intermedia: no gestiona la red directamente, sino que define las configuraciones de red de una manera clara usando archivos YAML, un formato de texto f\u00e1cil de leer.</p> <p>Lo interesante de Netplan es que puedes elegir qu\u00e9 herramienta quieres usar para gestionar la red: puedes usar NetworkManager (en escritorios o port\u00e1tiles) o systemd-networkd (m\u00e1s com\u00fan en servidores). Netplan simplifica la configuraci\u00f3n y te permite definir redes m\u00e1s complejas de forma m\u00e1s limpia que el viejo archivo <code>/etc/network/interfaces</code>.</p> <p>Por ejemplo, si quieres configurar una IP fija usando Netplan, el archivo se ve as\u00ed:</p> <pre><code>network:\n  version: 2\n  renderer: NetworkManager\n  ethernets:\n    enp0s3:\n      dhcp4: no\n      addresses:\n        - 192.168.1.100/24\n      gateway4: 192.168.1.1\n      nameservers:\n        addresses:\n          - 8.8.8.8\n</code></pre> <p>Netplan se asegura de que todo est\u00e9 bien estructurado y luego pasa esta informaci\u00f3n a NetworkManager o systemd para que hagan el trabajo real.</p>"},{"location":"99.-Anexos/01.-Recorrido%20hist%C3%B3rico%20de%20la%20gesti%C3%B3n%20de%20redes%20en%20Linux/#systemd-networkd","title":"<code>systemd-networkd</code>","text":"<p>Es un servicio ligero de <code>systemd</code> dise\u00f1ado para gestionar la configuraci\u00f3n de red en sistemas Linux, ideal para entornos de servidores o dispositivos con redes est\u00e1ticas o semi-din\u00e1micas.</p>"},{"location":"99.-Anexos/01.-Recorrido%20hist%C3%B3rico%20de%20la%20gesti%C3%B3n%20de%20redes%20en%20Linux/#caracteristicas-principales","title":"Caracter\u00edsticas principales:","text":"<ul> <li>Gestiona interfaces de red f\u00edsicas (Ethernet, Wi-Fi) y virtuales (VLANs, bridges).</li> <li>Utiliza archivos de configuraci\u00f3n simples en formato <code>.network</code>, ubicados en <code>/etc/systemd/network/</code>.</li> <li>Es eficiente, sin dependencias gr\u00e1ficas, lo que lo hace ideal para servidores.</li> <li>Se integra bien con otros servicios de systemd, como systemd-resolved para DNS.</li> </ul> <p>Ejemplo de configuraci\u00f3n est\u00e1tica:</p> <pre><code>[Match]\nName=enp0s3\n\n[Network]\nAddress=192.168.1.100/24\nGateway=192.168.1.1\nDNS=8.8.8.8\n</code></pre> <p>Es f\u00e1cil de usar y configurar, pero menos adecuado para entornos donde las redes cambian din\u00e1micamente, donde NetworkManager es m\u00e1s flexible. <code>systemd-networkd</code> es perfecto para servidores con configuraciones estables y predecibles.</p>"},{"location":"99.-Anexos/01.-Recorrido%20hist%C3%B3rico%20de%20la%20gesti%C3%B3n%20de%20redes%20en%20Linux/#netctl","title":"<code>netctl</code>","text":"<p>netctl es una herramienta espec\u00edfica de Arch Linux, dise\u00f1ada para la configuraci\u00f3n manual de redes. Es similar a lo que ser\u00eda el archivo <code>/etc/network/interfaces</code> en Debian/Ubuntu. Se gestiona mediante perfiles almacenados en <code>/etc/netctl/</code>, permitiendo configurar tanto redes cableadas como inal\u00e1mbricas. Es una opci\u00f3n para usuarios avanzados que prefieren una gesti\u00f3n manual de redes sin automatizaci\u00f3n.</p>"},{"location":"99.-Anexos/01.-Recorrido%20hist%C3%B3rico%20de%20la%20gesti%C3%B3n%20de%20redes%20en%20Linux/#wpa_supplicant","title":"wpa_supplicant","text":"<p>wpa_supplicant se utiliza para gestionar redes inal\u00e1mbricas, particularmente en configuraciones manuales o sistemas sin interfaces gr\u00e1ficas. Puede ser utilizado junto con <code>netctl</code> o <code>systemd-networkd</code> para gestionar conexiones Wi-Fi.</p>"},{"location":"99.-Anexos/01.-Recorrido%20hist%C3%B3rico%20de%20la%20gesti%C3%B3n%20de%20redes%20en%20Linux/#conclusion","title":"Conclusi\u00f3n","text":"<p>A lo largo de los a\u00f1os, la gesti\u00f3n de red en Linux ha pasado de ser un proceso manual y est\u00e1tico a algo mucho m\u00e1s din\u00e1mico y automatizado, adapt\u00e1ndose a las necesidades de usuarios de escritorio, servidores en la nube y grandes infraestructuras.</p> <ul> <li><code>/etc/network/interfaces</code>: B\u00e1sico, pero efectivo para peque\u00f1as redes.</li> <li>NetworkManager: Introdujo la gesti\u00f3n autom\u00e1tica de redes para entornos m\u00e1s din\u00e1micos y de escritorio.</li> <li>Cloud-Init: Dise\u00f1ado para automatizar la configuraci\u00f3n de servidores en entornos cloud.</li> <li>Netplan: Unifica y simplifica la configuraci\u00f3n de redes en Ubuntu, permitiendo elegir la herramienta de gesti\u00f3n m\u00e1s adecuada (NetworkManager o systemd-networkd).</li> <li>systemd-networkd: Un servicio ligero de systemd ideal para gestionar redes est\u00e1ticas o semi-din\u00e1micas en servidores, utilizando archivos de configuraci\u00f3n simples y ofreciendo integraci\u00f3n con otros servicios de systemd.</li> <li>netctl: Herramienta espec\u00edfica de Arch Linux para la gesti\u00f3n manual de redes mediante perfiles, adecuada para usuarios avanzados que prefieren configuraciones simples y sin automatizaci\u00f3n.   wpa_supplicant: Usado para gestionar redes Wi-Fi, especialmente en configuraciones manuales o minimalistas, y compatible con herramientas como netctl o systemd-networkd.</li> </ul> <p>\u00a1Ojo!: Netplan es una herramienta que pr\u00e1cticamente solo se usa en Ubuntu y sus derivados, mientras que otras distribuciones de Linux tienen sus propios m\u00e9todos para gestionar la red.</p> <p>Hoy en d\u00eda, estas herramientas se complementan para cubrir las necesidades de todo tipo de sistemas, desde el m\u00e1s simple hasta el m\u00e1s complejo.</p>"},{"location":"99.-Anexos/02.-C%C3%B3mo%20instalar%20NetworkManager/","title":"02.-C\u00f3mo instalar NetworkManager","text":""},{"location":"99.-Anexos/02.-C%C3%B3mo%20instalar%20NetworkManager/#como-instalar-networkmanager","title":"C\u00f3mo instalar NetworkManager","text":""},{"location":"99.-Anexos/02.-C%C3%B3mo%20instalar%20NetworkManager/#verificar-si-networkmanager-esta-gestionando-las-interfaces","title":"Verificar si NetworkManager est\u00e1 gestionando las interfaces","text":"<p>Aseg\u00farate de que el servicio NetworkManager est\u00e1 corriendo correctamente:</p> <pre><code>$ sudo systemctl status NetworkManager\n</code></pre> <p>Si el servicio no est\u00e1 activo, puedes iniciarlo con:</p> <pre><code>$ sudo systemctl start NetworkManager\n</code></pre> <p>y para que se inicie autom\u00e1ticamente en cada arranque:</p> <pre><code>$ sudo systemctl enable NetworkManager\n</code></pre>"},{"location":"99.-Anexos/02.-C%C3%B3mo%20instalar%20NetworkManager/#comprobar-si-networkmanager-esta-gestionando-la-interfaz","title":"Comprobar si NetworkManager est\u00e1 gestionando la interfaz","text":"<p>NetworkManager puede no estar gestionando tu interfaz de red si fue configurada manualmente o si est\u00e1 siendo controlada por otro servicio (por ejemplo, usando <code>netplan</code> o configuraciones en <code>/etc/network/interfaces</code>).</p> <p>Para asegurarte de que NetworkManager est\u00e1 gestionando las interfaces, sigue estos pasos:</p> <ul> <li>Verifica la configuraci\u00f3n de <code>/etc/network/interfaces</code>: Si tu interfaz est\u00e1 configurada en este archivo, NetworkManager no la gestionar\u00e1. Abre el archivo con un editor:</li> </ul> <pre><code>sudo nano /etc/network/interfaces\n</code></pre> <p>Si ves que tu interfaz est\u00e1 configurada en este archivo (algo como <code>auto enp0s3</code> o <code>iface enp0s3 inet static</code>), NetworkManager no podr\u00e1 gestionarla. Para que NetworkManager se haga cargo, comenta o elimina esas l\u00edneas. Guarda los cambios y reinicia el sistema o el servicio de red:</p> <pre><code>sudo systemctl restart NetworkManager\n</code></pre>"},{"location":"99.-Anexos/02.-C%C3%B3mo%20instalar%20NetworkManager/#deshabilitar-netplan-si-es-necesario","title":"Deshabilitar Netplan (si es necesario)","text":"<p>Si est\u00e1s utilizando una versi\u00f3n reciente de Ubuntu y Netplan est\u00e1 configurando la red, NetworkManager puede estar deshabilitado. Para usar NetworkManager en lugar de Netplan, abre el archivo de configuraci\u00f3n de Netplan:</p> <pre><code>$ sudo nano /etc/netplan/00-installer-config.yaml\n</code></pre> <p>Busca algo como esto:</p> <pre><code>network:\n  version: 2\n  renderer: networkd\n</code></pre> <p>Cambia <code>renderer: networkd</code> a <code>renderer: NetworkManager</code>. Quedar\u00eda as\u00ed:</p> <pre><code>network:\n  version: 2\n  renderer: NetworkManager\n</code></pre> <p>Guarda los cambios y aplica la nueva configuraci\u00f3n con:</p> <pre><code>$ sudo netplan apply\n</code></pre>"},{"location":"99.-Anexos/02.-C%C3%B3mo%20instalar%20NetworkManager/#agregar-una-nueva-conexion-manualmente","title":"Agregar una nueva conexi\u00f3n manualmente","text":"<p>Si despu\u00e9s de estos pasos sigues sin ver conexiones, puedes intentar agregar una conexi\u00f3n manualmente para tu interfaz de red. Por ejemplo:</p> <pre><code>sudo nmcli connection add type ethernet ifname enp0s3 con-name \"Wired connection 1\" ipv4.addresses 192.168.1.100/24 ipv4.gateway 192.168.1.1 ipv4.dns \"8.8.8.8 8.8.4.4\" ipv4.method manual\n</code></pre> <p>Reemplaza <code>enp0s3</code> por el nombre de tu interfaz de red (puedes verlo con <code>ip addr</code>).</p>"},{"location":"99.-Anexos/02.-C%C3%B3mo%20instalar%20NetworkManager/#verificar-la-conexion-de-red","title":"Verificar la conexi\u00f3n de red","text":"<p>Despu\u00e9s de agregar una nueva conexi\u00f3n, verifica si aparece en la lista:</p> <pre><code>nmcli connection show\n</code></pre> <p>Y luego puedes activarla con:</p> <pre><code>    sudo nmcli connection up \"Wired connection 1\"\n</code></pre> <p>Estos pasos deber\u00edan permitirte hacer que NetworkManager gestione tu interfaz de red y configurar una IP fija.</p>"},{"location":"99.-Anexos/02.-C%C3%B3mo%20instalar%20NetworkManager/#pasos-para-cambiar-de-netplan-a-networkmanager","title":"Pasos para cambiar de Netplan a NetworkManager","text":""},{"location":"99.-Anexos/02.-C%C3%B3mo%20instalar%20NetworkManager/#editar-el-archivo-de-configuracion-de-netplan","title":"Editar el archivo de configuraci\u00f3n de Netplan","text":"<p>Debes modificar el archivo de configuraci\u00f3n de Netplan para que utilice NetworkManager en lugar de la configuraci\u00f3n predeterminada. Para hacerlo, edita el archivo de configuraci\u00f3n de Netplan:</p> <pre><code>sudo nano /etc/netplan/50-cloud-init.yaml\n</code></pre> <p>Cambia el contenido a lo siguiente:</p> <pre><code>network:\n  version: 2\n  renderer: NetworkManager\n</code></pre> <p>Esto indica que NetworkManager ser\u00e1 el encargado de gestionar las interfaces de red.</p>"},{"location":"99.-Anexos/02.-C%C3%B3mo%20instalar%20NetworkManager/#aplicar-los-cambios","title":"Aplicar los cambios","text":"<p>Una vez que hayas modificado el archivo, guarda y cierra el editor (Ctrl + O para guardar y Ctrl + X para salir en nano).</p> <p>Luego, aplica la nueva configuraci\u00f3n de Netplan con el siguiente comando:</p> <pre><code>sudo netplan apply\n</code></pre> <p>Esto har\u00e1 que NetworkManager tome el control de la gesti\u00f3n de red.</p>"},{"location":"99.-Anexos/02.-C%C3%B3mo%20instalar%20NetworkManager/#verificar-que-networkmanager-este-activo","title":"Verificar que NetworkManager est\u00e9 activo","text":"<p>Aseg\u00farate de que NetworkManager est\u00e9 activo y corriendo:</p> <pre><code>$ sudo systemctl status NetworkManager\n</code></pre> <p>Si no est\u00e1 corriendo, puedes iniciarlo con:</p> <pre><code>$ sudo systemctl start NetworkManager\n</code></pre> <p>Y habilitarlo para que se inicie autom\u00e1ticamente en cada arranque:</p> <pre><code>$ sudo systemctl enable NetworkManager\n</code></pre>"},{"location":"99.-Anexos/02.-C%C3%B3mo%20instalar%20NetworkManager/#configurar-una-ip-fija-con-nmcli","title":"Configurar una IP fija con nmcli","text":"<p>Ahora que NetworkManager est\u00e1 gestionando las interfaces de red, puedes configurar la IP fija usando <code>nmcli</code>. Primero, lista las conexiones disponibles:</p> <pre><code>$ nmcli connection show\n</code></pre> <p>Esto te mostrar\u00e1 las conexiones de red activas. Busca el nombre de la conexi\u00f3n asociada a tu interfaz de red (probablemente ser\u00e1 algo como Wired connection 1 o similar).</p> <p>Luego, configura la IP fija con el siguiente comando (ajusta los valores seg\u00fan tu red):</p> <pre><code>$ sudo nmcli connection modify \"Wired connection 1\" ipv4.addresses 192.168.1.100/24 ipv4.gateway 192.168.1.1 ipv4.dns \"8.8.8.8 8.8.4.4\" ipv4.method manual\n</code></pre> <pre><code>ipv4.addresses: Es la IP fija que quieres asignar.\nipv4.gateway: La puerta de enlace de la red.\nipv4.dns: Los servidores DNS que deseas utilizar (puedes usar los DNS de Google u otros).\n</code></pre>"},{"location":"99.-Anexos/02.-C%C3%B3mo%20instalar%20NetworkManager/#reiniciar-la-conexion-de-red","title":"Reiniciar la conexi\u00f3n de red","text":"<p>Para aplicar los cambios, debes desactivar y reactivar la conexi\u00f3n de red:</p> <pre><code>$ sudo nmcli connection down \"Wired connection 1\" &amp;&amp; sudo nmcli connection up \"Wired connection 1\"\n</code></pre>"},{"location":"99.-Anexos/02.-C%C3%B3mo%20instalar%20NetworkManager/#verificar-la-nueva-configuracion","title":"Verificar la nueva configuraci\u00f3n","text":"<p>Despu\u00e9s de reiniciar la conexi\u00f3n, verifica que la IP fija est\u00e9 configurada correctamente:</p> <pre><code>$ ip addr\n</code></pre> <p>Esto deber\u00eda mostrar la nueva direcci\u00f3n IP asignada a la interfaz.</p>"},{"location":"99.-Anexos/02.-C%C3%B3mo%20instalar%20NetworkManager/#deshabilitar-cloud-init-si-es-necesario","title":"Deshabilitar Cloud-Init (si es necesario)","text":"<p>Para evitar que Cloud-Init sobreescriba las configuraciones en el futuro, puedes deshabilitar su control sobre la red. Crea el archivo /etc/cloud/cloud.cfg.d/99-disable-network-config.cfg con el siguiente contenido:</p> <pre><code>$ sudo nano /etc/cloud/cloud.cfg.d/99-disable-network-config.cfg\n</code></pre> <p>Agrega:</p> <pre><code>network: {config: disabled}\n</code></pre> <p>Guarda el archivo y reinicia el sistema si es necesario.</p> <p>Despu\u00e9s de estos pasos, tu red ser\u00e1 gestionada exclusivamente por NetworkManager, y podr\u00e1s configurarla de manera flexible usando <code>nmcli</code> o cualquier otro m\u00e9todo compatible con NetworkManager.</p>"},{"location":"99.-Anexos/03.-C%C3%B3mo%20cambiar%20el%20nombre%20del%20host%20en%20linux/","title":"03.-C\u00f3mo cambiar el nombre del host en linux","text":"<p>Ver el nombre de host actual</p> <pre><code>$ hostnamectl\n</code></pre> <p>Cambiar el nombre de host</p> <pre><code>$ sudo hostnamectl set-hostname &lt;nuevo-nombre-de-host&gt;\n</code></pre> <p>Tambi\u00e9n se puede cambiar modificando los archivos <code>/etc/hostname</code> y <code>/etc/hosts</code>.</p>"},{"location":"99.-Anexos/04.-Por%20qu%C3%A9%20tengo%20un%20fichero50-cloud-init%20en%20la%20configuraci%C3%B3n%20de%20netplan/","title":"04.-Por qu\u00e9 tengo un fichero50-cloud-init en la configuraci\u00f3n de netplan","text":"<p>El archivo de configuraci\u00f3n <code>/etc/netplan/50-cloud-init.yaml</code> en tu sistema se llama as\u00ed porque fue generado autom\u00e1ticamente por Cloud-Init durante el proceso de inicializaci\u00f3n de tu m\u00e1quina. Esto suele suceder cuando una m\u00e1quina se implementa en entornos de nube (como AWS, Azure, Google Cloud) o cuando tu sistema tiene Cloud-Init instalado y habilitado, incluso en m\u00e1quinas locales, como parte de la configuraci\u00f3n predeterminada de Ubuntu Server.</p>"},{"location":"99.-Anexos/04.-Por%20qu%C3%A9%20tengo%20un%20fichero50-cloud-init%20en%20la%20configuraci%C3%B3n%20de%20netplan/#que-es-cloud-init","title":"\u00bfQu\u00e9 es Cloud-Init?","text":"<p>Cloud-Init es una herramienta utilizada principalmente en entornos cloud para configurar y gestionar instancias de servidores autom\u00e1ticamente cuando se inician por primera vez. Cloud-Init maneja diversas tareas, como:</p> <ul> <li>Configuraci\u00f3n de redes.</li> <li>Configuraci\u00f3n de claves SSH.</li> <li>Establecer el nombre de host.</li> <li>Ejecuci\u00f3n de scripts personalizados en el arranque.</li> </ul> <p>El nombre del archivo \"50-cloud-init.yaml\" se genera siguiendo este esquema para priorizar y organizar las configuraciones. El prefijo <code>50-</code> es un n\u00famero que indica el orden en que Netplan aplicar\u00e1 los archivos de configuraci\u00f3n si hay varios (un n\u00famero m\u00e1s bajo se aplica primero).</p>"},{"location":"99.-Anexos/04.-Por%20qu%C3%A9%20tengo%20un%20fichero50-cloud-init%20en%20la%20configuraci%C3%B3n%20de%20netplan/#por-que-aparece-en-un-host-local","title":"\u00bfPor qu\u00e9 aparece en un host local?","text":"<p>Es posible que tu sistema est\u00e9 configurado para usar Cloud-Init por defecto, incluso en un entorno local, si:</p> <ul> <li>Est\u00e1s usando una imagen de Ubuntu Server que fue dise\u00f1ada para ser compatible con entornos en la nube.</li> <li>Durante la instalaci\u00f3n o configuraci\u00f3n del sistema, se habilit\u00f3 Cloud-Init para que maneje la configuraci\u00f3n inicial de la red.</li> </ul> <p>Aunque est\u00e9s en un entorno local, Cloud-Init puede estar activo y, al iniciar la m\u00e1quina, genera este archivo para gestionar la red.</p>"},{"location":"99.-Anexos/04.-Por%20qu%C3%A9%20tengo%20un%20fichero50-cloud-init%20en%20la%20configuraci%C3%B3n%20de%20netplan/#puedo-desactivar-cloud-init-si-no-lo-necesito","title":"\u00bfPuedo desactivar Cloud-Init si no lo necesito?","text":"<p>S\u00ed, si no est\u00e1s utilizando un entorno de nube y prefieres gestionar la configuraci\u00f3n de red manualmente o con otra herramienta, puedes desactivar Cloud-Init para evitar que sobrescriba las configuraciones de red.</p>"},{"location":"99.-Anexos/04.-Por%20qu%C3%A9%20tengo%20un%20fichero50-cloud-init%20en%20la%20configuraci%C3%B3n%20de%20netplan/#pasos-para-desactivar-cloud-init","title":"Pasos para desactivar Cloud-Init:","text":"<ol> <li>Crear un archivo de configuraci\u00f3n para desactivar Cloud-Init en la red: Puedes crear un archivo de configuraci\u00f3n que le diga a Cloud-Init que no gestione la red. Crea un archivo en <code>/etc/cloud/cloud.cfg.d/99-disable-network-config.cfg</code>:</li> </ol> <pre><code>$ sudo nano /etc/cloud/cloud.cfg.d/99-disable-network-config.cfg\n</code></pre> <ol> <li>A\u00f1adir la siguiente l\u00ednea:</li> </ol> <pre><code>network: {config: disabled}\n</code></pre> <ol> <li>Aplicar los cambios: Guarda el archivo y Cloud-Init dejar\u00e1 de gestionar la red en el pr\u00f3ximo reinicio. Luego puedes gestionar la red con Netplan directamente o cualquier otra herramienta como NetworkManager o systemd-networkd.</li> </ol>"},{"location":"99.-Anexos/04.-Por%20qu%C3%A9%20tengo%20un%20fichero50-cloud-init%20en%20la%20configuraci%C3%B3n%20de%20netplan/#resumen","title":"Resumen","text":"<p>El archivo <code>50-cloud-init.yaml</code> se genera porque Cloud-Init est\u00e1 configurado para gestionar la red en tu sistema. Si no est\u00e1s en un entorno de nube o prefieres manejar la red manualmente, puedes desactivar Cloud-Init y configurar la red directamente con Netplan o cualquier otra herramienta de gesti\u00f3n de red que prefieras.</p>"},{"location":"99.-Anexos/05.-Esperas%20en%20el%20arranque%20de%20linux%20por%20la%20red/","title":"Pregunta:","text":"<p>Cuando arranco mi servidor Ubuntu, el sistema se queda esperando un buen rato y muestra el siguiente error:</p> <pre><code>[FAILED] Failed to start systemd-networkd-wait-online.service - Wait for Network to be Configured. See 'systemctl status systemd-networkd-wait-online.service' for details.\n</code></pre> <p>\u00bfQu\u00e9 significa este error y c\u00f3mo puedo solucionarlo?</p>"},{"location":"99.-Anexos/05.-Esperas%20en%20el%20arranque%20de%20linux%20por%20la%20red/#respuesta","title":"Respuesta:","text":"<p>Este error indica que el servicio <code>systemd-networkd-wait-online</code> ha fallado debido a un tiempo de espera mientras esperaba que la configuraci\u00f3n de red se completara. Este servicio est\u00e1 dise\u00f1ado para garantizar que la red est\u00e9 completamente configurada antes de continuar con el arranque de otros servicios que dependen de ella. El error puede ocurrir si la configuraci\u00f3n de red es incompleta o si alguna interfaz de red no est\u00e1 disponible o activa.</p>"},{"location":"99.-Anexos/05.-Esperas%20en%20el%20arranque%20de%20linux%20por%20la%20red/#posibles-causas","title":"Posibles causas:","text":"<ol> <li>Interfaces de red sin conexi\u00f3n: Si alguna de las interfaces configuradas no est\u00e1 conectada o disponible, el servicio puede quedarse esperando hasta que ocurra un timeout.</li> <li>Configuraci\u00f3n de red incorrecta o incompleta: Si la configuraci\u00f3n de red (por ejemplo, mediante Netplan) es incorrecta o est\u00e1 incompleta, esto puede provocar que el servicio falle.</li> <li>Conflictos con otras herramientas de gesti\u00f3n de red: Si tienes m\u00faltiples herramientas como NetworkManager o Cloud-Init gestionando la red junto con <code>systemd-networkd</code>, puede haber conflictos que causen el error.</li> </ol>"},{"location":"99.-Anexos/05.-Esperas%20en%20el%20arranque%20de%20linux%20por%20la%20red/#soluciones","title":"Soluciones:","text":""},{"location":"99.-Anexos/05.-Esperas%20en%20el%20arranque%20de%20linux%20por%20la%20red/#1-revisar-y-ajustar-la-configuracion-de-netplan","title":"1. Revisar y ajustar la configuraci\u00f3n de Netplan","text":"<p>Verifica tu archivo de configuraci\u00f3n de Netplan para asegurarte de que todas las interfaces est\u00e9n configuradas correctamente. Si hay interfaces que no se est\u00e1n utilizando o no son cr\u00edticas, puedes marcarlas como opcionales. Esto evita que el sistema espere indefinidamente por interfaces que no est\u00e1n conectadas.</p> <ol> <li>Edita el archivo de Netplan ubicado en <code>/etc/netplan/50-cloud-init.yaml</code>:</li> </ol> <pre><code>sudo nano /etc/netplan/50-cloud-init.yaml\n</code></pre> <ol> <li>A\u00f1ade la opci\u00f3n <code>optional: true</code> a las interfaces no cr\u00edticas o innecesarias:</li> </ol> <pre><code>network:\n  version: 2\n  ethernets:\n enp1s0:\ndhcp4: yes\noptional: true\n</code></pre> <ol> <li>Aplica los cambios:</li> </ol> <pre><code>sudo netplan apply\n</code></pre>"},{"location":"99.-Anexos/05.-Esperas%20en%20el%20arranque%20de%20linux%20por%20la%20red/#2-ajustar-el-tiempo-de-espera-del-servicio-systemd-networkd-wait-online","title":"2. Ajustar el tiempo de espera del servicio <code>systemd-networkd-wait-online</code>","text":"<p>Si tu red se configura correctamente pero el sistema sigue esperando demasiado, puedes aumentar el tiempo de espera del servicio para evitar que falle.</p> <ol> <li>Edita el archivo de configuraci\u00f3n del servicio:</li> </ol> <pre><code>sudo nano /lib/systemd/system/systemd-networkd-wait-online.service\n</code></pre> <ol> <li>A\u00f1ade o modifica el valor del tiempo de espera con <code>TimeoutStartSec=30</code>:</li> </ol> <pre><code>[Service]\nExecStart=/usr/lib/systemd/systemd-networkd-wait-online --timeout=30\n</code></pre> <ol> <li>Guarda el archivo y recarga systemd:</li> </ol> <pre><code>sudo systemctl daemon-reload\n</code></pre>"},{"location":"99.-Anexos/05.-Esperas%20en%20el%20arranque%20de%20linux%20por%20la%20red/#3-deshabilitar-systemd-networkd-wait-online","title":"3. Deshabilitar <code>systemd-networkd-wait-online</code>","text":"<p>Si no es necesario esperar a que la red est\u00e9 completamente configurada, puedes deshabilitar este servicio para acelerar el proceso de arranque:</p> <ol> <li>Deshabilita el servicio:</li> </ol> <pre><code>sudo systemctl disable systemd-networkd-wait-online.service\n</code></pre> <ol> <li>Det\u00e9n el servicio si est\u00e1 en ejecuci\u00f3n:</li> </ol> <pre><code>sudo systemctl stop systemd-networkd-wait-online.service\n</code></pre>"},{"location":"99.-Anexos/05.-Esperas%20en%20el%20arranque%20de%20linux%20por%20la%20red/#4-cambiar-a-networkmanager","title":"4. Cambiar a NetworkManager","text":"<p>Si prefieres utilizar NetworkManager en lugar de <code>systemd-networkd</code>, puedes deshabilitar <code>systemd-networkd</code> y activar NetworkManager:</p> <ol> <li>Desactiva <code>systemd-networkd</code>:</li> </ol> <pre><code>sudo systemctl disable systemd-networkd\nsudo systemctl stop systemd-networkd\n</code></pre> <ol> <li>Activa NetworkManager:</li> </ol> <pre><code>sudo systemctl enable NetworkManager\nsudo systemctl start NetworkManager\n</code></pre>"},{"location":"99.-Anexos/05.-Esperas%20en%20el%20arranque%20de%20linux%20por%20la%20red/#resumen","title":"Resumen:","text":"<p>Este error se produce porque el servicio <code>systemd-networkd-wait-online</code> est\u00e1 esperando a que se configure la red, y puede deberse a configuraciones incompletas, interfaces no conectadas o conflictos entre servicios de red. Las soluciones incluyen ajustar la configuraci\u00f3n de red, modificar el tiempo de espera o deshabilitar el servicio si no es necesario.</p>"},{"location":"99.-Anexos/06.-FAQ%20Clonaci%C3%B3n%20de%20M%C3%A1quinas%20Virtuales%20en%20KVM-QEMU/","title":"06.-FAQ Clonaci\u00f3n de M\u00e1quinas Virtuales en KVM-QEMU","text":""},{"location":"99.-Anexos/06.-FAQ%20Clonaci%C3%B3n%20de%20M%C3%A1quinas%20Virtuales%20en%20KVM-QEMU/#1-puedo-copiar-una-maquina-virtual-de-kvmqemu-directamente-desde-algun-directorio","title":"1. \u00bfPuedo copiar una m\u00e1quina virtual de KVM/QEMU directamente desde alg\u00fan directorio?","text":"<p>S\u00ed, puedes copiar una m\u00e1quina virtual de KVM/QEMU directamente desde el sistema de archivos. Las m\u00e1quinas virtuales en KVM/QEMU suelen estar compuestas por dos elementos principales:</p> <ol> <li>Los archivos de imagen de disco (generalmente en formato <code>.qcow2</code>, <code>.img</code>, etc.), que contienen el sistema operativo y los datos de la m\u00e1quina virtual.</li> <li>El archivo de configuraci\u00f3n de la m\u00e1quina virtual, que puede estar en formato XML si est\u00e1s usando <code>libvirt</code> para gestionar tus m\u00e1quinas virtuales.</li> </ol>"},{"location":"99.-Anexos/06.-FAQ%20Clonaci%C3%B3n%20de%20M%C3%A1quinas%20Virtuales%20en%20KVM-QEMU/#pasos-para-copiar-una-maquina-virtual","title":"Pasos para copiar una m\u00e1quina virtual:","text":"<ol> <li>Ubicaci\u00f3n de los archivos de imagen de disco: Los archivos de disco de la m\u00e1quina virtual suelen estar en <code>/var/lib/libvirt/images/</code> por defecto si est\u00e1s utilizando <code>libvirt</code>. Sin embargo, la ubicaci\u00f3n puede variar seg\u00fan tu configuraci\u00f3n. Si tienes una imagen en otro lugar, puedes buscarla utilizando un comando como:</li> </ol> <pre><code>virsh domblklist &lt;nombre_de_la_VM&gt;\n</code></pre> <p>Esto te mostrar\u00e1 las rutas de los discos asociados a esa m\u00e1quina virtual.</p> <ol> <li>Copiar el archivo de imagen: Una vez que encuentres el archivo de imagen, puedes copiarlo a otra ubicaci\u00f3n o m\u00e1quina utilizando <code>cp</code> o herramientas como <code>rsync</code> para transferencias remotas. Ejemplo:</li> </ol> <pre><code>cp /var/lib/libvirt/images/mi_vm.qcow2 /ruta/destino/mi_vm_copia.qcow2\n</code></pre> <p>O si deseas copiarlo a otra m\u00e1quina usando <code>rsync</code>:</p> <pre><code>rsync -avz /var/lib/libvirt/images/mi_vm.qcow2 usuario@otra_maquina:/ruta/destino/\n</code></pre> <ol> <li>Copiar el archivo de configuraci\u00f3n XML (si usas libvirt): El archivo de configuraci\u00f3n XML se encuentra generalmente en <code>/etc/libvirt/qemu/</code>. Puedes encontrarlo usando:</li> </ol> <pre><code>virsh dumpxml &lt;nombre_de_la_VM&gt; &gt; /ruta/destino/mi_vm.xml\n</code></pre> <p>Este comando exportar\u00e1 la configuraci\u00f3n actual de la m\u00e1quina virtual en un archivo XML.</p> <ol> <li>Importar la m\u00e1quina virtual copiada: Una vez que hayas copiado tanto el archivo de imagen como el archivo XML, puedes crear una nueva m\u00e1quina virtual utilizando el archivo XML. Esto se hace usando el siguiente comando:</li> </ol> <pre><code>virsh define /ruta/destino/mi_vm.xml\n</code></pre> <p>Luego, puedes verificar que la m\u00e1quina virtual est\u00e9 definida correctamente:</p> <pre><code>virsh list --all\n</code></pre>"},{"location":"99.-Anexos/06.-FAQ%20Clonaci%C3%B3n%20de%20M%C3%A1quinas%20Virtuales%20en%20KVM-QEMU/#consideraciones-adicionales","title":"Consideraciones adicionales:","text":"<ul> <li> <p>Cambiar UUID y nombre: Si est\u00e1s clonando una m\u00e1quina, es importante modificar el UUID y el nombre en el archivo XML para evitar conflictos si ambas m\u00e1quinas van a coexistir en el mismo sistema.</p> </li> <li> <p>Puedes generar un nuevo UUID con el siguiente comando:</p> </li> </ul> <p><code>bash  uuidgen</code></p> <ul> <li> <p>Luego, edita el archivo XML y reemplaza el UUID y el nombre de la m\u00e1quina virtual.</p> </li> <li> <p>Redes: Si la m\u00e1quina original tiene configurada una MAC address est\u00e1tica, tambi\u00e9n deber\u00edas cambiarla para evitar conflictos en la red.</p> </li> </ul>"},{"location":"99.-Anexos/06.-FAQ%20Clonaci%C3%B3n%20de%20M%C3%A1quinas%20Virtuales%20en%20KVM-QEMU/#ejemplo-para-cambiar-el-nombre-uuid-y-mac-en-el-xml","title":"Ejemplo para cambiar el nombre, UUID y MAC en el XML:","text":"<pre><code>&lt;name&gt;mi_vm_copia&lt;/name&gt;\n&lt;uuid&gt;nuevo-uuid-generado&lt;/uuid&gt;\n&lt;mac address='nueva-mac-address'/&gt;\n</code></pre> <p>Con esto, tendr\u00e1s una m\u00e1quina virtual completamente clonada y lista para ser ejecutada en el mismo o en otro servidor.</p>"},{"location":"99.-Anexos/06.-FAQ%20Clonaci%C3%B3n%20de%20M%C3%A1quinas%20Virtuales%20en%20KVM-QEMU/#2-si-clono-una-maquina-con-el-gestor-de-maquinas-virtuales-tengo-que-generar-la-nueva-mac-uuid-y-el-nombre-o-se-hace-automaticamente","title":"2. Si clono una m\u00e1quina con el Gestor de M\u00e1quinas Virtuales, \u00bftengo que generar la nueva MAC, UUID y el nombre, o se hace autom\u00e1ticamente?","text":"<p>Cuando clonas una m\u00e1quina virtual usando el Gestor de M\u00e1quinas Virtuales (Virtual Machine Manager o <code>virt-manager</code>), muchos de estos pasos se hacen autom\u00e1ticamente, lo que simplifica el proceso de clonaci\u00f3n. A continuaci\u00f3n, te explico c\u00f3mo se manejan los elementos clave durante el proceso de clonaci\u00f3n:</p>"},{"location":"99.-Anexos/06.-FAQ%20Clonaci%C3%B3n%20de%20M%C3%A1quinas%20Virtuales%20en%20KVM-QEMU/#1-nombre-de-la-maquina-virtual","title":"1. Nombre de la m\u00e1quina virtual:","text":"<ul> <li>Al clonar una m\u00e1quina con <code>virt-manager</code>, se te pedir\u00e1 un nuevo nombre para la m\u00e1quina virtual. No puedes usar el mismo nombre que la m\u00e1quina original, ya que el gestor no lo permite.</li> </ul>"},{"location":"99.-Anexos/06.-FAQ%20Clonaci%C3%B3n%20de%20M%C3%A1quinas%20Virtuales%20en%20KVM-QEMU/#2-uuid","title":"2. UUID:","text":"<ul> <li>El UUID de la m\u00e1quina virtual se genera autom\u00e1ticamente. No necesitas preocuparte por generar uno nuevo manualmente, ya que el sistema lo hace al clonar la m\u00e1quina.</li> </ul>"},{"location":"99.-Anexos/06.-FAQ%20Clonaci%C3%B3n%20de%20M%C3%A1quinas%20Virtuales%20en%20KVM-QEMU/#3-mac-address","title":"3. MAC Address:","text":"<ul> <li>La direcci\u00f3n MAC de la tarjeta de red de la m\u00e1quina virtual clonada tambi\u00e9n se generar\u00e1 autom\u00e1ticamente durante el proceso de clonaci\u00f3n. Esto es importante para evitar conflictos de red entre la m\u00e1quina original y la clonada.</li> </ul>"},{"location":"99.-Anexos/06.-FAQ%20Clonaci%C3%B3n%20de%20M%C3%A1quinas%20Virtuales%20en%20KVM-QEMU/#como-hacerlo-en-el-gestor-de-maquinas-virtuales-virt-manager","title":"\u00bfC\u00f3mo hacerlo en el gestor de m\u00e1quinas virtuales (virt-manager)?","text":"<ol> <li>Abre el <code>virt-manager</code>.</li> <li>Haz clic derecho sobre la m\u00e1quina virtual que deseas clonar y selecciona \"Clonar\".</li> <li>El sistema te pedir\u00e1 un nuevo nombre para la m\u00e1quina virtual clonada.</li> <li>Elige si deseas cambiar la ubicaci\u00f3n del archivo de imagen del disco (puedes mantenerlo o moverlo a otro lugar).</li> <li>Completa el proceso. El gestor se encargar\u00e1 de generar autom\u00e1ticamente un nuevo UUID y una nueva direcci\u00f3n MAC para la m\u00e1quina clonada.</li> </ol>"},{"location":"99.-Anexos/06.-FAQ%20Clonaci%C3%B3n%20de%20M%C3%A1quinas%20Virtuales%20en%20KVM-QEMU/#conclusion","title":"Conclusi\u00f3n:","text":"<ul> <li>Nombre: Se te solicitar\u00e1 durante el proceso de clonaci\u00f3n.</li> <li>UUID: Se genera autom\u00e1ticamente.</li> <li>MAC Address: Se genera autom\u00e1ticamente.</li> </ul>"},{"location":"99.-Anexos/07.-Manual%20B%C3%A1sico%20de%20NAT%20e%20IPTABLES/","title":"07.-Manual B\u00e1sico de NAT e IPTABLES","text":""},{"location":"99.-Anexos/07.-Manual%20B%C3%A1sico%20de%20NAT%20e%20IPTABLES/#1-que-es-nat","title":"1. \u00bfQu\u00e9 es NAT?","text":"<p>NAT (Network Address Translation) es una t\u00e9cnica de enrutamiento que permite modificar las direcciones IP de los paquetes de red en tr\u00e1nsito. Su principal uso es facilitar la comunicaci\u00f3n entre redes privadas y redes p\u00fablicas, permitiendo que m\u00faltiples dispositivos compartan una sola IP p\u00fablica para conectarse a Internet.</p>"},{"location":"99.-Anexos/07.-Manual%20B%C3%A1sico%20de%20NAT%20e%20IPTABLES/#tipos-de-nat","title":"Tipos de NAT:","text":"<ul> <li>SNAT (Source Network Address Translation): Cambia la direcci\u00f3n IP de origen de los paquetes cuando salen de la red.</li> <li>DNAT (Destination Network Address Translation): Cambia la direcci\u00f3n IP de destino de los paquetes cuando entran a la red.</li> </ul>"},{"location":"99.-Anexos/07.-Manual%20B%C3%A1sico%20de%20NAT%20e%20IPTABLES/#2-conceptos-clave-de-nat","title":"2. Conceptos Clave de NAT","text":""},{"location":"99.-Anexos/07.-Manual%20B%C3%A1sico%20de%20NAT%20e%20IPTABLES/#snat-source-network-address-translation","title":"SNAT (Source Network Address Translation)","text":"<p>SNAT cambia la direcci\u00f3n IP de origen de un paquete para que parezca provenir de una IP diferente, generalmente la IP p\u00fablica de un enrutador o firewall. Es \u00fatil cuando los dispositivos en una red privada necesitan acceder a Internet o a otra red sin exponer sus direcciones IP internas.</p> <p>Ejemplo de Uso de SNAT:    - Los dispositivos en una red privada (por ejemplo, IPs 192.168.1.x) necesitan acceder a Internet.    - El enrutador cambia la IP de origen a su IP p\u00fablica, permitiendo que el tr\u00e1fico retorne correctamente.</p>"},{"location":"99.-Anexos/07.-Manual%20B%C3%A1sico%20de%20NAT%20e%20IPTABLES/#dnat-destination-network-address-translation","title":"DNAT (Destination Network Address Translation)","text":"<p>DNAT modifica la direcci\u00f3n IP de destino de un paquete que llega desde fuera de la red. Esto permite redirigir el tr\u00e1fico entrante a un servidor o servicio espec\u00edfico dentro de una red privada.</p> <p>Ejemplo de Uso de DNAT:    - Un paquete que llega a la IP p\u00fablica del enrutador con un puerto espec\u00edfico (ej., HTTP en el puerto 80) puede ser redirigido a un servidor web interno con IP 192.168.1.10.</p>"},{"location":"99.-Anexos/07.-Manual%20B%C3%A1sico%20de%20NAT%20e%20IPTABLES/#3-iptables-herramienta-para-configuracion-de-nat","title":"3. IPTABLES: Herramienta para Configuraci\u00f3n de NAT","text":"<p>IPTABLES es una herramienta de firewall en Linux que permite manipular paquetes de red. Tambi\u00e9n se usa para aplicar reglas de NAT.</p>"},{"location":"99.-Anexos/07.-Manual%20B%C3%A1sico%20de%20NAT%20e%20IPTABLES/#principales-tablas-y-cadenas-en-iptables","title":"Principales Tablas y Cadenas en IPTABLES","text":"<ul> <li>Tablas:</li> <li><code>nat</code>: Para la traducci\u00f3n de direcciones (NAT).</li> <li><code>filter</code>: Para filtrado de paquetes.</li> <li> <p><code>mangle</code>: Para modificar campos en los encabezados de los paquetes.</p> </li> <li> <p>Cadenas:</p> </li> <li><code>PREROUTING</code>: Manipula los paquetes antes de que sean enrutados.</li> <li><code>POSTROUTING</code>: Manipula los paquetes despu\u00e9s de que han sido enrutados.</li> <li><code>FORWARD</code>: Controla el tr\u00e1fico que pasa a trav\u00e9s del servidor pero no se origina ni se entrega en \u00e9l.</li> </ul>"},{"location":"99.-Anexos/07.-Manual%20B%C3%A1sico%20de%20NAT%20e%20IPTABLES/#4-configuracion-basica-de-snat-y-dnat-con-iptables","title":"4. Configuraci\u00f3n B\u00e1sica de SNAT y DNAT con IPTABLES","text":""},{"location":"99.-Anexos/07.-Manual%20B%C3%A1sico%20de%20NAT%20e%20IPTABLES/#configuracion-de-snat","title":"Configuraci\u00f3n de SNAT","text":"<p>Para aplicar SNAT y permitir que una red interna acceda a Internet, realizamos los siguientes pasos:</p> <ol> <li>Activar el reenv\u00edo de paquetes (permite al kernel enviar paquetes entre interfaces):</li> </ol> <p><code>bash    sudo sysctl -w net.ipv4.ip_forward=1</code></p> <ol> <li>Configurar SNAT con iptables (para cambiar la IP de origen a la IP de salida del enrutador):</li> </ol> <p><code>bash    sudo iptables -t nat -A POSTROUTING -o eth0 -j SNAT --to-source &lt;IP_P\u00daBLICA&gt;</code></p> <ol> <li>Ejemplo con MASQUERADE: Si tu IP p\u00fablica cambia din\u00e1micamente (IP din\u00e1mica), usa <code>MASQUERADE</code> en lugar de <code>SNAT</code>:</li> </ol> <p><code>bash    sudo iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE</code></p>"},{"location":"99.-Anexos/07.-Manual%20B%C3%A1sico%20de%20NAT%20e%20IPTABLES/#configuracion-de-dnat","title":"Configuraci\u00f3n de DNAT","text":"<p>Para redirigir el tr\u00e1fico que llega a una IP p\u00fablica hacia un servidor en la red interna:</p> <ol> <li>A\u00f1adir una regla DNAT para redirigir el tr\u00e1fico a un servidor interno (por ejemplo, un servidor web en el puerto 80):</li> </ol> <p><code>bash    sudo iptables -t nat -A PREROUTING -p tcp -d &lt;IP_P\u00daBLICA&gt; --dport 80 -j DNAT --to-destination 192.168.1.10:80</code></p>"},{"location":"99.-Anexos/07.-Manual%20B%C3%A1sico%20de%20NAT%20e%20IPTABLES/#5-hacer-persistentes-las-reglas-de-iptables","title":"5. Hacer Persistentes las Reglas de IPTABLES","text":"<p>Para que las reglas de <code>iptables</code> no se pierdan al reiniciar, es recomendable usar <code>iptables-persistent</code>:</p> <ol> <li>Instalar <code>iptables-persistent</code> (disponible en distribuciones como Ubuntu/Debian):</li> </ol> <p><code>bash    sudo apt install iptables-persistent</code></p> <ol> <li>Guardar las reglas actuales:</li> </ol> <p><code>bash    sudo netfilter-persistent save</code></p>"},{"location":"99.-Anexos/07.-Manual%20B%C3%A1sico%20de%20NAT%20e%20IPTABLES/#6-ejemplo-completo-de-configuracion-de-snat-y-dnat","title":"6. Ejemplo Completo de Configuraci\u00f3n de SNAT y DNAT","text":"<p>Imaginemos un escenario en el que:</p> <ul> <li>La IP p\u00fablica del router es <code>203.0.113.5</code>.</li> <li>Una red interna (LAN) utiliza el rango <code>192.168.1.0/24</code>.</li> <li>Hay un servidor web en la LAN con IP <code>192.168.1.10</code> que debe ser accesible desde Internet.</li> </ul>"},{"location":"99.-Anexos/07.-Manual%20B%C3%A1sico%20de%20NAT%20e%20IPTABLES/#configuracion-de-snat-y-dnat","title":"Configuraci\u00f3n de SNAT y DNAT","text":"<pre><code># Configuraci\u00f3n de SNAT\nsudo iptables -t nat -A POSTROUTING -o eth0 -j SNAT --to-source 203.0.113.5\n\n# Configuraci\u00f3n de DNAT\nsudo iptables -t nat -A PREROUTING -p tcp -d 203.0.113.5 --dport 80 -j DNAT --to-destination 192.168.1.10:80\n</code></pre>"},{"location":"99.-Anexos/07.-Manual%20B%C3%A1sico%20de%20NAT%20e%20IPTABLES/#7-resumen-y-consejos","title":"7. Resumen y Consejos","text":"<ul> <li>SNAT: Se usa para cambiar la IP de origen, \u00fatil para que los dispositivos internos accedan a redes externas.</li> <li>DNAT: Se usa para redirigir el tr\u00e1fico que entra a una IP p\u00fablica hacia un dispositivo interno.</li> <li>MASQUERADE: Variante de SNAT que permite NAT en IP din\u00e1micas.</li> <li>Persistencia: Utiliza <code>iptables-persistent</code> o guiones de inicio para mantener las reglas despu\u00e9s de reiniciar.</li> </ul>"},{"location":"99.-Anexos/08.-El%20comando%20sudo/","title":"08.-El comando sudo","text":""},{"location":"99.-Anexos/08.-El%20comando%20sudo/#que-es-sudo","title":"\u00bfQu\u00e9 es <code>sudo</code>?","text":"<p><code>sudo</code> es un comando en sistemas Unix y Linux que permite a los usuarios ejecutar programas con los privilegios de seguridad de otro usuario, por defecto el superusuario (root). Esto es \u00fatil para tareas administrativas, ya que limita el acceso directo al usuario root y permite control de privilegios.</p>"},{"location":"99.-Anexos/08.-El%20comando%20sudo/#advertencia","title":"Advertencia","text":"<p>No todas las distribuciones de Linux incluyen <code>sudo</code> de manera predeterminada. En algunas distribuciones minimalistas o en sistemas reci\u00e9n instalados, es posible que <code>sudo</code> deba instalarse manualmente.</p>"},{"location":"99.-Anexos/08.-El%20comando%20sudo/#instrucciones-de-instalacion","title":"Instrucciones de Instalaci\u00f3n","text":"<p>Dependiendo de la distribuci\u00f3n, puedes instalar <code>sudo</code> ejecutando:</p> <ul> <li>Debian/Ubuntu:</li> </ul> <pre><code>  su -c \"apt install sudo\"\n</code></pre> <ul> <li>CentOS/RHEL:</li> </ul> <pre><code>  su -c \"yum install sudo\"\n</code></pre> <ul> <li>Arch Linux:</li> </ul> <pre><code>  su -c \"pacman -S sudo\"\n</code></pre> <p>Una vez instalado, puedes a\u00f1adir un usuario al grupo <code>sudo</code> (si es necesario) para otorgarle permisos de <code>sudo</code>.</p> <pre><code>usermod -aG sudo &lt;nombre_usuario&gt;\n</code></pre>"},{"location":"99.-Anexos/08.-El%20comando%20sudo/#sintaxis-basica","title":"Sintaxis B\u00e1sica","text":"<pre><code>sudo &lt;comando&gt;\n</code></pre> <p>Por ejemplo, para actualizar el sistema en una distribuci\u00f3n basada en Debian, puedes ejecutar:</p> <pre><code>sudo apt update\n</code></pre> <p>Este comando ejecuta <code>apt update</code> con permisos de superusuario.</p>"},{"location":"99.-Anexos/08.-El%20comando%20sudo/#configuracion-del-comando-sudo","title":"Configuraci\u00f3n del Comando <code>sudo</code>","text":"<ol> <li>Tiempo de Autenticaci\u00f3n</li> </ol> <p>Despu\u00e9s de ingresar la contrase\u00f1a, <code>sudo</code> recordar\u00e1 la autenticaci\u00f3n por un tiempo, generalmente 15 minutos, antes de solicitarla nuevamente. Este tiempo se puede ajustar en la configuraci\u00f3n.</p> <ol> <li>Archivo de Configuraci\u00f3n: <code>/etc/sudoers</code></li> </ol> <p>Las reglas y permisos de <code>sudo</code> se configuran en el archivo <code>/etc/sudoers</code>. Este archivo define qui\u00e9n puede usar <code>sudo</code> y con qu\u00e9 permisos. No se debe editar directamente, sino mediante el comando <code>visudo</code>, que asegura la integridad de la sintaxis.</p>"},{"location":"99.-Anexos/08.-El%20comando%20sudo/#opciones-utiles","title":"Opciones \u00datiles","text":"<ol> <li><code>-u</code>: Especifica el usuario con el cual ejecutar el comando.</li> </ol> <pre><code>   sudo -u &lt;usuario&gt; &lt;comando&gt;\n</code></pre> <p>Ejemplo:</p> <pre><code>   sudo -u postgres psql\n</code></pre> <p>Este comando ejecuta <code>psql</code> como el usuario <code>postgres</code>.</p> <ol> <li><code>-k</code>: Invalida el tiempo de autenticaci\u00f3n. \u00datil si deseas que <code>sudo</code> solicite la contrase\u00f1a nuevamente.</li> </ol> <pre><code>   sudo -k\n</code></pre> <ol> <li><code>-l</code>: Lista los permisos de <code>sudo</code> del usuario actual.</li> </ol> <pre><code>   sudo -l\n</code></pre> <ol> <li><code>-b</code>: Ejecuta el comando en segundo plano.</li> </ol> <pre><code>   sudo -b &lt;comando&gt;\n</code></pre> <ol> <li><code>--</code>: Indica el final de las opciones de <code>sudo</code> para evitar conflictos con el comando que se ejecutar\u00e1.</li> </ol> <pre><code>   sudo -- ls --color=auto\n</code></pre>"},{"location":"99.-Anexos/08.-El%20comando%20sudo/#visudo","title":"Visudo","text":"<p><code>visudo</code> es una herramienta en sistemas Unix/Linux dise\u00f1ada espec\u00edficamente para editar el archivo de configuraci\u00f3n de <code>sudo</code>, que define los permisos de los usuarios para ejecutar comandos con privilegios elevados. La principal ventaja de <code>visudo</code> es que previene errores de sintaxis y bloquea el archivo mientras est\u00e1 siendo editado, lo que es fundamental para mantener la integridad del sistema y evitar problemas de acceso.</p>"},{"location":"99.-Anexos/08.-El%20comando%20sudo/#caracteristicas-clave-de-visudo","title":"Caracter\u00edsticas Clave de <code>visudo</code>","text":"<ol> <li>Verificaci\u00f3n de Sintaxis:<ul> <li><code>visudo</code> comprueba autom\u00e1ticamente la sintaxis del archivo <code>/etc/sudoers</code> (o cualquier archivo que se edite con <code>visudo</code>) antes de guardar los cambios.</li> <li>Si se detecta un error de sintaxis, <code>visudo</code> muestra un mensaje de error y no permite guardar el archivo hasta que el error se corrija. Esto evita problemas graves, como quedar bloqueado sin acceso a <code>sudo</code>.</li> </ul> </li> <li>Bloqueo del Archivo:<ul> <li>Cuando <code>visudo</code> est\u00e1 en uso, bloquea el archivo <code>/etc/sudoers</code> para que no pueda ser editado por otro proceso o usuario simult\u00e1neamente. Esto asegura que no se generen conflictos de edici\u00f3n.</li> </ul> </li> <li>Edici\u00f3n Segura:<ul> <li><code>visudo</code> permite especificar un archivo alternativo para editar, lo cual es \u00fatil para agregar archivos en el directorio <code>/etc/sudoers.d</code> o para editar archivos de prueba. Por ejemplo:</li> </ul> </li> </ol> <pre><code>    $ sudo visudo -f /etc/sudoers.d/usuario_especifico\n</code></pre>"},{"location":"99.-Anexos/08.-El%20comando%20sudo/#como-usar-visudo","title":"C\u00f3mo usar <code>visudo</code>","text":""},{"location":"99.-Anexos/08.-El%20comando%20sudo/#abrir-el-archivo-etcsudoers","title":"Abrir el Archivo <code>/etc/sudoers</code>:","text":"<pre><code>- Ejecuta `visudo` como superusuario:\n</code></pre> <pre><code>    $ sudo visudo\n</code></pre> <ul> <li>Esto abrir\u00e1 el archivo <code>/etc/sudoers</code> en el editor de texto predeterminado (normalmente <code>vi</code> o <code>nano</code> en algunas distribuciones).</li> </ul>"},{"location":"99.-Anexos/08.-El%20comando%20sudo/#editar-el-archivo","title":"Editar el Archivo:","text":"<p>Puedes agregar reglas o permisos en el archivo, como la siguiente l\u00ednea que permite a un usuario llamado <code>gigante</code> ejecutar cualquier comando con <code>sudo</code>:</p> <pre><code>gigante ALL=(ALL) ALL\n</code></pre> <p>Tambi\u00e9n es com\u00fan a\u00f1adir configuraciones para grupos. Por ejemplo, para permitir que todos los usuarios en el grupo <code>sudo</code> tengan acceso completo:</p> <pre><code>sudo ALL=(ALL) ALL\n</code></pre>"},{"location":"99.-Anexos/08.-El%20comando%20sudo/#usar-visudo-con-archivos-en-etcsudoersd","title":"Usar <code>visudo</code> con Archivos en <code>/etc/sudoers.d</code>:","text":"<ul> <li>Para agregar configuraciones espec\u00edficas sin modificar el archivo principal <code>/etc/sudoers</code>, utiliza <code>visudo -f</code> para crear y editar archivos en <code>/etc/sudoers.d</code>.</li> </ul> <pre><code>sudo visudo -f /etc/sudoers.d/gigante\n</code></pre> <p>Esto permite que el usuario <code>gigante</code> ejecute <code>systemctl</code> y <code>reboot</code> sin necesidad de ingresar su contrase\u00f1a.</p>"},{"location":"99.-Anexos/08.-El%20comando%20sudo/#ejemplo-de-configuracion-con-visudo","title":"Ejemplo de Configuraci\u00f3n con <code>visudo</code>","text":"<p>Supongamos que quieres permitir que el usuario <code>gigante</code> ejecute comandos espec\u00edficos sin tener que ingresar su contrase\u00f1a. Con <code>visudo</code>, a\u00f1adir\u00edas en <code>/etc/sudoers</code> o en un archivo dentro de <code>/etc/sudoers.d</code>:</p> <pre><code>gigante ALL=(ALL) NOPASSWD: /usr/bin/systemctl, /usr/bin/reboot\n</code></pre> <p>Esto permite que el usuario <code>gigante</code> ejecute <code>systemctl</code> y <code>reboot</code> sin necesidad de ingresar su contrase\u00f1a.</p>"},{"location":"99.-Anexos/08.-El%20comando%20sudo/#buenas-practicas-con-visudo","title":"Buenas Pr\u00e1cticas con <code>visudo</code>","text":"<ul> <li>Siempre usa <code>visudo</code> para editar <code>sudoers</code>: Esto evita errores cr\u00edticos de configuraci\u00f3n.</li> <li>Limita el acceso a <code>sudo</code>: Otorga permisos m\u00ednimos necesarios para cada usuario o grupo, usando la opci\u00f3n <code>NOPASSWD</code> solo si es absolutamente necesario.</li> <li>Utiliza el directorio <code>/etc/sudoers.d</code>: Mantener configuraciones en archivos separados ayuda a la organizaci\u00f3n y a reducir errores en entornos con varios usuarios.</li> </ul>"},{"location":"99.-Anexos/08.-El%20comando%20sudo/#visudo-es-esencial-para-una-administracion-segura-y-estable-del-sistema-asegurando-que-los-permisos-de-sudo-se-configuren-correctamente-sin-errores-de-sintaxis-ni-conflictos","title":"<code>visudo</code> es esencial para una administraci\u00f3n segura y estable del sistema, asegurando que los permisos de <code>sudo</code> se configuren correctamente sin errores de sintaxis ni conflictos.","text":""},{"location":"99.-Anexos/08.-El%20comando%20sudo/#ejemplos-comunes-de-uso-de-sudo","title":"Ejemplos Comunes de uso de <code>sudo</code>","text":"<ol> <li>Actualizar y Mejorar el Sistema</li> </ol> <pre><code>   sudo apt update &amp;&amp; sudo apt upgrade\n</code></pre> <ol> <li>Editar un Archivo de Sistema</li> </ol> <pre><code>   sudo nano /etc/hosts\n</code></pre> <ol> <li>Reiniciar el Sistema</li> </ol> <pre><code>   sudo reboot\n</code></pre>"},{"location":"99.-Anexos/08.-El%20comando%20sudo/#seguridad-y-buenas-practicas","title":"Seguridad y Buenas Pr\u00e1cticas","text":"<ul> <li>M\u00ednimo Privilegio: Usa <code>sudo</code> solo cuando sea necesario. Ejecutar comandos con permisos de root puede ser peligroso.</li> <li>Visudo para Cambios: Edita <code>/etc/sudoers</code> solo con <code>visudo</code>.</li> <li>Auditor\u00eda: Las actividades de <code>sudo</code> pueden ser monitoreadas en los archivos de registro del sistema.</li> </ul>"},{"location":"99.-Anexos/08.-El%20comando%20sudo/#resumen","title":"Resumen","text":"<ul> <li><code>sudo</code> permite ejecutar comandos con privilegios elevados.</li> <li>Usa <code>visudo</code> para configurar los permisos de forma segura.</li> <li>Opciones como <code>-u</code>, <code>-k</code>, y <code>-b</code> permiten flexibilidad en su uso.</li> </ul> <p>Este comando es esencial para la administraci\u00f3n segura y controlada en sistemas Linux y Unix.</p>"},{"location":"99.-Anexos/09.-Conversor%20de%20OVA%20a%20QCOW2/","title":"09.-Conversor de OVA a QCOW2","text":"<p>Este documento describe el proceso para convertir una m\u00e1quina virtual en formato <code>.ova</code> a <code>.qcow2</code>, e incluye los pasos para iniciar la m\u00e1quina convertida en KVM/QEMU.</p>"},{"location":"99.-Anexos/09.-Conversor%20de%20OVA%20a%20QCOW2/#requisitos-previos","title":"Requisitos Previos","text":"<p>Es necesario tener <code>qemu-img</code> y <code>virt-manager</code> o <code>virsh</code> instalados para la conversi\u00f3n y puesta en marcha de la VM. En distribuciones Debian/Ubuntu puedes instalarlos con:</p> <pre><code>sudo apt update\nsudo apt install qemu-utils libvirt-daemon-system virt-manager\n</code></pre>"},{"location":"99.-Anexos/09.-Conversor%20de%20OVA%20a%20QCOW2/#pasos-para-la-conversion-manual","title":"Pasos para la Conversi\u00f3n Manual","text":"<ol> <li> <p>Extrae el archivo <code>.ova</code>:     Utiliza <code>tar</code> para descomprimir el archivo <code>.ova</code>, que suele contener archivos <code>.vmdk</code>.     <code>bash     tar -xvf archivo.ova</code></p> </li> <li> <p>Convierte el archivo <code>.vmdk</code> a <code>.qcow2</code>:     Utiliza <code>qemu-img</code> para convertir el archivo <code>.vmdk</code> extra\u00eddo al formato <code>.qcow2</code>.     <code>bash     qemu-img convert -f vmdk archivo.vmdk -O qcow2 archivo.qcow2</code></p> </li> <li> <p>Verifica la conversi\u00f3n:     <code>bash     qemu-img info archivo.qcow2</code></p> </li> </ol>"},{"location":"99.-Anexos/09.-Conversor%20de%20OVA%20a%20QCOW2/#script-en-bash-para-automatizar-la-conversion","title":"Script en Bash para automatizar la conversi\u00f3n","text":"<p>El siguiente script en Bash automatiza la conversi\u00f3n de <code>.ova</code> a <code>.qcow2</code>.</p> <pre><code>#!/bin/bash\n\n# Verifica que se haya proporcionado un archivo OVA como argumento\nif [ \"$#\" -ne 1 ]; then\n    echo \"Uso: $0 archivo.ova\"\n    exit 1\nfi\n\nOVA_FILE=$1\nBASE_NAME=$(basename \"$OVA_FILE\" .ova)\nTARGET_DIR=\"${BASE_NAME}_extracted\"\nQCOW2_FILE=\"${BASE_NAME}.qcow2\"\n\n# Verifica que el archivo OVA existe\nif [ ! -f \"$OVA_FILE\" ]; then\n    echo \"Error: el archivo $OVA_FILE no existe.\"\n    exit 1\nfi\n\n# Crea un directorio temporal para extraer los archivos\nmkdir -p \"$TARGET_DIR\"\necho \"Extrayendo $OVA_FILE a $TARGET_DIR...\"\ntar -xvf \"$OVA_FILE\" -C \"$TARGET_DIR\"\n\n# Encuentra el archivo .vmdk en el directorio extra\u00eddo\nVMDK_FILE=$(find \"$TARGET_DIR\" -name \"*.vmdk\" | head -n 1)\n\n# Verifica que se haya encontrado un archivo VMDK\nif [ -z \"$VMDK_FILE\" ]; then\n    echo \"Error: no se encontr\u00f3 un archivo .vmdk en $OVA_FILE.\"\n    exit 1\nfi\n\n# Convierte el archivo VMDK a QCOW2\necho \"Convirtiendo $VMDK_FILE a $QCOW2_FILE...\"\nqemu-img convert -f vmdk \"$VMDK_FILE\" -O qcow2 \"$QCOW2_FILE\"\n\n# Verifica que la conversi\u00f3n fue exitosa\nif [ $? -eq 0 ]; then\n    echo \"Conversi\u00f3n exitosa. El archivo QCOW2 se encuentra en $QCOW2_FILE.\"\nelse\n    echo \"Error: la conversi\u00f3n fall\u00f3.\"\n    exit 1\nfi\n\n# Limpia el directorio temporal\necho \"Limpiando archivos temporales...\"\nrm -rf \"$TARGET_DIR\"\n\necho \"Proceso completado.\"\n</code></pre>"},{"location":"99.-Anexos/09.-Conversor%20de%20OVA%20a%20QCOW2/#instrucciones","title":"Instrucciones","text":"<ol> <li>Guardar el script como <code>ova2qcow2.sh</code>.</li> <li>Hacer el script ejecutable:</li> </ol> <pre><code>    $ chmod +x ova2qcow2.sh\n</code></pre> <ol> <li>Ejecutar el script pasando como argumento el archivo <code>.ova</code>:     <code>bash     $ ./ova2qcow2.sh archivo.ova</code></li> </ol>"},{"location":"99.-Anexos/09.-Conversor%20de%20OVA%20a%20QCOW2/#configuracion-de-la-maquina-virtual-en-kvmqemu","title":"Configuraci\u00f3n de la M\u00e1quina Virtual en KVM/QEMU","text":"<p>Una vez convertido el archivo <code>.qcow2</code>, es necesario crear una nueva VM en KVM/QEMU que use el disco <code>.qcow2</code> resultante. Se puede hacer con <code>virt-manager</code> o con <code>virsh</code> desde la l\u00ednea de comandos.</p>"},{"location":"99.-Anexos/09.-Conversor%20de%20OVA%20a%20QCOW2/#usando-virt-manager","title":"Usando Virt-Manager","text":"<ol> <li>Abrir <code>virt-manager</code>.</li> <li>Crear una nueva m\u00e1quina virtual y selecciona la opci\u00f3n Importar imagen de disco existente.</li> <li>Seleccionar el archivo <code>.qcow2</code> generado.</li> <li>Asignar la cantidad de CPU, RAM y otras configuraciones de hardware seg\u00fan tus necesidades.</li> <li>Completar el asistente y comienza la m\u00e1quina virtual.</li> </ol>"},{"location":"99.-Anexos/09.-Conversor%20de%20OVA%20a%20QCOW2/#usando-virsh","title":"Usando Virsh","text":"<p>Alternativamente, puedes usar <code>virsh</code> para definir la m\u00e1quina virtual:</p> <pre><code># Definir la VM usando virsh\nsudo virt-install \\  \n\u00a0--name MV01 \\  \n\u00a0--ram 2048 \\  \n\u00a0--vcpus 2 \\  \n\u00a0--disk path=/var/lib/libvirt/images/MV01.qcow2,format=qcow2 \\  \n\u00a0--import \\  \n\u00a0--os-variant generic \\  \n\u00a0--network network=default \\  \n\u00a0--graphics spice \\  \n\u00a0--console pty,target_type=serial\n</code></pre> <p>Este comando crea y lanza una m\u00e1quina virtual utilizando el archivo <code>.qcow2</code>.</p> <ul> <li><code>--name</code>: Nombre de la VM.</li> <li><code>--memory</code>: Cantidad de memoria en MB.</li> <li><code>--vcpus</code>: N\u00famero de CPUs.</li> <li><code>--disk</code>: Ruta del archivo <code>.qcow2</code> y su formato.</li> <li><code>--import</code>: Indica que importamos una m\u00e1quina</li> <li><code>--os-variant</code>: Indica el sistema operativo que contiene la m\u00e1quina. En caso de desconocer <code>generic</code>.</li> <li><code>--network</code>: Configuraci\u00f3n de red, por ejemplo, <code>network=default</code> para una red NAT.</li> <li><code>--graphics</code>: Configura la conexi\u00f3n gr\u00e1fica; <code>spice</code> \u00f3 <code>vnc</code> para acceder remotamente.</li> </ul>"},{"location":"99.-Anexos/09.-Conversor%20de%20OVA%20a%20QCOW2/#explicacion-del-proceso","title":"Explicaci\u00f3n del Proceso","text":"<ul> <li>Conversi\u00f3n: El script convierte el archivo <code>.vmdk</code> en <code>.qcow2</code> autom\u00e1ticamente.</li> <li>Importaci\u00f3n en KVM: Puedes iniciar la VM utilizando <code>virt-manager</code> o <code>virsh</code> para aprovechar el formato <code>.qcow2</code> en un entorno KVM/QEMU.</li> </ul>"},{"location":"99.-Anexos/10.-Portabilizar%20M%C3%A1quinas%20Virtuales%20con%20KVM%20usando%20un%20Disco%20USB/","title":"10.-Portabilizar M\u00e1quinas Virtuales con KVM usando un Disco USB","text":"<p>Este manual describe el proceso para configurar y utilizar m\u00e1quinas virtuales almacenadas en un disco USB externo, permitiendo su uso en diferentes equipos con KVM/QEMU instalado. El objetivo es automatizar la detecci\u00f3n y montaje del disco USB, facilitando el acceso a las m\u00e1quinas virtuales en cualquier entorno.</p>"},{"location":"99.-Anexos/10.-Portabilizar%20M%C3%A1quinas%20Virtuales%20con%20KVM%20usando%20un%20Disco%20USB/#objetivo","title":"Objetivo","text":"<ul> <li>Almacenar las m\u00e1quinas virtuales en un disco USB externo.</li> <li>Permitir el uso de las m\u00e1quinas virtuales en diferentes equipos (por ejemplo, casa y trabajo).</li> <li>Automatizar el proceso de detecci\u00f3n y montaje del disco USB al conectarlo.</li> </ul>"},{"location":"99.-Anexos/10.-Portabilizar%20M%C3%A1quinas%20Virtuales%20con%20KVM%20usando%20un%20Disco%20USB/#pasos-realizados","title":"Pasos Realizados","text":""},{"location":"99.-Anexos/10.-Portabilizar%20M%C3%A1quinas%20Virtuales%20con%20KVM%20usando%20un%20Disco%20USB/#1-copiar-los-directorios-de-maquinas-virtuales-al-disco-usb","title":"1. Copiar los Directorios de M\u00e1quinas Virtuales al Disco USB","text":"<p>Copia los siguientes directorios al disco USB:</p> <ul> <li>Im\u00e1genes de las m\u00e1quinas virtuales:</li> </ul> <p><code>/var/lib/libvirt/images</code></p> <ul> <li>Archivos de configuraci\u00f3n de las m\u00e1quinas virtuales:</li> </ul> <p><code>/etc/libvirt/qemu</code></p>"},{"location":"99.-Anexos/10.-Portabilizar%20M%C3%A1quinas%20Virtuales%20con%20KVM%20usando%20un%20Disco%20USB/#2-etiquetar-la-particion-del-disco-usb","title":"2. Etiquetar la Partici\u00f3n del Disco USB","text":"<p>Para identificar f\u00e1cilmente la partici\u00f3n del disco USB en los diferentes sistemas, es necesario etiquetarla.</p>"},{"location":"99.-Anexos/10.-Portabilizar%20M%C3%A1quinas%20Virtuales%20con%20KVM%20usando%20un%20Disco%20USB/#paso-21-identificar-la-particion","title":"Paso 2.1: Identificar la Partici\u00f3n","text":"<p>Usa <code>lsblk -f</code> para listar las particiones y sistemas de archivos:</p> <pre><code>lsblk -f\n</code></pre> <p>Busca la partici\u00f3n correspondiente al disco USB (en este ejemplo, es <code>/dev/sdb4</code>).</p>"},{"location":"99.-Anexos/10.-Portabilizar%20M%C3%A1quinas%20Virtuales%20con%20KVM%20usando%20un%20Disco%20USB/#paso-22-etiquetar-la-particion","title":"Paso 2.2: Etiquetar la Partici\u00f3n","text":"<p>Como la partici\u00f3n es de tipo NTFS, utiliza <code>ntfslabel</code> para etiquetarla. En este caso, la etiqueta ser\u00e1 <code>mvusb</code> (de m\u00e1quinas virtuales en usb).</p> <pre><code>sudo ntfslabel /dev/sdb4 mvusb\n</code></pre>"},{"location":"99.-Anexos/10.-Portabilizar%20M%C3%A1quinas%20Virtuales%20con%20KVM%20usando%20un%20Disco%20USB/#paso-23-verificar-la-etiqueta","title":"Paso 2.3: Verificar la Etiqueta","text":"<p>Confirma que la etiqueta se aplic\u00f3 correctamente:</p> <pre><code>lsblk -f\n</code></pre> <p>Deber\u00edas ver la etiqueta <code>mvusb</code> asociada a la partici\u00f3n correspondiente.</p>"},{"location":"99.-Anexos/10.-Portabilizar%20M%C3%A1quinas%20Virtuales%20con%20KVM%20usando%20un%20Disco%20USB/#3-crear-un-script-para-detectar-y-montar-automaticamente-el-disco-usb","title":"3. Crear un Script para Detectar y Montar Autom\u00e1ticamente el Disco USB","text":"<p>El script permitir\u00e1 montar el disco USB autom\u00e1ticamente en una ruta espec\u00edfica al conectarlo.</p>"},{"location":"99.-Anexos/10.-Portabilizar%20M%C3%A1quinas%20Virtuales%20con%20KVM%20usando%20un%20Disco%20USB/#paso-31-crear-el-script","title":"Paso 3.1: Crear el Script","text":"<p>Crea un archivo llamado <code>montamvusb.sh</code> y a\u00f1ade el siguiente contenido:</p> <pre><code>#!/bin/bash\n\n# Variables de configuraci\u00f3n\nMOUNT_POINT=\"/mnt/mvusb\"\nDISK_LABEL=\"mvusb\"\n\n# Paso 1: Identificar el disco y partici\u00f3n usando lsblk en modo raw y sin encabezado\nDEVICE=$(lsblk -nr -o NAME,LABEL | grep -w \"$DISK_LABEL\" | awk '{print \"/dev/\"$1}')\n\nif [ -z \"$DEVICE\" ]; then\n    echo \"El disco con la etiqueta '$DISK_LABEL' no est\u00e1 conectado.\"\n    exit 1\nfi\n\n# (Opcional) Mostrar el dispositivo detectado para depuraci\u00f3n\necho \"Dispositivo detectado: $DEVICE\"\n\n# Paso 2: Crear el punto de montaje si no existe\nif [ ! -d \"$MOUNT_POINT\" ]; then\n    sudo mkdir -p \"$MOUNT_POINT\"\nfi\n\n# Paso 3: Montar el dispositivo en el punto de montaje\nsudo mount \"$DEVICE\" \"$MOUNT_POINT\"\n\n# Verificaci\u00f3n de montaje\nif mountpoint -q \"$MOUNT_POINT\"; then\n    echo \"Disco montado en $MOUNT_POINT\"\nelse\n    echo \"Error al montar el disco.\"\n    exit 1\nfi\n\n# Paso 4: Confirmar y listar el contenido\necho \"Contenido del disco USB:\"\nls \"$MOUNT_POINT\"\n</code></pre>"},{"location":"99.-Anexos/10.-Portabilizar%20M%C3%A1quinas%20Virtuales%20con%20KVM%20usando%20un%20Disco%20USB/#paso-32-dar-permisos-de-ejecucion-al-script","title":"Paso 3.2: Dar Permisos de Ejecuci\u00f3n al Script","text":"<pre><code>chmod +x montamvusb.sh\n</code></pre>"},{"location":"99.-Anexos/10.-Portabilizar%20M%C3%A1quinas%20Virtuales%20con%20KVM%20usando%20un%20Disco%20USB/#paso-33-explicacion-del-script","title":"Paso 3.3: Explicaci\u00f3n del Script","text":"<ul> <li>Variables de Configuraci\u00f3n:</li> <li><code>MOUNT_POINT</code>: Punto de montaje donde se montar\u00e1 el disco USB (<code>/mnt/mvusb</code>).</li> <li> <p><code>DISK_LABEL</code>: Etiqueta asignada a la partici\u00f3n del disco USB (<code>mvusb</code>).</p> </li> <li> <p>Identificaci\u00f3n del Dispositivo:</p> </li> <li>Utiliza <code>lsblk -nr -o NAME,LABEL</code> para listar dispositivos sin formato y sin encabezado.</li> <li><code>grep -w \"$DISK_LABEL\"</code> busca la etiqueta exacta.</li> <li> <p><code>awk '{print \"/dev/\"$1}'</code> obtiene la ruta del dispositivo.</p> </li> <li> <p>Montaje del Dispositivo:</p> </li> <li>Crea el punto de montaje si no existe.</li> <li>Monta el dispositivo en el punto de montaje especificado.</li> <li> <p>Verifica que el montaje fue exitoso.</p> </li> <li> <p>Confirmaci\u00f3n y Listado del Contenido:</p> </li> <li>Muestra el contenido del disco USB.</li> </ul>"},{"location":"99.-Anexos/10.-Portabilizar%20M%C3%A1quinas%20Virtuales%20con%20KVM%20usando%20un%20Disco%20USB/#4-ejecutar-el-script-y-verificar-el-montaje","title":"4. Ejecutar el Script y Verificar el Montaje","text":"<p>Ejecuta el script:</p> <pre><code>./montamvusb.sh\n</code></pre> <p>Deber\u00edas obtener una salida similar:</p> <pre><code>Dispositivo detectado: /dev/sdb4\nDisco montado en /mnt/mvusb\nContenido del disco USB:\n...\n</code></pre>"},{"location":"99.-Anexos/10.-Portabilizar%20M%C3%A1quinas%20Virtuales%20con%20KVM%20usando%20un%20Disco%20USB/#5-ajustar-las-rutas-en-los-archivos-de-configuracion-de-las-maquinas-virtuales","title":"5. Ajustar las Rutas en los Archivos de Configuraci\u00f3n de las M\u00e1quinas Virtuales","text":"<p>Para que las m\u00e1quinas virtuales puedan utilizar las im\u00e1genes desde el disco USB, es necesario ajustar las rutas en sus archivos de configuraci\u00f3n.</p>"},{"location":"99.-Anexos/10.-Portabilizar%20M%C3%A1quinas%20Virtuales%20con%20KVM%20usando%20un%20Disco%20USB/#paso-51-editar-los-archivos-xml-de-las-maquinas-virtuales","title":"Paso 5.1: Editar los Archivos XML de las M\u00e1quinas Virtuales","text":"<p>Para cada m\u00e1quina virtual, edita su archivo de configuraci\u00f3n XML:</p> <pre><code>sudo nano /etc/libvirt/qemu/mi_maquina_virtual.xml\n</code></pre>"},{"location":"99.-Anexos/10.-Portabilizar%20M%C3%A1quinas%20Virtuales%20con%20KVM%20usando%20un%20Disco%20USB/#paso-52-modificar-las-rutas-de-las-imagenes","title":"Paso 5.2: Modificar las Rutas de las Im\u00e1genes","text":"<p>Busca la secci\u00f3n <code>&lt;disk&gt;</code> y actualiza la ruta de la imagen al nuevo punto de montaje:</p> <pre><code>&lt;disk type='file' device='disk'&gt;\n   &lt;driver name='qemu' type='qcow2'/&gt;\n   &lt;source file='/mnt/mvusb/images/mi_imagen.qcow2'/&gt;\n   &lt;target dev='vda' bus='virtio'/&gt;\n&lt;/disk&gt;\n</code></pre>"},{"location":"99.-Anexos/10.-Portabilizar%20M%C3%A1quinas%20Virtuales%20con%20KVM%20usando%20un%20Disco%20USB/#paso-53-repetir-para-cada-maquina-virtual","title":"Paso 5.3: Repetir para Cada M\u00e1quina Virtual","text":"<p>Aseg\u00farate de actualizar las rutas en todos los archivos de configuraci\u00f3n correspondientes.</p>"},{"location":"99.-Anexos/10.-Portabilizar%20M%C3%A1quinas%20Virtuales%20con%20KVM%20usando%20un%20Disco%20USB/#paso-54-automatizacion-del-ajuste-de-rutas-en-los-archivos-xml","title":"Paso 5.4: Automatizaci\u00f3n del Ajuste de Rutas en los Archivos XML","text":"<p>Para automatizar el ajuste de las rutas en los archivos XML de las m\u00e1quinas virtuales, puedes utilizar el siguiente script en Bash. Este script recorre todos los archivos XML en el directorio <code>/mnt/mvusb/mv/xml</code> y actualiza la ruta de las im\u00e1genes de las m\u00e1quinas virtuales para que apunten a <code>/mnt/mvusb/mv/images</code>. Luego, define las m\u00e1quinas virtuales en <code>libvirt</code>.</p> <p>Guarda el script como <code>actualiza_rutas.sh</code>:</p> <pre><code>#!/bin/bash\n\n# Definici\u00f3n de rutas\nMOUNT_POINT=\"/mnt/mvusb\"\nIMAGES_DIR=\"$MOUNT_POINT/mv/images\"\nXML_DIR=\"$MOUNT_POINT/mv/xml\"\n\n# Verificar que el disco est\u00e9 montado en el punto de montaje\nif ! mountpoint -q \"$MOUNT_POINT\"; then\n    echo \"Error: El disco no est\u00e1 montado en $MOUNT_POINT.\"\n    exit 1\nfi\n\n# Verificar que existan los directorios de im\u00e1genes y XML\nif [ ! -d \"$IMAGES_DIR\" ]; then\n    echo \"Error: El directorio de im\u00e1genes $IMAGES_DIR no existe.\"\n    exit 1\nfi\n\nif [ ! -d \"$XML_DIR\" ]; then\n    echo \"Error: El directorio de XML $XML_DIR no existe.\"\n    exit 1\nfi\n\n# Actualizar las rutas en cada archivo XML y definir la m\u00e1quina virtual\nfor xml_file in \"$XML_DIR\"/*.xml; do\n    echo \"Procesando archivo XML: $xml_file\"\n\n    # Modificaci\u00f3n de sed para capturar tanto comillas simples como dobles\n    IMAGE_PATH=$(sed -n \"s/.*&lt;source file=['\\\"]\\([^'\\\"]*\\)['\\\"].*/\\1/p\" \"$xml_file\")\n    echo \"Ruta extra\u00edda por sed: $IMAGE_PATH\"  # Depuraci\u00f3n adicional\n\n    IMAGE_NAME=$(basename \"$IMAGE_PATH\")\n\n    if [ -z \"$IMAGE_NAME\" ]; then\n        echo \"Error: No se pudo encontrar la ruta de la imagen en $xml_file.\"\n        continue\n    fi\n\n    # Definir la nueva ruta completa de la imagen\n    NEW_IMAGE_PATH=\"$IMAGES_DIR/$IMAGE_NAME\"\n\n    # Verificar si la imagen existe en el nuevo directorio de im\u00e1genes\n    if [ ! -f \"$NEW_IMAGE_PATH\" ]; then\n        echo \"Advertencia: La imagen $NEW_IMAGE_PATH no existe. Aseg\u00farate de que todas las im\u00e1genes est\u00e9n en $IMAGES_DIR.\"\n        continue\n    fi\n\n    # Reemplazar la ruta en el archivo XML\n    sed -i \"s|&lt;source file=['\\\"][^'\\\"]*['\\\"]|&lt;source file=\\\"$NEW_IMAGE_PATH\\\"|g\" \"$xml_file\"\n\n    echo \"Ruta de imagen actualizada a: $NEW_IMAGE_PATH en $xml_file\"\n\n    # Definir la m\u00e1quina virtual en libvirt\n    sudo virsh define \"$xml_file\"\ndone\n\necho \"Actualizaci\u00f3n de rutas completada y m\u00e1quinas virtuales definidas.\"\n</code></pre>"},{"location":"99.-Anexos/10.-Portabilizar%20M%C3%A1quinas%20Virtuales%20con%20KVM%20usando%20un%20Disco%20USB/#explicacion-del-script","title":"Explicaci\u00f3n del Script","text":"<p>Este script automatiza el proceso de portabilizaci\u00f3n de m\u00e1quinas virtuales en KVM/QEMU almacenadas en un disco USB externo. Su prop\u00f3sito es facilitar el uso de las m\u00e1quinas virtuales en diferentes sistemas que compartan el mismo entorno, actualizando autom\u00e1ticamente las rutas de las im\u00e1genes de disco para que apunten al directorio en el disco USB.</p>"},{"location":"99.-Anexos/10.-Portabilizar%20M%C3%A1quinas%20Virtuales%20con%20KVM%20usando%20un%20Disco%20USB/#descripcion-general-del-script","title":"Descripci\u00f3n General del Script:","text":"<ol> <li> <p>Definici\u00f3n de Directorios: Configura las rutas de montaje (<code>/mnt/mvusb</code>), el directorio de im\u00e1genes (<code>/mnt/mvusb/mv/images</code>) y el directorio de archivos XML (<code>/mnt/mvusb/mv/xml</code>).</p> </li> <li> <p>Verificaci\u00f3n del Entorno: Asegura que el disco USB est\u00e9 montado y que existan los directorios de im\u00e1genes y XML.</p> </li> <li> <p>Procesamiento de Archivos XML:</p> <ul> <li>Para cada archivo XML de m\u00e1quina virtual, identifica la ruta actual de la imagen.</li> <li>Actualiza la ruta de la imagen dentro del XML para que apunte a la nueva ubicaci\u00f3n en el disco USB.</li> </ul> </li> <li> <p>Definici\u00f3n en <code>libvirt</code>: Una vez modificados, los archivos XML se utilizan para registrar cada m\u00e1quina virtual en <code>libvirt</code> en el sistema actual, permitiendo que las VMs sean reconocidas y ejecutadas en el entorno KVM/QEMU.</p> </li> <li> <p>Advertencias y Errores:</p> <ul> <li>Genera advertencias si alguna imagen no se encuentra en el directorio de im\u00e1genes esperado.</li> <li>Se\u00f1ala errores si no se pueden modificar archivos XML debido a permisos o si faltan rutas de imagen.</li> </ul> </li> </ol> <p>Este script es \u00fatil para simplificar la portabilidad y accesibilidad de entornos virtualizados en distintos equipos, asegurando que las m\u00e1quinas virtuales puedan ser utilizadas sin necesidad de ajustes manuales adicionales en cada sistema.</p>"},{"location":"99.-Anexos/10.-Portabilizar%20M%C3%A1quinas%20Virtuales%20con%20KVM%20usando%20un%20Disco%20USB/#uso-del-script","title":"Uso del Script","text":"<ol> <li>Haz el script ejecutable:</li> </ol> <p><code>bash    chmod +x actualiza_rutas.sh</code></p> <ol> <li>Ejecuta el script:</li> </ol> <p><code>bash    ./actualiza_rutas.sh</code></p> <p>Este script automatiza el proceso de ajuste de rutas en los archivos XML y define autom\u00e1ticamente las m\u00e1quinas en <code>libvirt</code>, completando el proceso de configuraci\u00f3n.</p>"},{"location":"99.-Anexos/10.-Portabilizar%20M%C3%A1quinas%20Virtuales%20con%20KVM%20usando%20un%20Disco%20USB/#6-importar-las-maquinas-virtuales-en-ambos-sistemas","title":"6. Importar las M\u00e1quinas Virtuales en Ambos Sistemas","text":"<p>Si las m\u00e1quinas virtuales no aparecen en la lista de <code>virsh</code>, def\u00ednelas utilizando los archivos XML actualizados:</p> <pre><code>sudo virsh define /mnt/mv/xml/mi_maquina_virtual.xml\n</code></pre> <p>Esto registra la m\u00e1quina virtual en <code>libvirt</code> para que pueda ser administrada.</p>"},{"location":"99.-Anexos/10.-Portabilizar%20M%C3%A1quinas%20Virtuales%20con%20KVM%20usando%20un%20Disco%20USB/#7-automatizar-la-ejecucion-del-script-al-conectar-el-disco-usb-opcional","title":"7. Automatizar la Ejecuci\u00f3n del Script al Conectar el Disco USB (Opcional)","text":"<p>Para automatizar el proceso de montaje al conectar el disco, puedes utilizar <code>udev</code>.</p>"},{"location":"99.-Anexos/10.-Portabilizar%20M%C3%A1quinas%20Virtuales%20con%20KVM%20usando%20un%20Disco%20USB/#paso-71-crear-una-regla-de-udev","title":"Paso 7.1: Crear una Regla de udev","text":"<p>Crea un archivo de reglas en <code>/etc/udev/rules.d/99-mvusb.rules</code>:</p> <pre><code>SUBSYSTEM==\"block\", KERNEL==\"sd*\", ENV{ID_FS_LABEL}==\"mvusb\", ACTION==\"add\", RUN+=\"/ruta/completa/a/montamvusb.sh\"\n</code></pre> <p>Aseg\u00farate de reemplazar <code>/ruta/completa/a/montamvusb.sh</code> con la ruta real del script.</p>"},{"location":"99.-Anexos/10.-Portabilizar%20M%C3%A1quinas%20Virtuales%20con%20KVM%20usando%20un%20Disco%20USB/#paso-72-recargar-las-reglas-de-udev","title":"Paso 7.2: Recargar las Reglas de udev","text":"<pre><code>sudo udevadm control --reload-rules\n</code></pre>"},{"location":"99.-Anexos/10.-Portabilizar%20M%C3%A1quinas%20Virtuales%20con%20KVM%20usando%20un%20Disco%20USB/#paso-73-probar-la-automatizacion","title":"Paso 7.3: Probar la Automatizaci\u00f3n","text":"<p>Desconecta y vuelve a conectar el disco USB para verificar que el script se ejecuta autom\u00e1ticamente y el disco se monta en <code>/mnt/mvusb</code>.</p>"},{"location":"99.-Anexos/10.-Portabilizar%20M%C3%A1quinas%20Virtuales%20con%20KVM%20usando%20un%20Disco%20USB/#8-consideraciones-adicionales","title":"8. Consideraciones Adicionales","text":""},{"location":"99.-Anexos/10.-Portabilizar%20M%C3%A1quinas%20Virtuales%20con%20KVM%20usando%20un%20Disco%20USB/#selinuxapparmor","title":"SELinux/AppArmor","text":"<p>Si utilizas SELinux o AppArmor, puede ser necesario ajustar las pol\u00edticas de seguridad para permitir que <code>libvirt</code> acceda a las im\u00e1genes en el nuevo punto de montaje.</p> <p>Para SELinux:</p> <pre><code>sudo chcon -R -t svirt_image_t /mnt/mvusb/images\n</code></pre>"},{"location":"99.-Anexos/10.-Portabilizar%20M%C3%A1quinas%20Virtuales%20con%20KVM%20usando%20un%20Disco%20USB/#permisos-de-acceso","title":"Permisos de Acceso","text":"<p>Aseg\u00farate de que el usuario tenga los permisos adecuados para acceder al punto de montaje y a los archivos dentro de <code>images</code>.</p>"},{"location":"99.-Anexos/10.-Portabilizar%20M%C3%A1quinas%20Virtuales%20con%20KVM%20usando%20un%20Disco%20USB/#conclusion","title":"Conclusi\u00f3n","text":"<p>Siguiendo estos pasos, has configurado un entorno port\u00e1til para tus m\u00e1quinas virtuales utilizando un disco USB etiquetado como <code>mvusb</code>. Al automatizar el proceso de detecci\u00f3n y montaje, puedes utilizar tus m\u00e1quinas virtuales en diferentes equipos sin necesidad de configuraciones manuales adicionales.</p>"},{"location":"99.-Anexos/10.-Portabilizar%20M%C3%A1quinas%20Virtuales%20con%20KVM%20usando%20un%20Disco%20USB/#referencias","title":"Referencias","text":"<ul> <li>Comandos Utilizados:</li> <li><code>lsblk</code>: Listar dispositivos de bloque.</li> <li><code>ntfslabel</code>: Etiquetar particiones NTFS.</li> <li><code>mount</code>: Montar sistemas de archivos.</li> <li><code>virsh define</code>: Registrar m\u00e1quinas virtuales en <code>libvirt</code>.</li> <li> <p><code>udev</code>: Gestionar dispositivos y automatizar acciones al conectar hardware.</p> </li> <li> <p>Archivos Importantes:</p> </li> <li><code>/etc/libvirt/qemu/*.xml</code>: Archivos de configuraci\u00f3n de las m\u00e1quinas virtuales.</li> <li><code>/mnt/mvusb</code>: Punto de montaje del disco USB.</li> <li><code>montamvusb.sh</code>: Script para detecci\u00f3n y montaje autom\u00e1tico.</li> </ul>"},{"location":"99.-Anexos/10.-Portabilizar%20M%C3%A1quinas%20Virtuales%20con%20KVM%20usando%20un%20Disco%20USB/#notas-finales","title":"Notas Finales","text":"<ul> <li>Consistencia en las Rutas: Aseg\u00farate de que el punto de montaje (<code>/mnt/mvusb</code>) sea el mismo en todos los sistemas donde utilizar\u00e1s el disco USB.</li> <li>Copia de Seguridad: Es recomendable mantener copias de seguridad de tus m\u00e1quinas virtuales y archivos de configuraci\u00f3n.</li> <li>Actualizaciones Futuras: Si agregas nuevas m\u00e1quinas virtuales o modificas las existentes, recuerda actualizar los archivos de configuraci\u00f3n y, si es necesario, los scripts correspondientes.</li> </ul>"},{"location":"99.-Anexos/11.-El%20puente%20virbr0/","title":"11.-El puente virbr0","text":""},{"location":"99.-Anexos/11.-El%20puente%20virbr0/#por-que-no-usar-virbr0","title":"\u00bfPor qu\u00e9 no usar <code>virbr0</code>?","text":"<p><code>virbr0</code> es un puente con NAT, creado autom\u00e1ticamente por libvirt para proporcionar una red interna aislada a las VMs. No permite que las VMs sean accesibles desde la red externa a menos que configures reenv\u00edo de puertos o cambies su configuraci\u00f3n. <code>br0</code> normalmente ser\u00eda un puente conectado a una interfaz f\u00edsica (como <code>eth0</code> o <code>enp0s25</code>), proporcionando a las VMs acceso directo a la red local del host o incluso a Internet sin usar NAT.</p>"},{"location":"99.-Anexos/11.-El%20puente%20virbr0/#creacion-de-un-bridge-publico-br0","title":"Creaci\u00f3n de un Bridge P\u00fablico <code>br0</code>","text":"<p>Si tu sistema necesita un puente <code>br0</code> conectado a la interfaz de red f\u00edsica (como <code>enp0s25</code>), puedes crearlo con estos pasos:</p>"},{"location":"99.-Anexos/11.-El%20puente%20virbr0/#crear-el-puente-publico-br0","title":"Crear el Puente P\u00fablico <code>br0</code>:","text":"<pre><code>sudo nmcli connection add type bridge ifname br0 con-name br0\n</code></pre>"},{"location":"99.-Anexos/11.-El%20puente%20virbr0/#asignar-la-interfaz-fisica-por-ejemplo-enp0s25-al-bridge","title":"Asignar la Interfaz F\u00edsica (por ejemplo, <code>enp0s25</code>) al Bridge:","text":"<pre><code>sudo nmcli connection add type bridge-slave ifname enp0s25 master br0\n</code></pre> <p>Configurar el Puente para Conectarse Autom\u00e1ticamente:</p> <pre><code>sudo nmcli connection modify br0 connection.autoconnect yes\n</code></pre>"},{"location":"99.-Anexos/11.-El%20puente%20virbr0/#activar-la-conexion","title":"Activar la Conexi\u00f3n:","text":"<pre><code>sudo nmcli connection up br0\n</code></pre> <p>Despu\u00e9s de esto, el puente <code>br0</code> estar\u00e1 disponible, y puedes usarlo en el comando <code>virt-install</code> .</p>"},{"location":"99.-Anexos/11.-El%20puente%20virbr0/#alternativa-con-virbr0","title":"Alternativa con <code>virbr0</code>","text":"<p>Si no necesitas que la VM est\u00e9 directamente en la red p\u00fablica o accesible desde fuera del host, puedes usar <code>virbr0</code> como alternativa a <code>br0</code> en el comando virt-install. Sin embargo, esto significa que la VM no ser\u00e1 directamente accesible en la red p\u00fablica.</p>"},{"location":"99.-Anexos/11.-El%20puente%20virbr0/#y-si-se-ha-borrado-accidentalmente","title":"\u00bfY si se ha borrado accidentalmente?","text":"<p>Puedes recrear la red <code>virbr0</code> en <code>libvirt</code> si se ha borrado accidentalmente. <code>virbr0</code> es la red predeterminada que se configura autom\u00e1ticamente durante la instalaci\u00f3n de <code>libvirt</code> para proporcionar NAT a las m\u00e1quinas virtuales. Estos son los pasos para restaurarla:</p>"},{"location":"99.-Anexos/11.-El%20puente%20virbr0/#paso-1-verificar-que-la-red-default-no-exista","title":"Paso 1: Verificar que la red default no exista","text":"<p>Primero, aseg\u00farate de que la red default (asociada a virbr0) ya no est\u00e9 definida:</p> <pre><code>virsh net-list --all\n</code></pre> <p>Si default aparece en la lista, puedes detener y eliminar la configuraci\u00f3n actual antes de recrearla:</p> <pre><code>sudo virsh net-destroy default  # Desactiva la red si est\u00e1 activa\nsudo virsh net-undefine default  # Borra la definici\u00f3n de la red si est\u00e1 presente\n</code></pre>"},{"location":"99.-Anexos/11.-El%20puente%20virbr0/#paso-2-crear-de-nuevo-la-red-default-con-nat","title":"Paso 2: Crear de nuevo la red default con NAT","text":"<p>Crear un archivo XML temporal para definir la red default. Puedes guardarlo como default.xml:</p> <pre><code>&lt;network&gt;\n  &lt;name&gt;default&lt;/name&gt;\n  &lt;uuid&gt;6fbd3e27-3657-4bfa-bf3c-f14b0d0b2001&lt;/uuid&gt;\n  &lt;forward mode=\"nat\"/&gt;\n  &lt;bridge name=\"virbr0\" stp=\"on\" delay=\"0\"/&gt;\n  &lt;ip address=\"192.168.122.1\" netmask=\"255.255.255.0\"&gt;\n    &lt;dhcp&gt;\n      &lt;range start=\"192.168.122.2\" end=\"192.168.122.254\"/&gt;\n    &lt;/dhcp&gt;\n  &lt;/ip&gt;\n&lt;/network&gt;\n</code></pre> <p>Este archivo XML configura una red NAT con el rango IP 192.168.122.0/24, que es la configuraci\u00f3n predeterminada de virbr0.</p> <p>Definir e iniciar la red usando el archivo XML:</p> <pre><code>    sudo virsh net-define default.xml\n    sudo virsh net-start default\n    sudo virsh net-autostart default\n</code></pre>"},{"location":"99.-Anexos/11.-El%20puente%20virbr0/#paso-3-verificar-la-creacion-de-virbr0","title":"Paso 3: Verificar la Creaci\u00f3n de virbr0","text":"<p>Despu\u00e9s de estos pasos, virbr0 deber\u00eda estar recreado y activo. Puedes verificarlo con:</p> <pre><code>ip a show virbr0\n</code></pre> <p>o revisando la lista de redes de <code>libvirt</code>:</p> <pre><code>virsh net-list --all\n</code></pre> <p>La red default con virbr0 ahora deber\u00eda estar lista para que las m\u00e1quinas virtuales puedan usarla nuevamente con NAT.</p>"},{"location":"99.-Anexos/11.-El%20puente%20virbr0/#como-hacer-publica-la-red","title":"\u00bfC\u00f3mo hacer p\u00fablica la red?","text":"<p>Para que, por ejemplo <code>br0</code>, act\u00fae como una red p\u00fablica y permita que las m\u00e1quinas virtuales se conecten directamente a la red externa, necesitas conectar <code>br0</code> a una interfaz de red f\u00edsica del host. Esto permite que las VMs tengan acceso a la misma red que el host, con direcciones IP v\u00e1lidas en esa red.</p> <p>Aqu\u00ed tienes una gu\u00eda paso a paso para configurar <code>br0</code> como un puente p\u00fablico en Linux, usando NetworkManager (que gestiona las conexiones con <code>nmcli</code>).</p>"},{"location":"99.-Anexos/11.-El%20puente%20virbr0/#pasos-para-configurar-br0-como-una-red-publica","title":"Pasos para Configurar <code>br0</code> como una Red P\u00fablica","text":""},{"location":"99.-Anexos/11.-El%20puente%20virbr0/#identifica-tu-interfaz-de-red-fisica","title":"Identifica tu Interfaz de Red F\u00edsica","text":"<p>Primero, identifica el nombre de la interfaz de red f\u00edsica que conecta tu host a la red p\u00fablica (por ejemplo, eth0 o enp0s25). Puedes verificarlo con el comando:</p> <pre><code>ip a\n</code></pre>"},{"location":"99.-Anexos/11.-El%20puente%20virbr0/#crea-el-bridge-br0","title":"Crea el Bridge br0","text":"<p>Utiliza nmcli para crear el bridge <code>br0</code>si a\u00fan no lo has hecho:</p> <pre><code>sudo nmcli connection add type bridge ifname br0 con-name br0\n</code></pre>"},{"location":"99.-Anexos/11.-El%20puente%20virbr0/#asigna-la-interfaz-fisica-al-bridge-br0","title":"Asigna la Interfaz F\u00edsica al Bridge <code>br0</code>","text":"<p>Asocia la interfaz de red f\u00edsica al bridge que acabas de crear (reemplaza enp0s25 con el nombre de tu interfaz f\u00edsica):</p> <pre><code>sudo nmcli connection add type bridge-slave ifname enp0s25 master br0\n</code></pre>"},{"location":"99.-Anexos/11.-El%20puente%20virbr0/#configura-la-direccion-ip-en-br0","title":"Configura la Direcci\u00f3n IP en br0","text":"<p>Configura <code>br0</code> con una direcci\u00f3n IP (o configuraci\u00f3n DHCP) para que el host siga teniendo acceso a la red. Esto depende de si tu red utiliza direcciones IP din\u00e1micas (DHCP) o una IP est\u00e1tica.</p> <p>Para DHCP:</p> <pre><code>sudo nmcli connection modify br0 ipv4.method auto\n</code></pre> <p>Para una IP Est\u00e1tica (sustituye con tus valores):</p> <pre><code>sudo nmcli connection modify br0 ipv4.method manual ipv4.addresses \"192.168.1.10/24\" ipv4.gateway \"192.168.1.1\" ipv4.dns \"8.8.8.8\"\n</code></pre>"},{"location":"99.-Anexos/11.-El%20puente%20virbr0/#habilita-la-conexion-automatica","title":"Habilita la Conexi\u00f3n Autom\u00e1tica","text":"<p>Configura br0 para que se conecte autom\u00e1ticamente al inicio:</p> <pre><code>sudo nmcli connection modify br0 connection.autoconnect yes\n</code></pre>"},{"location":"99.-Anexos/11.-El%20puente%20virbr0/#activa-la-conexion","title":"Activa la Conexi\u00f3n","text":"<p>Activa br0 para aplicar los cambios:</p> <pre><code>sudo nmcli connection up br0\n</code></pre>"},{"location":"99.-Anexos/11.-El%20puente%20virbr0/#configura-las-maquinas-virtuales-para-usar-br0","title":"Configura las M\u00e1quinas Virtuales para Usar <code>br0</code>","text":"<p>Ahora, configura las m\u00e1quinas virtuales para conectarse a <code>br0</code> en lugar de <code>virbr0</code> o cualquier otra red interna. Puedes especificar <code>br0</code> como puente en <code>virt-install</code> o modificar el archivo XML de la m\u00e1quina virtual:</p> <pre><code>    &lt;interface type=\"bridge\"&gt;\n        &lt;mac address=\"XX:XX:XX:XX:XX:XX\"/&gt;\n        &lt;source bridge=\"br0\"/&gt;\n        &lt;model type=\"virtio\"/&gt;\n    &lt;/interface&gt;\n</code></pre>"},{"location":"99.-Anexos/11.-El%20puente%20virbr0/#verificacion-de-conexion","title":"Verificaci\u00f3n de Conexi\u00f3n","text":"<p>Comprueba que el bridge est\u00e9 funcionando y que las VMs puedan acceder a la red externa. Puedes hacerlo desde una VM mediante ping a una direcci\u00f3n externa o verificando su IP con ip a.</p>"},{"location":"99.-Anexos/11.-El%20puente%20virbr0/#notas-importantes","title":"Notas Importantes","text":"<p>Permisos y Seguridad: Las VMs en br0 estar\u00e1n directamente expuestas a la red p\u00fablica, por lo que es importante asegurar que cada VM est\u00e9 configurada adecuadamente con un firewall o pol\u00edticas de seguridad. IP de las VMs: Para que cada VM tenga una IP p\u00fablica o en la misma subred del host, el servidor DHCP de la red deber\u00eda asignar una IP a las interfaces de red de las VMs.</p>"}]}